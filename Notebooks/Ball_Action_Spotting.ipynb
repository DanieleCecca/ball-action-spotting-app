{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanieleCecca/ball-action-spotting-app/blob/main/Notebooks/Ball_Action_Spotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HPAigi5O1qu"
      },
      "source": [
        "# Ball Action Spotting\n",
        "\n",
        "*Daniele Cecca*\n",
        "\n",
        "*Matr. 914358*\n",
        "\n",
        "*MSc Artificial Intelligence for Science and Technology*\n",
        "\n",
        "*Email: d.cecca@campus.unimib.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK1Nze5WPSSu"
      },
      "source": [
        "This project focuses on the development and implementation of **classification system for ball events in a football match**, also called ball action spotting.\n",
        "It utilizes the **SoccerNet dataset** and draws inspiration from previously proposed solutions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbK1BGyh3Jmz"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I install the library and I define the imports"
      ],
      "metadata": {
        "id": "J9g0Q_WbMCQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHMa5VFTRBHm",
        "outputId": "79d0c415-0691-439a-d341-75400192c7a2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SoccerNet\n",
            "  Downloading SoccerNet-0.1.60-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from SoccerNet) (4.66.4)\n",
            "Collecting scikit-video (from SoccerNet)\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from SoccerNet) (3.7.1)\n",
            "Collecting google-measurement-protocol (from SoccerNet)\n",
            "  Downloading google_measurement_protocol-1.1.0-py2.py3-none-any.whl.metadata (845 bytes)\n",
            "Collecting pycocoevalcap (from SoccerNet)\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: requests<3.0a0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from google-measurement-protocol->SoccerNet) (2.31.0)\n",
            "Collecting prices>=1.0.0 (from google-measurement-protocol->SoccerNet)\n",
            "  Downloading prices-1.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (2.8.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pycocoevalcap->SoccerNet) (2.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video->SoccerNet) (1.11.4)\n",
            "Requirement already satisfied: babel>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from prices>=1.0.0->google-measurement-protocol->SoccerNet) (2.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->SoccerNet) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2024.7.4)\n",
            "Downloading SoccerNet-0.1.60-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_measurement_protocol-1.1.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prices-1.1.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: prices, scikit-video, google-measurement-protocol, pycocoevalcap, SoccerNet\n",
            "Successfully installed SoccerNet-0.1.60 google-measurement-protocol-1.1.0 prices-1.1.1 pycocoevalcap-1.2 scikit-video-1.1.11\n",
            "Collecting skimpy\n",
            "  Downloading skimpy-0.0.15-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: Pygments<3.0.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from skimpy) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.6 in /usr/local/lib/python3.10/dist-packages (from skimpy) (8.1.7)\n",
            "Collecting ipykernel<7.0.0,>=6.7.0 (from skimpy)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from skimpy) (1.25.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from skimpy) (2.0.3)\n",
            "Requirement already satisfied: polars<0.21,>=0.19 in /usr/local/lib/python3.10/dist-packages (from skimpy) (0.20.2)\n",
            "Requirement already satisfied: pyarrow<17,>=13 in /usr/local/lib/python3.10/dist-packages (from skimpy) (14.0.2)\n",
            "Requirement already satisfied: rich<14.0,>=10.9 in /usr/local/lib/python3.10/dist-packages (from skimpy) (13.7.1)\n",
            "Collecting typeguard==4.2.1 (from skimpy)\n",
            "  Downloading typeguard-4.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from typeguard==4.2.1->skimpy) (4.12.2)\n",
            "Collecting comm>=0.1.1 (from ipykernel<7.0.0,>=6.7.0->skimpy)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.7.0->skimpy) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.0.3->skimpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.0.3->skimpy) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.0.3->skimpy) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=10.9->skimpy) (3.0.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (3.0.47)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel<7.0.0,>=6.7.0->skimpy) (4.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=10.9->skimpy) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.3->skimpy) (1.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel<7.0.0,>=6.7.0->skimpy) (0.2.13)\n",
            "Downloading skimpy-0.0.15-py3-none-any.whl (16 kB)\n",
            "Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typeguard, jedi, comm, ipykernel, skimpy\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comm-0.2.2 ipykernel-6.29.5 jedi-0.19.1 skimpy-0.0.15 typeguard-4.2.1\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.8\n"
          ]
        }
      ],
      "source": [
        "!pip install SoccerNet\n",
        "!pip install skimpy\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3FcGB5tZOWWz"
      },
      "outputs": [],
      "source": [
        "from SoccerNet.Downloader import SoccerNetDownloader\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimpy import skim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "import os\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.ops import sigmoid_focal_loss\n",
        "import json\n",
        "\n",
        "import wandb\n",
        "import seaborn as sns\n",
        "\n",
        "# Metrics for evaluating the performance of machine learning models\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I set the device where the training will be performed"
      ],
      "metadata": {
        "id": "z41HEv8RM5xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU (Graphics Processing Unit) is available for training\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "# Define the device to use for training based on GPU availability\n",
        "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
        "\n",
        "# Print the chosen device for training\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB8xSgLWM46L",
        "outputId": "fc104f12-1819-46fb-d695-c936a36afb84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngAhn0hxZsBZ"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define some function useful to manage the data and some function useful to load some metrics on wandb dashboard"
      ],
      "metadata": {
        "id": "IaKi7CBXMRll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vxA-N2dvZw7l"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r5HSBk_cjcP-"
      },
      "outputs": [],
      "source": [
        "def delete_folder(folder_path):\n",
        "    if os.path.exists(folder_path):\n",
        "        try:\n",
        "            shutil.rmtree(folder_path)\n",
        "            print(f\"Folder '{folder_path}' has been deleted successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "    else:\n",
        "        print(f\"Folder '{folder_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "75WQEGORrU-x"
      },
      "outputs": [],
      "source": [
        "def remove_720p_videos(folder_data):\n",
        "  leagues_files=os.listdir(folder_data)\n",
        "  for league  in leagues_files:\n",
        "      league_path=os.path.join(folder_data,league)\n",
        "      years=os.listdir(league_path)\n",
        "      for year in years:\n",
        "        year_path=os.path.join(league_path,year)\n",
        "        games=os.listdir(year_path)\n",
        "        for game in games:\n",
        "          files=os.listdir(os.path.join(year_path,game))\n",
        "          for  video in files:\n",
        "            if '720p.mp4' in video:\n",
        "              os.remove(os.path.join(year_path,game,'720p.mp4'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_annotations(json_path):\n",
        "    with open(json_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data['annotations']"
      ],
      "metadata": {
        "id": "TQ8U-DkUSh6G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_game_time_to_seconds(game_time):\n",
        "    period, time_str = game_time.split('-')\n",
        "    period=period.strip()\n",
        "    time_str=time_str.strip()\n",
        "    minutes, seconds = map(int, time_str.split(':'))\n",
        "    return (period,minutes * 60 + seconds)"
      ],
      "metadata": {
        "id": "cJSC-FsgSm6t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bbJFb1790lSD"
      },
      "outputs": [],
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "\n",
        "    # add metrics to wandb\n",
        "    wandb.log({\"epoch\": epoch, \"train/loss\": loss}, step=example_ct)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rFTOhYxQ0rxP"
      },
      "outputs": [],
      "source": [
        "def test_log(loss, accuracy, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "    accuracy = float(accuracy)\n",
        "\n",
        "    # add metrics to wandb\n",
        "    wandb.log({\"epoch\": epoch, \"validation/loss\": loss, \"validation/accuracy\": accuracy}, step=example_ct)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaNnhWZePVdw"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUU-AyiMaCFh"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umlQoQrtPaYp"
      },
      "source": [
        "The dataset is composed of **7 videos** of English Football League games, and to each video a **JSON** with the timestamp and the label is associated.\n",
        "\n",
        "In total we have have **12 different type of action**, some of them really similar one to each other:\n",
        "1. **Pass**\n",
        "2. **Drive**\n",
        "3. **Header**\n",
        "4. **High Pass**\n",
        "5. **Out**\n",
        "6. **Cross**\n",
        "7. **Throw In**\n",
        "8. **Shot**\n",
        "9. **Ball Player Block**\n",
        "10. **Player Successful Tackle**\n",
        "11. **Free Kick**\n",
        "12. **Goal**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create a folder where the data will be moved and I download the zip files where the data for this task are stored."
      ],
      "metadata": {
        "id": "sdLLBVgpNPeM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IlD4Uu01UIE8"
      },
      "outputs": [],
      "source": [
        "DATA_PATH=os.path.join(os.getcwd(), \"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HCV0YfVGZ3dh"
      },
      "outputs": [],
      "source": [
        "create_dir(DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdj7Vj0cQ-xX",
        "outputId": "23b711ea-64d9-463c-afb6-370c435c3778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading /content/data/spotting-ball-2024/train.zip...: : 8.45GiB [11:57, 11.8MiB/s]                         \n",
            "Downloading /content/data/spotting-ball-2024/valid.zip...: : 2.04GiB [03:00, 11.3MiB/s]                         \n",
            "Downloading /content/data/spotting-ball-2024/test.zip...: : 4.53GiB [11:13, 6.73MiB/s]                         \n",
            "Downloading /content/data/spotting-ball-2024/challenge.zip...: : 4.23GiB [06:19, 11.1MiB/s]                         \n"
          ]
        }
      ],
      "source": [
        "mySoccerNetDownloader = SoccerNetDownloader(LocalDirectory=DATA_PATH)\n",
        "mySoccerNetDownloader.downloadDataTask(task=\"spotting-ball-2024\", split=[\"train\", \"valid\", \"test\", \"challenge\"], password=\"s0cc3rn3t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QeLZqGSFf9zr"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/data/spotting-ball-2024/train.zip -d train_set\n",
        "!unzip -q /content/data/spotting-ball-2024/test.zip -d test_set\n",
        "!unzip -q /content/data/spotting-ball-2024/valid.zip -d val_set\n",
        "!unzip -q /content/data/spotting-ball-2024/challenge.zip -d challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHVjxWrys2LG"
      },
      "outputs": [],
      "source": [
        "shutil.move(\"/content/train_set\", \"/content/data\")\n",
        "shutil.move(\"/content/test_set\", \"/content/data\")\n",
        "shutil.move(\"/content/val_set\", \"/content/data\")\n",
        "shutil.move(\"/content/challenge\", \"/content/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B1RG0q8eppXP"
      },
      "outputs": [],
      "source": [
        "train_set_path=os.path.join(DATA_PATH,\"train_set\")\n",
        "test_set_path=os.path.join(DATA_PATH,\"test_set\")\n",
        "val_set_path=os.path.join(DATA_PATH,\"val_set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upRFQoSCnZbR",
        "outputId": "6a942bbc-73b6-4e1a-8535-676ba3370ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/SoccerNetv2-DevKit' does not exist.\n",
            "Folder '/content/data/spotting-ball-2024' has been deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "delete_folder('/content/SoccerNetv2-DevKit')\n",
        "delete_folder('/content/data/spotting-ball-2024')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvlP8JRZqRXi"
      },
      "source": [
        "For computational limit I use only the video at 224p and I remove the video-match at 720p.\n",
        "Both videos represent the same match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LtmMHeGrqqdQ"
      },
      "outputs": [],
      "source": [
        "remove_720p_videos(train_set_path)\n",
        "remove_720p_videos(test_set_path)\n",
        "remove_720p_videos(val_set_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3jJ1uvMaGYd"
      },
      "source": [
        "### Create Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am creating a dataframe where each sample represents a video segment containing an action and its corresponding label.\n",
        "\n",
        "To start, I need to split the video matches.\n",
        "Since defining precise temporal boundaries for actions is challenging because it's hard to pinpoint the exact start and end times, and knowing what occurs after the action can be beneficial, I extend the interval by one second beyond the defined action times in the JSON file."
      ],
      "metadata": {
        "id": "f8nN-XP5Q-4N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG3kaD420UHe"
      },
      "source": [
        "I define a fuction to split the video-match into small videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H1ZVIW5hz9KC"
      },
      "outputs": [],
      "source": [
        "def split_video_based_on_annotations(video_path, annotations, output_folder):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Open video file\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    #name id video\n",
        "    video_name=video_path.split('/')[-2] + '_' + video_path.split('/')[-1].split('.')[0]\n",
        "    print(video_name)\n",
        "\n",
        "    # Convert annotations to timestamps in seconds\n",
        "    timestamps = [convert_game_time_to_seconds(a['gameTime']) for a in annotations]\n",
        "\n",
        "    data=[]\n",
        "    # Process video in segments(i take also the second after the annotation is indicated)\n",
        "    for i in range(len(timestamps) - 1):\n",
        "        start_time = timestamps[i][1]\n",
        "        end_time = timestamps[i + 1][1] + 1\n",
        "\n",
        "        clip_duration = end_time - start_time\n",
        "\n",
        "        # Define codec and create VideoWriter object\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        clip_filename = os.path.join(output_folder, f\"{video_name}_clip_{i+1:04d}.mp4\")\n",
        "        out = cv2.VideoWriter(clip_filename, fourcc, fps, (width, height))\n",
        "\n",
        "        # Check if the VideoWriter object was successfully created\n",
        "        if not out.isOpened():\n",
        "            print(f\"Errore nella creazione del file video: {clip_filename}\")\n",
        "            continue\n",
        "        #TO DO Create directly here the dataframe\n",
        "        data.append({\n",
        "            'clip_filename': clip_filename,\n",
        "            'label': annotations[i]['label'],\n",
        "            'clip_duration': clip_duration\n",
        "        })\n",
        "\n",
        "        # Set the video position to the start_time\n",
        "        video.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
        "        current_time = start_time\n",
        "\n",
        "        while current_time < end_time:\n",
        "            success, frame = video.read()\n",
        "            if not success:\n",
        "                break\n",
        "            out.write(frame)\n",
        "            current_time += 1 / fps\n",
        "\n",
        "        out.release()\n",
        "\n",
        "    video.release()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the function to create the dataframe for each dataset.This fuction calls the function\n",
        "\n",
        "```\n",
        "split_video_based_on_annotations(video_path, annotations, output_folder)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DpL-fPwLTfVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UKdyKUhfUETe"
      },
      "outputs": [],
      "source": [
        "def create_dataframe(folder_data,output_folder):\n",
        "\n",
        "  df=pd.DataFrame(columns=['clip_filename','label','clip_duration'])\n",
        "  leagues_files=os.listdir(folder_data)\n",
        "  for league  in leagues_files:\n",
        "    league_path=os.path.join(folder_data,league)\n",
        "    years=os.listdir(league_path)\n",
        "    for year in years:\n",
        "      year_path=os.path.join(league_path,year)\n",
        "      games=os.listdir(year_path)\n",
        "      for game in games:\n",
        "        files=os.listdir(os.path.join(year_path,game))\n",
        "        videos=[video for  video in files if video.endswith('.mp4')]\n",
        "        jsons=[json for  json in files if json.endswith('.json')][0]\n",
        "\n",
        "        for video in videos:\n",
        "          video_path=os.path.join(year_path,game,video)\n",
        "          jsons_path=os.path.join(year_path,game,jsons)\n",
        "          sample=split_video_based_on_annotations(video_path,load_json_annotations(jsons_path),output_folder)\n",
        "          df = pd.concat([df, pd.DataFrame(sample)], ignore_index=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the path where the small videos will be saved.Their names have the following pattern:\n",
        "\n",
        "*2019-10-01 - Middlesbrough - Preston North End_224p_clip_0001.mp4*\n",
        "\n",
        "*date - team1 - team 224p_clip#*"
      ],
      "metadata": {
        "id": "iqPNIZ3dT5Md"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2a1tdu_KZLtl"
      },
      "outputs": [],
      "source": [
        "new_trainig_data=os.path.join(DATA_PATH,\"new_trainig_data\")\n",
        "new_test_data=os.path.join(DATA_PATH,\"new_test_data\")\n",
        "new_val_data=os.path.join(DATA_PATH,\"new_val_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIVwcOSKp-m8",
        "outputId": "ab112dcd-a961-400e-eff4-3793c508359a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2019-10-01 - Brentford - Bristol City_224p\n",
            "2019-10-01 - Hull City - Sheffield Wednesday_224p\n",
            "2019-10-01 - Leeds United - West Bromwich_224p\n",
            "2019-10-01 - Blackburn Rovers - Nottingham Forest_224p\n"
          ]
        }
      ],
      "source": [
        "trainig_df=create_dataframe(train_set_path,new_trainig_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xnql1R1p_Qs",
        "outputId": "ad0e5403-4d4a-4a32-e9fa-0ffc5fd0150a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2019-10-01 - Reading - Fulham_224p\n",
            "2019-10-01 - Stoke City - Huddersfield Town_224p\n"
          ]
        }
      ],
      "source": [
        "test_df=create_dataframe(test_set_path,new_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaMVewx0p_rl",
        "outputId": "3aa37a1d-a288-4e19-c7e8-794715b3e5f4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2019-10-01 - Middlesbrough - Preston North End_224p\n"
          ]
        }
      ],
      "source": [
        "val_df=create_dataframe(val_set_path,new_val_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainig_df.to_csv('trainig_df.csv', index=False)\n",
        "test_df.to_csv('test_df.csv', index=False)\n",
        "val_df.to_csv('val_df.csv', index=False)"
      ],
      "metadata": {
        "id": "XSjYcz9RDn_p"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFC_MLVowOHv"
      },
      "source": [
        "### Exploration of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I have the dataframes of each data set, I observe some basic statistics and the frquency of each label, for each data set."
      ],
      "metadata": {
        "id": "AY_PKh6WU60x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "10ySdGjqwRaJ"
      },
      "outputs": [],
      "source": [
        "trainig_df=pd.DataFrame.from_dict(trainig_df)\n",
        "test_df=pd.DataFrame.from_dict(test_df)\n",
        "val_df=pd.DataFrame.from_dict(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KfZnjHOywiMo",
        "outputId": "7a2bc5ef-12cb-418c-d618-9cb6e49e0f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       clip_filename      label clip_duration\n",
              "0  /content/data/new_trainig_data/2019-10-01 - Br...       PASS             3\n",
              "1  /content/data/new_trainig_data/2019-10-01 - Br...      DRIVE             2\n",
              "2  /content/data/new_trainig_data/2019-10-01 - Br...  HIGH PASS             4\n",
              "3  /content/data/new_trainig_data/2019-10-01 - Br...     HEADER             2\n",
              "4  /content/data/new_trainig_data/2019-10-01 - Br...      DRIVE             5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51e45188-ec25-4ba2-8c61-f4b9f7dab7d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clip_filename</th>\n",
              "      <th>label</th>\n",
              "      <th>clip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/new_trainig_data/2019-10-01 - Br...</td>\n",
              "      <td>PASS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/new_trainig_data/2019-10-01 - Br...</td>\n",
              "      <td>DRIVE</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/data/new_trainig_data/2019-10-01 - Br...</td>\n",
              "      <td>HIGH PASS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/data/new_trainig_data/2019-10-01 - Br...</td>\n",
              "      <td>HEADER</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/data/new_trainig_data/2019-10-01 - Br...</td>\n",
              "      <td>DRIVE</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51e45188-ec25-4ba2-8c61-f4b9f7dab7d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51e45188-ec25-4ba2-8c61-f4b9f7dab7d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51e45188-ec25-4ba2-8c61-f4b9f7dab7d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-245db1cf-f737-47c9-8374-a9b4f139a98b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-245db1cf-f737-47c9-8374-a9b4f139a98b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-245db1cf-f737-47c9-8374-a9b4f139a98b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "trainig_df",
              "summary": "{\n  \"name\": \"trainig_df\",\n  \"rows\": 6845,\n  \"fields\": [\n    {\n      \"column\": \"clip_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6845,\n        \"samples\": [\n          \"/content/data/new_trainig_data/2019-10-01 - Leeds United - West Bromwich_224p_clip_0900.mp4\",\n          \"/content/data/new_trainig_data/2019-10-01 - Blackburn Rovers - Nottingham Forest_224p_clip_0373.mp4\",\n          \"/content/data/new_trainig_data/2019-10-01 - Leeds United - West Bromwich_224p_clip_0915.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GOAL\",\n          \"PLAYER SUCCESSFUL TACKLE\",\n          \"PASS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clip_duration\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 149,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          1,\n          36,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trainig_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LaK442F37okX",
        "outputId": "39bf3ac2-8d69-4a28-efa3-8623ccb64572"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       clip_filename  label clip_duration\n",
              "0  /content/data/new_test_data/2019-10-01 - Readi...   PASS             2\n",
              "1  /content/data/new_test_data/2019-10-01 - Readi...  DRIVE             2\n",
              "2  /content/data/new_test_data/2019-10-01 - Readi...   PASS             2\n",
              "3  /content/data/new_test_data/2019-10-01 - Readi...  DRIVE             2\n",
              "4  /content/data/new_test_data/2019-10-01 - Readi...   PASS             2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-054b3494-d704-45fa-9151-b20acf553fb7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clip_filename</th>\n",
              "      <th>label</th>\n",
              "      <th>clip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/new_test_data/2019-10-01 - Readi...</td>\n",
              "      <td>PASS</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/new_test_data/2019-10-01 - Readi...</td>\n",
              "      <td>DRIVE</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/data/new_test_data/2019-10-01 - Readi...</td>\n",
              "      <td>PASS</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/data/new_test_data/2019-10-01 - Readi...</td>\n",
              "      <td>DRIVE</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/data/new_test_data/2019-10-01 - Readi...</td>\n",
              "      <td>PASS</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-054b3494-d704-45fa-9151-b20acf553fb7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-054b3494-d704-45fa-9151-b20acf553fb7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-054b3494-d704-45fa-9151-b20acf553fb7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40c354be-e339-4969-8bad-1d82111d1a63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40c354be-e339-4969-8bad-1d82111d1a63')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40c354be-e339-4969-8bad-1d82111d1a63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 3978,\n  \"fields\": [\n    {\n      \"column\": \"clip_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3978,\n        \"samples\": [\n          \"/content/data/new_test_data/2019-10-01 - Reading - Fulham_224p_clip_0409.mp4\",\n          \"/content/data/new_test_data/2019-10-01 - Stoke City - Huddersfield Town_224p_clip_0173.mp4\",\n          \"/content/data/new_test_data/2019-10-01 - Reading - Fulham_224p_clip_0683.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GOAL\",\n          \"CROSS\",\n          \"PASS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clip_duration\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 177,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          177,\n          48,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iMP85dt37pY9",
        "outputId": "cd612f53-080a-4466-c4a4-7ad66ddd6cf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"val_df\",\n  \"rows\": 1603,\n  \"fields\": [\n    {\n      \"column\": \"clip_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1603,\n        \"samples\": [\n          \"/content/data/new_val_data/2019-10-01 - Middlesbrough - Preston North End_224p_clip_0529.mp4\",\n          \"/content/data/new_val_data/2019-10-01 - Middlesbrough - Preston North End_224p_clip_1146.mp4\",\n          \"/content/data/new_val_data/2019-10-01 - Middlesbrough - Preston North End_224p_clip_0169.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GOAL\",\n          \"PLAYER SUCCESSFUL TACKLE\",\n          \"PASS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clip_duration\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 104,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          16,\n          38,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "val_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1c03fbf1-76fa-4360-b76b-088f240a3691\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clip_filename</th>\n",
              "      <th>label</th>\n",
              "      <th>clip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/new_val_data/2019-10-01 - Middle...</td>\n",
              "      <td>PASS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/new_val_data/2019-10-01 - Middle...</td>\n",
              "      <td>DRIVE</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/data/new_val_data/2019-10-01 - Middle...</td>\n",
              "      <td>PASS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/data/new_val_data/2019-10-01 - Middle...</td>\n",
              "      <td>DRIVE</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/data/new_val_data/2019-10-01 - Middle...</td>\n",
              "      <td>HIGH PASS</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c03fbf1-76fa-4360-b76b-088f240a3691')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c03fbf1-76fa-4360-b76b-088f240a3691 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c03fbf1-76fa-4360-b76b-088f240a3691');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa1784fe-9a49-4b8c-ba4f-703e4cb26b41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa1784fe-9a49-4b8c-ba4f-703e4cb26b41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa1784fe-9a49-4b8c-ba4f-703e4cb26b41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                       clip_filename      label clip_duration\n",
              "0  /content/data/new_val_data/2019-10-01 - Middle...       PASS             1\n",
              "1  /content/data/new_val_data/2019-10-01 - Middle...      DRIVE             2\n",
              "2  /content/data/new_val_data/2019-10-01 - Middle...       PASS             3\n",
              "3  /content/data/new_val_data/2019-10-01 - Middle...      DRIVE             4\n",
              "4  /content/data/new_val_data/2019-10-01 - Middle...  HIGH PASS             7"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is really unbalanced"
      ],
      "metadata": {
        "id": "ChshmUfQVUdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "vwiGdSI3xieT",
        "outputId": "9e33adb5-3563-4e19-a5d6-a430c45884ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "PASS                        2678\n",
            "DRIVE                       2296\n",
            "HIGH PASS                    464\n",
            "HEADER                       404\n",
            "OUT                          331\n",
            "THROW IN                     212\n",
            "CROSS                        177\n",
            "BALL PLAYER BLOCK            128\n",
            "SHOT                         100\n",
            "PLAYER SUCCESSFUL TACKLE      34\n",
            "FREE KICK                     15\n",
            "GOAL                           6\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "target_count = trainig_df['label'].value_counts()\n",
        "print(target_count)\n",
        "\n",
        "target_count = trainig_df['label'].value_counts()\n",
        "target_count.plot(kind='bar', title='Count (target)')\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "WnYt_toa8EL2",
        "outputId": "1245ca94-b7b5-4d7b-cb01-0249a73e2d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "PASS                        1721\n",
            "DRIVE                       1448\n",
            "HEADER                       182\n",
            "HIGH PASS                    180\n",
            "OUT                          145\n",
            "THROW IN                      95\n",
            "BALL PLAYER BLOCK             67\n",
            "CROSS                         60\n",
            "SHOT                          44\n",
            "PLAYER SUCCESSFUL TACKLE      28\n",
            "GOAL                           6\n",
            "FREE KICK                      2\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "target_count = test_df['label'].value_counts()\n",
        "print(target_count)\n",
        "\n",
        "target_count = test_df['label'].value_counts()\n",
        "target_count.plot(kind='bar', title='Count (target)')\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "TU1-j0Il8Eue",
        "outputId": "7e9ee702-7f4a-472a-a420-c5740ea374e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "PASS                        585\n",
            "DRIVE                       554\n",
            "HEADER                      127\n",
            "HIGH PASS                   115\n",
            "OUT                          74\n",
            "THROW IN                     54\n",
            "BALL PLAYER BLOCK            28\n",
            "SHOT                         25\n",
            "CROSS                        24\n",
            "PLAYER SUCCESSFUL TACKLE     12\n",
            "FREE KICK                     4\n",
            "GOAL                          1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "target_count = val_df['label'].value_counts()\n",
        "print(target_count)\n",
        "\n",
        "target_count = val_df['label'].value_counts()\n",
        "target_count.plot(kind='bar', title='Count (target)')\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use the label encoding to encode the labels attribute as number"
      ],
      "metadata": {
        "id": "JG_Wigm00TxO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dQDUM6TzxOxg"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(trainig_df['label'])\n",
        "trainig_df['label'] = le.transform(trainig_df['label'])\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(test_df['label'])\n",
        "test_df['label'] = le.transform(test_df['label'])\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(val_df['label'])\n",
        "val_df['label'] = le.transform(val_df['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By observing this data I can deduce that the mean duration of the clips is of 4sec."
      ],
      "metadata": {
        "id": "GR_odONOVdgh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P6YIy46-wmtB",
        "outputId": "264a7c4c-706d-4145-b837-2593773d490c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
              "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m                                                          │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
              "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mdataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃                                                          │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
              "│ │ Number of rows    │ 6845   │ │ int64       │ 2     │                                                          │\n",
              "│ │ Number of columns │ 3      │ │ string      │ 1     │                                                          │\n",
              "│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n",
              "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━┓  │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist   \u001b[0m\u001b[1m \u001b[0m┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━┩  │\n",
              "│ │ \u001b[38;5;141mlabel              \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m   5.408\u001b[0m │ \u001b[36m   3.014\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    2\u001b[0m │ \u001b[36m    6\u001b[0m │ \u001b[36m   8\u001b[0m │ \u001b[36m   11\u001b[0m │ \u001b[32m▁▇▁▂▇▁ \u001b[0m │  │\n",
              "│ │ \u001b[38;5;141mclip_duration      \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m   4.366\u001b[0m │ \u001b[36m   7.357\u001b[0m │ \u001b[36m   1\u001b[0m │ \u001b[36m    2\u001b[0m │ \u001b[36m    3\u001b[0m │ \u001b[36m   4\u001b[0m │ \u001b[36m  149\u001b[0m │ \u001b[32m   ▇   \u001b[0m │  │\n",
              "│ └─────────────────────┴──────┴─────────┴──────────┴──────────┴──────┴───────┴───────┴──────┴───────┴─────────┘  │\n",
              "│ \u001b[3m                                                    string                                                    \u001b[0m  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords per row              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtotal words            \u001b[0m\u001b[1m \u001b[0m┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
              "│ │ \u001b[38;5;141mclip_filename               \u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                        6.7\u001b[0m │ \u001b[36m                  46101\u001b[0m │  │\n",
              "│ └──────────────────────────────┴────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
              "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
              "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span>                                                          │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
              "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                          │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
              "│ │ Number of rows    │ 6845   │ │ int64       │ 2     │                                                          │\n",
              "│ │ Number of columns │ 3      │ │ string      │ 1     │                                                          │\n",
              "│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n",
              "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━┓  │\n",
              "│ ┃<span style=\"font-weight: bold\"> column_name         </span>┃<span style=\"font-weight: bold\"> NA   </span>┃<span style=\"font-weight: bold\"> NA %    </span>┃<span style=\"font-weight: bold\"> mean     </span>┃<span style=\"font-weight: bold\"> sd       </span>┃<span style=\"font-weight: bold\"> p0   </span>┃<span style=\"font-weight: bold\"> p25   </span>┃<span style=\"font-weight: bold\"> p50   </span>┃<span style=\"font-weight: bold\"> p75  </span>┃<span style=\"font-weight: bold\"> p100  </span>┃<span style=\"font-weight: bold\"> hist    </span>┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━┩  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">label              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   5.408</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   3.014</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   11</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▁▇▁▂▇▁ </span> │  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">clip_duration      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   4.366</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   7.357</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  149</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">   ▇   </span> │  │\n",
              "│ └─────────────────────┴──────┴─────────┴──────────┴──────────┴──────┴───────┴───────┴──────┴───────┴─────────┘  │\n",
              "│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
              "│ ┃<span style=\"font-weight: bold\"> column_name                  </span>┃<span style=\"font-weight: bold\"> NA     </span>┃<span style=\"font-weight: bold\"> NA %       </span>┃<span style=\"font-weight: bold\"> words per row               </span>┃<span style=\"font-weight: bold\"> total words             </span>┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">clip_filename               </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                        6.7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  46101</span> │  │\n",
              "│ └──────────────────────────────┴────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
              "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
              "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m                                                          │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
              "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mdataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃                                                          │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
              "│ │ Number of rows    │ 3978   │ │ int64       │ 2     │                                                          │\n",
              "│ │ Number of columns │ 3      │ │ string      │ 1     │                                                          │\n",
              "│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n",
              "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━┓  │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist   \u001b[0m\u001b[1m \u001b[0m┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━┩  │\n",
              "│ │ \u001b[38;5;141mlabel              \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m   5.404\u001b[0m │ \u001b[36m   3.019\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    2\u001b[0m │ \u001b[36m    7\u001b[0m │ \u001b[36m   8\u001b[0m │ \u001b[36m   11\u001b[0m │ \u001b[32m▁▇▁▁▇▁ \u001b[0m │  │\n",
              "│ │ \u001b[38;5;141mclip_duration      \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m       4\u001b[0m │ \u001b[36m    7.68\u001b[0m │ \u001b[36m   1\u001b[0m │ \u001b[36m    2\u001b[0m │ \u001b[36m    3\u001b[0m │ \u001b[36m   3\u001b[0m │ \u001b[36m  177\u001b[0m │ \u001b[32m   ▇   \u001b[0m │  │\n",
              "│ └─────────────────────┴──────┴─────────┴──────────┴──────────┴──────┴───────┴───────┴──────┴───────┴─────────┘  │\n",
              "│ \u001b[3m                                                    string                                                    \u001b[0m  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords per row              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtotal words            \u001b[0m\u001b[1m \u001b[0m┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
              "│ │ \u001b[38;5;141mclip_filename               \u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                        5.9\u001b[0m │ \u001b[36m                  23576\u001b[0m │  │\n",
              "│ └──────────────────────────────┴────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
              "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
              "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span>                                                          │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
              "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                          │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
              "│ │ Number of rows    │ 3978   │ │ int64       │ 2     │                                                          │\n",
              "│ │ Number of columns │ 3      │ │ string      │ 1     │                                                          │\n",
              "│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n",
              "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━┓  │\n",
              "│ ┃<span style=\"font-weight: bold\"> column_name         </span>┃<span style=\"font-weight: bold\"> NA   </span>┃<span style=\"font-weight: bold\"> NA %    </span>┃<span style=\"font-weight: bold\"> mean     </span>┃<span style=\"font-weight: bold\"> sd       </span>┃<span style=\"font-weight: bold\"> p0   </span>┃<span style=\"font-weight: bold\"> p25   </span>┃<span style=\"font-weight: bold\"> p50   </span>┃<span style=\"font-weight: bold\"> p75  </span>┃<span style=\"font-weight: bold\"> p100  </span>┃<span style=\"font-weight: bold\"> hist    </span>┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━┩  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">label              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   5.404</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   3.019</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   11</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▁▇▁▁▇▁ </span> │  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">clip_duration      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">       4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    7.68</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  177</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">   ▇   </span> │  │\n",
              "│ └─────────────────────┴──────┴─────────┴──────────┴──────────┴──────┴───────┴───────┴──────┴───────┴─────────┘  │\n",
              "│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
              "│ ┃<span style=\"font-weight: bold\"> column_name                  </span>┃<span style=\"font-weight: bold\"> NA     </span>┃<span style=\"font-weight: bold\"> NA %       </span>┃<span style=\"font-weight: bold\"> words per row               </span>┃<span style=\"font-weight: bold\"> total words             </span>┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">clip_filename               </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                        5.9</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  23576</span> │  │\n",
              "│ └──────────────────────────────┴────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
              "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
              "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m                                                          │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
              "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mdataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃                                                          │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
              "│ │ Number of rows    │ 1603   │ │ int64       │ 2     │                                                          │\n",
              "│ │ Number of columns │ 3      │ │ string      │ 1     │                                                          │\n",
              "│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n",
              "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━┓  │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist   \u001b[0m\u001b[1m \u001b[0m┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━┩  │\n",
              "│ │ \u001b[38;5;141mlabel              \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m   5.379\u001b[0m │ \u001b[36m   2.987\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    2\u001b[0m │ \u001b[36m    6\u001b[0m │ \u001b[36m   8\u001b[0m │ \u001b[36m   11\u001b[0m │ \u001b[32m▁▇▂▃▇▁ \u001b[0m │  │\n",
              "│ │ \u001b[38;5;141mclip_duration      \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m   4.662\u001b[0m │ \u001b[36m   8.153\u001b[0m │ \u001b[36m   1\u001b[0m │ \u001b[36m    2\u001b[0m │ \u001b[36m    3\u001b[0m │ \u001b[36m   4\u001b[0m │ \u001b[36m  104\u001b[0m │ \u001b[32m   ▇   \u001b[0m │  │\n",
              "│ └─────────────────────┴──────┴─────────┴──────────┴──────────┴──────┴───────┴───────┴──────┴───────┴─────────┘  │\n",
              "│ \u001b[3m                                                    string                                                    \u001b[0m  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
              "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords per row              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtotal words            \u001b[0m\u001b[1m \u001b[0m┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
              "│ │ \u001b[38;5;141mclip_filename               \u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                          7\u001b[0m │ \u001b[36m                  11221\u001b[0m │  │\n",
              "│ └──────────────────────────────┴────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
              "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
              "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span>                                                          │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
              "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                          │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
              "│ │ Number of rows    │ 1603   │ │ int64       │ 2     │                                                          │\n",
              "│ │ Number of columns │ 3      │ │ string      │ 1     │                                                          │\n",
              "│ └───────────────────┴────────┘ └─────────────┴───────┘                                                          │\n",
              "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━┓  │\n",
              "│ ┃<span style=\"font-weight: bold\"> column_name         </span>┃<span style=\"font-weight: bold\"> NA   </span>┃<span style=\"font-weight: bold\"> NA %    </span>┃<span style=\"font-weight: bold\"> mean     </span>┃<span style=\"font-weight: bold\"> sd       </span>┃<span style=\"font-weight: bold\"> p0   </span>┃<span style=\"font-weight: bold\"> p25   </span>┃<span style=\"font-weight: bold\"> p50   </span>┃<span style=\"font-weight: bold\"> p75  </span>┃<span style=\"font-weight: bold\"> p100  </span>┃<span style=\"font-weight: bold\"> hist    </span>┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━┩  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">label              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   5.379</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   2.987</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   11</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▁▇▂▃▇▁ </span> │  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">clip_duration      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   4.662</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   8.153</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  104</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">   ▇   </span> │  │\n",
              "│ └─────────────────────┴──────┴─────────┴──────────┴──────────┴──────┴───────┴───────┴──────┴───────┴─────────┘  │\n",
              "│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n",
              "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
              "│ ┃<span style=\"font-weight: bold\"> column_name                  </span>┃<span style=\"font-weight: bold\"> NA     </span>┃<span style=\"font-weight: bold\"> NA %       </span>┃<span style=\"font-weight: bold\"> words per row               </span>┃<span style=\"font-weight: bold\"> total words             </span>┃  │\n",
              "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
              "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">clip_filename               </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                          7</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  11221</span> │  │\n",
              "│ └──────────────────────────────┴────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
              "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "skim(trainig_df)\n",
        "skim(test_df)\n",
        "skim(val_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibzh-Xyc_mTQ"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lI_gg5vCsmA"
      },
      "source": [
        "### Class Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the **ActionRecognitionDataset class**. This class is developed to manage the loading and video data in action recognition tasks.The key functionalities include loading video frames, stacking consecutive frames, and applying optional transformations.\n",
        "\n",
        "The main idea is to take for each clip 15 frames, one every 12 frames(because the mean lenght is 4),and then divide this frames in stack of 3 frames.\n",
        "So in the end we will have a vector of [1,5, 3, 224, 398] where [B,T ,C ,H ,W].\n",
        "\n",
        "Thi will be useful to stack temporal information that will be processe by the network"
      ],
      "metadata": {
        "id": "kGTYQGp7WcRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DEYLY1lv-pol"
      },
      "outputs": [],
      "source": [
        "class ActionRecognitionDataset(Dataset):\n",
        "    def __init__(self, dataframe, num_frames=15, frames_per_stack=3, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            video_paths (list of str): List of paths to video files or directories of frames.\n",
        "            labels (list of int): List of labels corresponding to each video.\n",
        "            num_frames (int): Total number of frames to consider from each video.\n",
        "            frames_per_stack (int): Number of consecutive frames to stack as channels.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.video_paths = dataframe['clip_filename']\n",
        "        self.labels = dataframe['label']\n",
        "\n",
        "        self.num_frames = num_frames\n",
        "        self.frames_per_stack = frames_per_stack\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_paths.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "\n",
        "\n",
        "        # Load frames\n",
        "        frames = self.load_frames(video_path)\n",
        "\n",
        "        # Stack frames\n",
        "        stacked_frames = self.stack_frames(frames)\n",
        "        #stacked_frames = stacked_frames.unsqueeze(0)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = torch.tensor(label).long()\n",
        "        return stacked_frames, label\n",
        "\n",
        "    def load_frames(self, video_path):\n",
        "        \"\"\"\n",
        "        Load and return the required number of grayscale frames from a video file.\n",
        "        \"\"\"\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        success, frame = cap.read()\n",
        "        count = 0\n",
        "        frame_taken=0\n",
        "\n",
        "        #TO DO One thing that i can do is to duplicate the video with less number and take 15 frame casualy\n",
        "        #Because the mean of the videos is 3. something I take the frame every 12frame 180/15=12\n",
        "        while success and frame_taken < self.num_frames:\n",
        "            if count % 12 == 0:\n",
        "              gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "\n",
        "              # Apply transformations\n",
        "              if self.transform:\n",
        "                  gray_frame = self.transform(gray_frame) # Pass individual frame to transform\n",
        "\n",
        "              gray_frame = torch.tensor(gray_frame).float() / 255.0 # Convert individual frame to tensor\n",
        "\n",
        "              frames.append(gray_frame)\n",
        "              success, frame = cap.read()\n",
        "              frame_taken += 1\n",
        "            count += 1\n",
        "        cap.release()\n",
        "\n",
        "        # Ensure we have exactly num_frames\n",
        "        if len(frames) < self.num_frames:\n",
        "            frames += [frames[-1]] * (self.num_frames - len(frames))  # Pad with the last frame\n",
        "\n",
        "        return frames\n",
        "\n",
        "    def stack_frames(self, frames):\n",
        "        \"\"\"\n",
        "        Stack frames in sets of 'frames_per_stack' along the channel dimension.\n",
        "        \"\"\"\n",
        "        stacked_frames = []\n",
        "        for i in range(0, len(frames) - self.frames_per_stack + 1, self.frames_per_stack):\n",
        "            stack = frames[i:i + self.frames_per_stack]\n",
        "            # Stack tensors along a new dimension (assuming they have the same shape)\n",
        "            stacked_frames.append(torch.stack(stack, dim=0))\n",
        "        return torch.stack(stacked_frames, dim=0) # Stack the resulting stacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA_4HwQotcrb",
        "outputId": "0ed7a393-9ff0-4baf-a87b-1c8d892256a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample shape: torch.Size([1, 5, 3, 224, 398])\n",
            "Label: tensor(2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#Example\n",
        "dataset = ActionRecognitionDataset(test_df)\n",
        "sample, label = dataset[1]\n",
        "sample=sample.unsqueeze(0)\n",
        "print(\"Sample shape:\", sample.shape)  # Expected: (B,T, C, H, W)\n",
        "print(\"Label:\", label)\n",
        "type(label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNWI3GV7CxxW"
      },
      "source": [
        "### Class Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define our custom network, **SlowFusionNetVLAD**, designed for video action recognition. This architecture integrates both 2D and 3D convolutional layers with advanced pooling techniques to effectively capture spatiotemporal features from video data. The model utilizes a pre-trained EfficientNetV2 as its 2D encoder and employs a NetVLAD pooling layer for aggregating temporal features.\n",
        "\n",
        "1. **EfficientNetV2-based 2D Encoder**: The network begins with EfficientNetV2, which serves as a robust 2D feature extractor. This pre-trained model is used to extract high-level features from stacked frames.We can say that is more **2.5D encoder**, because in this case the channels represent temporal information(frames at difrent time). The output from EfficientNetV2 is then reduced to a smaller dimension using a 1x1 convolutional layer, making the feature maps compatible for the subsequent 3D processing.\n",
        "\n",
        "2. **3D Convolutional Layers**: After extracting features with the 2D encoder, the network employs a series of 3D convolutional layers. These layers are designed to capture spatiotemporal patterns by analyzing the sequence of frames together. The network includes multiple **residual blocks**, which help in mitigating the vanishing gradient problem and enable the training of deeper networks. Each residual block consists of:\n",
        "\n",
        "  - Two convolutional layers\n",
        "  - Batch normalization to stabilize training\n",
        "  - A shortcut connection that adds the input of the block to its output, improving gradient flow.\n",
        "\n",
        "3. **NetVLAD Pooling Layer**: Following the 3D convolutional layers, the network uses the NetVLAD pooling layer to aggregate the temporal features. NetVLAD is a powerful pooling technique that clusters features into a fixed-size representation, capturing the essential information from variable-length sequences. This layer is crucial for transforming the spatiotemporal feature maps into a compact, discriminative feature vector.\n",
        "\n",
        "4. **Classifier**: The final stage of the network involves a fully connected layer that performs classification based on the aggregated features. A dropout layer is applied before the classifier to prevent overfitting."
      ],
      "metadata": {
        "id": "I-oB8viRYhj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RfOw6zp4hhFr"
      },
      "outputs": [],
      "source": [
        "class NetVLAD(nn.Module):\n",
        "    \"\"\"NetVLAD layer implementation https://github.com/lyakaap/NetVLAD-pytorch\"\"\"\n",
        "\n",
        "    def __init__(self, num_clusters=64, dim=128, alpha=100.0,\n",
        "                 normalize_input=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_clusters : int\n",
        "                The number of clusters\n",
        "            dim : int\n",
        "                Dimension of descriptors\n",
        "            alpha : float\n",
        "                Parameter of initialization. Larger value is harder assignment.\n",
        "            normalize_input : bool\n",
        "                If true, descriptor-wise L2 normalization is applied to input.\n",
        "        \"\"\"\n",
        "        super(NetVLAD, self).__init__()\n",
        "        self.num_clusters = num_clusters\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.normalize_input = normalize_input\n",
        "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
        "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        self.conv.weight = nn.Parameter(\n",
        "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
        "        )\n",
        "        self.conv.bias = nn.Parameter(\n",
        "            - self.alpha * self.centroids.norm(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        N, C = x.shape[:2]\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n",
        "\n",
        "        # soft-assignment\n",
        "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
        "        soft_assign = F.softmax(soft_assign, dim=1)\n",
        "\n",
        "        #TO DO I can change the shape directly here\n",
        "        x_flatten = x.view(N, C, -1)\n",
        "        #print(x_flatten.shape)\n",
        "\n",
        "        # calculate residuals to each clusters\n",
        "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
        "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
        "        residual *= soft_assign.unsqueeze(2)\n",
        "        vlad = residual.sum(dim=-1)\n",
        "\n",
        "        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n",
        "        vlad = vlad.view(x.size(0), -1)  # flatten\n",
        "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n",
        "\n",
        "        return vlad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm3d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ClLAiqWe-GQP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5F1gO7_uKym4"
      },
      "outputs": [],
      "source": [
        "class SlowFusionNetVLAD(nn.Module):\n",
        "    def __init__(self, num_classes=12, vocab_size=256,dropout=0.4):\n",
        "        super(SlowFusionNetVLAD, self).__init__()\n",
        "\n",
        "        # EfficientNetV2 as a 2D Encoder\n",
        "        efficient_net = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        self.encoder_2d = nn.Sequential(\n",
        "            efficient_net.features,\n",
        "            nn.Conv2d(1280, 192, kernel_size=1)  # Reduce the dimension to 192\n",
        "        )\n",
        "\n",
        "        # 3D Encoder\n",
        "        self.encoder_3d = nn.Sequential(\n",
        "            ResidualBlock(192, 256),\n",
        "            ResidualBlock(256, 256),\n",
        "            ResidualBlock(256, 256),\n",
        "        )\n",
        "\n",
        "        # NetVLAD Pooling Layer\n",
        "        #TO DO cercare un modo per prendere in automatico dim==(T*C)\n",
        "        self.pool_layer = NetVLAD(num_clusters=vocab_size, dim=1280,alpha=1.0)\n",
        "        #self.pool_layer_after = NetVLAD(cluster_size=vocab_size//2, feature_size=256, add_batch_norm=True)\n",
        "\n",
        "        # Classifier\n",
        "        #TO DO cercare un modo per prendere in automatico in_features\n",
        "        self.fc = nn.Linear(in_features=327680, out_features=num_classes)\n",
        "        self.drop = nn.Dropout(p=dropout)\n",
        "        #self.sigmoid = nn.Sigmoid()#If I use the sigmoid I assign to each label a p independently(2 event at the same time)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C, H, W = x.shape  # x is expected to have shape (B, T, C, H, W)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Shared weights among the stacks\n",
        "        x = x.view(B * T, C, H, W)\n",
        "        x = self.encoder_2d(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Reshape to (B, T, C, H, W)\n",
        "        _, C, H, W = x.shape\n",
        "        x = x.view(B, T, C, H, W)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Permute to (B, C, T, H, W) for 3D convolution\n",
        "        x = x.permute(0, 2, 1, 3, 4)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Pass through the 3D encoder\n",
        "        x = self.encoder_3d(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Reshape for NetVLAD  # x [BS, T, D]\n",
        "\n",
        "        #Concat temporal feature\n",
        "        B, T, C, H, W = x.shape\n",
        "        x=x.view(B,T*C,H,W)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x=self.pool_layer(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        # Classifier\n",
        "        x=self.drop(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qoVeOMdpoA1",
        "collapsed": true,
        "outputId": "b3fd7acd-0c95-48c7-c9a8-780f1a0b813c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 170MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2dNormActivation(\n",
              "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "    )\n",
              "    (1): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (2): Sequential(\n",
              "    (0): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
              "    )\n",
              "    (1): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
              "    )\n",
              "    (2): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
              "    )\n",
              "    (3): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (3): Sequential(\n",
              "    (0): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
              "    )\n",
              "    (1): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
              "    )\n",
              "    (2): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
              "    )\n",
              "    (3): FusedMBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (4): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
              "    )\n",
              "    (3): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
              "    )\n",
              "    (4): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
              "    )\n",
              "    (5): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "          (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
              "    )\n",
              "    (3): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
              "    )\n",
              "    (4): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "    )\n",
              "    (5): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
              "    )\n",
              "    (6): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
              "    )\n",
              "    (7): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
              "    )\n",
              "    (8): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
              "    )\n",
              "    (3): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
              "    )\n",
              "    (4): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
              "    )\n",
              "    (5): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
              "    )\n",
              "    (6): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
              "    )\n",
              "    (7): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
              "    )\n",
              "    (8): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
              "    )\n",
              "    (9): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
              "    )\n",
              "    (10): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
              "    )\n",
              "    (11): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
              "    )\n",
              "    (12): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
              "    )\n",
              "    (13): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
              "    )\n",
              "    (14): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "          (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (7): Conv2dNormActivation(\n",
              "    (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "efficient_net = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "efficient_net.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nLWzTV4hyRb",
        "outputId": "8560d649-324e-4aaf-d9f2-ad797f93ee55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 327680])\n"
          ]
        }
      ],
      "source": [
        "vlad=NetVLAD(num_clusters=256, dim=1280, alpha=1.0, normalize_input=True)\n",
        "input_tensor = torch.randn(1, 1280, 7, 13)\n",
        "output = vlad(input_tensor)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZOfd44yCy14",
        "outputId": "390b1e3b-6353-4423-d45f-5aa4d97aec0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 12])\n"
          ]
        }
      ],
      "source": [
        "model = SlowFusionNetVLAD(num_classes=12, vocab_size=256)\n",
        "input_tensor = torch.randn(1,5, 3, 224, 398)  # (batch_size, time_steps, channels, height, width)\n",
        "output = model(input_tensor)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-XkEIGkEKR_",
        "collapsed": true,
        "outputId": "b03ac073-a4e6-4583-82ee-cc1db43c94df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SlowFusionNetVLAD(\n",
            "  (encoder_2d): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2dNormActivation(\n",
            "        (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "        )\n",
            "        (1): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
            "        )\n",
            "        (1): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
            "        )\n",
            "        (2): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
            "        )\n",
            "        (3): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
            "        )\n",
            "        (1): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
            "        )\n",
            "        (2): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
            "        )\n",
            "        (3): FusedMBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
            "        )\n",
            "        (3): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
            "        )\n",
            "        (4): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
            "        )\n",
            "        (5): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
            "              (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
            "        )\n",
            "        (3): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
            "        )\n",
            "        (4): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
            "        )\n",
            "        (5): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
            "        )\n",
            "        (6): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
            "        )\n",
            "        (7): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
            "        )\n",
            "        (8): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
            "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
            "        )\n",
            "        (3): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
            "        )\n",
            "        (4): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
            "        )\n",
            "        (5): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
            "        )\n",
            "        (6): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
            "        )\n",
            "        (7): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
            "        )\n",
            "        (8): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
            "        )\n",
            "        (9): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
            "        )\n",
            "        (10): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
            "        )\n",
            "        (11): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
            "        )\n",
            "        (12): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
            "        )\n",
            "        (13): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
            "        )\n",
            "        (14): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (7): Conv2dNormActivation(\n",
            "        (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (encoder_3d): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv3d(192, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (pool_layer): NetVLAD(\n",
            "    (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (fc): Linear(in_features=327680, out_features=12, bias=True)\n",
            "  (drop): Dropout(p=0.4, inplace=False)\n",
            ")\n",
            "Number of parameters in the model: 35238428\n"
          ]
        }
      ],
      "source": [
        "model= SlowFusionNetVLAD()\n",
        "# Count the number of parameters in the model\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters in the model: {num_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P22tofN7Czqu"
      },
      "source": [
        "### System Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFBCOy8esiKy"
      },
      "source": [
        "#### Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knV-m3YetKLv"
      },
      "source": [
        "In this section, we define the hyperparameters for the network. Specifically, we create a configuration that will be used by the **Weights and Biases agent** to set the different hyperparameters during various experiments. This allows us to systematically explore the effect of different hyperparameter settings on the model's performance.\n",
        "\n",
        "Hyperparameters:\n",
        "- **epochs** : The number of times the entire training dataset is passed through the network.\n",
        "- **learning rate** : The step size at each iteration while moving towards a minimum of the loss function.\n",
        "- **drop out** : The fraction of input units to drop during training. Dropout is a regularization technique that helps prevent overfitting by randomly setting a fraction of input units to zero at each update during training.\n",
        "- **batch size** : The number of training examples utilized in one iteration\n",
        "- **loss fuction** : The function that measures how well the model's predictions match the target values\n",
        "\n",
        "Other hyperparameters like the optimizer or the scheduler of the learning rate will be specified directly in the training function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the dataset is umbalanced I use the **Focal Loss**.\n",
        "\n",
        "**Focal Loss** is a loss function designed to address the challenge of class imbalance in tasks such as object detection.\n",
        "\n",
        "Focal Loss is a modified version of the standard Cross-Entropy Loss that down-weights the contribution of easy-to-classify examples and focuses more on hard-to-classify examples. It is defined as:\n",
        "\n",
        "$\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t) \\$\n",
        "\n",
        "where:\n",
        "- $p_t$ is the model's estimated probability for the true class.\n",
        "\n",
        "- $\\alpha_t \\$is a weighting factor for the class, balancing the importance of positive/negative examples.\n",
        "\n",
        "- $\\gamma \\$ is a focusing parameter that adjusts the rate at which easy examples are down-weighted.\n",
        "\n"
      ],
      "metadata": {
        "id": "edx4wBVtbcqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25, reduction=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Compute cross-entropy loss\n",
        "        ce_loss = F.cross_entropy(inputs, targets)#reducitonm none because we have already mean here\n",
        "\n",
        "        # Get the probability corresponding to the correct class\n",
        "        pt = torch.exp(-ce_loss)\n",
        "\n",
        "\n",
        "        # Compute the focal loss\n",
        "        focal_loss = self.alpha *(1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "\n",
        "        # Check reduction option and return loss accordingly\n",
        "        if self.reduction == \"mean\":\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == \"sum\":\n",
        "            return focal_loss.sum()\n",
        "        elif self.reduction is None or self.reduction == 'none':\n",
        "            return focal_loss\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Invalid Value for arg 'reduction': '{self.reduction}'. Supported reduction modes: 'none', 'mean', 'sum'.\"\n",
        "            )\n"
      ],
      "metadata": {
        "id": "P7EkriRfl5Id"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "R0BjGf9rs3Dx"
      },
      "outputs": [],
      "source": [
        "epochs=5\n",
        "loss_funct=FocalLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y27iRgMWtR1f"
      },
      "source": [
        "Also I specify the method that the wandb angent sweep will use to select the combination of hyperparameters; in this case they will be selected randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_ZnpZFd5tT_b"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-wIFfUrttUVp"
      },
      "outputs": [],
      "source": [
        "parameters_dict = {\n",
        "    'dropout': {\n",
        "          'values': [0.4, 0.5]\n",
        "        },\n",
        "    'batch_size':{\n",
        "        'values':[1,3,5]\n",
        "    },\n",
        "    'epochs': {\n",
        "        'value': epochs\n",
        "        },\n",
        "    'lr': {\n",
        "        'values': [0.01, 0.001, 0.0001]\n",
        "        }\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIYi2DHvtWkE",
        "outputId": "287599ec-e7a8-4aad-b3e2-245a6b731d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'random',\n",
            " 'parameters': {'batch_size': {'values': [1, 3, 5]},\n",
            "                'dropout': {'values': [0.4, 0.5]},\n",
            "                'epochs': {'value': 5},\n",
            "                'lr': {'values': [0.01, 0.001, 0.0001]}}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMPwUDx3uDIp"
      },
      "source": [
        "#### Dataset-DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuTEktYDuQoc"
      },
      "source": [
        "I create the **training**, **test**, and v**alidation datasets** and **dataloaders** by instantiating the class created previously and initializing the dataloaders.\n",
        "\n",
        "Also I instantiate a Transform object that will apply a set of transformation on the training data with a given probability, to try to increase the search space and avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "G52sJfy-_YbN"
      },
      "outputs": [],
      "source": [
        "transforms = v2.Compose([\n",
        "    v2.RandomVerticalFlip(p=0.7),\n",
        "    v2.RandomHorizontalFlip(p=0.7),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "QmA3a_G8v7hD"
      },
      "outputs": [],
      "source": [
        "train_dataset = ActionRecognitionDataset(trainig_df, num_frames=15, frames_per_stack=3, transform=transforms)\n",
        "val_dataset = ActionRecognitionDataset(val_df, num_frames=15, frames_per_stack=3, transform=None)\n",
        "test_dataset = ActionRecognitionDataset(test_df, num_frames=15, frames_per_stack=3, transform=None)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUJCRvpgs5I1"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create the function to validate the model on validation set."
      ],
      "metadata": {
        "id": "yUxT394Ue5Md"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "s804x801fh_d"
      },
      "outputs": [],
      "source": [
        "def validate_model(model, val_dataloader, loss_funct):\n",
        "    model.eval()\n",
        "    val_loss=0\n",
        "    with torch.no_grad():\n",
        "        correct=0\n",
        "        for i, (x, y) in enumerate(val_dataloader):\n",
        "            x=x.to(device)#image\n",
        "            y=y.to(device)#label\n",
        "\n",
        "            #Forward pass\n",
        "            out=model(x)\n",
        "            loss=loss_funct(out,y)\n",
        "            val_loss+=loss.item()\n",
        "\n",
        "            # Compute accuracy and accumulate\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "        accuracy=correct / len(val_dataloader.dataset)\n",
        "        val_loss=val_loss / len(val_dataloader.dataset)\n",
        "\n",
        "    return val_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GsO5SAUs7Ry"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create the function for the training of the model during the phase hyperparameters tuning."
      ],
      "metadata": {
        "id": "UxgqeFY-e8B8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "UB-THnID_l3s"
      },
      "outputs": [],
      "source": [
        "def train_agent(config=None, val_dataloader=val_loader, train_dataset=train_dataset):\n",
        "    with wandb.init(project=\"AdvancedTechniques\", job_type=\"traninig\", config=config) as run:\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        #Setting the network\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "        model = SlowFusionNetVLAD(dropout=config.dropout).to(device)\n",
        "        optimizer =  torch.optim.Adam(params=model.parameters(),lr=config.lr)\n",
        "\n",
        "        #Start the training\n",
        "        best_val_loss=10000\n",
        "        example_ct = 0\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train()\n",
        "            for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "\n",
        "                x= x.to(device)\n",
        "                y=y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward pass\n",
        "                out = model(x)\n",
        "                train_loss = loss_funct(out, y)\n",
        "\n",
        "                # backward pass\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                example_ct += len(x)\n",
        "\n",
        "\n",
        "                print('Train Epoch: {} [{}/{} ({:.0%})]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(x), len(train_dataloader.dataset),\n",
        "                    batch_idx / len(train_dataloader), train_loss.item()))\n",
        "\n",
        "                train_log(train_loss, example_ct, epoch)\n",
        "\n",
        "            #Loss on training\n",
        "            print('Epoch')\n",
        "            print(f'train/train_loss: {train_loss}\\n')\n",
        "\n",
        "            val_loss, accuracy = validate_model(model, val_dataloader, loss_funct)\n",
        "\n",
        "            # add validation loss and metrics to wandb\n",
        "            test_log(val_loss, accuracy, example_ct, epoch)\n",
        "            print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "            #save best model\n",
        "            curr_val_loss=val_loss\n",
        "            if curr_val_loss < best_val_loss:\n",
        "                best_val_loss=curr_val_loss\n",
        "\n",
        "                model_artifact = wandb.Artifact(\n",
        "                        \"trained-model\", type=\"model\",\n",
        "                        description=\"Trained NN model\")\n",
        "\n",
        "                torch.save(model.state_dict(), \"trained_model.pth\")\n",
        "                model_artifact.add_file(\"trained_model.pth\")\n",
        "                wandb.save(\"trained_model.pth\")\n",
        "\n",
        "                run.log_artifact(model_artifact)\n",
        "            torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create the function to train the best model"
      ],
      "metadata": {
        "id": "jjYlzsrOe_9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "wHwTHcgl1SWO"
      },
      "outputs": [],
      "source": [
        "def train_bestModel(model,train_dataloader, val_dataloader, freeze_module=None, epochs=10):\n",
        "    with wandb.init(project=\"AdvancedTechniques\", job_type=\"training\") as run:\n",
        "        model.to(device)\n",
        "\n",
        "        model.train()\n",
        "        # Freeze specified module if provided\n",
        "        if freeze_module:\n",
        "            for param in freeze_module.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(\"Frozen module:\", freeze_module)\n",
        "\n",
        "        # Create an optimizer only for parameters that require gradients\n",
        "        optimizer = torch.optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=0.0001\n",
        "        )\n",
        "\n",
        "        example_ct = 0\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "\n",
        "                x= x.to(device)\n",
        "                y=y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward pass\n",
        "                out = model(x)\n",
        "                train_loss = loss_funct(out, y)\n",
        "\n",
        "                # backward pass\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                example_ct += len(x)\n",
        "\n",
        "\n",
        "                print('Train Epoch: {} [{}/{} ({:.0%})]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(x), len(train_dataloader.dataset),\n",
        "                    batch_idx / len(train_dataloader), train_loss.item()))\n",
        "\n",
        "                train_log(train_loss, example_ct, epoch)\n",
        "\n",
        "\n",
        "            #Loss on training\n",
        "            print('Epoch')\n",
        "            print(f'train/train_loss: {train_loss}\\n')\n",
        "\n",
        "            val_loss, accuracy = validate_model(model, val_dataloader, loss_funct)\n",
        "            # add validation loss and metrics to wandb\n",
        "            test_log(val_loss, accuracy, example_ct, epoch)\n",
        "            print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "        model_artifact = wandb.Artifact(\n",
        "        \"trained-model\", type=\"model\",\n",
        "        description=\"Complete Trained NN model\")\n",
        "\n",
        "        torch.save(model.state_dict(), \"trained_model.pth\")\n",
        "        model_artifact.add_file(\"trained_model.pth\")\n",
        "        wandb.save(\"trained_model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuFS9GJKs9Ea"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the function for the test and evaluation of the model on test data."
      ],
      "metadata": {
        "id": "Ph-cer9LfCxK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2iqmbjdtfnlm"
      },
      "outputs": [],
      "source": [
        "def test(model, test_dataloader, loss_funct, batch_idx=0):\n",
        "  with wandb.init(project=\"AdvancedTechniques\", job_type=\"test\") as run:\n",
        "      model.eval()\n",
        "      test_loss=0\n",
        "      accuracy=0\n",
        "      correct=0\n",
        "      example_ct=0\n",
        "      predicted_list=[]\n",
        "      with torch.no_grad():\n",
        "          for i, (x, y) in enumerate(test_dataloader):\n",
        "              x=x.to(device)#image\n",
        "              y=y.to(device)#label\n",
        "\n",
        "              #Forward pass\n",
        "              out=model(x)\n",
        "              loss=loss_funct(out,y)\n",
        "              test_loss+=loss.item()\n",
        "\n",
        "              # Compute accuracy and accumulate\n",
        "              _, predicted = torch.max(out.data, 1)\n",
        "              correct += (predicted == y).sum().item()\n",
        "              predicted_list.append(predicted)\n",
        "\n",
        "\n",
        "          accuracy=correct / len(test_dataloader.dataset)\n",
        "          test_loss=test_loss / len(test_dataloader.dataset)\n",
        "\n",
        "          test_log(test_loss, accuracy, example_ct, epoch=0)\n",
        "\n",
        "      return test_loss, accuracy,predicted_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRsKXyXQ1pux"
      },
      "source": [
        "## Run training with agent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run different experiments, with different hypeparameter I use an **agent (sweep),** that selects randomly the parameters. I initialize sweep with the configuration created previously."
      ],
      "metadata": {
        "id": "a8EN_LHWfH2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNPUA7v01tBr",
        "outputId": "2eb96eed-7de8-4077-8c18-55e3bfc4ab79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "wandb.login(key='3cf965029e23342db8eec1393abbf2f0ed412f02')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tN6NOSh1uh-",
        "outputId": "d915074e-02ae-4427-bc03-ee58b6bd0bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: fa5dcf96\n",
            "Sweep URL: https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"AdvancedTechniques\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "54f2ee6195c74b9fafdb67e845983b40",
            "5eda307355254b798a68be363df35827",
            "a3f7a0cc432b46228c65b9a0c793cc20",
            "7f15538309364ed89e932679dfd17d4f",
            "4c5d93f6f42548338d1acf1d579a8633",
            "a4bc278b57ee4bfdb43dca4e6536126e",
            "05395abfd33e44a4877d2572237f3f86",
            "995b17a93aa042a9848ef375d1118147",
            "7c75fc2d1f064f2b86a071b6d4228231",
            "c325a789424f4662987614a8cac594e0",
            "30b4df2b9cc848c0b9745aeedcadcf01",
            "b2af51ee4a9a4f13a861912f7e17a8cb",
            "669061f8a5434978bf361c37ba582170",
            "94ac1cd48bc34af2ae20d53e52b5e166",
            "9dd90a2f793442dc9062b0466f87150e",
            "12a2c163cc8d449aaa7375cee81c06a4",
            "594cbd9216664d31a708dfeefb371fa5",
            "d7d3b81665c54ab597c14119138cc9c1",
            "934be64636d145d99f318d7aa5a58b3a",
            "29d602b43f494457bc0158603782c5ec",
            "852aa0110c87474ab6be1b4c79b7817a",
            "e74956629dc4431d92e2ff792bb09cf1",
            "a4e630f1f95941e78e7a22ecd112e270",
            "aeba7209f42047fdb06d8c9807ea8144",
            "cc3766f0d55e4cecb2e8100ba40c7014",
            "9978de6d376845c4b22e517fafc301e0",
            "aebcd3adf72e4ace918e81de09654436",
            "ebdb507c60da4c348157e2cdc9c8988f",
            "90b55f3fee524482852cff5652c7248b",
            "8a45c9f067574d5ea09c439d68ce20c7",
            "078c41090e1b4804a9227560b2ffabbf",
            "0c8207f1c91b4b0ab975a6b4d9dcc9d4",
            "50efaff24d9d47479b30bf029c23a951",
            "d5270a6a786b4f90b62da73b035b46eb",
            "af5db11571364e348392a91167fbbb1f",
            "477545b20ce948f5bc5c9699122ece16",
            "0653731a0a934005afb4de6ab95a9a04",
            "7a4b82e138364f998a2b3544d2491c44",
            "e9f33ee5593143bfbeaff582ad7486a8",
            "c09211f1b84f41f1a27bed300c3d1398"
          ]
        },
        "id": "i3VyURtV1v-G",
        "outputId": "a78b4d26-814a-44ab-d41f-cdfb8998cd4a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1pffni86 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md-cecca\u001b[0m (\u001b[33mcecca\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240829_165728-1pffni86</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/1pffni86' target=\"_blank\">fresh-sweep-1</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/1pffni86' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/1pffni86</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train Epoch: 3 [2964/3978 (75%)]\tLoss: 0.883278\n",
            "Train Epoch: 3 [2965/3978 (75%)]\tLoss: 0.609569\n",
            "Train Epoch: 3 [2966/3978 (75%)]\tLoss: 0.076489\n",
            "Train Epoch: 3 [2967/3978 (75%)]\tLoss: 0.082219\n",
            "Train Epoch: 3 [2968/3978 (75%)]\tLoss: 0.085173\n",
            "Train Epoch: 3 [2969/3978 (75%)]\tLoss: 0.099987\n",
            "Train Epoch: 3 [2970/3978 (75%)]\tLoss: 0.093649\n",
            "Train Epoch: 3 [2971/3978 (75%)]\tLoss: 0.094522\n",
            "Train Epoch: 3 [2972/3978 (75%)]\tLoss: 0.159398\n",
            "Train Epoch: 3 [2973/3978 (75%)]\tLoss: 0.095209\n",
            "Train Epoch: 3 [2974/3978 (75%)]\tLoss: 0.105939\n",
            "Train Epoch: 3 [2975/3978 (75%)]\tLoss: 0.465600\n",
            "Train Epoch: 3 [2976/3978 (75%)]\tLoss: 0.079609\n",
            "Train Epoch: 3 [2977/3978 (75%)]\tLoss: 0.109807\n",
            "Train Epoch: 3 [2978/3978 (75%)]\tLoss: 0.699982\n",
            "Train Epoch: 3 [2979/3978 (75%)]\tLoss: 1.076766\n",
            "Train Epoch: 3 [2980/3978 (75%)]\tLoss: 0.138997\n",
            "Train Epoch: 3 [2981/3978 (75%)]\tLoss: 0.087959\n",
            "Train Epoch: 3 [2982/3978 (75%)]\tLoss: 0.105717\n",
            "Train Epoch: 3 [2983/3978 (75%)]\tLoss: 0.487266\n",
            "Train Epoch: 3 [2984/3978 (75%)]\tLoss: 0.107852\n",
            "Train Epoch: 3 [2985/3978 (75%)]\tLoss: 0.072377\n",
            "Train Epoch: 3 [2986/3978 (75%)]\tLoss: 0.111546\n",
            "Train Epoch: 3 [2987/3978 (75%)]\tLoss: 0.132258\n",
            "Train Epoch: 3 [2988/3978 (75%)]\tLoss: 0.946111\n",
            "Train Epoch: 3 [2989/3978 (75%)]\tLoss: 0.671416\n",
            "Train Epoch: 3 [2990/3978 (75%)]\tLoss: 0.105439\n",
            "Train Epoch: 3 [2991/3978 (75%)]\tLoss: 0.147119\n",
            "Train Epoch: 3 [2992/3978 (75%)]\tLoss: 0.118506\n",
            "Train Epoch: 3 [2993/3978 (75%)]\tLoss: 0.109750\n",
            "Train Epoch: 3 [2994/3978 (75%)]\tLoss: 0.094599\n",
            "Train Epoch: 3 [2995/3978 (75%)]\tLoss: 0.103299\n",
            "Train Epoch: 3 [2996/3978 (75%)]\tLoss: 0.117471\n",
            "Train Epoch: 3 [2997/3978 (75%)]\tLoss: 0.104416\n",
            "Train Epoch: 3 [2998/3978 (75%)]\tLoss: 0.542771\n",
            "Train Epoch: 3 [2999/3978 (75%)]\tLoss: 0.484587\n",
            "Train Epoch: 3 [3000/3978 (75%)]\tLoss: 0.555773\n",
            "Train Epoch: 3 [3001/3978 (75%)]\tLoss: 0.078682\n",
            "Train Epoch: 3 [3002/3978 (75%)]\tLoss: 0.159592\n",
            "Train Epoch: 3 [3003/3978 (75%)]\tLoss: 0.095668\n",
            "Train Epoch: 3 [3004/3978 (76%)]\tLoss: 0.104169\n",
            "Train Epoch: 3 [3005/3978 (76%)]\tLoss: 0.080204\n",
            "Train Epoch: 3 [3006/3978 (76%)]\tLoss: 0.501967\n",
            "Train Epoch: 3 [3007/3978 (76%)]\tLoss: 0.150382\n",
            "Train Epoch: 3 [3008/3978 (76%)]\tLoss: 0.097180\n",
            "Train Epoch: 3 [3009/3978 (76%)]\tLoss: 0.128895\n",
            "Train Epoch: 3 [3010/3978 (76%)]\tLoss: 0.089700\n",
            "Train Epoch: 3 [3011/3978 (76%)]\tLoss: 0.082984\n",
            "Train Epoch: 3 [3012/3978 (76%)]\tLoss: 0.818398\n",
            "Train Epoch: 3 [3013/3978 (76%)]\tLoss: 0.108676\n",
            "Train Epoch: 3 [3014/3978 (76%)]\tLoss: 0.081142\n",
            "Train Epoch: 3 [3015/3978 (76%)]\tLoss: 0.113726\n",
            "Train Epoch: 3 [3016/3978 (76%)]\tLoss: 0.133083\n",
            "Train Epoch: 3 [3017/3978 (76%)]\tLoss: 0.087659\n",
            "Train Epoch: 3 [3018/3978 (76%)]\tLoss: 0.106194\n",
            "Train Epoch: 3 [3019/3978 (76%)]\tLoss: 0.084165\n",
            "Train Epoch: 3 [3020/3978 (76%)]\tLoss: 0.098523\n",
            "Train Epoch: 3 [3021/3978 (76%)]\tLoss: 0.107364\n",
            "Train Epoch: 3 [3022/3978 (76%)]\tLoss: 0.112584\n",
            "Train Epoch: 3 [3023/3978 (76%)]\tLoss: 0.105520\n",
            "Train Epoch: 3 [3024/3978 (76%)]\tLoss: 0.091651\n",
            "Train Epoch: 3 [3025/3978 (76%)]\tLoss: 0.125600\n",
            "Train Epoch: 3 [3026/3978 (76%)]\tLoss: 0.086268\n",
            "Train Epoch: 3 [3027/3978 (76%)]\tLoss: 0.099310\n",
            "Train Epoch: 3 [3028/3978 (76%)]\tLoss: 0.078498\n",
            "Train Epoch: 3 [3029/3978 (76%)]\tLoss: 0.121193\n",
            "Train Epoch: 3 [3030/3978 (76%)]\tLoss: 1.016540\n",
            "Train Epoch: 3 [3031/3978 (76%)]\tLoss: 0.149484\n",
            "Train Epoch: 3 [3032/3978 (76%)]\tLoss: 0.125867\n",
            "Train Epoch: 3 [3033/3978 (76%)]\tLoss: 0.066257\n",
            "Train Epoch: 3 [3034/3978 (76%)]\tLoss: 0.100894\n",
            "Train Epoch: 3 [3035/3978 (76%)]\tLoss: 0.065024\n",
            "Train Epoch: 3 [3036/3978 (76%)]\tLoss: 0.152007\n",
            "Train Epoch: 3 [3037/3978 (76%)]\tLoss: 0.781681\n",
            "Train Epoch: 3 [3038/3978 (76%)]\tLoss: 0.615900\n",
            "Train Epoch: 3 [3039/3978 (76%)]\tLoss: 0.061254\n",
            "Train Epoch: 3 [3040/3978 (76%)]\tLoss: 0.060214\n",
            "Train Epoch: 3 [3041/3978 (76%)]\tLoss: 0.075069\n",
            "Train Epoch: 3 [3042/3978 (76%)]\tLoss: 0.060512\n",
            "Train Epoch: 3 [3043/3978 (76%)]\tLoss: 0.102152\n",
            "Train Epoch: 3 [3044/3978 (77%)]\tLoss: 0.131099\n",
            "Train Epoch: 3 [3045/3978 (77%)]\tLoss: 0.064144\n",
            "Train Epoch: 3 [3046/3978 (77%)]\tLoss: 0.083287\n",
            "Train Epoch: 3 [3047/3978 (77%)]\tLoss: 0.625314\n",
            "Train Epoch: 3 [3048/3978 (77%)]\tLoss: 0.090182\n",
            "Train Epoch: 3 [3049/3978 (77%)]\tLoss: 0.119519\n",
            "Train Epoch: 3 [3050/3978 (77%)]\tLoss: 0.057248\n",
            "Train Epoch: 3 [3051/3978 (77%)]\tLoss: 0.124778\n",
            "Train Epoch: 3 [3052/3978 (77%)]\tLoss: 0.090993\n",
            "Train Epoch: 3 [3053/3978 (77%)]\tLoss: 0.161716\n",
            "Train Epoch: 3 [3054/3978 (77%)]\tLoss: 0.110468\n",
            "Train Epoch: 3 [3055/3978 (77%)]\tLoss: 0.087056\n",
            "Train Epoch: 3 [3056/3978 (77%)]\tLoss: 0.106783\n",
            "Train Epoch: 3 [3057/3978 (77%)]\tLoss: 1.161561\n",
            "Train Epoch: 3 [3058/3978 (77%)]\tLoss: 0.902322\n",
            "Train Epoch: 3 [3059/3978 (77%)]\tLoss: 0.120705\n",
            "Train Epoch: 3 [3060/3978 (77%)]\tLoss: 0.099736\n",
            "Train Epoch: 3 [3061/3978 (77%)]\tLoss: 0.059444\n",
            "Train Epoch: 3 [3062/3978 (77%)]\tLoss: 0.118355\n",
            "Train Epoch: 3 [3063/3978 (77%)]\tLoss: 0.107625\n",
            "Train Epoch: 3 [3064/3978 (77%)]\tLoss: 0.070849\n",
            "Train Epoch: 3 [3065/3978 (77%)]\tLoss: 0.995594\n",
            "Train Epoch: 3 [3066/3978 (77%)]\tLoss: 0.093996\n",
            "Train Epoch: 3 [3067/3978 (77%)]\tLoss: 0.083051\n",
            "Train Epoch: 3 [3068/3978 (77%)]\tLoss: 0.098277\n",
            "Train Epoch: 3 [3069/3978 (77%)]\tLoss: 0.092991\n",
            "Train Epoch: 3 [3070/3978 (77%)]\tLoss: 0.696698\n",
            "Train Epoch: 3 [3071/3978 (77%)]\tLoss: 0.566900\n",
            "Train Epoch: 3 [3072/3978 (77%)]\tLoss: 0.067746\n",
            "Train Epoch: 3 [3073/3978 (77%)]\tLoss: 0.666560\n",
            "Train Epoch: 3 [3074/3978 (77%)]\tLoss: 0.130271\n",
            "Train Epoch: 3 [3075/3978 (77%)]\tLoss: 0.089601\n",
            "Train Epoch: 3 [3076/3978 (77%)]\tLoss: 0.091528\n",
            "Train Epoch: 3 [3077/3978 (77%)]\tLoss: 0.113241\n",
            "Train Epoch: 3 [3078/3978 (77%)]\tLoss: 0.548098\n",
            "Train Epoch: 3 [3079/3978 (77%)]\tLoss: 0.070270\n",
            "Train Epoch: 3 [3080/3978 (77%)]\tLoss: 0.116584\n",
            "Train Epoch: 3 [3081/3978 (77%)]\tLoss: 0.093355\n",
            "Train Epoch: 3 [3082/3978 (77%)]\tLoss: 0.070220\n",
            "Train Epoch: 3 [3083/3978 (78%)]\tLoss: 0.099293\n",
            "Train Epoch: 3 [3084/3978 (78%)]\tLoss: 0.078979\n",
            "Train Epoch: 3 [3085/3978 (78%)]\tLoss: 0.092632\n",
            "Train Epoch: 3 [3086/3978 (78%)]\tLoss: 0.100017\n",
            "Train Epoch: 3 [3087/3978 (78%)]\tLoss: 0.917334\n",
            "Train Epoch: 3 [3088/3978 (78%)]\tLoss: 0.711996\n",
            "Train Epoch: 3 [3089/3978 (78%)]\tLoss: 0.093686\n",
            "Train Epoch: 3 [3090/3978 (78%)]\tLoss: 0.089357\n",
            "Train Epoch: 3 [3091/3978 (78%)]\tLoss: 0.087160\n",
            "Train Epoch: 3 [3092/3978 (78%)]\tLoss: 1.040464\n",
            "Train Epoch: 3 [3093/3978 (78%)]\tLoss: 0.077828\n",
            "Train Epoch: 3 [3094/3978 (78%)]\tLoss: 0.094599\n",
            "Train Epoch: 3 [3095/3978 (78%)]\tLoss: 0.076718\n",
            "Train Epoch: 3 [3096/3978 (78%)]\tLoss: 0.880235\n",
            "Train Epoch: 3 [3097/3978 (78%)]\tLoss: 1.625886\n",
            "Train Epoch: 3 [3098/3978 (78%)]\tLoss: 0.120844\n",
            "Train Epoch: 3 [3099/3978 (78%)]\tLoss: 0.072492\n",
            "Train Epoch: 3 [3100/3978 (78%)]\tLoss: 0.627110\n",
            "Train Epoch: 3 [3101/3978 (78%)]\tLoss: 0.109762\n",
            "Train Epoch: 3 [3102/3978 (78%)]\tLoss: 0.614588\n",
            "Train Epoch: 3 [3103/3978 (78%)]\tLoss: 0.134208\n",
            "Train Epoch: 3 [3104/3978 (78%)]\tLoss: 0.098567\n",
            "Train Epoch: 3 [3105/3978 (78%)]\tLoss: 0.094843\n",
            "Train Epoch: 3 [3106/3978 (78%)]\tLoss: 0.123137\n",
            "Train Epoch: 3 [3107/3978 (78%)]\tLoss: 0.072465\n",
            "Train Epoch: 3 [3108/3978 (78%)]\tLoss: 0.149440\n",
            "Train Epoch: 3 [3109/3978 (78%)]\tLoss: 0.121768\n",
            "Train Epoch: 3 [3110/3978 (78%)]\tLoss: 0.098463\n",
            "Train Epoch: 3 [3111/3978 (78%)]\tLoss: 0.075565\n",
            "Train Epoch: 3 [3112/3978 (78%)]\tLoss: 0.076282\n",
            "Train Epoch: 3 [3113/3978 (78%)]\tLoss: 0.101193\n",
            "Train Epoch: 3 [3114/3978 (78%)]\tLoss: 0.093843\n",
            "Train Epoch: 3 [3115/3978 (78%)]\tLoss: 0.102055\n",
            "Train Epoch: 3 [3116/3978 (78%)]\tLoss: 0.096189\n",
            "Train Epoch: 3 [3117/3978 (78%)]\tLoss: 0.086686\n",
            "Train Epoch: 3 [3118/3978 (78%)]\tLoss: 0.091658\n",
            "Train Epoch: 3 [3119/3978 (78%)]\tLoss: 0.095027\n",
            "Train Epoch: 3 [3120/3978 (78%)]\tLoss: 0.117165\n",
            "Train Epoch: 3 [3121/3978 (78%)]\tLoss: 0.095195\n",
            "Train Epoch: 3 [3122/3978 (78%)]\tLoss: 0.834096\n",
            "Train Epoch: 3 [3123/3978 (79%)]\tLoss: 0.819003\n",
            "Train Epoch: 3 [3124/3978 (79%)]\tLoss: 0.106378\n",
            "Train Epoch: 3 [3125/3978 (79%)]\tLoss: 0.519179\n",
            "Train Epoch: 3 [3126/3978 (79%)]\tLoss: 0.131600\n",
            "Train Epoch: 3 [3127/3978 (79%)]\tLoss: 0.074355\n",
            "Train Epoch: 3 [3128/3978 (79%)]\tLoss: 0.092461\n",
            "Train Epoch: 3 [3129/3978 (79%)]\tLoss: 0.141956\n",
            "Train Epoch: 3 [3130/3978 (79%)]\tLoss: 0.694101\n",
            "Train Epoch: 3 [3131/3978 (79%)]\tLoss: 0.559234\n",
            "Train Epoch: 3 [3132/3978 (79%)]\tLoss: 0.089519\n",
            "Train Epoch: 3 [3133/3978 (79%)]\tLoss: 0.116691\n",
            "Train Epoch: 3 [3134/3978 (79%)]\tLoss: 0.092516\n",
            "Train Epoch: 3 [3135/3978 (79%)]\tLoss: 0.704135\n",
            "Train Epoch: 3 [3136/3978 (79%)]\tLoss: 0.074017\n",
            "Train Epoch: 3 [3137/3978 (79%)]\tLoss: 0.085713\n",
            "Train Epoch: 3 [3138/3978 (79%)]\tLoss: 0.080616\n",
            "Train Epoch: 3 [3139/3978 (79%)]\tLoss: 0.090548\n",
            "Train Epoch: 3 [3140/3978 (79%)]\tLoss: 0.083211\n",
            "Train Epoch: 3 [3141/3978 (79%)]\tLoss: 0.848841\n",
            "Train Epoch: 3 [3142/3978 (79%)]\tLoss: 0.704277\n",
            "Train Epoch: 3 [3143/3978 (79%)]\tLoss: 0.084905\n",
            "Train Epoch: 3 [3144/3978 (79%)]\tLoss: 0.083387\n",
            "Train Epoch: 3 [3145/3978 (79%)]\tLoss: 0.111638\n",
            "Train Epoch: 3 [3146/3978 (79%)]\tLoss: 0.520875\n",
            "Train Epoch: 3 [3147/3978 (79%)]\tLoss: 0.097356\n",
            "Train Epoch: 3 [3148/3978 (79%)]\tLoss: 0.134374\n",
            "Train Epoch: 3 [3149/3978 (79%)]\tLoss: 0.099676\n",
            "Train Epoch: 3 [3150/3978 (79%)]\tLoss: 0.138316\n",
            "Train Epoch: 3 [3151/3978 (79%)]\tLoss: 0.138787\n",
            "Train Epoch: 3 [3152/3978 (79%)]\tLoss: 0.113069\n",
            "Train Epoch: 3 [3153/3978 (79%)]\tLoss: 0.131279\n",
            "Train Epoch: 3 [3154/3978 (79%)]\tLoss: 0.793625\n",
            "Train Epoch: 3 [3155/3978 (79%)]\tLoss: 0.080658\n",
            "Train Epoch: 3 [3156/3978 (79%)]\tLoss: 0.134582\n",
            "Train Epoch: 3 [3157/3978 (79%)]\tLoss: 0.131398\n",
            "Train Epoch: 3 [3158/3978 (79%)]\tLoss: 0.596054\n",
            "Train Epoch: 3 [3159/3978 (79%)]\tLoss: 0.096145\n",
            "Train Epoch: 3 [3160/3978 (79%)]\tLoss: 0.085941\n",
            "Train Epoch: 3 [3161/3978 (79%)]\tLoss: 0.105398\n",
            "Train Epoch: 3 [3162/3978 (79%)]\tLoss: 0.590120\n",
            "Train Epoch: 3 [3163/3978 (80%)]\tLoss: 0.104144\n",
            "Train Epoch: 3 [3164/3978 (80%)]\tLoss: 0.125810\n",
            "Train Epoch: 3 [3165/3978 (80%)]\tLoss: 0.133516\n",
            "Train Epoch: 3 [3166/3978 (80%)]\tLoss: 0.098597\n",
            "Train Epoch: 3 [3167/3978 (80%)]\tLoss: 0.502754\n",
            "Train Epoch: 3 [3168/3978 (80%)]\tLoss: 0.126645\n",
            "Train Epoch: 3 [3169/3978 (80%)]\tLoss: 0.582457\n",
            "Train Epoch: 3 [3170/3978 (80%)]\tLoss: 0.123770\n",
            "Train Epoch: 3 [3171/3978 (80%)]\tLoss: 0.132181\n",
            "Train Epoch: 3 [3172/3978 (80%)]\tLoss: 0.082414\n",
            "Train Epoch: 3 [3173/3978 (80%)]\tLoss: 0.129646\n",
            "Train Epoch: 3 [3174/3978 (80%)]\tLoss: 0.084679\n",
            "Train Epoch: 3 [3175/3978 (80%)]\tLoss: 0.646973\n",
            "Train Epoch: 3 [3176/3978 (80%)]\tLoss: 0.076984\n",
            "Train Epoch: 3 [3177/3978 (80%)]\tLoss: 0.106539\n",
            "Train Epoch: 3 [3178/3978 (80%)]\tLoss: 0.095339\n",
            "Train Epoch: 3 [3179/3978 (80%)]\tLoss: 0.129504\n",
            "Train Epoch: 3 [3180/3978 (80%)]\tLoss: 0.121457\n",
            "Train Epoch: 3 [3181/3978 (80%)]\tLoss: 0.999019\n",
            "Train Epoch: 3 [3182/3978 (80%)]\tLoss: 0.135439\n",
            "Train Epoch: 3 [3183/3978 (80%)]\tLoss: 0.110461\n",
            "Train Epoch: 3 [3184/3978 (80%)]\tLoss: 0.526858\n",
            "Train Epoch: 3 [3185/3978 (80%)]\tLoss: 0.522055\n",
            "Train Epoch: 3 [3186/3978 (80%)]\tLoss: 0.085856\n",
            "Train Epoch: 3 [3187/3978 (80%)]\tLoss: 0.078156\n",
            "Train Epoch: 3 [3188/3978 (80%)]\tLoss: 0.077969\n",
            "Train Epoch: 3 [3189/3978 (80%)]\tLoss: 0.098605\n",
            "Train Epoch: 3 [3190/3978 (80%)]\tLoss: 0.088372\n",
            "Train Epoch: 3 [3191/3978 (80%)]\tLoss: 0.967341\n",
            "Train Epoch: 3 [3192/3978 (80%)]\tLoss: 0.124577\n",
            "Train Epoch: 3 [3193/3978 (80%)]\tLoss: 0.551341\n",
            "Train Epoch: 3 [3194/3978 (80%)]\tLoss: 0.096976\n",
            "Train Epoch: 3 [3195/3978 (80%)]\tLoss: 0.118206\n",
            "Train Epoch: 3 [3196/3978 (80%)]\tLoss: 0.119531\n",
            "Train Epoch: 3 [3197/3978 (80%)]\tLoss: 0.130122\n",
            "Train Epoch: 3 [3198/3978 (80%)]\tLoss: 0.111583\n",
            "Train Epoch: 3 [3199/3978 (80%)]\tLoss: 0.119994\n",
            "Train Epoch: 3 [3200/3978 (80%)]\tLoss: 0.097995\n",
            "Train Epoch: 3 [3201/3978 (80%)]\tLoss: 0.113173\n",
            "Train Epoch: 3 [3202/3978 (80%)]\tLoss: 0.086261\n",
            "Train Epoch: 3 [3203/3978 (81%)]\tLoss: 0.090918\n",
            "Train Epoch: 3 [3204/3978 (81%)]\tLoss: 0.093996\n",
            "Train Epoch: 3 [3205/3978 (81%)]\tLoss: 0.079128\n",
            "Train Epoch: 3 [3206/3978 (81%)]\tLoss: 0.125184\n",
            "Train Epoch: 3 [3207/3978 (81%)]\tLoss: 0.084510\n",
            "Train Epoch: 3 [3208/3978 (81%)]\tLoss: 0.085804\n",
            "Train Epoch: 3 [3209/3978 (81%)]\tLoss: 0.074408\n",
            "Train Epoch: 3 [3210/3978 (81%)]\tLoss: 0.077276\n",
            "Train Epoch: 3 [3211/3978 (81%)]\tLoss: 0.126501\n",
            "Train Epoch: 3 [3212/3978 (81%)]\tLoss: 0.111148\n",
            "Train Epoch: 3 [3213/3978 (81%)]\tLoss: 0.078780\n",
            "Train Epoch: 3 [3214/3978 (81%)]\tLoss: 0.094316\n",
            "Train Epoch: 3 [3215/3978 (81%)]\tLoss: 0.106478\n",
            "Train Epoch: 3 [3216/3978 (81%)]\tLoss: 0.091013\n",
            "Train Epoch: 3 [3217/3978 (81%)]\tLoss: 0.464278\n",
            "Train Epoch: 3 [3218/3978 (81%)]\tLoss: 0.100968\n",
            "Train Epoch: 3 [3219/3978 (81%)]\tLoss: 0.110738\n",
            "Train Epoch: 3 [3220/3978 (81%)]\tLoss: 1.087438\n",
            "Train Epoch: 3 [3221/3978 (81%)]\tLoss: 0.454228\n",
            "Train Epoch: 3 [3222/3978 (81%)]\tLoss: 0.094228\n",
            "Train Epoch: 3 [3223/3978 (81%)]\tLoss: 0.065187\n",
            "Train Epoch: 3 [3224/3978 (81%)]\tLoss: 0.702241\n",
            "Train Epoch: 3 [3225/3978 (81%)]\tLoss: 0.064728\n",
            "Train Epoch: 3 [3226/3978 (81%)]\tLoss: 0.936467\n",
            "Train Epoch: 3 [3227/3978 (81%)]\tLoss: 0.107644\n",
            "Train Epoch: 3 [3228/3978 (81%)]\tLoss: 0.063476\n",
            "Train Epoch: 3 [3229/3978 (81%)]\tLoss: 0.060867\n",
            "Train Epoch: 3 [3230/3978 (81%)]\tLoss: 0.084820\n",
            "Train Epoch: 3 [3231/3978 (81%)]\tLoss: 0.086662\n",
            "Train Epoch: 3 [3232/3978 (81%)]\tLoss: 0.077057\n",
            "Train Epoch: 3 [3233/3978 (81%)]\tLoss: 0.110905\n",
            "Train Epoch: 3 [3234/3978 (81%)]\tLoss: 0.086905\n",
            "Train Epoch: 3 [3235/3978 (81%)]\tLoss: 0.066446\n",
            "Train Epoch: 3 [3236/3978 (81%)]\tLoss: 0.489485\n",
            "Train Epoch: 3 [3237/3978 (81%)]\tLoss: 0.086015\n",
            "Train Epoch: 3 [3238/3978 (81%)]\tLoss: 0.165290\n",
            "Train Epoch: 3 [3239/3978 (81%)]\tLoss: 0.117840\n",
            "Train Epoch: 3 [3240/3978 (81%)]\tLoss: 0.124825\n",
            "Train Epoch: 3 [3241/3978 (81%)]\tLoss: 0.047882\n",
            "Train Epoch: 3 [3242/3978 (81%)]\tLoss: 0.049970\n",
            "Train Epoch: 3 [3243/3978 (82%)]\tLoss: 0.112583\n",
            "Train Epoch: 3 [3244/3978 (82%)]\tLoss: 0.123015\n",
            "Train Epoch: 3 [3245/3978 (82%)]\tLoss: 0.150168\n",
            "Train Epoch: 3 [3246/3978 (82%)]\tLoss: 0.052959\n",
            "Train Epoch: 3 [3247/3978 (82%)]\tLoss: 0.103711\n",
            "Train Epoch: 3 [3248/3978 (82%)]\tLoss: 0.075932\n",
            "Train Epoch: 3 [3249/3978 (82%)]\tLoss: 0.083625\n",
            "Train Epoch: 3 [3250/3978 (82%)]\tLoss: 0.064297\n",
            "Train Epoch: 3 [3251/3978 (82%)]\tLoss: 0.100015\n",
            "Train Epoch: 3 [3252/3978 (82%)]\tLoss: 0.494564\n",
            "Train Epoch: 3 [3253/3978 (82%)]\tLoss: 0.123781\n",
            "Train Epoch: 3 [3254/3978 (82%)]\tLoss: 0.092119\n",
            "Train Epoch: 3 [3255/3978 (82%)]\tLoss: 0.070348\n",
            "Train Epoch: 3 [3256/3978 (82%)]\tLoss: 0.075476\n",
            "Train Epoch: 3 [3257/3978 (82%)]\tLoss: 0.061320\n",
            "Train Epoch: 3 [3258/3978 (82%)]\tLoss: 0.076413\n",
            "Train Epoch: 3 [3259/3978 (82%)]\tLoss: 0.058233\n",
            "Train Epoch: 3 [3260/3978 (82%)]\tLoss: 0.056332\n",
            "Train Epoch: 3 [3261/3978 (82%)]\tLoss: 0.061178\n",
            "Train Epoch: 3 [3262/3978 (82%)]\tLoss: 0.053161\n",
            "Train Epoch: 3 [3263/3978 (82%)]\tLoss: 0.427682\n",
            "Train Epoch: 3 [3264/3978 (82%)]\tLoss: 0.127457\n",
            "Train Epoch: 3 [3265/3978 (82%)]\tLoss: 0.096655\n",
            "Train Epoch: 3 [3266/3978 (82%)]\tLoss: 0.095861\n",
            "Train Epoch: 3 [3267/3978 (82%)]\tLoss: 0.049503\n",
            "Train Epoch: 3 [3268/3978 (82%)]\tLoss: 0.069180\n",
            "Train Epoch: 3 [3269/3978 (82%)]\tLoss: 0.096836\n",
            "Train Epoch: 3 [3270/3978 (82%)]\tLoss: 0.054627\n",
            "Train Epoch: 3 [3271/3978 (82%)]\tLoss: 0.440608\n",
            "Train Epoch: 3 [3272/3978 (82%)]\tLoss: 0.080272\n",
            "Train Epoch: 3 [3273/3978 (82%)]\tLoss: 0.050116\n",
            "Train Epoch: 3 [3274/3978 (82%)]\tLoss: 0.128293\n",
            "Train Epoch: 3 [3275/3978 (82%)]\tLoss: 0.064703\n",
            "Train Epoch: 3 [3276/3978 (82%)]\tLoss: 0.129078\n",
            "Train Epoch: 3 [3277/3978 (82%)]\tLoss: 0.800427\n",
            "Train Epoch: 3 [3278/3978 (82%)]\tLoss: 0.893965\n",
            "Train Epoch: 3 [3279/3978 (82%)]\tLoss: 0.051121\n",
            "Train Epoch: 3 [3280/3978 (82%)]\tLoss: 0.056219\n",
            "Train Epoch: 3 [3281/3978 (82%)]\tLoss: 0.687418\n",
            "Train Epoch: 3 [3282/3978 (83%)]\tLoss: 0.051350\n",
            "Train Epoch: 3 [3283/3978 (83%)]\tLoss: 0.102131\n",
            "Train Epoch: 3 [3284/3978 (83%)]\tLoss: 1.036483\n",
            "Train Epoch: 3 [3285/3978 (83%)]\tLoss: 0.149217\n",
            "Train Epoch: 3 [3286/3978 (83%)]\tLoss: 0.049595\n",
            "Train Epoch: 3 [3287/3978 (83%)]\tLoss: 0.107728\n",
            "Train Epoch: 3 [3288/3978 (83%)]\tLoss: 0.716836\n",
            "Train Epoch: 3 [3289/3978 (83%)]\tLoss: 0.052827\n",
            "Train Epoch: 3 [3290/3978 (83%)]\tLoss: 0.144511\n",
            "Train Epoch: 3 [3291/3978 (83%)]\tLoss: 0.060397\n",
            "Train Epoch: 3 [3292/3978 (83%)]\tLoss: 0.975997\n",
            "Train Epoch: 3 [3293/3978 (83%)]\tLoss: 0.121118\n",
            "Train Epoch: 3 [3294/3978 (83%)]\tLoss: 0.135873\n",
            "Train Epoch: 3 [3295/3978 (83%)]\tLoss: 0.097017\n",
            "Train Epoch: 3 [3296/3978 (83%)]\tLoss: 0.135039\n",
            "Train Epoch: 3 [3297/3978 (83%)]\tLoss: 0.939253\n",
            "Train Epoch: 3 [3298/3978 (83%)]\tLoss: 0.103228\n",
            "Train Epoch: 3 [3299/3978 (83%)]\tLoss: 0.124838\n",
            "Train Epoch: 3 [3300/3978 (83%)]\tLoss: 0.971490\n",
            "Train Epoch: 3 [3301/3978 (83%)]\tLoss: 0.067423\n",
            "Train Epoch: 3 [3302/3978 (83%)]\tLoss: 0.625052\n",
            "Train Epoch: 3 [3303/3978 (83%)]\tLoss: 0.111622\n",
            "Train Epoch: 3 [3304/3978 (83%)]\tLoss: 0.081523\n",
            "Train Epoch: 3 [3305/3978 (83%)]\tLoss: 0.880461\n",
            "Train Epoch: 3 [3306/3978 (83%)]\tLoss: 0.097426\n",
            "Train Epoch: 3 [3307/3978 (83%)]\tLoss: 0.085722\n",
            "Train Epoch: 3 [3308/3978 (83%)]\tLoss: 0.067958\n",
            "Train Epoch: 3 [3309/3978 (83%)]\tLoss: 0.919857\n",
            "Train Epoch: 3 [3310/3978 (83%)]\tLoss: 0.108412\n",
            "Train Epoch: 3 [3311/3978 (83%)]\tLoss: 0.904793\n",
            "Train Epoch: 3 [3312/3978 (83%)]\tLoss: 0.101119\n",
            "Train Epoch: 3 [3313/3978 (83%)]\tLoss: 0.902388\n",
            "Train Epoch: 3 [3314/3978 (83%)]\tLoss: 0.093852\n",
            "Train Epoch: 3 [3315/3978 (83%)]\tLoss: 0.815450\n",
            "Train Epoch: 3 [3316/3978 (83%)]\tLoss: 0.097869\n",
            "Train Epoch: 3 [3317/3978 (83%)]\tLoss: 0.707632\n",
            "Train Epoch: 3 [3318/3978 (83%)]\tLoss: 0.097127\n",
            "Train Epoch: 3 [3319/3978 (83%)]\tLoss: 0.057256\n",
            "Train Epoch: 3 [3320/3978 (83%)]\tLoss: 0.155139\n",
            "Train Epoch: 3 [3321/3978 (83%)]\tLoss: 0.131699\n",
            "Train Epoch: 3 [3322/3978 (84%)]\tLoss: 0.683908\n",
            "Train Epoch: 3 [3323/3978 (84%)]\tLoss: 0.126724\n",
            "Train Epoch: 3 [3324/3978 (84%)]\tLoss: 0.588001\n",
            "Train Epoch: 3 [3325/3978 (84%)]\tLoss: 0.678371\n",
            "Train Epoch: 3 [3326/3978 (84%)]\tLoss: 0.159358\n",
            "Train Epoch: 3 [3327/3978 (84%)]\tLoss: 0.068421\n",
            "Train Epoch: 3 [3328/3978 (84%)]\tLoss: 0.138126\n",
            "Train Epoch: 3 [3329/3978 (84%)]\tLoss: 0.722954\n",
            "Train Epoch: 3 [3330/3978 (84%)]\tLoss: 0.729694\n",
            "Train Epoch: 3 [3331/3978 (84%)]\tLoss: 0.099035\n",
            "Train Epoch: 3 [3332/3978 (84%)]\tLoss: 0.117933\n",
            "Train Epoch: 3 [3333/3978 (84%)]\tLoss: 0.092995\n",
            "Train Epoch: 3 [3334/3978 (84%)]\tLoss: 0.120090\n",
            "Train Epoch: 3 [3335/3978 (84%)]\tLoss: 0.532381\n",
            "Train Epoch: 3 [3336/3978 (84%)]\tLoss: 0.604062\n",
            "Train Epoch: 3 [3337/3978 (84%)]\tLoss: 0.100000\n",
            "Train Epoch: 3 [3338/3978 (84%)]\tLoss: 0.121507\n",
            "Train Epoch: 3 [3339/3978 (84%)]\tLoss: 0.525147\n",
            "Train Epoch: 3 [3340/3978 (84%)]\tLoss: 0.118865\n",
            "Train Epoch: 3 [3341/3978 (84%)]\tLoss: 0.076076\n",
            "Train Epoch: 3 [3342/3978 (84%)]\tLoss: 0.154713\n",
            "Train Epoch: 3 [3343/3978 (84%)]\tLoss: 0.075482\n",
            "Train Epoch: 3 [3344/3978 (84%)]\tLoss: 0.147734\n",
            "Train Epoch: 3 [3345/3978 (84%)]\tLoss: 0.509376\n",
            "Train Epoch: 3 [3346/3978 (84%)]\tLoss: 0.544120\n",
            "Train Epoch: 3 [3347/3978 (84%)]\tLoss: 0.087873\n",
            "Train Epoch: 3 [3348/3978 (84%)]\tLoss: 0.117220\n",
            "Train Epoch: 3 [3349/3978 (84%)]\tLoss: 0.114073\n",
            "Train Epoch: 3 [3350/3978 (84%)]\tLoss: 0.106871\n",
            "Train Epoch: 3 [3351/3978 (84%)]\tLoss: 0.157849\n",
            "Train Epoch: 3 [3352/3978 (84%)]\tLoss: 0.086369\n",
            "Train Epoch: 3 [3353/3978 (84%)]\tLoss: 0.673205\n",
            "Train Epoch: 3 [3354/3978 (84%)]\tLoss: 0.089712\n",
            "Train Epoch: 3 [3355/3978 (84%)]\tLoss: 0.142013\n",
            "Train Epoch: 3 [3356/3978 (84%)]\tLoss: 0.102205\n",
            "Train Epoch: 3 [3357/3978 (84%)]\tLoss: 0.125361\n",
            "Train Epoch: 3 [3358/3978 (84%)]\tLoss: 0.147154\n",
            "Train Epoch: 3 [3359/3978 (84%)]\tLoss: 0.109898\n",
            "Train Epoch: 3 [3360/3978 (84%)]\tLoss: 0.109299\n",
            "Train Epoch: 3 [3361/3978 (84%)]\tLoss: 0.131039\n",
            "Train Epoch: 3 [3362/3978 (85%)]\tLoss: 0.109529\n",
            "Train Epoch: 3 [3363/3978 (85%)]\tLoss: 0.146962\n",
            "Train Epoch: 3 [3364/3978 (85%)]\tLoss: 0.118544\n",
            "Train Epoch: 3 [3365/3978 (85%)]\tLoss: 0.552669\n",
            "Train Epoch: 3 [3366/3978 (85%)]\tLoss: 0.706675\n",
            "Train Epoch: 3 [3367/3978 (85%)]\tLoss: 0.508855\n",
            "Train Epoch: 3 [3368/3978 (85%)]\tLoss: 0.071112\n",
            "Train Epoch: 3 [3369/3978 (85%)]\tLoss: 0.102243\n",
            "Train Epoch: 3 [3370/3978 (85%)]\tLoss: 0.499651\n",
            "Train Epoch: 3 [3371/3978 (85%)]\tLoss: 0.069874\n",
            "Train Epoch: 3 [3372/3978 (85%)]\tLoss: 0.106904\n",
            "Train Epoch: 3 [3373/3978 (85%)]\tLoss: 0.117060\n",
            "Train Epoch: 3 [3374/3978 (85%)]\tLoss: 0.114586\n",
            "Train Epoch: 3 [3375/3978 (85%)]\tLoss: 0.115097\n",
            "Train Epoch: 3 [3376/3978 (85%)]\tLoss: 0.127975\n",
            "Train Epoch: 3 [3377/3978 (85%)]\tLoss: 0.074982\n",
            "Train Epoch: 3 [3378/3978 (85%)]\tLoss: 0.533367\n",
            "Train Epoch: 3 [3379/3978 (85%)]\tLoss: 0.112304\n",
            "Train Epoch: 3 [3380/3978 (85%)]\tLoss: 0.082640\n",
            "Train Epoch: 3 [3381/3978 (85%)]\tLoss: 0.728916\n",
            "Train Epoch: 3 [3382/3978 (85%)]\tLoss: 0.065706\n",
            "Train Epoch: 3 [3383/3978 (85%)]\tLoss: 0.115099\n",
            "Train Epoch: 3 [3384/3978 (85%)]\tLoss: 0.173870\n",
            "Train Epoch: 3 [3385/3978 (85%)]\tLoss: 0.132812\n",
            "Train Epoch: 3 [3386/3978 (85%)]\tLoss: 0.065272\n",
            "Train Epoch: 3 [3387/3978 (85%)]\tLoss: 0.174160\n",
            "Train Epoch: 3 [3388/3978 (85%)]\tLoss: 0.087133\n",
            "Train Epoch: 3 [3389/3978 (85%)]\tLoss: 0.071822\n",
            "Train Epoch: 3 [3390/3978 (85%)]\tLoss: 0.064559\n",
            "Train Epoch: 3 [3391/3978 (85%)]\tLoss: 0.111509\n",
            "Train Epoch: 3 [3392/3978 (85%)]\tLoss: 0.166529\n",
            "Train Epoch: 3 [3393/3978 (85%)]\tLoss: 0.107772\n",
            "Train Epoch: 3 [3394/3978 (85%)]\tLoss: 0.110335\n",
            "Train Epoch: 3 [3395/3978 (85%)]\tLoss: 0.527740\n",
            "Train Epoch: 3 [3396/3978 (85%)]\tLoss: 0.080290\n",
            "Train Epoch: 3 [3397/3978 (85%)]\tLoss: 0.131892\n",
            "Train Epoch: 3 [3398/3978 (85%)]\tLoss: 0.075944\n",
            "Train Epoch: 3 [3399/3978 (85%)]\tLoss: 1.061993\n",
            "Train Epoch: 3 [3400/3978 (85%)]\tLoss: 0.081855\n",
            "Train Epoch: 3 [3401/3978 (85%)]\tLoss: 0.648761\n",
            "Train Epoch: 3 [3402/3978 (86%)]\tLoss: 0.097334\n",
            "Train Epoch: 3 [3403/3978 (86%)]\tLoss: 0.070198\n",
            "Train Epoch: 3 [3404/3978 (86%)]\tLoss: 0.061650\n",
            "Train Epoch: 3 [3405/3978 (86%)]\tLoss: 0.104990\n",
            "Train Epoch: 3 [3406/3978 (86%)]\tLoss: 0.124972\n",
            "Train Epoch: 3 [3407/3978 (86%)]\tLoss: 0.123861\n",
            "Train Epoch: 3 [3408/3978 (86%)]\tLoss: 0.624004\n",
            "Train Epoch: 3 [3409/3978 (86%)]\tLoss: 0.111510\n",
            "Train Epoch: 3 [3410/3978 (86%)]\tLoss: 0.112809\n",
            "Train Epoch: 3 [3411/3978 (86%)]\tLoss: 0.132369\n",
            "Train Epoch: 3 [3412/3978 (86%)]\tLoss: 0.110613\n",
            "Train Epoch: 3 [3413/3978 (86%)]\tLoss: 0.079601\n",
            "Train Epoch: 3 [3414/3978 (86%)]\tLoss: 0.087180\n",
            "Train Epoch: 3 [3415/3978 (86%)]\tLoss: 0.084670\n",
            "Train Epoch: 3 [3416/3978 (86%)]\tLoss: 0.079813\n",
            "Train Epoch: 3 [3417/3978 (86%)]\tLoss: 0.624626\n",
            "Train Epoch: 3 [3418/3978 (86%)]\tLoss: 0.072912\n",
            "Train Epoch: 3 [3419/3978 (86%)]\tLoss: 1.420457\n",
            "Train Epoch: 3 [3420/3978 (86%)]\tLoss: 0.111065\n",
            "Train Epoch: 3 [3421/3978 (86%)]\tLoss: 0.101542\n",
            "Train Epoch: 3 [3422/3978 (86%)]\tLoss: 0.121131\n",
            "Train Epoch: 3 [3423/3978 (86%)]\tLoss: 0.079712\n",
            "Train Epoch: 3 [3424/3978 (86%)]\tLoss: 0.079876\n",
            "Train Epoch: 3 [3425/3978 (86%)]\tLoss: 0.097011\n",
            "Train Epoch: 3 [3426/3978 (86%)]\tLoss: 0.102727\n",
            "Train Epoch: 3 [3427/3978 (86%)]\tLoss: 0.076567\n",
            "Train Epoch: 3 [3428/3978 (86%)]\tLoss: 0.102575\n",
            "Train Epoch: 3 [3429/3978 (86%)]\tLoss: 1.017375\n",
            "Train Epoch: 3 [3430/3978 (86%)]\tLoss: 0.099307\n",
            "Train Epoch: 3 [3431/3978 (86%)]\tLoss: 0.088138\n",
            "Train Epoch: 3 [3432/3978 (86%)]\tLoss: 0.074758\n",
            "Train Epoch: 3 [3433/3978 (86%)]\tLoss: 0.113923\n",
            "Train Epoch: 3 [3434/3978 (86%)]\tLoss: 0.118066\n",
            "Train Epoch: 3 [3435/3978 (86%)]\tLoss: 0.595698\n",
            "Train Epoch: 3 [3436/3978 (86%)]\tLoss: 0.070489\n",
            "Train Epoch: 3 [3437/3978 (86%)]\tLoss: 0.071692\n",
            "Train Epoch: 3 [3438/3978 (86%)]\tLoss: 0.726471\n",
            "Train Epoch: 3 [3439/3978 (86%)]\tLoss: 0.088291\n",
            "Train Epoch: 3 [3440/3978 (86%)]\tLoss: 0.085270\n",
            "Train Epoch: 3 [3441/3978 (87%)]\tLoss: 0.066489\n",
            "Train Epoch: 3 [3442/3978 (87%)]\tLoss: 0.069426\n",
            "Train Epoch: 3 [3443/3978 (87%)]\tLoss: 0.095347\n",
            "Train Epoch: 3 [3444/3978 (87%)]\tLoss: 0.952448\n",
            "Train Epoch: 3 [3445/3978 (87%)]\tLoss: 0.645382\n",
            "Train Epoch: 3 [3446/3978 (87%)]\tLoss: 0.072526\n",
            "Train Epoch: 3 [3447/3978 (87%)]\tLoss: 0.083952\n",
            "Train Epoch: 3 [3448/3978 (87%)]\tLoss: 0.058287\n",
            "Train Epoch: 3 [3449/3978 (87%)]\tLoss: 0.133589\n",
            "Train Epoch: 3 [3450/3978 (87%)]\tLoss: 0.702663\n",
            "Train Epoch: 3 [3451/3978 (87%)]\tLoss: 1.012880\n",
            "Train Epoch: 3 [3452/3978 (87%)]\tLoss: 0.152453\n",
            "Train Epoch: 3 [3453/3978 (87%)]\tLoss: 0.605160\n",
            "Train Epoch: 3 [3454/3978 (87%)]\tLoss: 0.875564\n",
            "Train Epoch: 3 [3455/3978 (87%)]\tLoss: 0.045813\n",
            "Train Epoch: 3 [3456/3978 (87%)]\tLoss: 0.127074\n",
            "Train Epoch: 3 [3457/3978 (87%)]\tLoss: 0.653106\n",
            "Train Epoch: 3 [3458/3978 (87%)]\tLoss: 0.050505\n",
            "Train Epoch: 3 [3459/3978 (87%)]\tLoss: 0.063883\n",
            "Train Epoch: 3 [3460/3978 (87%)]\tLoss: 0.047088\n",
            "Train Epoch: 3 [3461/3978 (87%)]\tLoss: 0.057451\n",
            "Train Epoch: 3 [3462/3978 (87%)]\tLoss: 0.091473\n",
            "Train Epoch: 3 [3463/3978 (87%)]\tLoss: 0.137117\n",
            "Train Epoch: 3 [3464/3978 (87%)]\tLoss: 0.142508\n",
            "Train Epoch: 3 [3465/3978 (87%)]\tLoss: 0.056839\n",
            "Train Epoch: 3 [3466/3978 (87%)]\tLoss: 0.071751\n",
            "Train Epoch: 3 [3467/3978 (87%)]\tLoss: 0.136588\n",
            "Train Epoch: 3 [3468/3978 (87%)]\tLoss: 0.167491\n",
            "Train Epoch: 3 [3469/3978 (87%)]\tLoss: 0.643527\n",
            "Train Epoch: 3 [3470/3978 (87%)]\tLoss: 0.133173\n",
            "Train Epoch: 3 [3471/3978 (87%)]\tLoss: 0.049929\n",
            "Train Epoch: 3 [3472/3978 (87%)]\tLoss: 0.140099\n",
            "Train Epoch: 3 [3473/3978 (87%)]\tLoss: 0.132236\n",
            "Train Epoch: 3 [3474/3978 (87%)]\tLoss: 0.069639\n",
            "Train Epoch: 3 [3475/3978 (87%)]\tLoss: 0.124858\n",
            "Train Epoch: 3 [3476/3978 (87%)]\tLoss: 0.109384\n",
            "Train Epoch: 3 [3477/3978 (87%)]\tLoss: 0.067604\n",
            "Train Epoch: 3 [3478/3978 (87%)]\tLoss: 0.072556\n",
            "Train Epoch: 3 [3479/3978 (87%)]\tLoss: 0.064005\n",
            "Train Epoch: 3 [3480/3978 (87%)]\tLoss: 0.098156\n",
            "Train Epoch: 3 [3481/3978 (88%)]\tLoss: 0.064415\n",
            "Train Epoch: 3 [3482/3978 (88%)]\tLoss: 0.062878\n",
            "Train Epoch: 3 [3483/3978 (88%)]\tLoss: 0.078901\n",
            "Train Epoch: 3 [3484/3978 (88%)]\tLoss: 0.063505\n",
            "Train Epoch: 3 [3485/3978 (88%)]\tLoss: 0.090150\n",
            "Train Epoch: 3 [3486/3978 (88%)]\tLoss: 1.037253\n",
            "Train Epoch: 3 [3487/3978 (88%)]\tLoss: 0.594499\n",
            "Train Epoch: 3 [3488/3978 (88%)]\tLoss: 0.057212\n",
            "Train Epoch: 3 [3489/3978 (88%)]\tLoss: 0.134988\n",
            "Train Epoch: 3 [3490/3978 (88%)]\tLoss: 0.123175\n",
            "Train Epoch: 3 [3491/3978 (88%)]\tLoss: 0.718286\n",
            "Train Epoch: 3 [3492/3978 (88%)]\tLoss: 0.648041\n",
            "Train Epoch: 3 [3493/3978 (88%)]\tLoss: 0.109720\n",
            "Train Epoch: 3 [3494/3978 (88%)]\tLoss: 0.063279\n",
            "Train Epoch: 3 [3495/3978 (88%)]\tLoss: 0.112691\n",
            "Train Epoch: 3 [3496/3978 (88%)]\tLoss: 0.096195\n",
            "Train Epoch: 3 [3497/3978 (88%)]\tLoss: 0.635584\n",
            "Train Epoch: 3 [3498/3978 (88%)]\tLoss: 0.055783\n",
            "Train Epoch: 3 [3499/3978 (88%)]\tLoss: 0.163966\n",
            "Train Epoch: 3 [3500/3978 (88%)]\tLoss: 0.058998\n",
            "Train Epoch: 3 [3501/3978 (88%)]\tLoss: 0.105459\n",
            "Train Epoch: 3 [3502/3978 (88%)]\tLoss: 0.542928\n",
            "Train Epoch: 3 [3503/3978 (88%)]\tLoss: 0.595303\n",
            "Train Epoch: 3 [3504/3978 (88%)]\tLoss: 0.062065\n",
            "Train Epoch: 3 [3505/3978 (88%)]\tLoss: 0.067846\n",
            "Train Epoch: 3 [3506/3978 (88%)]\tLoss: 0.138883\n",
            "Train Epoch: 3 [3507/3978 (88%)]\tLoss: 0.064504\n",
            "Train Epoch: 3 [3508/3978 (88%)]\tLoss: 0.833093\n",
            "Train Epoch: 3 [3509/3978 (88%)]\tLoss: 0.083908\n",
            "Train Epoch: 3 [3510/3978 (88%)]\tLoss: 0.102585\n",
            "Train Epoch: 3 [3511/3978 (88%)]\tLoss: 0.110233\n",
            "Train Epoch: 3 [3512/3978 (88%)]\tLoss: 0.101804\n",
            "Train Epoch: 3 [3513/3978 (88%)]\tLoss: 0.067900\n",
            "Train Epoch: 3 [3514/3978 (88%)]\tLoss: 0.589656\n",
            "Train Epoch: 3 [3515/3978 (88%)]\tLoss: 0.141619\n",
            "Train Epoch: 3 [3516/3978 (88%)]\tLoss: 0.099150\n",
            "Train Epoch: 3 [3517/3978 (88%)]\tLoss: 0.129593\n",
            "Train Epoch: 3 [3518/3978 (88%)]\tLoss: 0.879424\n",
            "Train Epoch: 3 [3519/3978 (88%)]\tLoss: 0.524139\n",
            "Train Epoch: 3 [3520/3978 (88%)]\tLoss: 0.504839\n",
            "Train Epoch: 3 [3521/3978 (89%)]\tLoss: 0.134178\n",
            "Train Epoch: 3 [3522/3978 (89%)]\tLoss: 0.099576\n",
            "Train Epoch: 3 [3523/3978 (89%)]\tLoss: 1.288316\n",
            "Train Epoch: 3 [3524/3978 (89%)]\tLoss: 0.094777\n",
            "Train Epoch: 3 [3525/3978 (89%)]\tLoss: 0.083107\n",
            "Train Epoch: 3 [3526/3978 (89%)]\tLoss: 0.081557\n",
            "Train Epoch: 3 [3527/3978 (89%)]\tLoss: 0.102106\n",
            "Train Epoch: 3 [3528/3978 (89%)]\tLoss: 0.641476\n",
            "Train Epoch: 3 [3529/3978 (89%)]\tLoss: 0.128810\n",
            "Train Epoch: 3 [3530/3978 (89%)]\tLoss: 0.451212\n",
            "Train Epoch: 3 [3531/3978 (89%)]\tLoss: 0.105585\n",
            "Train Epoch: 3 [3532/3978 (89%)]\tLoss: 0.557533\n",
            "Train Epoch: 3 [3533/3978 (89%)]\tLoss: 0.098909\n",
            "Train Epoch: 3 [3534/3978 (89%)]\tLoss: 0.089054\n",
            "Train Epoch: 3 [3535/3978 (89%)]\tLoss: 0.152199\n",
            "Train Epoch: 3 [3536/3978 (89%)]\tLoss: 0.096838\n",
            "Train Epoch: 3 [3537/3978 (89%)]\tLoss: 0.180389\n",
            "Train Epoch: 3 [3538/3978 (89%)]\tLoss: 0.348803\n",
            "Train Epoch: 3 [3539/3978 (89%)]\tLoss: 0.526708\n",
            "Train Epoch: 3 [3540/3978 (89%)]\tLoss: 0.120422\n",
            "Train Epoch: 3 [3541/3978 (89%)]\tLoss: 0.156503\n",
            "Train Epoch: 3 [3542/3978 (89%)]\tLoss: 0.124108\n",
            "Train Epoch: 3 [3543/3978 (89%)]\tLoss: 0.098865\n",
            "Train Epoch: 3 [3544/3978 (89%)]\tLoss: 0.174638\n",
            "Train Epoch: 3 [3545/3978 (89%)]\tLoss: 0.565064\n",
            "Train Epoch: 3 [3546/3978 (89%)]\tLoss: 0.103307\n",
            "Train Epoch: 3 [3547/3978 (89%)]\tLoss: 0.131825\n",
            "Train Epoch: 3 [3548/3978 (89%)]\tLoss: 0.167138\n",
            "Train Epoch: 3 [3549/3978 (89%)]\tLoss: 0.922297\n",
            "Train Epoch: 3 [3550/3978 (89%)]\tLoss: 0.155796\n",
            "Train Epoch: 3 [3551/3978 (89%)]\tLoss: 0.935971\n",
            "Train Epoch: 3 [3552/3978 (89%)]\tLoss: 0.128101\n",
            "Train Epoch: 3 [3553/3978 (89%)]\tLoss: 0.125529\n",
            "Train Epoch: 3 [3554/3978 (89%)]\tLoss: 0.102418\n",
            "Train Epoch: 3 [3555/3978 (89%)]\tLoss: 0.093498\n",
            "Train Epoch: 3 [3556/3978 (89%)]\tLoss: 0.156919\n",
            "Train Epoch: 3 [3557/3978 (89%)]\tLoss: 0.127682\n",
            "Train Epoch: 3 [3558/3978 (89%)]\tLoss: 0.446817\n",
            "Train Epoch: 3 [3559/3978 (89%)]\tLoss: 0.105423\n",
            "Train Epoch: 3 [3560/3978 (89%)]\tLoss: 0.083512\n",
            "Train Epoch: 3 [3561/3978 (90%)]\tLoss: 0.096693\n",
            "Train Epoch: 3 [3562/3978 (90%)]\tLoss: 0.111877\n",
            "Train Epoch: 3 [3563/3978 (90%)]\tLoss: 0.076905\n",
            "Train Epoch: 3 [3564/3978 (90%)]\tLoss: 0.127383\n",
            "Train Epoch: 3 [3565/3978 (90%)]\tLoss: 0.114001\n",
            "Train Epoch: 3 [3566/3978 (90%)]\tLoss: 0.068261\n",
            "Train Epoch: 3 [3567/3978 (90%)]\tLoss: 0.759071\n",
            "Train Epoch: 3 [3568/3978 (90%)]\tLoss: 0.135509\n",
            "Train Epoch: 3 [3569/3978 (90%)]\tLoss: 0.166476\n",
            "Train Epoch: 3 [3570/3978 (90%)]\tLoss: 0.062199\n",
            "Train Epoch: 3 [3571/3978 (90%)]\tLoss: 0.653370\n",
            "Train Epoch: 3 [3572/3978 (90%)]\tLoss: 0.084103\n",
            "Train Epoch: 3 [3573/3978 (90%)]\tLoss: 0.648922\n",
            "Train Epoch: 3 [3574/3978 (90%)]\tLoss: 0.871517\n",
            "Train Epoch: 3 [3575/3978 (90%)]\tLoss: 1.263415\n",
            "Train Epoch: 3 [3576/3978 (90%)]\tLoss: 0.523151\n",
            "Train Epoch: 3 [3577/3978 (90%)]\tLoss: 0.419218\n",
            "Train Epoch: 3 [3578/3978 (90%)]\tLoss: 0.128642\n",
            "Train Epoch: 3 [3579/3978 (90%)]\tLoss: 0.062072\n",
            "Train Epoch: 3 [3580/3978 (90%)]\tLoss: 0.061564\n",
            "Train Epoch: 3 [3581/3978 (90%)]\tLoss: 0.111944\n",
            "Train Epoch: 3 [3582/3978 (90%)]\tLoss: 0.113540\n",
            "Train Epoch: 3 [3583/3978 (90%)]\tLoss: 0.062172\n",
            "Train Epoch: 3 [3584/3978 (90%)]\tLoss: 0.177947\n",
            "Train Epoch: 3 [3585/3978 (90%)]\tLoss: 0.199932\n",
            "Train Epoch: 3 [3586/3978 (90%)]\tLoss: 0.061407\n",
            "Train Epoch: 3 [3587/3978 (90%)]\tLoss: 0.567691\n",
            "Train Epoch: 3 [3588/3978 (90%)]\tLoss: 0.189807\n",
            "Train Epoch: 3 [3589/3978 (90%)]\tLoss: 0.135346\n",
            "Train Epoch: 3 [3590/3978 (90%)]\tLoss: 0.199485\n",
            "Train Epoch: 3 [3591/3978 (90%)]\tLoss: 1.133678\n",
            "Train Epoch: 3 [3592/3978 (90%)]\tLoss: 0.178675\n",
            "Train Epoch: 3 [3593/3978 (90%)]\tLoss: 0.182741\n",
            "Train Epoch: 3 [3594/3978 (90%)]\tLoss: 0.138980\n",
            "Train Epoch: 3 [3595/3978 (90%)]\tLoss: 0.107877\n",
            "Train Epoch: 3 [3596/3978 (90%)]\tLoss: 0.166277\n",
            "Train Epoch: 3 [3597/3978 (90%)]\tLoss: 0.111128\n",
            "Train Epoch: 3 [3598/3978 (90%)]\tLoss: 0.121269\n",
            "Train Epoch: 3 [3599/3978 (90%)]\tLoss: 0.088831\n",
            "Train Epoch: 3 [3600/3978 (90%)]\tLoss: 0.153119\n",
            "Train Epoch: 3 [3601/3978 (91%)]\tLoss: 0.075588\n",
            "Train Epoch: 3 [3602/3978 (91%)]\tLoss: 0.130718\n",
            "Train Epoch: 3 [3603/3978 (91%)]\tLoss: 0.095315\n",
            "Train Epoch: 3 [3604/3978 (91%)]\tLoss: 0.067893\n",
            "Train Epoch: 3 [3605/3978 (91%)]\tLoss: 0.137963\n",
            "Train Epoch: 3 [3606/3978 (91%)]\tLoss: 0.107679\n",
            "Train Epoch: 3 [3607/3978 (91%)]\tLoss: 0.564364\n",
            "Train Epoch: 3 [3608/3978 (91%)]\tLoss: 0.138519\n",
            "Train Epoch: 3 [3609/3978 (91%)]\tLoss: 0.138606\n",
            "Train Epoch: 3 [3610/3978 (91%)]\tLoss: 0.159648\n",
            "Train Epoch: 3 [3611/3978 (91%)]\tLoss: 0.595614\n",
            "Train Epoch: 3 [3612/3978 (91%)]\tLoss: 0.082028\n",
            "Train Epoch: 3 [3613/3978 (91%)]\tLoss: 0.077266\n",
            "Train Epoch: 3 [3614/3978 (91%)]\tLoss: 0.073178\n",
            "Train Epoch: 3 [3615/3978 (91%)]\tLoss: 0.150302\n",
            "Train Epoch: 3 [3616/3978 (91%)]\tLoss: 0.134907\n",
            "Train Epoch: 3 [3617/3978 (91%)]\tLoss: 1.063645\n",
            "Train Epoch: 3 [3618/3978 (91%)]\tLoss: 0.091646\n",
            "Train Epoch: 3 [3619/3978 (91%)]\tLoss: 0.108566\n",
            "Train Epoch: 3 [3620/3978 (91%)]\tLoss: 0.069447\n",
            "Train Epoch: 3 [3621/3978 (91%)]\tLoss: 0.137957\n",
            "Train Epoch: 3 [3622/3978 (91%)]\tLoss: 0.108438\n",
            "Train Epoch: 3 [3623/3978 (91%)]\tLoss: 0.071332\n",
            "Train Epoch: 3 [3624/3978 (91%)]\tLoss: 0.549185\n",
            "Train Epoch: 3 [3625/3978 (91%)]\tLoss: 0.067127\n",
            "Train Epoch: 3 [3626/3978 (91%)]\tLoss: 0.585359\n",
            "Train Epoch: 3 [3627/3978 (91%)]\tLoss: 0.525006\n",
            "Train Epoch: 3 [3628/3978 (91%)]\tLoss: 0.888001\n",
            "Train Epoch: 3 [3629/3978 (91%)]\tLoss: 0.951941\n",
            "Train Epoch: 3 [3630/3978 (91%)]\tLoss: 0.142192\n",
            "Train Epoch: 3 [3631/3978 (91%)]\tLoss: 0.113219\n",
            "Train Epoch: 3 [3632/3978 (91%)]\tLoss: 0.109213\n",
            "Train Epoch: 3 [3633/3978 (91%)]\tLoss: 1.146672\n",
            "Train Epoch: 3 [3634/3978 (91%)]\tLoss: 0.074195\n",
            "Train Epoch: 3 [3635/3978 (91%)]\tLoss: 0.147213\n",
            "Train Epoch: 3 [3636/3978 (91%)]\tLoss: 0.085117\n",
            "Train Epoch: 3 [3637/3978 (91%)]\tLoss: 0.089517\n",
            "Train Epoch: 3 [3638/3978 (91%)]\tLoss: 0.105195\n",
            "Train Epoch: 3 [3639/3978 (91%)]\tLoss: 0.153027\n",
            "Train Epoch: 3 [3640/3978 (92%)]\tLoss: 0.102977\n",
            "Train Epoch: 3 [3641/3978 (92%)]\tLoss: 0.559589\n",
            "Train Epoch: 3 [3642/3978 (92%)]\tLoss: 0.065371\n",
            "Train Epoch: 3 [3643/3978 (92%)]\tLoss: 0.055947\n",
            "Train Epoch: 3 [3644/3978 (92%)]\tLoss: 0.057038\n",
            "Train Epoch: 3 [3645/3978 (92%)]\tLoss: 0.054729\n",
            "Train Epoch: 3 [3646/3978 (92%)]\tLoss: 0.169843\n",
            "Train Epoch: 3 [3647/3978 (92%)]\tLoss: 0.123194\n",
            "Train Epoch: 3 [3648/3978 (92%)]\tLoss: 0.135357\n",
            "Train Epoch: 3 [3649/3978 (92%)]\tLoss: 0.058723\n",
            "Train Epoch: 3 [3650/3978 (92%)]\tLoss: 0.114068\n",
            "Train Epoch: 3 [3651/3978 (92%)]\tLoss: 0.145294\n",
            "Train Epoch: 3 [3652/3978 (92%)]\tLoss: 0.538209\n",
            "Train Epoch: 3 [3653/3978 (92%)]\tLoss: 0.113836\n",
            "Train Epoch: 3 [3654/3978 (92%)]\tLoss: 0.053711\n",
            "Train Epoch: 3 [3655/3978 (92%)]\tLoss: 1.059829\n",
            "Train Epoch: 3 [3656/3978 (92%)]\tLoss: 0.057932\n",
            "Train Epoch: 3 [3657/3978 (92%)]\tLoss: 0.664620\n",
            "Train Epoch: 3 [3658/3978 (92%)]\tLoss: 0.095381\n",
            "Train Epoch: 3 [3659/3978 (92%)]\tLoss: 0.100686\n",
            "Train Epoch: 3 [3660/3978 (92%)]\tLoss: 0.079780\n",
            "Train Epoch: 3 [3661/3978 (92%)]\tLoss: 0.071540\n",
            "Train Epoch: 3 [3662/3978 (92%)]\tLoss: 0.112959\n",
            "Train Epoch: 3 [3663/3978 (92%)]\tLoss: 0.077380\n",
            "Train Epoch: 3 [3664/3978 (92%)]\tLoss: 0.101423\n",
            "Train Epoch: 3 [3665/3978 (92%)]\tLoss: 0.057747\n",
            "Train Epoch: 3 [3666/3978 (92%)]\tLoss: 0.075700\n",
            "Train Epoch: 3 [3667/3978 (92%)]\tLoss: 0.125251\n",
            "Train Epoch: 3 [3668/3978 (92%)]\tLoss: 0.088147\n",
            "Train Epoch: 3 [3669/3978 (92%)]\tLoss: 0.075895\n",
            "Train Epoch: 3 [3670/3978 (92%)]\tLoss: 0.095111\n",
            "Train Epoch: 3 [3671/3978 (92%)]\tLoss: 0.093733\n",
            "Train Epoch: 3 [3672/3978 (92%)]\tLoss: 0.143930\n",
            "Train Epoch: 3 [3673/3978 (92%)]\tLoss: 0.083444\n",
            "Train Epoch: 3 [3674/3978 (92%)]\tLoss: 0.068195\n",
            "Train Epoch: 3 [3675/3978 (92%)]\tLoss: 0.104634\n",
            "Train Epoch: 3 [3676/3978 (92%)]\tLoss: 0.543363\n",
            "Train Epoch: 3 [3677/3978 (92%)]\tLoss: 0.105023\n",
            "Train Epoch: 3 [3678/3978 (92%)]\tLoss: 0.137243\n",
            "Train Epoch: 3 [3679/3978 (92%)]\tLoss: 0.109503\n",
            "Train Epoch: 3 [3680/3978 (93%)]\tLoss: 0.047881\n",
            "Train Epoch: 3 [3681/3978 (93%)]\tLoss: 0.704665\n",
            "Train Epoch: 3 [3682/3978 (93%)]\tLoss: 0.126438\n",
            "Train Epoch: 3 [3683/3978 (93%)]\tLoss: 0.060686\n",
            "Train Epoch: 3 [3684/3978 (93%)]\tLoss: 0.904665\n",
            "Train Epoch: 3 [3685/3978 (93%)]\tLoss: 0.493002\n",
            "Train Epoch: 3 [3686/3978 (93%)]\tLoss: 0.092279\n",
            "Train Epoch: 3 [3687/3978 (93%)]\tLoss: 0.118032\n",
            "Train Epoch: 3 [3688/3978 (93%)]\tLoss: 0.084339\n",
            "Train Epoch: 3 [3689/3978 (93%)]\tLoss: 0.081364\n",
            "Train Epoch: 3 [3690/3978 (93%)]\tLoss: 0.085647\n",
            "Train Epoch: 3 [3691/3978 (93%)]\tLoss: 0.081656\n",
            "Train Epoch: 3 [3692/3978 (93%)]\tLoss: 0.126657\n",
            "Train Epoch: 3 [3693/3978 (93%)]\tLoss: 0.890860\n",
            "Train Epoch: 3 [3694/3978 (93%)]\tLoss: 0.068130\n",
            "Train Epoch: 3 [3695/3978 (93%)]\tLoss: 0.096756\n",
            "Train Epoch: 3 [3696/3978 (93%)]\tLoss: 0.091592\n",
            "Train Epoch: 3 [3697/3978 (93%)]\tLoss: 0.073349\n",
            "Train Epoch: 3 [3698/3978 (93%)]\tLoss: 0.072121\n",
            "Train Epoch: 3 [3699/3978 (93%)]\tLoss: 0.068056\n",
            "Train Epoch: 3 [3700/3978 (93%)]\tLoss: 1.175267\n",
            "Train Epoch: 3 [3701/3978 (93%)]\tLoss: 1.157518\n",
            "Train Epoch: 3 [3702/3978 (93%)]\tLoss: 0.085270\n",
            "Train Epoch: 3 [3703/3978 (93%)]\tLoss: 0.067037\n",
            "Train Epoch: 3 [3704/3978 (93%)]\tLoss: 0.089149\n",
            "Train Epoch: 3 [3705/3978 (93%)]\tLoss: 0.084135\n",
            "Train Epoch: 3 [3706/3978 (93%)]\tLoss: 0.055490\n",
            "Train Epoch: 3 [3707/3978 (93%)]\tLoss: 0.670503\n",
            "Train Epoch: 3 [3708/3978 (93%)]\tLoss: 0.072874\n",
            "Train Epoch: 3 [3709/3978 (93%)]\tLoss: 0.089684\n",
            "Train Epoch: 3 [3710/3978 (93%)]\tLoss: 0.052324\n",
            "Train Epoch: 3 [3711/3978 (93%)]\tLoss: 0.164486\n",
            "Train Epoch: 3 [3712/3978 (93%)]\tLoss: 0.107430\n",
            "Train Epoch: 3 [3713/3978 (93%)]\tLoss: 0.061806\n",
            "Train Epoch: 3 [3714/3978 (93%)]\tLoss: 0.163446\n",
            "Train Epoch: 3 [3715/3978 (93%)]\tLoss: 0.044086\n",
            "Train Epoch: 3 [3716/3978 (93%)]\tLoss: 0.042703\n",
            "Train Epoch: 3 [3717/3978 (93%)]\tLoss: 0.159396\n",
            "Train Epoch: 3 [3718/3978 (93%)]\tLoss: 0.116494\n",
            "Train Epoch: 3 [3719/3978 (93%)]\tLoss: 0.143996\n",
            "Train Epoch: 3 [3720/3978 (94%)]\tLoss: 0.157020\n",
            "Train Epoch: 3 [3721/3978 (94%)]\tLoss: 0.762120\n",
            "Train Epoch: 3 [3722/3978 (94%)]\tLoss: 0.076302\n",
            "Train Epoch: 3 [3723/3978 (94%)]\tLoss: 0.788268\n",
            "Train Epoch: 3 [3724/3978 (94%)]\tLoss: 0.105680\n",
            "Train Epoch: 3 [3725/3978 (94%)]\tLoss: 0.976610\n",
            "Train Epoch: 3 [3726/3978 (94%)]\tLoss: 0.063608\n",
            "Train Epoch: 3 [3727/3978 (94%)]\tLoss: 0.073391\n",
            "Train Epoch: 3 [3728/3978 (94%)]\tLoss: 0.138011\n",
            "Train Epoch: 3 [3729/3978 (94%)]\tLoss: 0.120026\n",
            "Train Epoch: 3 [3730/3978 (94%)]\tLoss: 0.110085\n",
            "Train Epoch: 3 [3731/3978 (94%)]\tLoss: 0.111125\n",
            "Train Epoch: 3 [3732/3978 (94%)]\tLoss: 1.137791\n",
            "Train Epoch: 3 [3733/3978 (94%)]\tLoss: 0.077914\n",
            "Train Epoch: 3 [3734/3978 (94%)]\tLoss: 0.070822\n",
            "Train Epoch: 3 [3735/3978 (94%)]\tLoss: 0.770525\n",
            "Train Epoch: 3 [3736/3978 (94%)]\tLoss: 0.074267\n",
            "Train Epoch: 3 [3737/3978 (94%)]\tLoss: 0.092346\n",
            "Train Epoch: 3 [3738/3978 (94%)]\tLoss: 0.104115\n",
            "Train Epoch: 3 [3739/3978 (94%)]\tLoss: 0.067293\n",
            "Train Epoch: 3 [3740/3978 (94%)]\tLoss: 0.107344\n",
            "Train Epoch: 3 [3741/3978 (94%)]\tLoss: 0.060200\n",
            "Train Epoch: 3 [3742/3978 (94%)]\tLoss: 0.128404\n",
            "Train Epoch: 3 [3743/3978 (94%)]\tLoss: 0.132089\n",
            "Train Epoch: 3 [3744/3978 (94%)]\tLoss: 0.099351\n",
            "Train Epoch: 3 [3745/3978 (94%)]\tLoss: 0.924008\n",
            "Train Epoch: 3 [3746/3978 (94%)]\tLoss: 0.645305\n",
            "Train Epoch: 3 [3747/3978 (94%)]\tLoss: 0.742418\n",
            "Train Epoch: 3 [3748/3978 (94%)]\tLoss: 0.060027\n",
            "Train Epoch: 3 [3749/3978 (94%)]\tLoss: 0.067604\n",
            "Train Epoch: 3 [3750/3978 (94%)]\tLoss: 0.130235\n",
            "Train Epoch: 3 [3751/3978 (94%)]\tLoss: 0.076668\n",
            "Train Epoch: 3 [3752/3978 (94%)]\tLoss: 0.070448\n",
            "Train Epoch: 3 [3753/3978 (94%)]\tLoss: 0.056676\n",
            "Train Epoch: 3 [3754/3978 (94%)]\tLoss: 0.053858\n",
            "Train Epoch: 3 [3755/3978 (94%)]\tLoss: 0.057814\n",
            "Train Epoch: 3 [3756/3978 (94%)]\tLoss: 0.567522\n",
            "Train Epoch: 3 [3757/3978 (94%)]\tLoss: 0.089454\n",
            "Train Epoch: 3 [3758/3978 (94%)]\tLoss: 0.135277\n",
            "Train Epoch: 3 [3759/3978 (94%)]\tLoss: 0.156360\n",
            "Train Epoch: 3 [3760/3978 (95%)]\tLoss: 0.062153\n",
            "Train Epoch: 3 [3761/3978 (95%)]\tLoss: 0.138503\n",
            "Train Epoch: 3 [3762/3978 (95%)]\tLoss: 0.081547\n",
            "Train Epoch: 3 [3763/3978 (95%)]\tLoss: 0.558167\n",
            "Train Epoch: 3 [3764/3978 (95%)]\tLoss: 0.081776\n",
            "Train Epoch: 3 [3765/3978 (95%)]\tLoss: 0.697794\n",
            "Train Epoch: 3 [3766/3978 (95%)]\tLoss: 0.045981\n",
            "Train Epoch: 3 [3767/3978 (95%)]\tLoss: 0.162321\n",
            "Train Epoch: 3 [3768/3978 (95%)]\tLoss: 0.045821\n",
            "Train Epoch: 3 [3769/3978 (95%)]\tLoss: 0.048544\n",
            "Train Epoch: 3 [3770/3978 (95%)]\tLoss: 0.113214\n",
            "Train Epoch: 3 [3771/3978 (95%)]\tLoss: 0.165912\n",
            "Train Epoch: 3 [3772/3978 (95%)]\tLoss: 0.698098\n",
            "Train Epoch: 3 [3773/3978 (95%)]\tLoss: 0.045183\n",
            "Train Epoch: 3 [3774/3978 (95%)]\tLoss: 0.063095\n",
            "Train Epoch: 3 [3775/3978 (95%)]\tLoss: 0.047683\n",
            "Train Epoch: 3 [3776/3978 (95%)]\tLoss: 0.132537\n",
            "Train Epoch: 3 [3777/3978 (95%)]\tLoss: 0.138573\n",
            "Train Epoch: 3 [3778/3978 (95%)]\tLoss: 0.107116\n",
            "Train Epoch: 3 [3779/3978 (95%)]\tLoss: 1.001409\n",
            "Train Epoch: 3 [3780/3978 (95%)]\tLoss: 0.101393\n",
            "Train Epoch: 3 [3781/3978 (95%)]\tLoss: 0.098658\n",
            "Train Epoch: 3 [3782/3978 (95%)]\tLoss: 0.681963\n",
            "Train Epoch: 3 [3783/3978 (95%)]\tLoss: 0.090395\n",
            "Train Epoch: 3 [3784/3978 (95%)]\tLoss: 0.095312\n",
            "Train Epoch: 3 [3785/3978 (95%)]\tLoss: 0.085882\n",
            "Train Epoch: 3 [3786/3978 (95%)]\tLoss: 0.104041\n",
            "Train Epoch: 3 [3787/3978 (95%)]\tLoss: 0.095739\n",
            "Train Epoch: 3 [3788/3978 (95%)]\tLoss: 0.076511\n",
            "Train Epoch: 3 [3789/3978 (95%)]\tLoss: 0.088917\n",
            "Train Epoch: 3 [3790/3978 (95%)]\tLoss: 0.654109\n",
            "Train Epoch: 3 [3791/3978 (95%)]\tLoss: 0.124611\n",
            "Train Epoch: 3 [3792/3978 (95%)]\tLoss: 0.138104\n",
            "Train Epoch: 3 [3793/3978 (95%)]\tLoss: 0.089215\n",
            "Train Epoch: 3 [3794/3978 (95%)]\tLoss: 0.090688\n",
            "Train Epoch: 3 [3795/3978 (95%)]\tLoss: 0.077405\n",
            "Train Epoch: 3 [3796/3978 (95%)]\tLoss: 0.117033\n",
            "Train Epoch: 3 [3797/3978 (95%)]\tLoss: 0.097961\n",
            "Train Epoch: 3 [3798/3978 (95%)]\tLoss: 0.600748\n",
            "Train Epoch: 3 [3799/3978 (96%)]\tLoss: 0.098046\n",
            "Train Epoch: 3 [3800/3978 (96%)]\tLoss: 0.089916\n",
            "Train Epoch: 3 [3801/3978 (96%)]\tLoss: 0.898756\n",
            "Train Epoch: 3 [3802/3978 (96%)]\tLoss: 0.095067\n",
            "Train Epoch: 3 [3803/3978 (96%)]\tLoss: 0.057331\n",
            "Train Epoch: 3 [3804/3978 (96%)]\tLoss: 0.091163\n",
            "Train Epoch: 3 [3805/3978 (96%)]\tLoss: 0.089096\n",
            "Train Epoch: 3 [3806/3978 (96%)]\tLoss: 0.116075\n",
            "Train Epoch: 3 [3807/3978 (96%)]\tLoss: 0.056545\n",
            "Train Epoch: 3 [3808/3978 (96%)]\tLoss: 0.090122\n",
            "Train Epoch: 3 [3809/3978 (96%)]\tLoss: 0.057392\n",
            "Train Epoch: 3 [3810/3978 (96%)]\tLoss: 0.113093\n",
            "Train Epoch: 3 [3811/3978 (96%)]\tLoss: 0.522776\n",
            "Train Epoch: 3 [3812/3978 (96%)]\tLoss: 0.101293\n",
            "Train Epoch: 3 [3813/3978 (96%)]\tLoss: 0.105009\n",
            "Train Epoch: 3 [3814/3978 (96%)]\tLoss: 0.099233\n",
            "Train Epoch: 3 [3815/3978 (96%)]\tLoss: 0.124002\n",
            "Train Epoch: 3 [3816/3978 (96%)]\tLoss: 0.073164\n",
            "Train Epoch: 3 [3817/3978 (96%)]\tLoss: 0.064101\n",
            "Train Epoch: 3 [3818/3978 (96%)]\tLoss: 0.084943\n",
            "Train Epoch: 3 [3819/3978 (96%)]\tLoss: 0.807959\n",
            "Train Epoch: 3 [3820/3978 (96%)]\tLoss: 0.074949\n",
            "Train Epoch: 3 [3821/3978 (96%)]\tLoss: 0.099653\n",
            "Train Epoch: 3 [3822/3978 (96%)]\tLoss: 0.103544\n",
            "Train Epoch: 3 [3823/3978 (96%)]\tLoss: 0.094567\n",
            "Train Epoch: 3 [3824/3978 (96%)]\tLoss: 0.109650\n",
            "Train Epoch: 3 [3825/3978 (96%)]\tLoss: 0.064700\n",
            "Train Epoch: 3 [3826/3978 (96%)]\tLoss: 0.103585\n",
            "Train Epoch: 3 [3827/3978 (96%)]\tLoss: 0.756373\n",
            "Train Epoch: 3 [3828/3978 (96%)]\tLoss: 0.068811\n",
            "Train Epoch: 3 [3829/3978 (96%)]\tLoss: 0.084335\n",
            "Train Epoch: 3 [3830/3978 (96%)]\tLoss: 0.070225\n",
            "Train Epoch: 3 [3831/3978 (96%)]\tLoss: 0.094495\n",
            "Train Epoch: 3 [3832/3978 (96%)]\tLoss: 0.770043\n",
            "Train Epoch: 3 [3833/3978 (96%)]\tLoss: 0.060528\n",
            "Train Epoch: 3 [3834/3978 (96%)]\tLoss: 0.525536\n",
            "Train Epoch: 3 [3835/3978 (96%)]\tLoss: 0.064543\n",
            "Train Epoch: 3 [3836/3978 (96%)]\tLoss: 0.920689\n",
            "Train Epoch: 3 [3837/3978 (96%)]\tLoss: 0.120529\n",
            "Train Epoch: 3 [3838/3978 (96%)]\tLoss: 0.862890\n",
            "Train Epoch: 3 [3839/3978 (97%)]\tLoss: 0.124081\n",
            "Train Epoch: 3 [3840/3978 (97%)]\tLoss: 0.097063\n",
            "Train Epoch: 3 [3841/3978 (97%)]\tLoss: 0.120787\n",
            "Train Epoch: 3 [3842/3978 (97%)]\tLoss: 1.042136\n",
            "Train Epoch: 3 [3843/3978 (97%)]\tLoss: 0.612813\n",
            "Train Epoch: 3 [3844/3978 (97%)]\tLoss: 0.074407\n",
            "Train Epoch: 3 [3845/3978 (97%)]\tLoss: 0.058540\n",
            "Train Epoch: 3 [3846/3978 (97%)]\tLoss: 0.093315\n",
            "Train Epoch: 3 [3847/3978 (97%)]\tLoss: 0.064113\n",
            "Train Epoch: 3 [3848/3978 (97%)]\tLoss: 0.119002\n",
            "Train Epoch: 3 [3849/3978 (97%)]\tLoss: 0.778462\n",
            "Train Epoch: 3 [3850/3978 (97%)]\tLoss: 0.117938\n",
            "Train Epoch: 3 [3851/3978 (97%)]\tLoss: 0.065729\n",
            "Train Epoch: 3 [3852/3978 (97%)]\tLoss: 0.864409\n",
            "Train Epoch: 3 [3853/3978 (97%)]\tLoss: 0.083669\n",
            "Train Epoch: 3 [3854/3978 (97%)]\tLoss: 0.139055\n",
            "Train Epoch: 3 [3855/3978 (97%)]\tLoss: 0.113655\n",
            "Train Epoch: 3 [3856/3978 (97%)]\tLoss: 0.068638\n",
            "Train Epoch: 3 [3857/3978 (97%)]\tLoss: 0.100777\n",
            "Train Epoch: 3 [3858/3978 (97%)]\tLoss: 0.140624\n",
            "Train Epoch: 3 [3859/3978 (97%)]\tLoss: 0.795258\n",
            "Train Epoch: 3 [3860/3978 (97%)]\tLoss: 0.075307\n",
            "Train Epoch: 3 [3861/3978 (97%)]\tLoss: 0.142745\n",
            "Train Epoch: 3 [3862/3978 (97%)]\tLoss: 0.066604\n",
            "Train Epoch: 3 [3863/3978 (97%)]\tLoss: 0.117799\n",
            "Train Epoch: 3 [3864/3978 (97%)]\tLoss: 0.735389\n",
            "Train Epoch: 3 [3865/3978 (97%)]\tLoss: 0.726935\n",
            "Train Epoch: 3 [3866/3978 (97%)]\tLoss: 0.114877\n",
            "Train Epoch: 3 [3867/3978 (97%)]\tLoss: 0.136148\n",
            "Train Epoch: 3 [3868/3978 (97%)]\tLoss: 0.697401\n",
            "Train Epoch: 3 [3869/3978 (97%)]\tLoss: 0.093604\n",
            "Train Epoch: 3 [3870/3978 (97%)]\tLoss: 0.074425\n",
            "Train Epoch: 3 [3871/3978 (97%)]\tLoss: 0.123506\n",
            "Train Epoch: 3 [3872/3978 (97%)]\tLoss: 0.094851\n",
            "Train Epoch: 3 [3873/3978 (97%)]\tLoss: 0.074769\n",
            "Train Epoch: 3 [3874/3978 (97%)]\tLoss: 0.117126\n",
            "Train Epoch: 3 [3875/3978 (97%)]\tLoss: 0.088446\n",
            "Train Epoch: 3 [3876/3978 (97%)]\tLoss: 0.125431\n",
            "Train Epoch: 3 [3877/3978 (97%)]\tLoss: 0.082521\n",
            "Train Epoch: 3 [3878/3978 (97%)]\tLoss: 0.725076\n",
            "Train Epoch: 3 [3879/3978 (98%)]\tLoss: 0.801509\n",
            "Train Epoch: 3 [3880/3978 (98%)]\tLoss: 0.077894\n",
            "Train Epoch: 3 [3881/3978 (98%)]\tLoss: 0.090186\n",
            "Train Epoch: 3 [3882/3978 (98%)]\tLoss: 0.094634\n",
            "Train Epoch: 3 [3883/3978 (98%)]\tLoss: 0.096604\n",
            "Train Epoch: 3 [3884/3978 (98%)]\tLoss: 0.099497\n",
            "Train Epoch: 3 [3885/3978 (98%)]\tLoss: 0.067139\n",
            "Train Epoch: 3 [3886/3978 (98%)]\tLoss: 0.627554\n",
            "Train Epoch: 3 [3887/3978 (98%)]\tLoss: 0.091119\n",
            "Train Epoch: 3 [3888/3978 (98%)]\tLoss: 0.112007\n",
            "Train Epoch: 3 [3889/3978 (98%)]\tLoss: 0.141441\n",
            "Train Epoch: 3 [3890/3978 (98%)]\tLoss: 0.111737\n",
            "Train Epoch: 3 [3891/3978 (98%)]\tLoss: 0.095465\n",
            "Train Epoch: 3 [3892/3978 (98%)]\tLoss: 0.900136\n",
            "Train Epoch: 3 [3893/3978 (98%)]\tLoss: 0.083031\n",
            "Train Epoch: 3 [3894/3978 (98%)]\tLoss: 0.682666\n",
            "Train Epoch: 3 [3895/3978 (98%)]\tLoss: 1.081808\n",
            "Train Epoch: 3 [3896/3978 (98%)]\tLoss: 0.118555\n",
            "Train Epoch: 3 [3897/3978 (98%)]\tLoss: 0.069821\n",
            "Train Epoch: 3 [3898/3978 (98%)]\tLoss: 0.085104\n",
            "Train Epoch: 3 [3899/3978 (98%)]\tLoss: 0.081032\n",
            "Train Epoch: 3 [3900/3978 (98%)]\tLoss: 0.123984\n",
            "Train Epoch: 3 [3901/3978 (98%)]\tLoss: 0.600522\n",
            "Train Epoch: 3 [3902/3978 (98%)]\tLoss: 0.130633\n",
            "Train Epoch: 3 [3903/3978 (98%)]\tLoss: 0.137804\n",
            "Train Epoch: 3 [3904/3978 (98%)]\tLoss: 0.083155\n",
            "Train Epoch: 3 [3905/3978 (98%)]\tLoss: 0.054572\n",
            "Train Epoch: 3 [3906/3978 (98%)]\tLoss: 0.053733\n",
            "Train Epoch: 3 [3907/3978 (98%)]\tLoss: 0.133847\n",
            "Train Epoch: 3 [3908/3978 (98%)]\tLoss: 0.141728\n",
            "Train Epoch: 3 [3909/3978 (98%)]\tLoss: 0.052486\n",
            "Train Epoch: 3 [3910/3978 (98%)]\tLoss: 0.116895\n",
            "Train Epoch: 3 [3911/3978 (98%)]\tLoss: 0.116915\n",
            "Train Epoch: 3 [3912/3978 (98%)]\tLoss: 0.076410\n",
            "Train Epoch: 3 [3913/3978 (98%)]\tLoss: 0.100279\n",
            "Train Epoch: 3 [3914/3978 (98%)]\tLoss: 0.096863\n",
            "Train Epoch: 3 [3915/3978 (98%)]\tLoss: 0.066353\n",
            "Train Epoch: 3 [3916/3978 (98%)]\tLoss: 0.160221\n",
            "Train Epoch: 3 [3917/3978 (98%)]\tLoss: 0.720954\n",
            "Train Epoch: 3 [3918/3978 (98%)]\tLoss: 0.120826\n",
            "Train Epoch: 3 [3919/3978 (99%)]\tLoss: 0.057687\n",
            "Train Epoch: 3 [3920/3978 (99%)]\tLoss: 0.704961\n",
            "Train Epoch: 3 [3921/3978 (99%)]\tLoss: 0.783906\n",
            "Train Epoch: 3 [3922/3978 (99%)]\tLoss: 1.214298\n",
            "Train Epoch: 3 [3923/3978 (99%)]\tLoss: 0.052889\n",
            "Train Epoch: 3 [3924/3978 (99%)]\tLoss: 0.153837\n",
            "Train Epoch: 3 [3925/3978 (99%)]\tLoss: 0.062075\n",
            "Train Epoch: 3 [3926/3978 (99%)]\tLoss: 0.152144\n",
            "Train Epoch: 3 [3927/3978 (99%)]\tLoss: 1.019393\n",
            "Train Epoch: 3 [3928/3978 (99%)]\tLoss: 0.059545\n",
            "Train Epoch: 3 [3929/3978 (99%)]\tLoss: 0.101226\n",
            "Train Epoch: 3 [3930/3978 (99%)]\tLoss: 0.066709\n",
            "Train Epoch: 3 [3931/3978 (99%)]\tLoss: 0.155440\n",
            "Train Epoch: 3 [3932/3978 (99%)]\tLoss: 0.088936\n",
            "Train Epoch: 3 [3933/3978 (99%)]\tLoss: 0.627995\n",
            "Train Epoch: 3 [3934/3978 (99%)]\tLoss: 0.154429\n",
            "Train Epoch: 3 [3935/3978 (99%)]\tLoss: 0.153376\n",
            "Train Epoch: 3 [3936/3978 (99%)]\tLoss: 0.097448\n",
            "Train Epoch: 3 [3937/3978 (99%)]\tLoss: 0.096625\n",
            "Train Epoch: 3 [3938/3978 (99%)]\tLoss: 0.866426\n",
            "Train Epoch: 3 [3939/3978 (99%)]\tLoss: 0.100207\n",
            "Train Epoch: 3 [3940/3978 (99%)]\tLoss: 0.111709\n",
            "Train Epoch: 3 [3941/3978 (99%)]\tLoss: 0.097726\n",
            "Train Epoch: 3 [3942/3978 (99%)]\tLoss: 0.094417\n",
            "Train Epoch: 3 [3943/3978 (99%)]\tLoss: 0.086127\n",
            "Train Epoch: 3 [3944/3978 (99%)]\tLoss: 0.126237\n",
            "Train Epoch: 3 [3945/3978 (99%)]\tLoss: 0.096835\n",
            "Train Epoch: 3 [3946/3978 (99%)]\tLoss: 0.086967\n",
            "Train Epoch: 3 [3947/3978 (99%)]\tLoss: 0.083778\n",
            "Train Epoch: 3 [3948/3978 (99%)]\tLoss: 0.079371\n",
            "Train Epoch: 3 [3949/3978 (99%)]\tLoss: 0.077930\n",
            "Train Epoch: 3 [3950/3978 (99%)]\tLoss: 0.072493\n",
            "Train Epoch: 3 [3951/3978 (99%)]\tLoss: 0.727778\n",
            "Train Epoch: 3 [3952/3978 (99%)]\tLoss: 0.089627\n",
            "Train Epoch: 3 [3953/3978 (99%)]\tLoss: 0.074771\n",
            "Train Epoch: 3 [3954/3978 (99%)]\tLoss: 0.076319\n",
            "Train Epoch: 3 [3955/3978 (99%)]\tLoss: 0.079399\n",
            "Train Epoch: 3 [3956/3978 (99%)]\tLoss: 0.085041\n",
            "Train Epoch: 3 [3957/3978 (99%)]\tLoss: 0.116473\n",
            "Train Epoch: 3 [3958/3978 (99%)]\tLoss: 0.083325\n",
            "Train Epoch: 3 [3959/3978 (100%)]\tLoss: 0.730479\n",
            "Train Epoch: 3 [3960/3978 (100%)]\tLoss: 0.094819\n",
            "Train Epoch: 3 [3961/3978 (100%)]\tLoss: 0.090393\n",
            "Train Epoch: 3 [3962/3978 (100%)]\tLoss: 0.135621\n",
            "Train Epoch: 3 [3963/3978 (100%)]\tLoss: 0.708981\n",
            "Train Epoch: 3 [3964/3978 (100%)]\tLoss: 0.106778\n",
            "Train Epoch: 3 [3965/3978 (100%)]\tLoss: 1.093719\n",
            "Train Epoch: 3 [3966/3978 (100%)]\tLoss: 0.055842\n",
            "Train Epoch: 3 [3967/3978 (100%)]\tLoss: 0.138713\n",
            "Train Epoch: 3 [3968/3978 (100%)]\tLoss: 0.063345\n",
            "Train Epoch: 3 [3969/3978 (100%)]\tLoss: 0.097584\n",
            "Train Epoch: 3 [3970/3978 (100%)]\tLoss: 0.779004\n",
            "Train Epoch: 3 [3971/3978 (100%)]\tLoss: 0.058164\n",
            "Train Epoch: 3 [3972/3978 (100%)]\tLoss: 0.633961\n",
            "Train Epoch: 3 [3973/3978 (100%)]\tLoss: 0.794563\n",
            "Train Epoch: 3 [3974/3978 (100%)]\tLoss: 0.700418\n",
            "Train Epoch: 3 [3975/3978 (100%)]\tLoss: 0.107446\n",
            "Train Epoch: 3 [3976/3978 (100%)]\tLoss: 0.116501\n",
            "Train Epoch: 3 [3977/3978 (100%)]\tLoss: 0.054989\n",
            "Epoch\n",
            "train/train_loss: 0.05498891323804855\n",
            "\n",
            "Train Loss: 0.055, Valid Loss: 0.292479, Accuracy: 0.36\n",
            "Train Epoch: 4 [0/3978 (0%)]\tLoss: 0.071594\n",
            "Train Epoch: 4 [1/3978 (0%)]\tLoss: 0.099710\n",
            "Train Epoch: 4 [2/3978 (0%)]\tLoss: 0.711822\n",
            "Train Epoch: 4 [3/3978 (0%)]\tLoss: 0.066391\n",
            "Train Epoch: 4 [4/3978 (0%)]\tLoss: 0.628140\n",
            "Train Epoch: 4 [5/3978 (0%)]\tLoss: 0.604313\n",
            "Train Epoch: 4 [6/3978 (0%)]\tLoss: 0.073501\n",
            "Train Epoch: 4 [7/3978 (0%)]\tLoss: 0.155982\n",
            "Train Epoch: 4 [8/3978 (0%)]\tLoss: 0.066662\n",
            "Train Epoch: 4 [9/3978 (0%)]\tLoss: 0.070671\n",
            "Train Epoch: 4 [10/3978 (0%)]\tLoss: 0.143828\n",
            "Train Epoch: 4 [11/3978 (0%)]\tLoss: 0.136110\n",
            "Train Epoch: 4 [12/3978 (0%)]\tLoss: 0.112574\n",
            "Train Epoch: 4 [13/3978 (0%)]\tLoss: 0.071661\n",
            "Train Epoch: 4 [14/3978 (0%)]\tLoss: 0.146662\n",
            "Train Epoch: 4 [15/3978 (0%)]\tLoss: 0.119444\n",
            "Train Epoch: 4 [16/3978 (0%)]\tLoss: 0.073258\n",
            "Train Epoch: 4 [17/3978 (0%)]\tLoss: 0.115038\n",
            "Train Epoch: 4 [18/3978 (0%)]\tLoss: 0.129613\n",
            "Train Epoch: 4 [19/3978 (0%)]\tLoss: 0.075792\n",
            "Train Epoch: 4 [20/3978 (1%)]\tLoss: 0.075230\n",
            "Train Epoch: 4 [21/3978 (1%)]\tLoss: 0.068766\n",
            "Train Epoch: 4 [22/3978 (1%)]\tLoss: 0.107500\n",
            "Train Epoch: 4 [23/3978 (1%)]\tLoss: 0.094728\n",
            "Train Epoch: 4 [24/3978 (1%)]\tLoss: 0.129479\n",
            "Train Epoch: 4 [25/3978 (1%)]\tLoss: 0.718818\n",
            "Train Epoch: 4 [26/3978 (1%)]\tLoss: 0.121982\n",
            "Train Epoch: 4 [27/3978 (1%)]\tLoss: 0.078895\n",
            "Train Epoch: 4 [28/3978 (1%)]\tLoss: 0.100841\n",
            "Train Epoch: 4 [29/3978 (1%)]\tLoss: 0.098934\n",
            "Train Epoch: 4 [30/3978 (1%)]\tLoss: 0.082223\n",
            "Train Epoch: 4 [31/3978 (1%)]\tLoss: 0.077162\n",
            "Train Epoch: 4 [32/3978 (1%)]\tLoss: 0.070664\n",
            "Train Epoch: 4 [33/3978 (1%)]\tLoss: 0.100473\n",
            "Train Epoch: 4 [34/3978 (1%)]\tLoss: 0.070520\n",
            "Train Epoch: 4 [35/3978 (1%)]\tLoss: 0.102002\n",
            "Train Epoch: 4 [36/3978 (1%)]\tLoss: 0.084204\n",
            "Train Epoch: 4 [37/3978 (1%)]\tLoss: 0.114208\n",
            "Train Epoch: 4 [38/3978 (1%)]\tLoss: 0.872983\n",
            "Train Epoch: 4 [39/3978 (1%)]\tLoss: 0.722797\n",
            "Train Epoch: 4 [40/3978 (1%)]\tLoss: 0.736093\n",
            "Train Epoch: 4 [41/3978 (1%)]\tLoss: 0.081903\n",
            "Train Epoch: 4 [42/3978 (1%)]\tLoss: 0.065577\n",
            "Train Epoch: 4 [43/3978 (1%)]\tLoss: 0.079387\n",
            "Train Epoch: 4 [44/3978 (1%)]\tLoss: 0.083202\n",
            "Train Epoch: 4 [45/3978 (1%)]\tLoss: 0.883703\n",
            "Train Epoch: 4 [46/3978 (1%)]\tLoss: 0.556927\n",
            "Train Epoch: 4 [47/3978 (1%)]\tLoss: 0.082902\n",
            "Train Epoch: 4 [48/3978 (1%)]\tLoss: 0.090725\n",
            "Train Epoch: 4 [49/3978 (1%)]\tLoss: 0.072276\n",
            "Train Epoch: 4 [50/3978 (1%)]\tLoss: 0.098659\n",
            "Train Epoch: 4 [51/3978 (1%)]\tLoss: 0.867857\n",
            "Train Epoch: 4 [52/3978 (1%)]\tLoss: 0.088026\n",
            "Train Epoch: 4 [53/3978 (1%)]\tLoss: 0.708214\n",
            "Train Epoch: 4 [54/3978 (1%)]\tLoss: 0.674579\n",
            "Train Epoch: 4 [55/3978 (1%)]\tLoss: 0.067679\n",
            "Train Epoch: 4 [56/3978 (1%)]\tLoss: 0.136046\n",
            "Train Epoch: 4 [57/3978 (1%)]\tLoss: 0.533214\n",
            "Train Epoch: 4 [58/3978 (1%)]\tLoss: 0.103399\n",
            "Train Epoch: 4 [59/3978 (1%)]\tLoss: 0.097337\n",
            "Train Epoch: 4 [60/3978 (2%)]\tLoss: 0.140401\n",
            "Train Epoch: 4 [61/3978 (2%)]\tLoss: 0.084289\n",
            "Train Epoch: 4 [62/3978 (2%)]\tLoss: 0.586858\n",
            "Train Epoch: 4 [63/3978 (2%)]\tLoss: 0.143759\n",
            "Train Epoch: 4 [64/3978 (2%)]\tLoss: 0.144723\n",
            "Train Epoch: 4 [65/3978 (2%)]\tLoss: 0.134280\n",
            "Train Epoch: 4 [66/3978 (2%)]\tLoss: 0.113478\n",
            "Train Epoch: 4 [67/3978 (2%)]\tLoss: 0.620758\n",
            "Train Epoch: 4 [68/3978 (2%)]\tLoss: 0.100319\n",
            "Train Epoch: 4 [69/3978 (2%)]\tLoss: 0.088307\n",
            "Train Epoch: 4 [70/3978 (2%)]\tLoss: 0.918793\n",
            "Train Epoch: 4 [71/3978 (2%)]\tLoss: 0.095718\n",
            "Train Epoch: 4 [72/3978 (2%)]\tLoss: 0.088841\n",
            "Train Epoch: 4 [73/3978 (2%)]\tLoss: 0.090923\n",
            "Train Epoch: 4 [74/3978 (2%)]\tLoss: 0.083156\n",
            "Train Epoch: 4 [75/3978 (2%)]\tLoss: 0.461959\n",
            "Train Epoch: 4 [76/3978 (2%)]\tLoss: 0.084555\n",
            "Train Epoch: 4 [77/3978 (2%)]\tLoss: 0.086134\n",
            "Train Epoch: 4 [78/3978 (2%)]\tLoss: 0.579508\n",
            "Train Epoch: 4 [79/3978 (2%)]\tLoss: 0.091005\n",
            "Train Epoch: 4 [80/3978 (2%)]\tLoss: 0.148001\n",
            "Train Epoch: 4 [81/3978 (2%)]\tLoss: 0.099367\n",
            "Train Epoch: 4 [82/3978 (2%)]\tLoss: 0.081493\n",
            "Train Epoch: 4 [83/3978 (2%)]\tLoss: 0.091502\n",
            "Train Epoch: 4 [84/3978 (2%)]\tLoss: 0.115192\n",
            "Train Epoch: 4 [85/3978 (2%)]\tLoss: 0.137425\n",
            "Train Epoch: 4 [86/3978 (2%)]\tLoss: 0.602638\n",
            "Train Epoch: 4 [87/3978 (2%)]\tLoss: 0.095601\n",
            "Train Epoch: 4 [88/3978 (2%)]\tLoss: 0.104398\n",
            "Train Epoch: 4 [89/3978 (2%)]\tLoss: 0.134058\n",
            "Train Epoch: 4 [90/3978 (2%)]\tLoss: 0.838814\n",
            "Train Epoch: 4 [91/3978 (2%)]\tLoss: 0.099672\n",
            "Train Epoch: 4 [92/3978 (2%)]\tLoss: 0.988544\n",
            "Train Epoch: 4 [93/3978 (2%)]\tLoss: 0.101348\n",
            "Train Epoch: 4 [94/3978 (2%)]\tLoss: 0.099248\n",
            "Train Epoch: 4 [95/3978 (2%)]\tLoss: 0.101790\n",
            "Train Epoch: 4 [96/3978 (2%)]\tLoss: 0.097947\n",
            "Train Epoch: 4 [97/3978 (2%)]\tLoss: 0.122884\n",
            "Train Epoch: 4 [98/3978 (2%)]\tLoss: 0.465413\n",
            "Train Epoch: 4 [99/3978 (2%)]\tLoss: 0.140905\n",
            "Train Epoch: 4 [100/3978 (3%)]\tLoss: 0.136743\n",
            "Train Epoch: 4 [101/3978 (3%)]\tLoss: 0.806745\n",
            "Train Epoch: 4 [102/3978 (3%)]\tLoss: 0.097927\n",
            "Train Epoch: 4 [103/3978 (3%)]\tLoss: 0.092314\n",
            "Train Epoch: 4 [104/3978 (3%)]\tLoss: 0.084673\n",
            "Train Epoch: 4 [105/3978 (3%)]\tLoss: 0.464371\n",
            "Train Epoch: 4 [106/3978 (3%)]\tLoss: 0.077877\n",
            "Train Epoch: 4 [107/3978 (3%)]\tLoss: 0.146479\n",
            "Train Epoch: 4 [108/3978 (3%)]\tLoss: 0.124356\n",
            "Train Epoch: 4 [109/3978 (3%)]\tLoss: 0.114342\n",
            "Train Epoch: 4 [110/3978 (3%)]\tLoss: 0.084983\n",
            "Train Epoch: 4 [111/3978 (3%)]\tLoss: 0.105341\n",
            "Train Epoch: 4 [112/3978 (3%)]\tLoss: 0.128492\n",
            "Train Epoch: 4 [113/3978 (3%)]\tLoss: 0.110647\n",
            "Train Epoch: 4 [114/3978 (3%)]\tLoss: 0.770547\n",
            "Train Epoch: 4 [115/3978 (3%)]\tLoss: 0.100873\n",
            "Train Epoch: 4 [116/3978 (3%)]\tLoss: 0.075071\n",
            "Train Epoch: 4 [117/3978 (3%)]\tLoss: 0.072940\n",
            "Train Epoch: 4 [118/3978 (3%)]\tLoss: 0.112973\n",
            "Train Epoch: 4 [119/3978 (3%)]\tLoss: 0.115322\n",
            "Train Epoch: 4 [120/3978 (3%)]\tLoss: 0.646354\n",
            "Train Epoch: 4 [121/3978 (3%)]\tLoss: 0.098348\n",
            "Train Epoch: 4 [122/3978 (3%)]\tLoss: 0.069178\n",
            "Train Epoch: 4 [123/3978 (3%)]\tLoss: 0.108002\n",
            "Train Epoch: 4 [124/3978 (3%)]\tLoss: 0.639833\n",
            "Train Epoch: 4 [125/3978 (3%)]\tLoss: 0.068047\n",
            "Train Epoch: 4 [126/3978 (3%)]\tLoss: 0.096311\n",
            "Train Epoch: 4 [127/3978 (3%)]\tLoss: 0.096769\n",
            "Train Epoch: 4 [128/3978 (3%)]\tLoss: 0.085573\n",
            "Train Epoch: 4 [129/3978 (3%)]\tLoss: 0.103426\n",
            "Train Epoch: 4 [130/3978 (3%)]\tLoss: 0.088884\n",
            "Train Epoch: 4 [131/3978 (3%)]\tLoss: 1.264259\n",
            "Train Epoch: 4 [132/3978 (3%)]\tLoss: 0.083035\n",
            "Train Epoch: 4 [133/3978 (3%)]\tLoss: 0.099763\n",
            "Train Epoch: 4 [134/3978 (3%)]\tLoss: 0.433800\n",
            "Train Epoch: 4 [135/3978 (3%)]\tLoss: 0.079185\n",
            "Train Epoch: 4 [136/3978 (3%)]\tLoss: 0.094408\n",
            "Train Epoch: 4 [137/3978 (3%)]\tLoss: 0.111250\n",
            "Train Epoch: 4 [138/3978 (3%)]\tLoss: 0.116641\n",
            "Train Epoch: 4 [139/3978 (3%)]\tLoss: 0.093217\n",
            "Train Epoch: 4 [140/3978 (4%)]\tLoss: 0.095799\n",
            "Train Epoch: 4 [141/3978 (4%)]\tLoss: 0.102405\n",
            "Train Epoch: 4 [142/3978 (4%)]\tLoss: 0.071224\n",
            "Train Epoch: 4 [143/3978 (4%)]\tLoss: 0.073717\n",
            "Train Epoch: 4 [144/3978 (4%)]\tLoss: 0.933794\n",
            "Train Epoch: 4 [145/3978 (4%)]\tLoss: 0.072353\n",
            "Train Epoch: 4 [146/3978 (4%)]\tLoss: 0.718833\n",
            "Train Epoch: 4 [147/3978 (4%)]\tLoss: 0.086517\n",
            "Train Epoch: 4 [148/3978 (4%)]\tLoss: 0.081142\n",
            "Train Epoch: 4 [149/3978 (4%)]\tLoss: 0.093194\n",
            "Train Epoch: 4 [150/3978 (4%)]\tLoss: 0.783469\n",
            "Train Epoch: 4 [151/3978 (4%)]\tLoss: 0.109414\n",
            "Train Epoch: 4 [152/3978 (4%)]\tLoss: 0.107366\n",
            "Train Epoch: 4 [153/3978 (4%)]\tLoss: 0.714978\n",
            "Train Epoch: 4 [154/3978 (4%)]\tLoss: 0.073361\n",
            "Train Epoch: 4 [155/3978 (4%)]\tLoss: 0.110685\n",
            "Train Epoch: 4 [156/3978 (4%)]\tLoss: 0.109287\n",
            "Train Epoch: 4 [157/3978 (4%)]\tLoss: 0.098550\n",
            "Train Epoch: 4 [158/3978 (4%)]\tLoss: 0.095788\n",
            "Train Epoch: 4 [159/3978 (4%)]\tLoss: 0.086957\n",
            "Train Epoch: 4 [160/3978 (4%)]\tLoss: 0.122345\n",
            "Train Epoch: 4 [161/3978 (4%)]\tLoss: 0.106412\n",
            "Train Epoch: 4 [162/3978 (4%)]\tLoss: 0.080701\n",
            "Train Epoch: 4 [163/3978 (4%)]\tLoss: 0.096245\n",
            "Train Epoch: 4 [164/3978 (4%)]\tLoss: 0.697521\n",
            "Train Epoch: 4 [165/3978 (4%)]\tLoss: 0.100816\n",
            "Train Epoch: 4 [166/3978 (4%)]\tLoss: 0.082644\n",
            "Train Epoch: 4 [167/3978 (4%)]\tLoss: 1.757875\n",
            "Train Epoch: 4 [168/3978 (4%)]\tLoss: 0.084094\n",
            "Train Epoch: 4 [169/3978 (4%)]\tLoss: 0.092011\n",
            "Train Epoch: 4 [170/3978 (4%)]\tLoss: 0.677730\n",
            "Train Epoch: 4 [171/3978 (4%)]\tLoss: 0.083759\n",
            "Train Epoch: 4 [172/3978 (4%)]\tLoss: 0.135019\n",
            "Train Epoch: 4 [173/3978 (4%)]\tLoss: 0.084866\n",
            "Train Epoch: 4 [174/3978 (4%)]\tLoss: 0.090365\n",
            "Train Epoch: 4 [175/3978 (4%)]\tLoss: 0.073057\n",
            "Train Epoch: 4 [176/3978 (4%)]\tLoss: 0.097534\n",
            "Train Epoch: 4 [177/3978 (4%)]\tLoss: 0.089021\n",
            "Train Epoch: 4 [178/3978 (4%)]\tLoss: 0.084020\n",
            "Train Epoch: 4 [179/3978 (4%)]\tLoss: 0.076057\n",
            "Train Epoch: 4 [180/3978 (5%)]\tLoss: 0.074515\n",
            "Train Epoch: 4 [181/3978 (5%)]\tLoss: 0.133638\n",
            "Train Epoch: 4 [182/3978 (5%)]\tLoss: 0.665201\n",
            "Train Epoch: 4 [183/3978 (5%)]\tLoss: 0.091280\n",
            "Train Epoch: 4 [184/3978 (5%)]\tLoss: 0.112763\n",
            "Train Epoch: 4 [185/3978 (5%)]\tLoss: 0.999567\n",
            "Train Epoch: 4 [186/3978 (5%)]\tLoss: 0.130908\n",
            "Train Epoch: 4 [187/3978 (5%)]\tLoss: 0.707956\n",
            "Train Epoch: 4 [188/3978 (5%)]\tLoss: 0.111982\n",
            "Train Epoch: 4 [189/3978 (5%)]\tLoss: 0.076830\n",
            "Train Epoch: 4 [190/3978 (5%)]\tLoss: 0.100121\n",
            "Train Epoch: 4 [191/3978 (5%)]\tLoss: 0.088405\n",
            "Train Epoch: 4 [192/3978 (5%)]\tLoss: 0.074268\n",
            "Train Epoch: 4 [193/3978 (5%)]\tLoss: 0.083859\n",
            "Train Epoch: 4 [194/3978 (5%)]\tLoss: 0.098126\n",
            "Train Epoch: 4 [195/3978 (5%)]\tLoss: 0.079547\n",
            "Train Epoch: 4 [196/3978 (5%)]\tLoss: 0.077333\n",
            "Train Epoch: 4 [197/3978 (5%)]\tLoss: 0.085582\n",
            "Train Epoch: 4 [198/3978 (5%)]\tLoss: 0.732613\n",
            "Train Epoch: 4 [199/3978 (5%)]\tLoss: 0.844344\n",
            "Train Epoch: 4 [200/3978 (5%)]\tLoss: 1.080262\n",
            "Train Epoch: 4 [201/3978 (5%)]\tLoss: 0.073095\n",
            "Train Epoch: 4 [202/3978 (5%)]\tLoss: 0.910944\n",
            "Train Epoch: 4 [203/3978 (5%)]\tLoss: 0.721562\n",
            "Train Epoch: 4 [204/3978 (5%)]\tLoss: 0.732997\n",
            "Train Epoch: 4 [205/3978 (5%)]\tLoss: 0.090879\n",
            "Train Epoch: 4 [206/3978 (5%)]\tLoss: 0.590145\n",
            "Train Epoch: 4 [207/3978 (5%)]\tLoss: 0.096756\n",
            "Train Epoch: 4 [208/3978 (5%)]\tLoss: 0.115949\n",
            "Train Epoch: 4 [209/3978 (5%)]\tLoss: 0.073944\n",
            "Train Epoch: 4 [210/3978 (5%)]\tLoss: 0.119478\n",
            "Train Epoch: 4 [211/3978 (5%)]\tLoss: 0.076418\n",
            "Train Epoch: 4 [212/3978 (5%)]\tLoss: 1.061226\n",
            "Train Epoch: 4 [213/3978 (5%)]\tLoss: 0.082167\n",
            "Train Epoch: 4 [214/3978 (5%)]\tLoss: 0.067759\n",
            "Train Epoch: 4 [215/3978 (5%)]\tLoss: 0.070047\n",
            "Train Epoch: 4 [216/3978 (5%)]\tLoss: 0.121985\n",
            "Train Epoch: 4 [217/3978 (5%)]\tLoss: 0.105269\n",
            "Train Epoch: 4 [218/3978 (5%)]\tLoss: 0.955339\n",
            "Train Epoch: 4 [219/3978 (6%)]\tLoss: 0.093730\n",
            "Train Epoch: 4 [220/3978 (6%)]\tLoss: 0.917296\n",
            "Train Epoch: 4 [221/3978 (6%)]\tLoss: 0.114861\n",
            "Train Epoch: 4 [222/3978 (6%)]\tLoss: 0.063896\n",
            "Train Epoch: 4 [223/3978 (6%)]\tLoss: 0.064537\n",
            "Train Epoch: 4 [224/3978 (6%)]\tLoss: 0.068329\n",
            "Train Epoch: 4 [225/3978 (6%)]\tLoss: 0.149244\n",
            "Train Epoch: 4 [226/3978 (6%)]\tLoss: 0.164473\n",
            "Train Epoch: 4 [227/3978 (6%)]\tLoss: 0.131288\n",
            "Train Epoch: 4 [228/3978 (6%)]\tLoss: 0.117766\n",
            "Train Epoch: 4 [229/3978 (6%)]\tLoss: 0.174566\n",
            "Train Epoch: 4 [230/3978 (6%)]\tLoss: 0.078025\n",
            "Train Epoch: 4 [231/3978 (6%)]\tLoss: 0.137213\n",
            "Train Epoch: 4 [232/3978 (6%)]\tLoss: 0.123403\n",
            "Train Epoch: 4 [233/3978 (6%)]\tLoss: 0.100128\n",
            "Train Epoch: 4 [234/3978 (6%)]\tLoss: 0.904058\n",
            "Train Epoch: 4 [235/3978 (6%)]\tLoss: 0.094579\n",
            "Train Epoch: 4 [236/3978 (6%)]\tLoss: 0.119203\n",
            "Train Epoch: 4 [237/3978 (6%)]\tLoss: 0.078585\n",
            "Train Epoch: 4 [238/3978 (6%)]\tLoss: 0.079145\n",
            "Train Epoch: 4 [239/3978 (6%)]\tLoss: 0.080349\n",
            "Train Epoch: 4 [240/3978 (6%)]\tLoss: 0.088083\n",
            "Train Epoch: 4 [241/3978 (6%)]\tLoss: 0.106114\n",
            "Train Epoch: 4 [242/3978 (6%)]\tLoss: 0.081908\n",
            "Train Epoch: 4 [243/3978 (6%)]\tLoss: 0.084538\n",
            "Train Epoch: 4 [244/3978 (6%)]\tLoss: 0.082360\n",
            "Train Epoch: 4 [245/3978 (6%)]\tLoss: 0.096178\n",
            "Train Epoch: 4 [246/3978 (6%)]\tLoss: 0.093575\n",
            "Train Epoch: 4 [247/3978 (6%)]\tLoss: 0.078628\n",
            "Train Epoch: 4 [248/3978 (6%)]\tLoss: 0.076346\n",
            "Train Epoch: 4 [249/3978 (6%)]\tLoss: 0.076262\n",
            "Train Epoch: 4 [250/3978 (6%)]\tLoss: 0.076278\n",
            "Train Epoch: 4 [251/3978 (6%)]\tLoss: 0.079478\n",
            "Train Epoch: 4 [252/3978 (6%)]\tLoss: 0.883073\n",
            "Train Epoch: 4 [253/3978 (6%)]\tLoss: 0.096093\n",
            "Train Epoch: 4 [254/3978 (6%)]\tLoss: 0.730124\n",
            "Train Epoch: 4 [255/3978 (6%)]\tLoss: 1.237870\n",
            "Train Epoch: 4 [256/3978 (6%)]\tLoss: 0.088042\n",
            "Train Epoch: 4 [257/3978 (6%)]\tLoss: 0.080434\n",
            "Train Epoch: 4 [258/3978 (6%)]\tLoss: 0.079193\n",
            "Train Epoch: 4 [259/3978 (7%)]\tLoss: 0.104230\n",
            "Train Epoch: 4 [260/3978 (7%)]\tLoss: 0.103599\n",
            "Train Epoch: 4 [261/3978 (7%)]\tLoss: 0.690833\n",
            "Train Epoch: 4 [262/3978 (7%)]\tLoss: 0.101512\n",
            "Train Epoch: 4 [263/3978 (7%)]\tLoss: 0.072167\n",
            "Train Epoch: 4 [264/3978 (7%)]\tLoss: 0.127657\n",
            "Train Epoch: 4 [265/3978 (7%)]\tLoss: 0.083418\n",
            "Train Epoch: 4 [266/3978 (7%)]\tLoss: 0.077846\n",
            "Train Epoch: 4 [267/3978 (7%)]\tLoss: 0.099590\n",
            "Train Epoch: 4 [268/3978 (7%)]\tLoss: 1.684496\n",
            "Train Epoch: 4 [269/3978 (7%)]\tLoss: 0.099787\n",
            "Train Epoch: 4 [270/3978 (7%)]\tLoss: 0.999535\n",
            "Train Epoch: 4 [271/3978 (7%)]\tLoss: 0.091768\n",
            "Train Epoch: 4 [272/3978 (7%)]\tLoss: 0.076021\n",
            "Train Epoch: 4 [273/3978 (7%)]\tLoss: 0.100989\n",
            "Train Epoch: 4 [274/3978 (7%)]\tLoss: 0.128363\n",
            "Train Epoch: 4 [275/3978 (7%)]\tLoss: 0.978165\n",
            "Train Epoch: 4 [276/3978 (7%)]\tLoss: 0.632102\n",
            "Train Epoch: 4 [277/3978 (7%)]\tLoss: 0.079564\n",
            "Train Epoch: 4 [278/3978 (7%)]\tLoss: 0.083473\n",
            "Train Epoch: 4 [279/3978 (7%)]\tLoss: 0.080487\n",
            "Train Epoch: 4 [280/3978 (7%)]\tLoss: 0.082116\n",
            "Train Epoch: 4 [281/3978 (7%)]\tLoss: 0.076697\n",
            "Train Epoch: 4 [282/3978 (7%)]\tLoss: 0.078067\n",
            "Train Epoch: 4 [283/3978 (7%)]\tLoss: 0.095094\n",
            "Train Epoch: 4 [284/3978 (7%)]\tLoss: 0.077505\n",
            "Train Epoch: 4 [285/3978 (7%)]\tLoss: 0.682789\n",
            "Train Epoch: 4 [286/3978 (7%)]\tLoss: 0.077122\n",
            "Train Epoch: 4 [287/3978 (7%)]\tLoss: 0.086969\n",
            "Train Epoch: 4 [288/3978 (7%)]\tLoss: 0.087967\n",
            "Train Epoch: 4 [289/3978 (7%)]\tLoss: 0.096349\n",
            "Train Epoch: 4 [290/3978 (7%)]\tLoss: 0.084515\n",
            "Train Epoch: 4 [291/3978 (7%)]\tLoss: 0.110152\n",
            "Train Epoch: 4 [292/3978 (7%)]\tLoss: 0.735656\n",
            "Train Epoch: 4 [293/3978 (7%)]\tLoss: 0.704879\n",
            "Train Epoch: 4 [294/3978 (7%)]\tLoss: 0.138776\n",
            "Train Epoch: 4 [295/3978 (7%)]\tLoss: 0.077060\n",
            "Train Epoch: 4 [296/3978 (7%)]\tLoss: 0.087985\n",
            "Train Epoch: 4 [297/3978 (7%)]\tLoss: 0.086832\n",
            "Train Epoch: 4 [298/3978 (7%)]\tLoss: 0.073075\n",
            "Train Epoch: 4 [299/3978 (8%)]\tLoss: 0.088266\n",
            "Train Epoch: 4 [300/3978 (8%)]\tLoss: 0.072548\n",
            "Train Epoch: 4 [301/3978 (8%)]\tLoss: 0.116695\n",
            "Train Epoch: 4 [302/3978 (8%)]\tLoss: 0.062571\n",
            "Train Epoch: 4 [303/3978 (8%)]\tLoss: 0.062825\n",
            "Train Epoch: 4 [304/3978 (8%)]\tLoss: 0.822533\n",
            "Train Epoch: 4 [305/3978 (8%)]\tLoss: 0.079169\n",
            "Train Epoch: 4 [306/3978 (8%)]\tLoss: 0.737390\n",
            "Train Epoch: 4 [307/3978 (8%)]\tLoss: 0.058238\n",
            "Train Epoch: 4 [308/3978 (8%)]\tLoss: 0.074022\n",
            "Train Epoch: 4 [309/3978 (8%)]\tLoss: 0.099048\n",
            "Train Epoch: 4 [310/3978 (8%)]\tLoss: 0.127765\n",
            "Train Epoch: 4 [311/3978 (8%)]\tLoss: 0.065707\n",
            "Train Epoch: 4 [312/3978 (8%)]\tLoss: 0.690613\n",
            "Train Epoch: 4 [313/3978 (8%)]\tLoss: 0.172870\n",
            "Train Epoch: 4 [314/3978 (8%)]\tLoss: 0.063152\n",
            "Train Epoch: 4 [315/3978 (8%)]\tLoss: 0.123052\n",
            "Train Epoch: 4 [316/3978 (8%)]\tLoss: 0.129546\n",
            "Train Epoch: 4 [317/3978 (8%)]\tLoss: 0.084458\n",
            "Train Epoch: 4 [318/3978 (8%)]\tLoss: 0.053854\n",
            "Train Epoch: 4 [319/3978 (8%)]\tLoss: 0.118064\n",
            "Train Epoch: 4 [320/3978 (8%)]\tLoss: 0.575474\n",
            "Train Epoch: 4 [321/3978 (8%)]\tLoss: 0.139920\n",
            "Train Epoch: 4 [322/3978 (8%)]\tLoss: 0.060337\n",
            "Train Epoch: 4 [323/3978 (8%)]\tLoss: 0.718271\n",
            "Train Epoch: 4 [324/3978 (8%)]\tLoss: 0.057338\n",
            "Train Epoch: 4 [325/3978 (8%)]\tLoss: 0.837590\n",
            "Train Epoch: 4 [326/3978 (8%)]\tLoss: 0.141189\n",
            "Train Epoch: 4 [327/3978 (8%)]\tLoss: 0.062999\n",
            "Train Epoch: 4 [328/3978 (8%)]\tLoss: 0.068956\n",
            "Train Epoch: 4 [329/3978 (8%)]\tLoss: 0.061899\n",
            "Train Epoch: 4 [330/3978 (8%)]\tLoss: 0.060269\n",
            "Train Epoch: 4 [331/3978 (8%)]\tLoss: 0.055419\n",
            "Train Epoch: 4 [332/3978 (8%)]\tLoss: 0.641796\n",
            "Train Epoch: 4 [333/3978 (8%)]\tLoss: 0.126770\n",
            "Train Epoch: 4 [334/3978 (8%)]\tLoss: 0.128693\n",
            "Train Epoch: 4 [335/3978 (8%)]\tLoss: 0.118613\n",
            "Train Epoch: 4 [336/3978 (8%)]\tLoss: 0.118006\n",
            "Train Epoch: 4 [337/3978 (8%)]\tLoss: 0.123252\n",
            "Train Epoch: 4 [338/3978 (8%)]\tLoss: 0.058001\n",
            "Train Epoch: 4 [339/3978 (9%)]\tLoss: 0.814535\n",
            "Train Epoch: 4 [340/3978 (9%)]\tLoss: 0.063672\n",
            "Train Epoch: 4 [341/3978 (9%)]\tLoss: 0.079512\n",
            "Train Epoch: 4 [342/3978 (9%)]\tLoss: 0.073251\n",
            "Train Epoch: 4 [343/3978 (9%)]\tLoss: 0.110973\n",
            "Train Epoch: 4 [344/3978 (9%)]\tLoss: 0.544252\n",
            "Train Epoch: 4 [345/3978 (9%)]\tLoss: 0.582189\n",
            "Train Epoch: 4 [346/3978 (9%)]\tLoss: 0.068540\n",
            "Train Epoch: 4 [347/3978 (9%)]\tLoss: 0.107385\n",
            "Train Epoch: 4 [348/3978 (9%)]\tLoss: 0.107764\n",
            "Train Epoch: 4 [349/3978 (9%)]\tLoss: 0.817692\n",
            "Train Epoch: 4 [350/3978 (9%)]\tLoss: 0.118179\n",
            "Train Epoch: 4 [351/3978 (9%)]\tLoss: 0.613943\n",
            "Train Epoch: 4 [352/3978 (9%)]\tLoss: 0.129081\n",
            "Train Epoch: 4 [353/3978 (9%)]\tLoss: 0.097439\n",
            "Train Epoch: 4 [354/3978 (9%)]\tLoss: 0.092093\n",
            "Train Epoch: 4 [355/3978 (9%)]\tLoss: 0.077569\n",
            "Train Epoch: 4 [356/3978 (9%)]\tLoss: 0.097258\n",
            "Train Epoch: 4 [357/3978 (9%)]\tLoss: 0.086173\n",
            "Train Epoch: 4 [358/3978 (9%)]\tLoss: 0.096377\n",
            "Train Epoch: 4 [359/3978 (9%)]\tLoss: 0.710492\n",
            "Train Epoch: 4 [360/3978 (9%)]\tLoss: 0.073179\n",
            "Train Epoch: 4 [361/3978 (9%)]\tLoss: 0.119316\n",
            "Train Epoch: 4 [362/3978 (9%)]\tLoss: 0.088757\n",
            "Train Epoch: 4 [363/3978 (9%)]\tLoss: 0.076847\n",
            "Train Epoch: 4 [364/3978 (9%)]\tLoss: 0.068168\n",
            "Train Epoch: 4 [365/3978 (9%)]\tLoss: 0.077918\n",
            "Train Epoch: 4 [366/3978 (9%)]\tLoss: 0.672969\n",
            "Train Epoch: 4 [367/3978 (9%)]\tLoss: 0.652213\n",
            "Train Epoch: 4 [368/3978 (9%)]\tLoss: 0.064234\n",
            "Train Epoch: 4 [369/3978 (9%)]\tLoss: 0.131025\n",
            "Train Epoch: 4 [370/3978 (9%)]\tLoss: 0.744196\n",
            "Train Epoch: 4 [371/3978 (9%)]\tLoss: 0.134291\n",
            "Train Epoch: 4 [372/3978 (9%)]\tLoss: 0.626902\n",
            "Train Epoch: 4 [373/3978 (9%)]\tLoss: 0.146813\n",
            "Train Epoch: 4 [374/3978 (9%)]\tLoss: 0.061329\n",
            "Train Epoch: 4 [375/3978 (9%)]\tLoss: 0.713097\n",
            "Train Epoch: 4 [376/3978 (9%)]\tLoss: 0.154136\n",
            "Train Epoch: 4 [377/3978 (9%)]\tLoss: 0.147554\n",
            "Train Epoch: 4 [378/3978 (10%)]\tLoss: 0.600947\n",
            "Train Epoch: 4 [379/3978 (10%)]\tLoss: 0.561340\n",
            "Train Epoch: 4 [380/3978 (10%)]\tLoss: 0.129506\n",
            "Train Epoch: 4 [381/3978 (10%)]\tLoss: 0.909134\n",
            "Train Epoch: 4 [382/3978 (10%)]\tLoss: 1.124441\n",
            "Train Epoch: 4 [383/3978 (10%)]\tLoss: 0.113929\n",
            "Train Epoch: 4 [384/3978 (10%)]\tLoss: 0.083467\n",
            "Train Epoch: 4 [385/3978 (10%)]\tLoss: 0.629801\n",
            "Train Epoch: 4 [386/3978 (10%)]\tLoss: 0.116103\n",
            "Train Epoch: 4 [387/3978 (10%)]\tLoss: 0.535128\n",
            "Train Epoch: 4 [388/3978 (10%)]\tLoss: 0.098331\n",
            "Train Epoch: 4 [389/3978 (10%)]\tLoss: 0.104382\n",
            "Train Epoch: 4 [390/3978 (10%)]\tLoss: 0.109922\n",
            "Train Epoch: 4 [391/3978 (10%)]\tLoss: 0.102429\n",
            "Train Epoch: 4 [392/3978 (10%)]\tLoss: 0.570892\n",
            "Train Epoch: 4 [393/3978 (10%)]\tLoss: 0.122701\n",
            "Train Epoch: 4 [394/3978 (10%)]\tLoss: 0.117880\n",
            "Train Epoch: 4 [395/3978 (10%)]\tLoss: 0.510485\n",
            "Train Epoch: 4 [396/3978 (10%)]\tLoss: 0.104713\n",
            "Train Epoch: 4 [397/3978 (10%)]\tLoss: 0.114002\n",
            "Train Epoch: 4 [398/3978 (10%)]\tLoss: 0.178529\n",
            "Train Epoch: 4 [399/3978 (10%)]\tLoss: 0.104777\n",
            "Train Epoch: 4 [400/3978 (10%)]\tLoss: 0.112159\n",
            "Train Epoch: 4 [401/3978 (10%)]\tLoss: 0.120044\n",
            "Train Epoch: 4 [402/3978 (10%)]\tLoss: 0.090671\n",
            "Train Epoch: 4 [403/3978 (10%)]\tLoss: 0.120361\n",
            "Train Epoch: 4 [404/3978 (10%)]\tLoss: 0.145384\n",
            "Train Epoch: 4 [405/3978 (10%)]\tLoss: 0.559325\n",
            "Train Epoch: 4 [406/3978 (10%)]\tLoss: 0.088482\n",
            "Train Epoch: 4 [407/3978 (10%)]\tLoss: 0.141499\n",
            "Train Epoch: 4 [408/3978 (10%)]\tLoss: 0.538436\n",
            "Train Epoch: 4 [409/3978 (10%)]\tLoss: 0.865306\n",
            "Train Epoch: 4 [410/3978 (10%)]\tLoss: 0.134463\n",
            "Train Epoch: 4 [411/3978 (10%)]\tLoss: 0.196486\n",
            "Train Epoch: 4 [412/3978 (10%)]\tLoss: 0.124793\n",
            "Train Epoch: 4 [413/3978 (10%)]\tLoss: 0.099363\n",
            "Train Epoch: 4 [414/3978 (10%)]\tLoss: 0.483676\n",
            "Train Epoch: 4 [415/3978 (10%)]\tLoss: 0.079782\n",
            "Train Epoch: 4 [416/3978 (10%)]\tLoss: 0.087702\n",
            "Train Epoch: 4 [417/3978 (10%)]\tLoss: 0.080484\n",
            "Train Epoch: 4 [418/3978 (11%)]\tLoss: 0.093045\n",
            "Train Epoch: 4 [419/3978 (11%)]\tLoss: 0.137998\n",
            "Train Epoch: 4 [420/3978 (11%)]\tLoss: 0.083802\n",
            "Train Epoch: 4 [421/3978 (11%)]\tLoss: 0.143094\n",
            "Train Epoch: 4 [422/3978 (11%)]\tLoss: 0.072616\n",
            "Train Epoch: 4 [423/3978 (11%)]\tLoss: 0.139926\n",
            "Train Epoch: 4 [424/3978 (11%)]\tLoss: 0.077588\n",
            "Train Epoch: 4 [425/3978 (11%)]\tLoss: 0.130213\n",
            "Train Epoch: 4 [426/3978 (11%)]\tLoss: 0.131449\n",
            "Train Epoch: 4 [427/3978 (11%)]\tLoss: 0.456660\n",
            "Train Epoch: 4 [428/3978 (11%)]\tLoss: 0.641723\n",
            "Train Epoch: 4 [429/3978 (11%)]\tLoss: 0.598794\n",
            "Train Epoch: 4 [430/3978 (11%)]\tLoss: 0.075595\n",
            "Train Epoch: 4 [431/3978 (11%)]\tLoss: 0.113972\n",
            "Train Epoch: 4 [432/3978 (11%)]\tLoss: 0.094364\n",
            "Train Epoch: 4 [433/3978 (11%)]\tLoss: 0.138236\n",
            "Train Epoch: 4 [434/3978 (11%)]\tLoss: 0.181346\n",
            "Train Epoch: 4 [435/3978 (11%)]\tLoss: 0.112266\n",
            "Train Epoch: 4 [436/3978 (11%)]\tLoss: 0.113428\n",
            "Train Epoch: 4 [437/3978 (11%)]\tLoss: 0.114613\n",
            "Train Epoch: 4 [438/3978 (11%)]\tLoss: 0.139640\n",
            "Train Epoch: 4 [439/3978 (11%)]\tLoss: 0.802334\n",
            "Train Epoch: 4 [440/3978 (11%)]\tLoss: 0.140841\n",
            "Train Epoch: 4 [441/3978 (11%)]\tLoss: 0.101333\n",
            "Train Epoch: 4 [442/3978 (11%)]\tLoss: 0.105774\n",
            "Train Epoch: 4 [443/3978 (11%)]\tLoss: 0.091318\n",
            "Train Epoch: 4 [444/3978 (11%)]\tLoss: 0.131927\n",
            "Train Epoch: 4 [445/3978 (11%)]\tLoss: 0.096208\n",
            "Train Epoch: 4 [446/3978 (11%)]\tLoss: 0.091072\n",
            "Train Epoch: 4 [447/3978 (11%)]\tLoss: 0.089843\n",
            "Train Epoch: 4 [448/3978 (11%)]\tLoss: 0.094199\n",
            "Train Epoch: 4 [449/3978 (11%)]\tLoss: 0.091913\n",
            "Train Epoch: 4 [450/3978 (11%)]\tLoss: 0.086353\n",
            "Train Epoch: 4 [451/3978 (11%)]\tLoss: 0.098931\n",
            "Train Epoch: 4 [452/3978 (11%)]\tLoss: 0.095972\n",
            "Train Epoch: 4 [453/3978 (11%)]\tLoss: 0.099953\n",
            "Train Epoch: 4 [454/3978 (11%)]\tLoss: 0.093788\n",
            "Train Epoch: 4 [455/3978 (11%)]\tLoss: 0.080012\n",
            "Train Epoch: 4 [456/3978 (11%)]\tLoss: 0.077888\n",
            "Train Epoch: 4 [457/3978 (11%)]\tLoss: 0.103608\n",
            "Train Epoch: 4 [458/3978 (12%)]\tLoss: 0.072386\n",
            "Train Epoch: 4 [459/3978 (12%)]\tLoss: 0.626451\n",
            "Train Epoch: 4 [460/3978 (12%)]\tLoss: 0.717233\n",
            "Train Epoch: 4 [461/3978 (12%)]\tLoss: 0.064120\n",
            "Train Epoch: 4 [462/3978 (12%)]\tLoss: 0.070941\n",
            "Train Epoch: 4 [463/3978 (12%)]\tLoss: 0.102843\n",
            "Train Epoch: 4 [464/3978 (12%)]\tLoss: 0.112301\n",
            "Train Epoch: 4 [465/3978 (12%)]\tLoss: 0.707486\n",
            "Train Epoch: 4 [466/3978 (12%)]\tLoss: 0.082528\n",
            "Train Epoch: 4 [467/3978 (12%)]\tLoss: 0.114437\n",
            "Train Epoch: 4 [468/3978 (12%)]\tLoss: 0.106721\n",
            "Train Epoch: 4 [469/3978 (12%)]\tLoss: 0.102993\n",
            "Train Epoch: 4 [470/3978 (12%)]\tLoss: 0.056447\n",
            "Train Epoch: 4 [471/3978 (12%)]\tLoss: 0.130473\n",
            "Train Epoch: 4 [472/3978 (12%)]\tLoss: 0.056208\n",
            "Train Epoch: 4 [473/3978 (12%)]\tLoss: 0.668810\n",
            "Train Epoch: 4 [474/3978 (12%)]\tLoss: 0.109741\n",
            "Train Epoch: 4 [475/3978 (12%)]\tLoss: 0.059118\n",
            "Train Epoch: 4 [476/3978 (12%)]\tLoss: 0.058439\n",
            "Train Epoch: 4 [477/3978 (12%)]\tLoss: 0.098228\n",
            "Train Epoch: 4 [478/3978 (12%)]\tLoss: 0.107143\n",
            "Train Epoch: 4 [479/3978 (12%)]\tLoss: 0.060298\n",
            "Train Epoch: 4 [480/3978 (12%)]\tLoss: 0.632391\n",
            "Train Epoch: 4 [481/3978 (12%)]\tLoss: 0.101998\n",
            "Train Epoch: 4 [482/3978 (12%)]\tLoss: 0.073262\n",
            "Train Epoch: 4 [483/3978 (12%)]\tLoss: 0.134761\n",
            "Train Epoch: 4 [484/3978 (12%)]\tLoss: 0.065663\n",
            "Train Epoch: 4 [485/3978 (12%)]\tLoss: 0.062134\n",
            "Train Epoch: 4 [486/3978 (12%)]\tLoss: 0.084170\n",
            "Train Epoch: 4 [487/3978 (12%)]\tLoss: 0.110686\n",
            "Train Epoch: 4 [488/3978 (12%)]\tLoss: 0.113431\n",
            "Train Epoch: 4 [489/3978 (12%)]\tLoss: 0.110649\n",
            "Train Epoch: 4 [490/3978 (12%)]\tLoss: 1.112625\n",
            "Train Epoch: 4 [491/3978 (12%)]\tLoss: 0.116413\n",
            "Train Epoch: 4 [492/3978 (12%)]\tLoss: 0.078330\n",
            "Train Epoch: 4 [493/3978 (12%)]\tLoss: 0.088639\n",
            "Train Epoch: 4 [494/3978 (12%)]\tLoss: 0.103710\n",
            "Train Epoch: 4 [495/3978 (12%)]\tLoss: 0.073513\n",
            "Train Epoch: 4 [496/3978 (12%)]\tLoss: 0.136085\n",
            "Train Epoch: 4 [497/3978 (12%)]\tLoss: 0.127181\n",
            "Train Epoch: 4 [498/3978 (13%)]\tLoss: 0.083541\n",
            "Train Epoch: 4 [499/3978 (13%)]\tLoss: 0.728411\n",
            "Train Epoch: 4 [500/3978 (13%)]\tLoss: 0.737223\n",
            "Train Epoch: 4 [501/3978 (13%)]\tLoss: 1.057386\n",
            "Train Epoch: 4 [502/3978 (13%)]\tLoss: 0.080469\n",
            "Train Epoch: 4 [503/3978 (13%)]\tLoss: 0.109724\n",
            "Train Epoch: 4 [504/3978 (13%)]\tLoss: 0.073685\n",
            "Train Epoch: 4 [505/3978 (13%)]\tLoss: 0.073437\n",
            "Train Epoch: 4 [506/3978 (13%)]\tLoss: 0.086361\n",
            "Train Epoch: 4 [507/3978 (13%)]\tLoss: 0.058518\n",
            "Train Epoch: 4 [508/3978 (13%)]\tLoss: 0.675742\n",
            "Train Epoch: 4 [509/3978 (13%)]\tLoss: 0.113935\n",
            "Train Epoch: 4 [510/3978 (13%)]\tLoss: 0.102572\n",
            "Train Epoch: 4 [511/3978 (13%)]\tLoss: 1.273626\n",
            "Train Epoch: 4 [512/3978 (13%)]\tLoss: 0.096778\n",
            "Train Epoch: 4 [513/3978 (13%)]\tLoss: 0.145127\n",
            "Train Epoch: 4 [514/3978 (13%)]\tLoss: 0.100588\n",
            "Train Epoch: 4 [515/3978 (13%)]\tLoss: 1.017626\n",
            "Train Epoch: 4 [516/3978 (13%)]\tLoss: 0.144919\n",
            "Train Epoch: 4 [517/3978 (13%)]\tLoss: 0.064152\n",
            "Train Epoch: 4 [518/3978 (13%)]\tLoss: 0.097664\n",
            "Train Epoch: 4 [519/3978 (13%)]\tLoss: 0.088331\n",
            "Train Epoch: 4 [520/3978 (13%)]\tLoss: 0.134336\n",
            "Train Epoch: 4 [521/3978 (13%)]\tLoss: 0.086854\n",
            "Train Epoch: 4 [522/3978 (13%)]\tLoss: 0.082708\n",
            "Train Epoch: 4 [523/3978 (13%)]\tLoss: 0.081654\n",
            "Train Epoch: 4 [524/3978 (13%)]\tLoss: 0.080307\n",
            "Train Epoch: 4 [525/3978 (13%)]\tLoss: 0.074761\n",
            "Train Epoch: 4 [526/3978 (13%)]\tLoss: 0.082363\n",
            "Train Epoch: 4 [527/3978 (13%)]\tLoss: 0.076344\n",
            "Train Epoch: 4 [528/3978 (13%)]\tLoss: 0.068276\n",
            "Train Epoch: 4 [529/3978 (13%)]\tLoss: 0.669415\n",
            "Train Epoch: 4 [530/3978 (13%)]\tLoss: 0.083994\n",
            "Train Epoch: 4 [531/3978 (13%)]\tLoss: 0.087327\n",
            "Train Epoch: 4 [532/3978 (13%)]\tLoss: 0.112858\n",
            "Train Epoch: 4 [533/3978 (13%)]\tLoss: 0.854799\n",
            "Train Epoch: 4 [534/3978 (13%)]\tLoss: 0.113026\n",
            "Train Epoch: 4 [535/3978 (13%)]\tLoss: 0.069789\n",
            "Train Epoch: 4 [536/3978 (13%)]\tLoss: 0.121399\n",
            "Train Epoch: 4 [537/3978 (13%)]\tLoss: 0.145522\n",
            "Train Epoch: 4 [538/3978 (14%)]\tLoss: 0.097710\n",
            "Train Epoch: 4 [539/3978 (14%)]\tLoss: 0.116844\n",
            "Train Epoch: 4 [540/3978 (14%)]\tLoss: 0.057679\n",
            "Train Epoch: 4 [541/3978 (14%)]\tLoss: 0.127124\n",
            "Train Epoch: 4 [542/3978 (14%)]\tLoss: 0.059104\n",
            "Train Epoch: 4 [543/3978 (14%)]\tLoss: 0.847620\n",
            "Train Epoch: 4 [544/3978 (14%)]\tLoss: 0.081471\n",
            "Train Epoch: 4 [545/3978 (14%)]\tLoss: 0.082132\n",
            "Train Epoch: 4 [546/3978 (14%)]\tLoss: 0.069594\n",
            "Train Epoch: 4 [547/3978 (14%)]\tLoss: 0.065475\n",
            "Train Epoch: 4 [548/3978 (14%)]\tLoss: 0.097049\n",
            "Train Epoch: 4 [549/3978 (14%)]\tLoss: 0.062550\n",
            "Train Epoch: 4 [550/3978 (14%)]\tLoss: 0.074812\n",
            "Train Epoch: 4 [551/3978 (14%)]\tLoss: 0.089055\n",
            "Train Epoch: 4 [552/3978 (14%)]\tLoss: 0.072783\n",
            "Train Epoch: 4 [553/3978 (14%)]\tLoss: 0.614910\n",
            "Train Epoch: 4 [554/3978 (14%)]\tLoss: 0.069190\n",
            "Train Epoch: 4 [555/3978 (14%)]\tLoss: 0.082025\n",
            "Train Epoch: 4 [556/3978 (14%)]\tLoss: 0.093748\n",
            "Train Epoch: 4 [557/3978 (14%)]\tLoss: 0.071861\n",
            "Train Epoch: 4 [558/3978 (14%)]\tLoss: 0.090040\n",
            "Train Epoch: 4 [559/3978 (14%)]\tLoss: 0.068545\n",
            "Train Epoch: 4 [560/3978 (14%)]\tLoss: 0.075672\n",
            "Train Epoch: 4 [561/3978 (14%)]\tLoss: 0.074216\n",
            "Train Epoch: 4 [562/3978 (14%)]\tLoss: 0.907827\n",
            "Train Epoch: 4 [563/3978 (14%)]\tLoss: 0.059426\n",
            "Train Epoch: 4 [564/3978 (14%)]\tLoss: 0.130176\n",
            "Train Epoch: 4 [565/3978 (14%)]\tLoss: 0.080417\n",
            "Train Epoch: 4 [566/3978 (14%)]\tLoss: 0.080130\n",
            "Train Epoch: 4 [567/3978 (14%)]\tLoss: 0.081480\n",
            "Train Epoch: 4 [568/3978 (14%)]\tLoss: 0.086358\n",
            "Train Epoch: 4 [569/3978 (14%)]\tLoss: 0.097338\n",
            "Train Epoch: 4 [570/3978 (14%)]\tLoss: 0.064357\n",
            "Train Epoch: 4 [571/3978 (14%)]\tLoss: 0.088370\n",
            "Train Epoch: 4 [572/3978 (14%)]\tLoss: 0.060479\n",
            "Train Epoch: 4 [573/3978 (14%)]\tLoss: 0.071999\n",
            "Train Epoch: 4 [574/3978 (14%)]\tLoss: 0.080572\n",
            "Train Epoch: 4 [575/3978 (14%)]\tLoss: 0.069034\n",
            "Train Epoch: 4 [576/3978 (14%)]\tLoss: 0.087301\n",
            "Train Epoch: 4 [577/3978 (15%)]\tLoss: 0.083772\n",
            "Train Epoch: 4 [578/3978 (15%)]\tLoss: 0.109685\n",
            "Train Epoch: 4 [579/3978 (15%)]\tLoss: 0.078839\n",
            "Train Epoch: 4 [580/3978 (15%)]\tLoss: 0.079974\n",
            "Train Epoch: 4 [581/3978 (15%)]\tLoss: 0.064667\n",
            "Train Epoch: 4 [582/3978 (15%)]\tLoss: 0.075157\n",
            "Train Epoch: 4 [583/3978 (15%)]\tLoss: 0.061439\n",
            "Train Epoch: 4 [584/3978 (15%)]\tLoss: 0.073929\n",
            "Train Epoch: 4 [585/3978 (15%)]\tLoss: 0.101950\n",
            "Train Epoch: 4 [586/3978 (15%)]\tLoss: 0.069455\n",
            "Train Epoch: 4 [587/3978 (15%)]\tLoss: 0.064030\n",
            "Train Epoch: 4 [588/3978 (15%)]\tLoss: 0.089429\n",
            "Train Epoch: 4 [589/3978 (15%)]\tLoss: 0.066034\n",
            "Train Epoch: 4 [590/3978 (15%)]\tLoss: 0.071866\n",
            "Train Epoch: 4 [591/3978 (15%)]\tLoss: 0.077043\n",
            "Train Epoch: 4 [592/3978 (15%)]\tLoss: 0.069800\n",
            "Train Epoch: 4 [593/3978 (15%)]\tLoss: 0.091869\n",
            "Train Epoch: 4 [594/3978 (15%)]\tLoss: 0.088070\n",
            "Train Epoch: 4 [595/3978 (15%)]\tLoss: 0.788470\n",
            "Train Epoch: 4 [596/3978 (15%)]\tLoss: 0.092614\n",
            "Train Epoch: 4 [597/3978 (15%)]\tLoss: 0.072824\n",
            "Train Epoch: 4 [598/3978 (15%)]\tLoss: 0.050802\n",
            "Train Epoch: 4 [599/3978 (15%)]\tLoss: 0.109243\n",
            "Train Epoch: 4 [600/3978 (15%)]\tLoss: 0.049759\n",
            "Train Epoch: 4 [601/3978 (15%)]\tLoss: 0.076370\n",
            "Train Epoch: 4 [602/3978 (15%)]\tLoss: 0.058778\n",
            "Train Epoch: 4 [603/3978 (15%)]\tLoss: 0.073956\n",
            "Train Epoch: 4 [604/3978 (15%)]\tLoss: 0.054467\n",
            "Train Epoch: 4 [605/3978 (15%)]\tLoss: 0.080836\n",
            "Train Epoch: 4 [606/3978 (15%)]\tLoss: 0.659746\n",
            "Train Epoch: 4 [607/3978 (15%)]\tLoss: 0.072169\n",
            "Train Epoch: 4 [608/3978 (15%)]\tLoss: 0.084843\n",
            "Train Epoch: 4 [609/3978 (15%)]\tLoss: 0.049317\n",
            "Train Epoch: 4 [610/3978 (15%)]\tLoss: 0.080759\n",
            "Train Epoch: 4 [611/3978 (15%)]\tLoss: 0.097098\n",
            "Train Epoch: 4 [612/3978 (15%)]\tLoss: 1.072297\n",
            "Train Epoch: 4 [613/3978 (15%)]\tLoss: 0.071125\n",
            "Train Epoch: 4 [614/3978 (15%)]\tLoss: 0.088019\n",
            "Train Epoch: 4 [615/3978 (15%)]\tLoss: 0.065005\n",
            "Train Epoch: 4 [616/3978 (15%)]\tLoss: 0.085436\n",
            "Train Epoch: 4 [617/3978 (16%)]\tLoss: 0.098191\n",
            "Train Epoch: 4 [618/3978 (16%)]\tLoss: 0.860290\n",
            "Train Epoch: 4 [619/3978 (16%)]\tLoss: 0.097462\n",
            "Train Epoch: 4 [620/3978 (16%)]\tLoss: 0.731982\n",
            "Train Epoch: 4 [621/3978 (16%)]\tLoss: 0.086422\n",
            "Train Epoch: 4 [622/3978 (16%)]\tLoss: 0.058982\n",
            "Train Epoch: 4 [623/3978 (16%)]\tLoss: 0.067824\n",
            "Train Epoch: 4 [624/3978 (16%)]\tLoss: 0.072520\n",
            "Train Epoch: 4 [625/3978 (16%)]\tLoss: 0.058725\n",
            "Train Epoch: 4 [626/3978 (16%)]\tLoss: 0.064072\n",
            "Train Epoch: 4 [627/3978 (16%)]\tLoss: 0.073139\n",
            "Train Epoch: 4 [628/3978 (16%)]\tLoss: 0.073168\n",
            "Train Epoch: 4 [629/3978 (16%)]\tLoss: 0.082016\n",
            "Train Epoch: 4 [630/3978 (16%)]\tLoss: 0.073142\n",
            "Train Epoch: 4 [631/3978 (16%)]\tLoss: 0.892591\n",
            "Train Epoch: 4 [632/3978 (16%)]\tLoss: 0.077835\n",
            "Train Epoch: 4 [633/3978 (16%)]\tLoss: 0.680013\n",
            "Train Epoch: 4 [634/3978 (16%)]\tLoss: 0.077865\n",
            "Train Epoch: 4 [635/3978 (16%)]\tLoss: 0.697138\n",
            "Train Epoch: 4 [636/3978 (16%)]\tLoss: 0.910296\n",
            "Train Epoch: 4 [637/3978 (16%)]\tLoss: 0.073793\n",
            "Train Epoch: 4 [638/3978 (16%)]\tLoss: 0.070101\n",
            "Train Epoch: 4 [639/3978 (16%)]\tLoss: 0.823010\n",
            "Train Epoch: 4 [640/3978 (16%)]\tLoss: 0.072618\n",
            "Train Epoch: 4 [641/3978 (16%)]\tLoss: 0.103784\n",
            "Train Epoch: 4 [642/3978 (16%)]\tLoss: 0.065515\n",
            "Train Epoch: 4 [643/3978 (16%)]\tLoss: 0.065888\n",
            "Train Epoch: 4 [644/3978 (16%)]\tLoss: 0.102735\n",
            "Train Epoch: 4 [645/3978 (16%)]\tLoss: 0.063858\n",
            "Train Epoch: 4 [646/3978 (16%)]\tLoss: 0.065410\n",
            "Train Epoch: 4 [647/3978 (16%)]\tLoss: 0.084066\n",
            "Train Epoch: 4 [648/3978 (16%)]\tLoss: 0.087485\n",
            "Train Epoch: 4 [649/3978 (16%)]\tLoss: 0.685117\n",
            "Train Epoch: 4 [650/3978 (16%)]\tLoss: 0.083750\n",
            "Train Epoch: 4 [651/3978 (16%)]\tLoss: 0.642712\n",
            "Train Epoch: 4 [652/3978 (16%)]\tLoss: 0.077257\n",
            "Train Epoch: 4 [653/3978 (16%)]\tLoss: 0.113479\n",
            "Train Epoch: 4 [654/3978 (16%)]\tLoss: 0.703454\n",
            "Train Epoch: 4 [655/3978 (16%)]\tLoss: 0.074898\n",
            "Train Epoch: 4 [656/3978 (16%)]\tLoss: 0.081247\n",
            "Train Epoch: 4 [657/3978 (17%)]\tLoss: 0.062656\n",
            "Train Epoch: 4 [658/3978 (17%)]\tLoss: 0.078745\n",
            "Train Epoch: 4 [659/3978 (17%)]\tLoss: 0.077348\n",
            "Train Epoch: 4 [660/3978 (17%)]\tLoss: 0.754502\n",
            "Train Epoch: 4 [661/3978 (17%)]\tLoss: 0.067288\n",
            "Train Epoch: 4 [662/3978 (17%)]\tLoss: 0.128129\n",
            "Train Epoch: 4 [663/3978 (17%)]\tLoss: 0.694721\n",
            "Train Epoch: 4 [664/3978 (17%)]\tLoss: 0.118781\n",
            "Train Epoch: 4 [665/3978 (17%)]\tLoss: 0.069217\n",
            "Train Epoch: 4 [666/3978 (17%)]\tLoss: 0.092178\n",
            "Train Epoch: 4 [667/3978 (17%)]\tLoss: 0.070141\n",
            "Train Epoch: 4 [668/3978 (17%)]\tLoss: 0.096654\n",
            "Train Epoch: 4 [669/3978 (17%)]\tLoss: 0.095538\n",
            "Train Epoch: 4 [670/3978 (17%)]\tLoss: 0.074341\n",
            "Train Epoch: 4 [671/3978 (17%)]\tLoss: 0.097151\n",
            "Train Epoch: 4 [672/3978 (17%)]\tLoss: 0.519557\n",
            "Train Epoch: 4 [673/3978 (17%)]\tLoss: 0.095594\n",
            "Train Epoch: 4 [674/3978 (17%)]\tLoss: 0.060976\n",
            "Train Epoch: 4 [675/3978 (17%)]\tLoss: 0.060932\n",
            "Train Epoch: 4 [676/3978 (17%)]\tLoss: 0.068787\n",
            "Train Epoch: 4 [677/3978 (17%)]\tLoss: 0.075709\n",
            "Train Epoch: 4 [678/3978 (17%)]\tLoss: 0.093775\n",
            "Train Epoch: 4 [679/3978 (17%)]\tLoss: 0.058799\n",
            "Train Epoch: 4 [680/3978 (17%)]\tLoss: 0.094177\n",
            "Train Epoch: 4 [681/3978 (17%)]\tLoss: 0.078874\n",
            "Train Epoch: 4 [682/3978 (17%)]\tLoss: 0.089303\n",
            "Train Epoch: 4 [683/3978 (17%)]\tLoss: 0.699729\n",
            "Train Epoch: 4 [684/3978 (17%)]\tLoss: 2.513689\n",
            "Train Epoch: 4 [685/3978 (17%)]\tLoss: 0.058111\n",
            "Train Epoch: 4 [686/3978 (17%)]\tLoss: 0.746798\n",
            "Train Epoch: 4 [687/3978 (17%)]\tLoss: 0.097850\n",
            "Train Epoch: 4 [688/3978 (17%)]\tLoss: 1.014716\n",
            "Train Epoch: 4 [689/3978 (17%)]\tLoss: 0.111275\n",
            "Train Epoch: 4 [690/3978 (17%)]\tLoss: 0.095859\n",
            "Train Epoch: 4 [691/3978 (17%)]\tLoss: 0.101147\n",
            "Train Epoch: 4 [692/3978 (17%)]\tLoss: 0.090402\n",
            "Train Epoch: 4 [693/3978 (17%)]\tLoss: 0.512623\n",
            "Train Epoch: 4 [694/3978 (17%)]\tLoss: 0.532043\n",
            "Train Epoch: 4 [695/3978 (17%)]\tLoss: 0.125717\n",
            "Train Epoch: 4 [696/3978 (17%)]\tLoss: 0.075328\n",
            "Train Epoch: 4 [697/3978 (18%)]\tLoss: 0.099969\n",
            "Train Epoch: 4 [698/3978 (18%)]\tLoss: 0.140576\n",
            "Train Epoch: 4 [699/3978 (18%)]\tLoss: 0.892490\n",
            "Train Epoch: 4 [700/3978 (18%)]\tLoss: 0.143469\n",
            "Train Epoch: 4 [701/3978 (18%)]\tLoss: 0.088109\n",
            "Train Epoch: 4 [702/3978 (18%)]\tLoss: 0.140799\n",
            "Train Epoch: 4 [703/3978 (18%)]\tLoss: 0.086067\n",
            "Train Epoch: 4 [704/3978 (18%)]\tLoss: 0.138341\n",
            "Train Epoch: 4 [705/3978 (18%)]\tLoss: 0.081487\n",
            "Train Epoch: 4 [706/3978 (18%)]\tLoss: 0.110478\n",
            "Train Epoch: 4 [707/3978 (18%)]\tLoss: 0.802989\n",
            "Train Epoch: 4 [708/3978 (18%)]\tLoss: 0.077884\n",
            "Train Epoch: 4 [709/3978 (18%)]\tLoss: 0.084380\n",
            "Train Epoch: 4 [710/3978 (18%)]\tLoss: 0.121920\n",
            "Train Epoch: 4 [711/3978 (18%)]\tLoss: 0.092039\n",
            "Train Epoch: 4 [712/3978 (18%)]\tLoss: 0.076933\n",
            "Train Epoch: 4 [713/3978 (18%)]\tLoss: 0.075055\n",
            "Train Epoch: 4 [714/3978 (18%)]\tLoss: 0.137350\n",
            "Train Epoch: 4 [715/3978 (18%)]\tLoss: 0.073569\n",
            "Train Epoch: 4 [716/3978 (18%)]\tLoss: 0.126370\n",
            "Train Epoch: 4 [717/3978 (18%)]\tLoss: 0.611358\n",
            "Train Epoch: 4 [718/3978 (18%)]\tLoss: 0.112154\n",
            "Train Epoch: 4 [719/3978 (18%)]\tLoss: 0.109851\n",
            "Train Epoch: 4 [720/3978 (18%)]\tLoss: 0.091013\n",
            "Train Epoch: 4 [721/3978 (18%)]\tLoss: 0.586629\n",
            "Train Epoch: 4 [722/3978 (18%)]\tLoss: 0.068104\n",
            "Train Epoch: 4 [723/3978 (18%)]\tLoss: 0.066580\n",
            "Train Epoch: 4 [724/3978 (18%)]\tLoss: 0.111692\n",
            "Train Epoch: 4 [725/3978 (18%)]\tLoss: 0.101617\n",
            "Train Epoch: 4 [726/3978 (18%)]\tLoss: 0.089956\n",
            "Train Epoch: 4 [727/3978 (18%)]\tLoss: 0.100588\n",
            "Train Epoch: 4 [728/3978 (18%)]\tLoss: 0.099180\n",
            "Train Epoch: 4 [729/3978 (18%)]\tLoss: 0.111176\n",
            "Train Epoch: 4 [730/3978 (18%)]\tLoss: 0.107162\n",
            "Train Epoch: 4 [731/3978 (18%)]\tLoss: 0.664329\n",
            "Train Epoch: 4 [732/3978 (18%)]\tLoss: 0.094198\n",
            "Train Epoch: 4 [733/3978 (18%)]\tLoss: 0.099685\n",
            "Train Epoch: 4 [734/3978 (18%)]\tLoss: 0.089696\n",
            "Train Epoch: 4 [735/3978 (18%)]\tLoss: 0.074787\n",
            "Train Epoch: 4 [736/3978 (19%)]\tLoss: 0.086343\n",
            "Train Epoch: 4 [737/3978 (19%)]\tLoss: 0.084962\n",
            "Train Epoch: 4 [738/3978 (19%)]\tLoss: 0.083024\n",
            "Train Epoch: 4 [739/3978 (19%)]\tLoss: 0.553319\n",
            "Train Epoch: 4 [740/3978 (19%)]\tLoss: 0.076009\n",
            "Train Epoch: 4 [741/3978 (19%)]\tLoss: 0.108191\n",
            "Train Epoch: 4 [742/3978 (19%)]\tLoss: 0.872425\n",
            "Train Epoch: 4 [743/3978 (19%)]\tLoss: 0.086658\n",
            "Train Epoch: 4 [744/3978 (19%)]\tLoss: 0.128538\n",
            "Train Epoch: 4 [745/3978 (19%)]\tLoss: 0.066485\n",
            "Train Epoch: 4 [746/3978 (19%)]\tLoss: 0.099244\n",
            "Train Epoch: 4 [747/3978 (19%)]\tLoss: 0.615909\n",
            "Train Epoch: 4 [748/3978 (19%)]\tLoss: 0.071226\n",
            "Train Epoch: 4 [749/3978 (19%)]\tLoss: 0.068469\n",
            "Train Epoch: 4 [750/3978 (19%)]\tLoss: 0.074199\n",
            "Train Epoch: 4 [751/3978 (19%)]\tLoss: 0.054278\n",
            "Train Epoch: 4 [752/3978 (19%)]\tLoss: 0.104627\n",
            "Train Epoch: 4 [753/3978 (19%)]\tLoss: 0.836211\n",
            "Train Epoch: 4 [754/3978 (19%)]\tLoss: 0.552634\n",
            "Train Epoch: 4 [755/3978 (19%)]\tLoss: 0.089194\n",
            "Train Epoch: 4 [756/3978 (19%)]\tLoss: 0.526833\n",
            "Train Epoch: 4 [757/3978 (19%)]\tLoss: 0.090632\n",
            "Train Epoch: 4 [758/3978 (19%)]\tLoss: 0.089695\n",
            "Train Epoch: 4 [759/3978 (19%)]\tLoss: 0.088695\n",
            "Train Epoch: 4 [760/3978 (19%)]\tLoss: 0.113818\n",
            "Train Epoch: 4 [761/3978 (19%)]\tLoss: 0.664730\n",
            "Train Epoch: 4 [762/3978 (19%)]\tLoss: 0.088184\n",
            "Train Epoch: 4 [763/3978 (19%)]\tLoss: 0.086682\n",
            "Train Epoch: 4 [764/3978 (19%)]\tLoss: 0.053748\n",
            "Train Epoch: 4 [765/3978 (19%)]\tLoss: 0.121984\n",
            "Train Epoch: 4 [766/3978 (19%)]\tLoss: 0.649692\n",
            "Train Epoch: 4 [767/3978 (19%)]\tLoss: 0.042220\n",
            "Train Epoch: 4 [768/3978 (19%)]\tLoss: 0.074891\n",
            "Train Epoch: 4 [769/3978 (19%)]\tLoss: 0.078229\n",
            "Train Epoch: 4 [770/3978 (19%)]\tLoss: 0.141444\n",
            "Train Epoch: 4 [771/3978 (19%)]\tLoss: 0.043628\n",
            "Train Epoch: 4 [772/3978 (19%)]\tLoss: 0.192157\n",
            "Train Epoch: 4 [773/3978 (19%)]\tLoss: 0.638768\n",
            "Train Epoch: 4 [774/3978 (19%)]\tLoss: 0.051434\n",
            "Train Epoch: 4 [775/3978 (19%)]\tLoss: 0.152295\n",
            "Train Epoch: 4 [776/3978 (20%)]\tLoss: 0.193420\n",
            "Train Epoch: 4 [777/3978 (20%)]\tLoss: 0.076144\n",
            "Train Epoch: 4 [778/3978 (20%)]\tLoss: 0.126015\n",
            "Train Epoch: 4 [779/3978 (20%)]\tLoss: 0.140517\n",
            "Train Epoch: 4 [780/3978 (20%)]\tLoss: 0.053028\n",
            "Train Epoch: 4 [781/3978 (20%)]\tLoss: 0.080507\n",
            "Train Epoch: 4 [782/3978 (20%)]\tLoss: 0.789176\n",
            "Train Epoch: 4 [783/3978 (20%)]\tLoss: 0.068830\n",
            "Train Epoch: 4 [784/3978 (20%)]\tLoss: 0.169363\n",
            "Train Epoch: 4 [785/3978 (20%)]\tLoss: 0.114842\n",
            "Train Epoch: 4 [786/3978 (20%)]\tLoss: 0.079060\n",
            "Train Epoch: 4 [787/3978 (20%)]\tLoss: 0.084867\n",
            "Train Epoch: 4 [788/3978 (20%)]\tLoss: 0.106468\n",
            "Train Epoch: 4 [789/3978 (20%)]\tLoss: 0.120312\n",
            "Train Epoch: 4 [790/3978 (20%)]\tLoss: 0.046618\n",
            "Train Epoch: 4 [791/3978 (20%)]\tLoss: 0.055806\n",
            "Train Epoch: 4 [792/3978 (20%)]\tLoss: 0.063351\n",
            "Train Epoch: 4 [793/3978 (20%)]\tLoss: 0.057048\n",
            "Train Epoch: 4 [794/3978 (20%)]\tLoss: 0.145405\n",
            "Train Epoch: 4 [795/3978 (20%)]\tLoss: 0.695033\n",
            "Train Epoch: 4 [796/3978 (20%)]\tLoss: 0.094018\n",
            "Train Epoch: 4 [797/3978 (20%)]\tLoss: 0.061652\n",
            "Train Epoch: 4 [798/3978 (20%)]\tLoss: 0.555045\n",
            "Train Epoch: 4 [799/3978 (20%)]\tLoss: 0.098144\n",
            "Train Epoch: 4 [800/3978 (20%)]\tLoss: 0.551688\n",
            "Train Epoch: 4 [801/3978 (20%)]\tLoss: 0.089455\n",
            "Train Epoch: 4 [802/3978 (20%)]\tLoss: 0.066200\n",
            "Train Epoch: 4 [803/3978 (20%)]\tLoss: 0.068550\n",
            "Train Epoch: 4 [804/3978 (20%)]\tLoss: 0.091032\n",
            "Train Epoch: 4 [805/3978 (20%)]\tLoss: 0.056683\n",
            "Train Epoch: 4 [806/3978 (20%)]\tLoss: 0.571133\n",
            "Train Epoch: 4 [807/3978 (20%)]\tLoss: 0.090805\n",
            "Train Epoch: 4 [808/3978 (20%)]\tLoss: 0.091216\n",
            "Train Epoch: 4 [809/3978 (20%)]\tLoss: 0.570059\n",
            "Train Epoch: 4 [810/3978 (20%)]\tLoss: 0.097820\n",
            "Train Epoch: 4 [811/3978 (20%)]\tLoss: 0.060059\n",
            "Train Epoch: 4 [812/3978 (20%)]\tLoss: 0.608292\n",
            "Train Epoch: 4 [813/3978 (20%)]\tLoss: 0.084941\n",
            "Train Epoch: 4 [814/3978 (20%)]\tLoss: 0.118556\n",
            "Train Epoch: 4 [815/3978 (20%)]\tLoss: 0.068458\n",
            "Train Epoch: 4 [816/3978 (21%)]\tLoss: 0.102167\n",
            "Train Epoch: 4 [817/3978 (21%)]\tLoss: 0.089603\n",
            "Train Epoch: 4 [818/3978 (21%)]\tLoss: 0.969032\n",
            "Train Epoch: 4 [819/3978 (21%)]\tLoss: 0.108627\n",
            "Train Epoch: 4 [820/3978 (21%)]\tLoss: 0.070118\n",
            "Train Epoch: 4 [821/3978 (21%)]\tLoss: 0.087169\n",
            "Train Epoch: 4 [822/3978 (21%)]\tLoss: 0.091535\n",
            "Train Epoch: 4 [823/3978 (21%)]\tLoss: 0.079389\n",
            "Train Epoch: 4 [824/3978 (21%)]\tLoss: 0.087397\n",
            "Train Epoch: 4 [825/3978 (21%)]\tLoss: 1.229250\n",
            "Train Epoch: 4 [826/3978 (21%)]\tLoss: 0.667403\n",
            "Train Epoch: 4 [827/3978 (21%)]\tLoss: 0.077453\n",
            "Train Epoch: 4 [828/3978 (21%)]\tLoss: 0.572123\n",
            "Train Epoch: 4 [829/3978 (21%)]\tLoss: 0.073570\n",
            "Train Epoch: 4 [830/3978 (21%)]\tLoss: 0.645403\n",
            "Train Epoch: 4 [831/3978 (21%)]\tLoss: 0.120780\n",
            "Train Epoch: 4 [832/3978 (21%)]\tLoss: 0.117030\n",
            "Train Epoch: 4 [833/3978 (21%)]\tLoss: 0.095849\n",
            "Train Epoch: 4 [834/3978 (21%)]\tLoss: 0.129081\n",
            "Train Epoch: 4 [835/3978 (21%)]\tLoss: 0.102061\n",
            "Train Epoch: 4 [836/3978 (21%)]\tLoss: 0.088641\n",
            "Train Epoch: 4 [837/3978 (21%)]\tLoss: 0.457265\n",
            "Train Epoch: 4 [838/3978 (21%)]\tLoss: 0.095244\n",
            "Train Epoch: 4 [839/3978 (21%)]\tLoss: 0.568842\n",
            "Train Epoch: 4 [840/3978 (21%)]\tLoss: 0.110064\n",
            "Train Epoch: 4 [841/3978 (21%)]\tLoss: 0.073043\n",
            "Train Epoch: 4 [842/3978 (21%)]\tLoss: 0.085694\n",
            "Train Epoch: 4 [843/3978 (21%)]\tLoss: 0.104955\n",
            "Train Epoch: 4 [844/3978 (21%)]\tLoss: 0.927778\n",
            "Train Epoch: 4 [845/3978 (21%)]\tLoss: 0.110755\n",
            "Train Epoch: 4 [846/3978 (21%)]\tLoss: 0.078190\n",
            "Train Epoch: 4 [847/3978 (21%)]\tLoss: 0.129242\n",
            "Train Epoch: 4 [848/3978 (21%)]\tLoss: 0.109562\n",
            "Train Epoch: 4 [849/3978 (21%)]\tLoss: 0.521396\n",
            "Train Epoch: 4 [850/3978 (21%)]\tLoss: 0.127128\n",
            "Train Epoch: 4 [851/3978 (21%)]\tLoss: 0.138259\n",
            "Train Epoch: 4 [852/3978 (21%)]\tLoss: 0.083548\n",
            "Train Epoch: 4 [853/3978 (21%)]\tLoss: 0.080295\n",
            "Train Epoch: 4 [854/3978 (21%)]\tLoss: 0.136401\n",
            "Train Epoch: 4 [855/3978 (21%)]\tLoss: 0.103836\n",
            "Train Epoch: 4 [856/3978 (22%)]\tLoss: 0.127263\n",
            "Train Epoch: 4 [857/3978 (22%)]\tLoss: 0.707312\n",
            "Train Epoch: 4 [858/3978 (22%)]\tLoss: 0.078321\n",
            "Train Epoch: 4 [859/3978 (22%)]\tLoss: 0.091460\n",
            "Train Epoch: 4 [860/3978 (22%)]\tLoss: 0.658465\n",
            "Train Epoch: 4 [861/3978 (22%)]\tLoss: 0.138087\n",
            "Train Epoch: 4 [862/3978 (22%)]\tLoss: 0.094586\n",
            "Train Epoch: 4 [863/3978 (22%)]\tLoss: 0.616967\n",
            "Train Epoch: 4 [864/3978 (22%)]\tLoss: 0.078285\n",
            "Train Epoch: 4 [865/3978 (22%)]\tLoss: 0.389783\n",
            "Train Epoch: 4 [866/3978 (22%)]\tLoss: 0.082287\n",
            "Train Epoch: 4 [867/3978 (22%)]\tLoss: 0.151571\n",
            "Train Epoch: 4 [868/3978 (22%)]\tLoss: 0.155822\n",
            "Train Epoch: 4 [869/3978 (22%)]\tLoss: 0.074974\n",
            "Train Epoch: 4 [870/3978 (22%)]\tLoss: 0.098327\n",
            "Train Epoch: 4 [871/3978 (22%)]\tLoss: 0.138950\n",
            "Train Epoch: 4 [872/3978 (22%)]\tLoss: 0.064926\n",
            "Train Epoch: 4 [873/3978 (22%)]\tLoss: 0.117845\n",
            "Train Epoch: 4 [874/3978 (22%)]\tLoss: 0.098345\n",
            "Train Epoch: 4 [875/3978 (22%)]\tLoss: 0.135798\n",
            "Train Epoch: 4 [876/3978 (22%)]\tLoss: 0.084815\n",
            "Train Epoch: 4 [877/3978 (22%)]\tLoss: 0.069597\n",
            "Train Epoch: 4 [878/3978 (22%)]\tLoss: 0.131347\n",
            "Train Epoch: 4 [879/3978 (22%)]\tLoss: 0.123537\n",
            "Train Epoch: 4 [880/3978 (22%)]\tLoss: 0.130900\n",
            "Train Epoch: 4 [881/3978 (22%)]\tLoss: 0.098257\n",
            "Train Epoch: 4 [882/3978 (22%)]\tLoss: 0.142350\n",
            "Train Epoch: 4 [883/3978 (22%)]\tLoss: 0.089326\n",
            "Train Epoch: 4 [884/3978 (22%)]\tLoss: 0.086870\n",
            "Train Epoch: 4 [885/3978 (22%)]\tLoss: 0.083407\n",
            "Train Epoch: 4 [886/3978 (22%)]\tLoss: 0.065813\n",
            "Train Epoch: 4 [887/3978 (22%)]\tLoss: 0.077678\n",
            "Train Epoch: 4 [888/3978 (22%)]\tLoss: 0.089732\n",
            "Train Epoch: 4 [889/3978 (22%)]\tLoss: 0.114122\n",
            "Train Epoch: 4 [890/3978 (22%)]\tLoss: 0.558960\n",
            "Train Epoch: 4 [891/3978 (22%)]\tLoss: 0.699769\n",
            "Train Epoch: 4 [892/3978 (22%)]\tLoss: 1.079134\n",
            "Train Epoch: 4 [893/3978 (22%)]\tLoss: 0.071008\n",
            "Train Epoch: 4 [894/3978 (22%)]\tLoss: 0.136747\n",
            "Train Epoch: 4 [895/3978 (22%)]\tLoss: 0.098015\n",
            "Train Epoch: 4 [896/3978 (23%)]\tLoss: 0.111292\n",
            "Train Epoch: 4 [897/3978 (23%)]\tLoss: 0.083815\n",
            "Train Epoch: 4 [898/3978 (23%)]\tLoss: 0.106808\n",
            "Train Epoch: 4 [899/3978 (23%)]\tLoss: 0.132597\n",
            "Train Epoch: 4 [900/3978 (23%)]\tLoss: 0.067646\n",
            "Train Epoch: 4 [901/3978 (23%)]\tLoss: 0.542689\n",
            "Train Epoch: 4 [902/3978 (23%)]\tLoss: 0.071973\n",
            "Train Epoch: 4 [903/3978 (23%)]\tLoss: 0.101367\n",
            "Train Epoch: 4 [904/3978 (23%)]\tLoss: 0.651398\n",
            "Train Epoch: 4 [905/3978 (23%)]\tLoss: 0.660796\n",
            "Train Epoch: 4 [906/3978 (23%)]\tLoss: 0.118579\n",
            "Train Epoch: 4 [907/3978 (23%)]\tLoss: 0.721012\n",
            "Train Epoch: 4 [908/3978 (23%)]\tLoss: 0.701635\n",
            "Train Epoch: 4 [909/3978 (23%)]\tLoss: 0.091965\n",
            "Train Epoch: 4 [910/3978 (23%)]\tLoss: 0.099507\n",
            "Train Epoch: 4 [911/3978 (23%)]\tLoss: 0.119092\n",
            "Train Epoch: 4 [912/3978 (23%)]\tLoss: 0.078246\n",
            "Train Epoch: 4 [913/3978 (23%)]\tLoss: 0.556266\n",
            "Train Epoch: 4 [914/3978 (23%)]\tLoss: 0.114784\n",
            "Train Epoch: 4 [915/3978 (23%)]\tLoss: 0.104750\n",
            "Train Epoch: 4 [916/3978 (23%)]\tLoss: 0.070511\n",
            "Train Epoch: 4 [917/3978 (23%)]\tLoss: 0.072033\n",
            "Train Epoch: 4 [918/3978 (23%)]\tLoss: 0.086494\n",
            "Train Epoch: 4 [919/3978 (23%)]\tLoss: 0.070939\n",
            "Train Epoch: 4 [920/3978 (23%)]\tLoss: 0.096302\n",
            "Train Epoch: 4 [921/3978 (23%)]\tLoss: 0.136745\n",
            "Train Epoch: 4 [922/3978 (23%)]\tLoss: 0.074925\n",
            "Train Epoch: 4 [923/3978 (23%)]\tLoss: 0.082549\n",
            "Train Epoch: 4 [924/3978 (23%)]\tLoss: 0.093868\n",
            "Train Epoch: 4 [925/3978 (23%)]\tLoss: 0.072353\n",
            "Train Epoch: 4 [926/3978 (23%)]\tLoss: 0.080422\n",
            "Train Epoch: 4 [927/3978 (23%)]\tLoss: 0.750936\n",
            "Train Epoch: 4 [928/3978 (23%)]\tLoss: 0.071064\n",
            "Train Epoch: 4 [929/3978 (23%)]\tLoss: 0.111172\n",
            "Train Epoch: 4 [930/3978 (23%)]\tLoss: 0.632600\n",
            "Train Epoch: 4 [931/3978 (23%)]\tLoss: 0.093693\n",
            "Train Epoch: 4 [932/3978 (23%)]\tLoss: 0.105878\n",
            "Train Epoch: 4 [933/3978 (23%)]\tLoss: 0.619640\n",
            "Train Epoch: 4 [934/3978 (23%)]\tLoss: 1.008908\n",
            "Train Epoch: 4 [935/3978 (24%)]\tLoss: 0.095523\n",
            "Train Epoch: 4 [936/3978 (24%)]\tLoss: 0.104463\n",
            "Train Epoch: 4 [937/3978 (24%)]\tLoss: 0.613243\n",
            "Train Epoch: 4 [938/3978 (24%)]\tLoss: 0.127168\n",
            "Train Epoch: 4 [939/3978 (24%)]\tLoss: 0.112123\n",
            "Train Epoch: 4 [940/3978 (24%)]\tLoss: 0.836332\n",
            "Train Epoch: 4 [941/3978 (24%)]\tLoss: 0.536121\n",
            "Train Epoch: 4 [942/3978 (24%)]\tLoss: 0.104818\n",
            "Train Epoch: 4 [943/3978 (24%)]\tLoss: 0.999136\n",
            "Train Epoch: 4 [944/3978 (24%)]\tLoss: 0.121875\n",
            "Train Epoch: 4 [945/3978 (24%)]\tLoss: 0.143304\n",
            "Train Epoch: 4 [946/3978 (24%)]\tLoss: 0.102502\n",
            "Train Epoch: 4 [947/3978 (24%)]\tLoss: 0.084670\n",
            "Train Epoch: 4 [948/3978 (24%)]\tLoss: 0.623770\n",
            "Train Epoch: 4 [949/3978 (24%)]\tLoss: 0.144286\n",
            "Train Epoch: 4 [950/3978 (24%)]\tLoss: 0.651229\n",
            "Train Epoch: 4 [951/3978 (24%)]\tLoss: 0.081400\n",
            "Train Epoch: 4 [952/3978 (24%)]\tLoss: 0.081584\n",
            "Train Epoch: 4 [953/3978 (24%)]\tLoss: 0.081331\n",
            "Train Epoch: 4 [954/3978 (24%)]\tLoss: 0.940393\n",
            "Train Epoch: 4 [955/3978 (24%)]\tLoss: 0.077993\n",
            "Train Epoch: 4 [956/3978 (24%)]\tLoss: 0.113953\n",
            "Train Epoch: 4 [957/3978 (24%)]\tLoss: 0.158633\n",
            "Train Epoch: 4 [958/3978 (24%)]\tLoss: 0.100792\n",
            "Train Epoch: 4 [959/3978 (24%)]\tLoss: 0.099843\n",
            "Train Epoch: 4 [960/3978 (24%)]\tLoss: 0.525107\n",
            "Train Epoch: 4 [961/3978 (24%)]\tLoss: 0.092802\n",
            "Train Epoch: 4 [962/3978 (24%)]\tLoss: 0.162433\n",
            "Train Epoch: 4 [963/3978 (24%)]\tLoss: 0.097274\n",
            "Train Epoch: 4 [964/3978 (24%)]\tLoss: 0.133910\n",
            "Train Epoch: 4 [965/3978 (24%)]\tLoss: 0.133048\n",
            "Train Epoch: 4 [966/3978 (24%)]\tLoss: 0.504173\n",
            "Train Epoch: 4 [967/3978 (24%)]\tLoss: 0.071264\n",
            "Train Epoch: 4 [968/3978 (24%)]\tLoss: 0.108398\n",
            "Train Epoch: 4 [969/3978 (24%)]\tLoss: 0.110217\n",
            "Train Epoch: 4 [970/3978 (24%)]\tLoss: 0.129821\n",
            "Train Epoch: 4 [971/3978 (24%)]\tLoss: 0.093584\n",
            "Train Epoch: 4 [972/3978 (24%)]\tLoss: 0.522191\n",
            "Train Epoch: 4 [973/3978 (24%)]\tLoss: 0.069173\n",
            "Train Epoch: 4 [974/3978 (24%)]\tLoss: 0.099158\n",
            "Train Epoch: 4 [975/3978 (25%)]\tLoss: 0.124585\n",
            "Train Epoch: 4 [976/3978 (25%)]\tLoss: 0.088072\n",
            "Train Epoch: 4 [977/3978 (25%)]\tLoss: 0.086378\n",
            "Train Epoch: 4 [978/3978 (25%)]\tLoss: 1.395403\n",
            "Train Epoch: 4 [979/3978 (25%)]\tLoss: 0.166101\n",
            "Train Epoch: 4 [980/3978 (25%)]\tLoss: 0.060848\n",
            "Train Epoch: 4 [981/3978 (25%)]\tLoss: 0.103244\n",
            "Train Epoch: 4 [982/3978 (25%)]\tLoss: 1.011938\n",
            "Train Epoch: 4 [983/3978 (25%)]\tLoss: 0.494104\n",
            "Train Epoch: 4 [984/3978 (25%)]\tLoss: 0.107850\n",
            "Train Epoch: 4 [985/3978 (25%)]\tLoss: 0.058668\n",
            "Train Epoch: 4 [986/3978 (25%)]\tLoss: 0.053108\n",
            "Train Epoch: 4 [987/3978 (25%)]\tLoss: 0.144522\n",
            "Train Epoch: 4 [988/3978 (25%)]\tLoss: 0.099530\n",
            "Train Epoch: 4 [989/3978 (25%)]\tLoss: 0.485223\n",
            "Train Epoch: 4 [990/3978 (25%)]\tLoss: 0.133370\n",
            "Train Epoch: 4 [991/3978 (25%)]\tLoss: 0.177650\n",
            "Train Epoch: 4 [992/3978 (25%)]\tLoss: 0.738705\n",
            "Train Epoch: 4 [993/3978 (25%)]\tLoss: 0.125931\n",
            "Train Epoch: 4 [994/3978 (25%)]\tLoss: 0.073122\n",
            "Train Epoch: 4 [995/3978 (25%)]\tLoss: 0.054982\n",
            "Train Epoch: 4 [996/3978 (25%)]\tLoss: 0.096449\n",
            "Train Epoch: 4 [997/3978 (25%)]\tLoss: 0.066625\n",
            "Train Epoch: 4 [998/3978 (25%)]\tLoss: 0.121413\n",
            "Train Epoch: 4 [999/3978 (25%)]\tLoss: 0.543329\n",
            "Train Epoch: 4 [1000/3978 (25%)]\tLoss: 0.061089\n",
            "Train Epoch: 4 [1001/3978 (25%)]\tLoss: 0.065509\n",
            "Train Epoch: 4 [1002/3978 (25%)]\tLoss: 0.128641\n",
            "Train Epoch: 4 [1003/3978 (25%)]\tLoss: 0.125860\n",
            "Train Epoch: 4 [1004/3978 (25%)]\tLoss: 0.120876\n",
            "Train Epoch: 4 [1005/3978 (25%)]\tLoss: 0.049681\n",
            "Train Epoch: 4 [1006/3978 (25%)]\tLoss: 0.974522\n",
            "Train Epoch: 4 [1007/3978 (25%)]\tLoss: 0.063492\n",
            "Train Epoch: 4 [1008/3978 (25%)]\tLoss: 0.064176\n",
            "Train Epoch: 4 [1009/3978 (25%)]\tLoss: 0.569647\n",
            "Train Epoch: 4 [1010/3978 (25%)]\tLoss: 0.130835\n",
            "Train Epoch: 4 [1011/3978 (25%)]\tLoss: 0.111997\n",
            "Train Epoch: 4 [1012/3978 (25%)]\tLoss: 0.054170\n",
            "Train Epoch: 4 [1013/3978 (25%)]\tLoss: 0.052646\n",
            "Train Epoch: 4 [1014/3978 (25%)]\tLoss: 0.108360\n",
            "Train Epoch: 4 [1015/3978 (26%)]\tLoss: 0.066557\n",
            "Train Epoch: 4 [1016/3978 (26%)]\tLoss: 0.645507\n",
            "Train Epoch: 4 [1017/3978 (26%)]\tLoss: 0.118863\n",
            "Train Epoch: 4 [1018/3978 (26%)]\tLoss: 0.104634\n",
            "Train Epoch: 4 [1019/3978 (26%)]\tLoss: 0.551144\n",
            "Train Epoch: 4 [1020/3978 (26%)]\tLoss: 0.099664\n",
            "Train Epoch: 4 [1021/3978 (26%)]\tLoss: 0.067985\n",
            "Train Epoch: 4 [1022/3978 (26%)]\tLoss: 0.068084\n",
            "Train Epoch: 4 [1023/3978 (26%)]\tLoss: 1.201141\n",
            "Train Epoch: 4 [1024/3978 (26%)]\tLoss: 0.100610\n",
            "Train Epoch: 4 [1025/3978 (26%)]\tLoss: 0.143794\n",
            "Train Epoch: 4 [1026/3978 (26%)]\tLoss: 0.132818\n",
            "Train Epoch: 4 [1027/3978 (26%)]\tLoss: 0.100075\n",
            "Train Epoch: 4 [1028/3978 (26%)]\tLoss: 0.089482\n",
            "Train Epoch: 4 [1029/3978 (26%)]\tLoss: 0.520208\n",
            "Train Epoch: 4 [1030/3978 (26%)]\tLoss: 0.084267\n",
            "Train Epoch: 4 [1031/3978 (26%)]\tLoss: 0.082170\n",
            "Train Epoch: 4 [1032/3978 (26%)]\tLoss: 0.104212\n",
            "Train Epoch: 4 [1033/3978 (26%)]\tLoss: 0.125401\n",
            "Train Epoch: 4 [1034/3978 (26%)]\tLoss: 0.090353\n",
            "Train Epoch: 4 [1035/3978 (26%)]\tLoss: 0.133505\n",
            "Train Epoch: 4 [1036/3978 (26%)]\tLoss: 0.086254\n",
            "Train Epoch: 4 [1037/3978 (26%)]\tLoss: 0.616714\n",
            "Train Epoch: 4 [1038/3978 (26%)]\tLoss: 0.588229\n",
            "Train Epoch: 4 [1039/3978 (26%)]\tLoss: 0.108062\n",
            "Train Epoch: 4 [1040/3978 (26%)]\tLoss: 0.085934\n",
            "Train Epoch: 4 [1041/3978 (26%)]\tLoss: 0.114318\n",
            "Train Epoch: 4 [1042/3978 (26%)]\tLoss: 0.102426\n",
            "Train Epoch: 4 [1043/3978 (26%)]\tLoss: 0.071223\n",
            "Train Epoch: 4 [1044/3978 (26%)]\tLoss: 0.141846\n",
            "Train Epoch: 4 [1045/3978 (26%)]\tLoss: 0.100051\n",
            "Train Epoch: 4 [1046/3978 (26%)]\tLoss: 0.080340\n",
            "Train Epoch: 4 [1047/3978 (26%)]\tLoss: 0.074802\n",
            "Train Epoch: 4 [1048/3978 (26%)]\tLoss: 0.073318\n",
            "Train Epoch: 4 [1049/3978 (26%)]\tLoss: 0.121350\n",
            "Train Epoch: 4 [1050/3978 (26%)]\tLoss: 0.078118\n",
            "Train Epoch: 4 [1051/3978 (26%)]\tLoss: 0.114620\n",
            "Train Epoch: 4 [1052/3978 (26%)]\tLoss: 0.120445\n",
            "Train Epoch: 4 [1053/3978 (26%)]\tLoss: 0.524048\n",
            "Train Epoch: 4 [1054/3978 (26%)]\tLoss: 0.069977\n",
            "Train Epoch: 4 [1055/3978 (27%)]\tLoss: 0.115793\n",
            "Train Epoch: 4 [1056/3978 (27%)]\tLoss: 0.580163\n",
            "Train Epoch: 4 [1057/3978 (27%)]\tLoss: 0.565031\n",
            "Train Epoch: 4 [1058/3978 (27%)]\tLoss: 0.952516\n",
            "Train Epoch: 4 [1059/3978 (27%)]\tLoss: 0.083898\n",
            "Train Epoch: 4 [1060/3978 (27%)]\tLoss: 0.094668\n",
            "Train Epoch: 4 [1061/3978 (27%)]\tLoss: 0.084120\n",
            "Train Epoch: 4 [1062/3978 (27%)]\tLoss: 0.086053\n",
            "Train Epoch: 4 [1063/3978 (27%)]\tLoss: 0.083366\n",
            "Train Epoch: 4 [1064/3978 (27%)]\tLoss: 0.102558\n",
            "Train Epoch: 4 [1065/3978 (27%)]\tLoss: 0.115989\n",
            "Train Epoch: 4 [1066/3978 (27%)]\tLoss: 0.620373\n",
            "Train Epoch: 4 [1067/3978 (27%)]\tLoss: 0.069842\n",
            "Train Epoch: 4 [1068/3978 (27%)]\tLoss: 0.132871\n",
            "Train Epoch: 4 [1069/3978 (27%)]\tLoss: 0.099304\n",
            "Train Epoch: 4 [1070/3978 (27%)]\tLoss: 0.469910\n",
            "Train Epoch: 4 [1071/3978 (27%)]\tLoss: 0.121882\n",
            "Train Epoch: 4 [1072/3978 (27%)]\tLoss: 0.085970\n",
            "Train Epoch: 4 [1073/3978 (27%)]\tLoss: 0.137530\n",
            "Train Epoch: 4 [1074/3978 (27%)]\tLoss: 0.081697\n",
            "Train Epoch: 4 [1075/3978 (27%)]\tLoss: 0.122901\n",
            "Train Epoch: 4 [1076/3978 (27%)]\tLoss: 0.100376\n",
            "Train Epoch: 4 [1077/3978 (27%)]\tLoss: 0.099318\n",
            "Train Epoch: 4 [1078/3978 (27%)]\tLoss: 0.078676\n",
            "Train Epoch: 4 [1079/3978 (27%)]\tLoss: 0.105056\n",
            "Train Epoch: 4 [1080/3978 (27%)]\tLoss: 0.092824\n",
            "Train Epoch: 4 [1081/3978 (27%)]\tLoss: 0.082149\n",
            "Train Epoch: 4 [1082/3978 (27%)]\tLoss: 0.551225\n",
            "Train Epoch: 4 [1083/3978 (27%)]\tLoss: 0.093556\n",
            "Train Epoch: 4 [1084/3978 (27%)]\tLoss: 0.076493\n",
            "Train Epoch: 4 [1085/3978 (27%)]\tLoss: 0.090080\n",
            "Train Epoch: 4 [1086/3978 (27%)]\tLoss: 0.607343\n",
            "Train Epoch: 4 [1087/3978 (27%)]\tLoss: 0.109630\n",
            "Train Epoch: 4 [1088/3978 (27%)]\tLoss: 0.095047\n",
            "Train Epoch: 4 [1089/3978 (27%)]\tLoss: 0.088220\n",
            "Train Epoch: 4 [1090/3978 (27%)]\tLoss: 0.089075\n",
            "Train Epoch: 4 [1091/3978 (27%)]\tLoss: 0.440064\n",
            "Train Epoch: 4 [1092/3978 (27%)]\tLoss: 0.118408\n",
            "Train Epoch: 4 [1093/3978 (27%)]\tLoss: 0.089053\n",
            "Train Epoch: 4 [1094/3978 (28%)]\tLoss: 0.065754\n",
            "Train Epoch: 4 [1095/3978 (28%)]\tLoss: 0.115488\n",
            "Train Epoch: 4 [1096/3978 (28%)]\tLoss: 0.112175\n",
            "Train Epoch: 4 [1097/3978 (28%)]\tLoss: 0.132880\n",
            "Train Epoch: 4 [1098/3978 (28%)]\tLoss: 0.064470\n",
            "Train Epoch: 4 [1099/3978 (28%)]\tLoss: 0.420050\n",
            "Train Epoch: 4 [1100/3978 (28%)]\tLoss: 0.085312\n",
            "Train Epoch: 4 [1101/3978 (28%)]\tLoss: 0.083586\n",
            "Train Epoch: 4 [1102/3978 (28%)]\tLoss: 0.092246\n",
            "Train Epoch: 4 [1103/3978 (28%)]\tLoss: 0.091362\n",
            "Train Epoch: 4 [1104/3978 (28%)]\tLoss: 0.894249\n",
            "Train Epoch: 4 [1105/3978 (28%)]\tLoss: 0.084239\n",
            "Train Epoch: 4 [1106/3978 (28%)]\tLoss: 0.067944\n",
            "Train Epoch: 4 [1107/3978 (28%)]\tLoss: 0.066513\n",
            "Train Epoch: 4 [1108/3978 (28%)]\tLoss: 0.460050\n",
            "Train Epoch: 4 [1109/3978 (28%)]\tLoss: 0.071072\n",
            "Train Epoch: 4 [1110/3978 (28%)]\tLoss: 0.134091\n",
            "Train Epoch: 4 [1111/3978 (28%)]\tLoss: 0.081397\n",
            "Train Epoch: 4 [1112/3978 (28%)]\tLoss: 0.606269\n",
            "Train Epoch: 4 [1113/3978 (28%)]\tLoss: 0.083667\n",
            "Train Epoch: 4 [1114/3978 (28%)]\tLoss: 0.089387\n",
            "Train Epoch: 4 [1115/3978 (28%)]\tLoss: 0.139942\n",
            "Train Epoch: 4 [1116/3978 (28%)]\tLoss: 0.081557\n",
            "Train Epoch: 4 [1117/3978 (28%)]\tLoss: 0.078483\n",
            "Train Epoch: 4 [1118/3978 (28%)]\tLoss: 0.106724\n",
            "Train Epoch: 4 [1119/3978 (28%)]\tLoss: 0.127265\n",
            "Train Epoch: 4 [1120/3978 (28%)]\tLoss: 0.057693\n",
            "Train Epoch: 4 [1121/3978 (28%)]\tLoss: 0.681918\n",
            "Train Epoch: 4 [1122/3978 (28%)]\tLoss: 1.019359\n",
            "Train Epoch: 4 [1123/3978 (28%)]\tLoss: 0.054258\n",
            "Train Epoch: 4 [1124/3978 (28%)]\tLoss: 0.114263\n",
            "Train Epoch: 4 [1125/3978 (28%)]\tLoss: 0.129780\n",
            "Train Epoch: 4 [1126/3978 (28%)]\tLoss: 0.101730\n",
            "Train Epoch: 4 [1127/3978 (28%)]\tLoss: 0.099416\n",
            "Train Epoch: 4 [1128/3978 (28%)]\tLoss: 0.058251\n",
            "Train Epoch: 4 [1129/3978 (28%)]\tLoss: 0.121729\n",
            "Train Epoch: 4 [1130/3978 (28%)]\tLoss: 0.106525\n",
            "Train Epoch: 4 [1131/3978 (28%)]\tLoss: 0.063007\n",
            "Train Epoch: 4 [1132/3978 (28%)]\tLoss: 0.114355\n",
            "Train Epoch: 4 [1133/3978 (28%)]\tLoss: 1.069597\n",
            "Train Epoch: 4 [1134/3978 (29%)]\tLoss: 0.090548\n",
            "Train Epoch: 4 [1135/3978 (29%)]\tLoss: 0.082874\n",
            "Train Epoch: 4 [1136/3978 (29%)]\tLoss: 1.427150\n",
            "Train Epoch: 4 [1137/3978 (29%)]\tLoss: 0.550797\n",
            "Train Epoch: 4 [1138/3978 (29%)]\tLoss: 0.082605\n",
            "Train Epoch: 4 [1139/3978 (29%)]\tLoss: 0.116824\n",
            "Train Epoch: 4 [1140/3978 (29%)]\tLoss: 0.098314\n",
            "Train Epoch: 4 [1141/3978 (29%)]\tLoss: 0.657083\n",
            "Train Epoch: 4 [1142/3978 (29%)]\tLoss: 0.093281\n",
            "Train Epoch: 4 [1143/3978 (29%)]\tLoss: 0.076861\n",
            "Train Epoch: 4 [1144/3978 (29%)]\tLoss: 0.098951\n",
            "Train Epoch: 4 [1145/3978 (29%)]\tLoss: 0.078013\n",
            "Train Epoch: 4 [1146/3978 (29%)]\tLoss: 0.096383\n",
            "Train Epoch: 4 [1147/3978 (29%)]\tLoss: 0.676630\n",
            "Train Epoch: 4 [1148/3978 (29%)]\tLoss: 0.070415\n",
            "Train Epoch: 4 [1149/3978 (29%)]\tLoss: 0.830320\n",
            "Train Epoch: 4 [1150/3978 (29%)]\tLoss: 0.077818\n",
            "Train Epoch: 4 [1151/3978 (29%)]\tLoss: 0.087358\n",
            "Train Epoch: 4 [1152/3978 (29%)]\tLoss: 0.074012\n",
            "Train Epoch: 4 [1153/3978 (29%)]\tLoss: 0.432799\n",
            "Train Epoch: 4 [1154/3978 (29%)]\tLoss: 1.264634\n",
            "Train Epoch: 4 [1155/3978 (29%)]\tLoss: 0.088552\n",
            "Train Epoch: 4 [1156/3978 (29%)]\tLoss: 0.064365\n",
            "Train Epoch: 4 [1157/3978 (29%)]\tLoss: 0.089433\n",
            "Train Epoch: 4 [1158/3978 (29%)]\tLoss: 0.090631\n",
            "Train Epoch: 4 [1159/3978 (29%)]\tLoss: 0.121758\n",
            "Train Epoch: 4 [1160/3978 (29%)]\tLoss: 0.069325\n",
            "Train Epoch: 4 [1161/3978 (29%)]\tLoss: 0.083275\n",
            "Train Epoch: 4 [1162/3978 (29%)]\tLoss: 0.594655\n",
            "Train Epoch: 4 [1163/3978 (29%)]\tLoss: 1.244190\n",
            "Train Epoch: 4 [1164/3978 (29%)]\tLoss: 0.089538\n",
            "Train Epoch: 4 [1165/3978 (29%)]\tLoss: 0.116822\n",
            "Train Epoch: 4 [1166/3978 (29%)]\tLoss: 0.111626\n",
            "Train Epoch: 4 [1167/3978 (29%)]\tLoss: 0.116886\n",
            "Train Epoch: 4 [1168/3978 (29%)]\tLoss: 0.116097\n",
            "Train Epoch: 4 [1169/3978 (29%)]\tLoss: 0.066584\n",
            "Train Epoch: 4 [1170/3978 (29%)]\tLoss: 1.179635\n",
            "Train Epoch: 4 [1171/3978 (29%)]\tLoss: 1.088462\n",
            "Train Epoch: 4 [1172/3978 (29%)]\tLoss: 0.142624\n",
            "Train Epoch: 4 [1173/3978 (29%)]\tLoss: 0.130891\n",
            "Train Epoch: 4 [1174/3978 (30%)]\tLoss: 0.081526\n",
            "Train Epoch: 4 [1175/3978 (30%)]\tLoss: 0.085552\n",
            "Train Epoch: 4 [1176/3978 (30%)]\tLoss: 0.069730\n",
            "Train Epoch: 4 [1177/3978 (30%)]\tLoss: 0.108453\n",
            "Train Epoch: 4 [1178/3978 (30%)]\tLoss: 0.079004\n",
            "Train Epoch: 4 [1179/3978 (30%)]\tLoss: 0.885662\n",
            "Train Epoch: 4 [1180/3978 (30%)]\tLoss: 0.077101\n",
            "Train Epoch: 4 [1181/3978 (30%)]\tLoss: 0.590095\n",
            "Train Epoch: 4 [1182/3978 (30%)]\tLoss: 0.118278\n",
            "Train Epoch: 4 [1183/3978 (30%)]\tLoss: 1.697086\n",
            "Train Epoch: 4 [1184/3978 (30%)]\tLoss: 0.093042\n",
            "Train Epoch: 4 [1185/3978 (30%)]\tLoss: 0.067623\n",
            "Train Epoch: 4 [1186/3978 (30%)]\tLoss: 0.587668\n",
            "Train Epoch: 4 [1187/3978 (30%)]\tLoss: 0.985703\n",
            "Train Epoch: 4 [1188/3978 (30%)]\tLoss: 0.119569\n",
            "Train Epoch: 4 [1189/3978 (30%)]\tLoss: 0.090277\n",
            "Train Epoch: 4 [1190/3978 (30%)]\tLoss: 0.114423\n",
            "Train Epoch: 4 [1191/3978 (30%)]\tLoss: 0.066348\n",
            "Train Epoch: 4 [1192/3978 (30%)]\tLoss: 0.075883\n",
            "Train Epoch: 4 [1193/3978 (30%)]\tLoss: 0.108579\n",
            "Train Epoch: 4 [1194/3978 (30%)]\tLoss: 0.111816\n",
            "Train Epoch: 4 [1195/3978 (30%)]\tLoss: 0.782055\n",
            "Train Epoch: 4 [1196/3978 (30%)]\tLoss: 0.111741\n",
            "Train Epoch: 4 [1197/3978 (30%)]\tLoss: 0.102163\n",
            "Train Epoch: 4 [1198/3978 (30%)]\tLoss: 0.095740\n",
            "Train Epoch: 4 [1199/3978 (30%)]\tLoss: 0.111251\n",
            "Train Epoch: 4 [1200/3978 (30%)]\tLoss: 0.110022\n",
            "Train Epoch: 4 [1201/3978 (30%)]\tLoss: 0.067812\n",
            "Train Epoch: 4 [1202/3978 (30%)]\tLoss: 0.096903\n",
            "Train Epoch: 4 [1203/3978 (30%)]\tLoss: 0.089589\n",
            "Train Epoch: 4 [1204/3978 (30%)]\tLoss: 0.089982\n",
            "Train Epoch: 4 [1205/3978 (30%)]\tLoss: 0.723078\n",
            "Train Epoch: 4 [1206/3978 (30%)]\tLoss: 0.140258\n",
            "Train Epoch: 4 [1207/3978 (30%)]\tLoss: 0.074840\n",
            "Train Epoch: 4 [1208/3978 (30%)]\tLoss: 0.999269\n",
            "Train Epoch: 4 [1209/3978 (30%)]\tLoss: 0.128437\n",
            "Train Epoch: 4 [1210/3978 (30%)]\tLoss: 0.506388\n",
            "Train Epoch: 4 [1211/3978 (30%)]\tLoss: 0.087678\n",
            "Train Epoch: 4 [1212/3978 (30%)]\tLoss: 0.104679\n",
            "Train Epoch: 4 [1213/3978 (30%)]\tLoss: 0.125165\n",
            "Train Epoch: 4 [1214/3978 (31%)]\tLoss: 1.115674\n",
            "Train Epoch: 4 [1215/3978 (31%)]\tLoss: 0.099698\n",
            "Train Epoch: 4 [1216/3978 (31%)]\tLoss: 0.096746\n",
            "Train Epoch: 4 [1217/3978 (31%)]\tLoss: 0.119828\n",
            "Train Epoch: 4 [1218/3978 (31%)]\tLoss: 0.083739\n",
            "Train Epoch: 4 [1219/3978 (31%)]\tLoss: 0.089012\n",
            "Train Epoch: 4 [1220/3978 (31%)]\tLoss: 0.085501\n",
            "Train Epoch: 4 [1221/3978 (31%)]\tLoss: 0.078067\n",
            "Train Epoch: 4 [1222/3978 (31%)]\tLoss: 0.086974\n",
            "Train Epoch: 4 [1223/3978 (31%)]\tLoss: 0.072440\n",
            "Train Epoch: 4 [1224/3978 (31%)]\tLoss: 0.119396\n",
            "Train Epoch: 4 [1225/3978 (31%)]\tLoss: 0.069903\n",
            "Train Epoch: 4 [1226/3978 (31%)]\tLoss: 0.083469\n",
            "Train Epoch: 4 [1227/3978 (31%)]\tLoss: 0.070614\n",
            "Train Epoch: 4 [1228/3978 (31%)]\tLoss: 0.091434\n",
            "Train Epoch: 4 [1229/3978 (31%)]\tLoss: 0.111280\n",
            "Train Epoch: 4 [1230/3978 (31%)]\tLoss: 0.076693\n",
            "Train Epoch: 4 [1231/3978 (31%)]\tLoss: 0.057178\n",
            "Train Epoch: 4 [1232/3978 (31%)]\tLoss: 0.112044\n",
            "Train Epoch: 4 [1233/3978 (31%)]\tLoss: 0.058450\n",
            "Train Epoch: 4 [1234/3978 (31%)]\tLoss: 0.053285\n",
            "Train Epoch: 4 [1235/3978 (31%)]\tLoss: 0.052687\n",
            "Train Epoch: 4 [1236/3978 (31%)]\tLoss: 0.091481\n",
            "Train Epoch: 4 [1237/3978 (31%)]\tLoss: 0.099090\n",
            "Train Epoch: 4 [1238/3978 (31%)]\tLoss: 0.047191\n",
            "Train Epoch: 4 [1239/3978 (31%)]\tLoss: 0.104369\n",
            "Train Epoch: 4 [1240/3978 (31%)]\tLoss: 0.105131\n",
            "Train Epoch: 4 [1241/3978 (31%)]\tLoss: 0.107090\n",
            "Train Epoch: 4 [1242/3978 (31%)]\tLoss: 0.058648\n",
            "Train Epoch: 4 [1243/3978 (31%)]\tLoss: 0.122353\n",
            "Train Epoch: 4 [1244/3978 (31%)]\tLoss: 0.134288\n",
            "Train Epoch: 4 [1245/3978 (31%)]\tLoss: 0.054815\n",
            "Train Epoch: 4 [1246/3978 (31%)]\tLoss: 0.083498\n",
            "Train Epoch: 4 [1247/3978 (31%)]\tLoss: 0.056735\n",
            "Train Epoch: 4 [1248/3978 (31%)]\tLoss: 0.665053\n",
            "Train Epoch: 4 [1249/3978 (31%)]\tLoss: 0.125175\n",
            "Train Epoch: 4 [1250/3978 (31%)]\tLoss: 0.667069\n",
            "Train Epoch: 4 [1251/3978 (31%)]\tLoss: 0.101606\n",
            "Train Epoch: 4 [1252/3978 (31%)]\tLoss: 0.099259\n",
            "Train Epoch: 4 [1253/3978 (31%)]\tLoss: 0.054276\n",
            "Train Epoch: 4 [1254/3978 (32%)]\tLoss: 0.758049\n",
            "Train Epoch: 4 [1255/3978 (32%)]\tLoss: 0.679615\n",
            "Train Epoch: 4 [1256/3978 (32%)]\tLoss: 0.772479\n",
            "Train Epoch: 4 [1257/3978 (32%)]\tLoss: 0.087957\n",
            "Train Epoch: 4 [1258/3978 (32%)]\tLoss: 0.059466\n",
            "Train Epoch: 4 [1259/3978 (32%)]\tLoss: 0.639533\n",
            "Train Epoch: 4 [1260/3978 (32%)]\tLoss: 0.871102\n",
            "Train Epoch: 4 [1261/3978 (32%)]\tLoss: 0.100874\n",
            "Train Epoch: 4 [1262/3978 (32%)]\tLoss: 0.071194\n",
            "Train Epoch: 4 [1263/3978 (32%)]\tLoss: 0.062687\n",
            "Train Epoch: 4 [1264/3978 (32%)]\tLoss: 0.847767\n",
            "Train Epoch: 4 [1265/3978 (32%)]\tLoss: 0.137715\n",
            "Train Epoch: 4 [1266/3978 (32%)]\tLoss: 0.098092\n",
            "Train Epoch: 4 [1267/3978 (32%)]\tLoss: 0.056839\n",
            "Train Epoch: 4 [1268/3978 (32%)]\tLoss: 0.092149\n",
            "Train Epoch: 4 [1269/3978 (32%)]\tLoss: 0.547281\n",
            "Train Epoch: 4 [1270/3978 (32%)]\tLoss: 0.072415\n",
            "Train Epoch: 4 [1271/3978 (32%)]\tLoss: 0.097355\n",
            "Train Epoch: 4 [1272/3978 (32%)]\tLoss: 0.065085\n",
            "Train Epoch: 4 [1273/3978 (32%)]\tLoss: 0.103170\n",
            "Train Epoch: 4 [1274/3978 (32%)]\tLoss: 0.129936\n",
            "Train Epoch: 4 [1275/3978 (32%)]\tLoss: 0.061846\n",
            "Train Epoch: 4 [1276/3978 (32%)]\tLoss: 0.096420\n",
            "Train Epoch: 4 [1277/3978 (32%)]\tLoss: 0.116126\n",
            "Train Epoch: 4 [1278/3978 (32%)]\tLoss: 0.652585\n",
            "Train Epoch: 4 [1279/3978 (32%)]\tLoss: 0.893314\n",
            "Train Epoch: 4 [1280/3978 (32%)]\tLoss: 0.107443\n",
            "Train Epoch: 4 [1281/3978 (32%)]\tLoss: 0.085314\n",
            "Train Epoch: 4 [1282/3978 (32%)]\tLoss: 0.117165\n",
            "Train Epoch: 4 [1283/3978 (32%)]\tLoss: 0.643203\n",
            "Train Epoch: 4 [1284/3978 (32%)]\tLoss: 0.065957\n",
            "Train Epoch: 4 [1285/3978 (32%)]\tLoss: 0.077342\n",
            "Train Epoch: 4 [1286/3978 (32%)]\tLoss: 0.121072\n",
            "Train Epoch: 4 [1287/3978 (32%)]\tLoss: 0.092158\n",
            "Train Epoch: 4 [1288/3978 (32%)]\tLoss: 0.769133\n",
            "Train Epoch: 4 [1289/3978 (32%)]\tLoss: 0.652632\n",
            "Train Epoch: 4 [1290/3978 (32%)]\tLoss: 0.122262\n",
            "Train Epoch: 4 [1291/3978 (32%)]\tLoss: 0.065421\n",
            "Train Epoch: 4 [1292/3978 (32%)]\tLoss: 0.085937\n",
            "Train Epoch: 4 [1293/3978 (33%)]\tLoss: 0.122120\n",
            "Train Epoch: 4 [1294/3978 (33%)]\tLoss: 0.090677\n",
            "Train Epoch: 4 [1295/3978 (33%)]\tLoss: 0.603049\n",
            "Train Epoch: 4 [1296/3978 (33%)]\tLoss: 0.091915\n",
            "Train Epoch: 4 [1297/3978 (33%)]\tLoss: 0.577830\n",
            "Train Epoch: 4 [1298/3978 (33%)]\tLoss: 0.090446\n",
            "Train Epoch: 4 [1299/3978 (33%)]\tLoss: 0.092758\n",
            "Train Epoch: 4 [1300/3978 (33%)]\tLoss: 0.122594\n",
            "Train Epoch: 4 [1301/3978 (33%)]\tLoss: 0.136526\n",
            "Train Epoch: 4 [1302/3978 (33%)]\tLoss: 0.103371\n",
            "Train Epoch: 4 [1303/3978 (33%)]\tLoss: 0.126787\n",
            "Train Epoch: 4 [1304/3978 (33%)]\tLoss: 0.146703\n",
            "Train Epoch: 4 [1305/3978 (33%)]\tLoss: 0.093983\n",
            "Train Epoch: 4 [1306/3978 (33%)]\tLoss: 0.088901\n",
            "Train Epoch: 4 [1307/3978 (33%)]\tLoss: 0.076744\n",
            "Train Epoch: 4 [1308/3978 (33%)]\tLoss: 0.087707\n",
            "Train Epoch: 4 [1309/3978 (33%)]\tLoss: 0.706946\n",
            "Train Epoch: 4 [1310/3978 (33%)]\tLoss: 0.107777\n",
            "Train Epoch: 4 [1311/3978 (33%)]\tLoss: 0.080549\n",
            "Train Epoch: 4 [1312/3978 (33%)]\tLoss: 0.082780\n",
            "Train Epoch: 4 [1313/3978 (33%)]\tLoss: 0.842097\n",
            "Train Epoch: 4 [1314/3978 (33%)]\tLoss: 0.129157\n",
            "Train Epoch: 4 [1315/3978 (33%)]\tLoss: 0.081062\n",
            "Train Epoch: 4 [1316/3978 (33%)]\tLoss: 0.142623\n",
            "Train Epoch: 4 [1317/3978 (33%)]\tLoss: 0.081673\n",
            "Train Epoch: 4 [1318/3978 (33%)]\tLoss: 0.127118\n",
            "Train Epoch: 4 [1319/3978 (33%)]\tLoss: 0.101002\n",
            "Train Epoch: 4 [1320/3978 (33%)]\tLoss: 0.073295\n",
            "Train Epoch: 4 [1321/3978 (33%)]\tLoss: 0.858250\n",
            "Train Epoch: 4 [1322/3978 (33%)]\tLoss: 0.105968\n",
            "Train Epoch: 4 [1323/3978 (33%)]\tLoss: 0.122794\n",
            "Train Epoch: 4 [1324/3978 (33%)]\tLoss: 0.074794\n",
            "Train Epoch: 4 [1325/3978 (33%)]\tLoss: 0.107214\n",
            "Train Epoch: 4 [1326/3978 (33%)]\tLoss: 0.107741\n",
            "Train Epoch: 4 [1327/3978 (33%)]\tLoss: 0.107584\n",
            "Train Epoch: 4 [1328/3978 (33%)]\tLoss: 0.099603\n",
            "Train Epoch: 4 [1329/3978 (33%)]\tLoss: 0.682132\n",
            "Train Epoch: 4 [1330/3978 (33%)]\tLoss: 0.076745\n",
            "Train Epoch: 4 [1331/3978 (33%)]\tLoss: 0.085098\n",
            "Train Epoch: 4 [1332/3978 (33%)]\tLoss: 0.068782\n",
            "Train Epoch: 4 [1333/3978 (34%)]\tLoss: 0.095795\n",
            "Train Epoch: 4 [1334/3978 (34%)]\tLoss: 0.594088\n",
            "Train Epoch: 4 [1335/3978 (34%)]\tLoss: 1.292593\n",
            "Train Epoch: 4 [1336/3978 (34%)]\tLoss: 0.090653\n",
            "Train Epoch: 4 [1337/3978 (34%)]\tLoss: 0.617060\n",
            "Train Epoch: 4 [1338/3978 (34%)]\tLoss: 1.032790\n",
            "Train Epoch: 4 [1339/3978 (34%)]\tLoss: 0.085830\n",
            "Train Epoch: 4 [1340/3978 (34%)]\tLoss: 0.088998\n",
            "Train Epoch: 4 [1341/3978 (34%)]\tLoss: 0.110576\n",
            "Train Epoch: 4 [1342/3978 (34%)]\tLoss: 0.596325\n",
            "Train Epoch: 4 [1343/3978 (34%)]\tLoss: 0.727951\n",
            "Train Epoch: 4 [1344/3978 (34%)]\tLoss: 0.081425\n",
            "Train Epoch: 4 [1345/3978 (34%)]\tLoss: 0.075251\n",
            "Train Epoch: 4 [1346/3978 (34%)]\tLoss: 0.132441\n",
            "Train Epoch: 4 [1347/3978 (34%)]\tLoss: 0.094669\n",
            "Train Epoch: 4 [1348/3978 (34%)]\tLoss: 0.100962\n",
            "Train Epoch: 4 [1349/3978 (34%)]\tLoss: 0.089658\n",
            "Train Epoch: 4 [1350/3978 (34%)]\tLoss: 0.095776\n",
            "Train Epoch: 4 [1351/3978 (34%)]\tLoss: 0.097691\n",
            "Train Epoch: 4 [1352/3978 (34%)]\tLoss: 0.123134\n",
            "Train Epoch: 4 [1353/3978 (34%)]\tLoss: 0.128509\n",
            "Train Epoch: 4 [1354/3978 (34%)]\tLoss: 0.119409\n",
            "Train Epoch: 4 [1355/3978 (34%)]\tLoss: 0.148196\n",
            "Train Epoch: 4 [1356/3978 (34%)]\tLoss: 0.144161\n",
            "Train Epoch: 4 [1357/3978 (34%)]\tLoss: 0.129448\n",
            "Train Epoch: 4 [1358/3978 (34%)]\tLoss: 0.112480\n",
            "Train Epoch: 4 [1359/3978 (34%)]\tLoss: 0.091181\n",
            "Train Epoch: 4 [1360/3978 (34%)]\tLoss: 0.064896\n",
            "Train Epoch: 4 [1361/3978 (34%)]\tLoss: 0.084909\n",
            "Train Epoch: 4 [1362/3978 (34%)]\tLoss: 0.489838\n",
            "Train Epoch: 4 [1363/3978 (34%)]\tLoss: 0.123977\n",
            "Train Epoch: 4 [1364/3978 (34%)]\tLoss: 0.086260\n",
            "Train Epoch: 4 [1365/3978 (34%)]\tLoss: 0.064139\n",
            "Train Epoch: 4 [1366/3978 (34%)]\tLoss: 0.064294\n",
            "Train Epoch: 4 [1367/3978 (34%)]\tLoss: 0.124390\n",
            "Train Epoch: 4 [1368/3978 (34%)]\tLoss: 0.619068\n",
            "Train Epoch: 4 [1369/3978 (34%)]\tLoss: 0.092193\n",
            "Train Epoch: 4 [1370/3978 (34%)]\tLoss: 0.084025\n",
            "Train Epoch: 4 [1371/3978 (34%)]\tLoss: 0.075162\n",
            "Train Epoch: 4 [1372/3978 (34%)]\tLoss: 0.089361\n",
            "Train Epoch: 4 [1373/3978 (35%)]\tLoss: 0.109985\n",
            "Train Epoch: 4 [1374/3978 (35%)]\tLoss: 0.068187\n",
            "Train Epoch: 4 [1375/3978 (35%)]\tLoss: 0.783332\n",
            "Train Epoch: 4 [1376/3978 (35%)]\tLoss: 0.092846\n",
            "Train Epoch: 4 [1377/3978 (35%)]\tLoss: 0.059546\n",
            "Train Epoch: 4 [1378/3978 (35%)]\tLoss: 0.111859\n",
            "Train Epoch: 4 [1379/3978 (35%)]\tLoss: 0.122493\n",
            "Train Epoch: 4 [1380/3978 (35%)]\tLoss: 0.073027\n",
            "Train Epoch: 4 [1381/3978 (35%)]\tLoss: 0.143089\n",
            "Train Epoch: 4 [1382/3978 (35%)]\tLoss: 0.105133\n",
            "Train Epoch: 4 [1383/3978 (35%)]\tLoss: 0.069057\n",
            "Train Epoch: 4 [1384/3978 (35%)]\tLoss: 0.099169\n",
            "Train Epoch: 4 [1385/3978 (35%)]\tLoss: 0.061160\n",
            "Train Epoch: 4 [1386/3978 (35%)]\tLoss: 0.141241\n",
            "Train Epoch: 4 [1387/3978 (35%)]\tLoss: 0.094553\n",
            "Train Epoch: 4 [1388/3978 (35%)]\tLoss: 0.093843\n",
            "Train Epoch: 4 [1389/3978 (35%)]\tLoss: 0.066118\n",
            "Train Epoch: 4 [1390/3978 (35%)]\tLoss: 1.157342\n",
            "Train Epoch: 4 [1391/3978 (35%)]\tLoss: 0.072708\n",
            "Train Epoch: 4 [1392/3978 (35%)]\tLoss: 0.085242\n",
            "Train Epoch: 4 [1393/3978 (35%)]\tLoss: 0.079071\n",
            "Train Epoch: 4 [1394/3978 (35%)]\tLoss: 0.087658\n",
            "Train Epoch: 4 [1395/3978 (35%)]\tLoss: 0.088970\n",
            "Train Epoch: 4 [1396/3978 (35%)]\tLoss: 0.085379\n",
            "Train Epoch: 4 [1397/3978 (35%)]\tLoss: 0.068243\n",
            "Train Epoch: 4 [1398/3978 (35%)]\tLoss: 0.077432\n",
            "Train Epoch: 4 [1399/3978 (35%)]\tLoss: 0.897203\n",
            "Train Epoch: 4 [1400/3978 (35%)]\tLoss: 0.099242\n",
            "Train Epoch: 4 [1401/3978 (35%)]\tLoss: 0.078535\n",
            "Train Epoch: 4 [1402/3978 (35%)]\tLoss: 0.717216\n",
            "Train Epoch: 4 [1403/3978 (35%)]\tLoss: 0.065414\n",
            "Train Epoch: 4 [1404/3978 (35%)]\tLoss: 0.084375\n",
            "Train Epoch: 4 [1405/3978 (35%)]\tLoss: 0.083893\n",
            "Train Epoch: 4 [1406/3978 (35%)]\tLoss: 0.061911\n",
            "Train Epoch: 4 [1407/3978 (35%)]\tLoss: 0.576786\n",
            "Train Epoch: 4 [1408/3978 (35%)]\tLoss: 0.942269\n",
            "Train Epoch: 4 [1409/3978 (35%)]\tLoss: 0.057812\n",
            "Train Epoch: 4 [1410/3978 (35%)]\tLoss: 0.645972\n",
            "Train Epoch: 4 [1411/3978 (35%)]\tLoss: 0.847315\n",
            "Train Epoch: 4 [1412/3978 (35%)]\tLoss: 0.104942\n",
            "Train Epoch: 4 [1413/3978 (36%)]\tLoss: 0.073331\n",
            "Train Epoch: 4 [1414/3978 (36%)]\tLoss: 0.078070\n",
            "Train Epoch: 4 [1415/3978 (36%)]\tLoss: 0.080716\n",
            "Train Epoch: 4 [1416/3978 (36%)]\tLoss: 0.529391\n",
            "Train Epoch: 4 [1417/3978 (36%)]\tLoss: 0.091966\n",
            "Train Epoch: 4 [1418/3978 (36%)]\tLoss: 0.067048\n",
            "Train Epoch: 4 [1419/3978 (36%)]\tLoss: 0.118244\n",
            "Train Epoch: 4 [1420/3978 (36%)]\tLoss: 0.123271\n",
            "Train Epoch: 4 [1421/3978 (36%)]\tLoss: 0.122795\n",
            "Train Epoch: 4 [1422/3978 (36%)]\tLoss: 0.115819\n",
            "Train Epoch: 4 [1423/3978 (36%)]\tLoss: 0.730529\n",
            "Train Epoch: 4 [1424/3978 (36%)]\tLoss: 1.134612\n",
            "Train Epoch: 4 [1425/3978 (36%)]\tLoss: 0.094197\n",
            "Train Epoch: 4 [1426/3978 (36%)]\tLoss: 0.086487\n",
            "Train Epoch: 4 [1427/3978 (36%)]\tLoss: 0.740059\n",
            "Train Epoch: 4 [1428/3978 (36%)]\tLoss: 0.081552\n",
            "Train Epoch: 4 [1429/3978 (36%)]\tLoss: 0.071631\n",
            "Train Epoch: 4 [1430/3978 (36%)]\tLoss: 0.101730\n",
            "Train Epoch: 4 [1431/3978 (36%)]\tLoss: 0.084399\n",
            "Train Epoch: 4 [1432/3978 (36%)]\tLoss: 0.084034\n",
            "Train Epoch: 4 [1433/3978 (36%)]\tLoss: 0.083307\n",
            "Train Epoch: 4 [1434/3978 (36%)]\tLoss: 0.121162\n",
            "Train Epoch: 4 [1435/3978 (36%)]\tLoss: 0.092359\n",
            "Train Epoch: 4 [1436/3978 (36%)]\tLoss: 0.084340\n",
            "Train Epoch: 4 [1437/3978 (36%)]\tLoss: 0.129818\n",
            "Train Epoch: 4 [1438/3978 (36%)]\tLoss: 0.068790\n",
            "Train Epoch: 4 [1439/3978 (36%)]\tLoss: 0.632855\n",
            "Train Epoch: 4 [1440/3978 (36%)]\tLoss: 0.076924\n",
            "Train Epoch: 4 [1441/3978 (36%)]\tLoss: 0.755415\n",
            "Train Epoch: 4 [1442/3978 (36%)]\tLoss: 0.092742\n",
            "Train Epoch: 4 [1443/3978 (36%)]\tLoss: 0.123243\n",
            "Train Epoch: 4 [1444/3978 (36%)]\tLoss: 0.078160\n",
            "Train Epoch: 4 [1445/3978 (36%)]\tLoss: 0.071602\n",
            "Train Epoch: 4 [1446/3978 (36%)]\tLoss: 0.102566\n",
            "Train Epoch: 4 [1447/3978 (36%)]\tLoss: 0.127270\n",
            "Train Epoch: 4 [1448/3978 (36%)]\tLoss: 0.081349\n",
            "Train Epoch: 4 [1449/3978 (36%)]\tLoss: 0.114575\n",
            "Train Epoch: 4 [1450/3978 (36%)]\tLoss: 0.075686\n",
            "Train Epoch: 4 [1451/3978 (36%)]\tLoss: 0.769481\n",
            "Train Epoch: 4 [1452/3978 (37%)]\tLoss: 0.120488\n",
            "Train Epoch: 4 [1453/3978 (37%)]\tLoss: 0.816261\n",
            "Train Epoch: 4 [1454/3978 (37%)]\tLoss: 0.097165\n",
            "Train Epoch: 4 [1455/3978 (37%)]\tLoss: 0.068208\n",
            "Train Epoch: 4 [1456/3978 (37%)]\tLoss: 0.080184\n",
            "Train Epoch: 4 [1457/3978 (37%)]\tLoss: 0.079475\n",
            "Train Epoch: 4 [1458/3978 (37%)]\tLoss: 0.090017\n",
            "Train Epoch: 4 [1459/3978 (37%)]\tLoss: 0.088382\n",
            "Train Epoch: 4 [1460/3978 (37%)]\tLoss: 0.073301\n",
            "Train Epoch: 4 [1461/3978 (37%)]\tLoss: 0.756488\n",
            "Train Epoch: 4 [1462/3978 (37%)]\tLoss: 0.550769\n",
            "Train Epoch: 4 [1463/3978 (37%)]\tLoss: 1.072972\n",
            "Train Epoch: 4 [1464/3978 (37%)]\tLoss: 0.070474\n",
            "Train Epoch: 4 [1465/3978 (37%)]\tLoss: 0.116152\n",
            "Train Epoch: 4 [1466/3978 (37%)]\tLoss: 0.090636\n",
            "Train Epoch: 4 [1467/3978 (37%)]\tLoss: 0.650444\n",
            "Train Epoch: 4 [1468/3978 (37%)]\tLoss: 0.627955\n",
            "Train Epoch: 4 [1469/3978 (37%)]\tLoss: 0.098850\n",
            "Train Epoch: 4 [1470/3978 (37%)]\tLoss: 0.106802\n",
            "Train Epoch: 4 [1471/3978 (37%)]\tLoss: 0.061352\n",
            "Train Epoch: 4 [1472/3978 (37%)]\tLoss: 0.115476\n",
            "Train Epoch: 4 [1473/3978 (37%)]\tLoss: 0.100569\n",
            "Train Epoch: 4 [1474/3978 (37%)]\tLoss: 0.058564\n",
            "Train Epoch: 4 [1475/3978 (37%)]\tLoss: 0.095444\n",
            "Train Epoch: 4 [1476/3978 (37%)]\tLoss: 0.103721\n",
            "Train Epoch: 4 [1477/3978 (37%)]\tLoss: 0.102087\n",
            "Train Epoch: 4 [1478/3978 (37%)]\tLoss: 0.536677\n",
            "Train Epoch: 4 [1479/3978 (37%)]\tLoss: 0.137473\n",
            "Train Epoch: 4 [1480/3978 (37%)]\tLoss: 0.067039\n",
            "Train Epoch: 4 [1481/3978 (37%)]\tLoss: 0.083138\n",
            "Train Epoch: 4 [1482/3978 (37%)]\tLoss: 0.074951\n",
            "Train Epoch: 4 [1483/3978 (37%)]\tLoss: 0.152709\n",
            "Train Epoch: 4 [1484/3978 (37%)]\tLoss: 0.065331\n",
            "Train Epoch: 4 [1485/3978 (37%)]\tLoss: 0.075192\n",
            "Train Epoch: 4 [1486/3978 (37%)]\tLoss: 0.134286\n",
            "Train Epoch: 4 [1487/3978 (37%)]\tLoss: 0.116811\n",
            "Train Epoch: 4 [1488/3978 (37%)]\tLoss: 0.120321\n",
            "Train Epoch: 4 [1489/3978 (37%)]\tLoss: 0.057091\n",
            "Train Epoch: 4 [1490/3978 (37%)]\tLoss: 0.106169\n",
            "Train Epoch: 4 [1491/3978 (37%)]\tLoss: 0.112732\n",
            "Train Epoch: 4 [1492/3978 (38%)]\tLoss: 0.120689\n",
            "Train Epoch: 4 [1493/3978 (38%)]\tLoss: 0.102217\n",
            "Train Epoch: 4 [1494/3978 (38%)]\tLoss: 0.642941\n",
            "Train Epoch: 4 [1495/3978 (38%)]\tLoss: 0.121912\n",
            "Train Epoch: 4 [1496/3978 (38%)]\tLoss: 0.634468\n",
            "Train Epoch: 4 [1497/3978 (38%)]\tLoss: 0.744189\n",
            "Train Epoch: 4 [1498/3978 (38%)]\tLoss: 0.116291\n",
            "Train Epoch: 4 [1499/3978 (38%)]\tLoss: 0.116811\n",
            "Train Epoch: 4 [1500/3978 (38%)]\tLoss: 0.078487\n",
            "Train Epoch: 4 [1501/3978 (38%)]\tLoss: 0.073323\n",
            "Train Epoch: 4 [1502/3978 (38%)]\tLoss: 0.640813\n",
            "Train Epoch: 4 [1503/3978 (38%)]\tLoss: 0.056517\n",
            "Train Epoch: 4 [1504/3978 (38%)]\tLoss: 0.058418\n",
            "Train Epoch: 4 [1505/3978 (38%)]\tLoss: 0.112643\n",
            "Train Epoch: 4 [1506/3978 (38%)]\tLoss: 0.647033\n",
            "Train Epoch: 4 [1507/3978 (38%)]\tLoss: 0.144396\n",
            "Train Epoch: 4 [1508/3978 (38%)]\tLoss: 0.117283\n",
            "Train Epoch: 4 [1509/3978 (38%)]\tLoss: 0.156438\n",
            "Train Epoch: 4 [1510/3978 (38%)]\tLoss: 0.156002\n",
            "Train Epoch: 4 [1511/3978 (38%)]\tLoss: 0.086652\n",
            "Train Epoch: 4 [1512/3978 (38%)]\tLoss: 0.579101\n",
            "Train Epoch: 4 [1513/3978 (38%)]\tLoss: 0.807701\n",
            "Train Epoch: 4 [1514/3978 (38%)]\tLoss: 0.057117\n",
            "Train Epoch: 4 [1515/3978 (38%)]\tLoss: 0.057897\n",
            "Train Epoch: 4 [1516/3978 (38%)]\tLoss: 0.154684\n",
            "Train Epoch: 4 [1517/3978 (38%)]\tLoss: 0.053464\n",
            "Train Epoch: 4 [1518/3978 (38%)]\tLoss: 0.117788\n",
            "Train Epoch: 4 [1519/3978 (38%)]\tLoss: 0.057906\n",
            "Train Epoch: 4 [1520/3978 (38%)]\tLoss: 0.164428\n",
            "Train Epoch: 4 [1521/3978 (38%)]\tLoss: 0.150047\n",
            "Train Epoch: 4 [1522/3978 (38%)]\tLoss: 0.093854\n",
            "Train Epoch: 4 [1523/3978 (38%)]\tLoss: 0.064537\n",
            "Train Epoch: 4 [1524/3978 (38%)]\tLoss: 0.121790\n",
            "Train Epoch: 4 [1525/3978 (38%)]\tLoss: 0.060066\n",
            "Train Epoch: 4 [1526/3978 (38%)]\tLoss: 0.104976\n",
            "Train Epoch: 4 [1527/3978 (38%)]\tLoss: 0.099585\n",
            "Train Epoch: 4 [1528/3978 (38%)]\tLoss: 0.103561\n",
            "Train Epoch: 4 [1529/3978 (38%)]\tLoss: 0.065026\n",
            "Train Epoch: 4 [1530/3978 (38%)]\tLoss: 0.065593\n",
            "Train Epoch: 4 [1531/3978 (38%)]\tLoss: 0.066140\n",
            "Train Epoch: 4 [1532/3978 (39%)]\tLoss: 0.070912\n",
            "Train Epoch: 4 [1533/3978 (39%)]\tLoss: 0.064026\n",
            "Train Epoch: 4 [1534/3978 (39%)]\tLoss: 0.100619\n",
            "Train Epoch: 4 [1535/3978 (39%)]\tLoss: 1.240105\n",
            "Train Epoch: 4 [1536/3978 (39%)]\tLoss: 1.109329\n",
            "Train Epoch: 4 [1537/3978 (39%)]\tLoss: 0.052795\n",
            "Train Epoch: 4 [1538/3978 (39%)]\tLoss: 0.064092\n",
            "Train Epoch: 4 [1539/3978 (39%)]\tLoss: 0.055956\n",
            "Train Epoch: 4 [1540/3978 (39%)]\tLoss: 0.559399\n",
            "Train Epoch: 4 [1541/3978 (39%)]\tLoss: 0.055741\n",
            "Train Epoch: 4 [1542/3978 (39%)]\tLoss: 0.108551\n",
            "Train Epoch: 4 [1543/3978 (39%)]\tLoss: 0.981586\n",
            "Train Epoch: 4 [1544/3978 (39%)]\tLoss: 0.108803\n",
            "Train Epoch: 4 [1545/3978 (39%)]\tLoss: 0.721496\n",
            "Train Epoch: 4 [1546/3978 (39%)]\tLoss: 1.140144\n",
            "Train Epoch: 4 [1547/3978 (39%)]\tLoss: 0.718976\n",
            "Train Epoch: 4 [1548/3978 (39%)]\tLoss: 0.749574\n",
            "Train Epoch: 4 [1549/3978 (39%)]\tLoss: 0.855122\n",
            "Train Epoch: 4 [1550/3978 (39%)]\tLoss: 0.052208\n",
            "Train Epoch: 4 [1551/3978 (39%)]\tLoss: 0.162794\n",
            "Train Epoch: 4 [1552/3978 (39%)]\tLoss: 0.122431\n",
            "Train Epoch: 4 [1553/3978 (39%)]\tLoss: 0.112113\n",
            "Train Epoch: 4 [1554/3978 (39%)]\tLoss: 0.054377\n",
            "Train Epoch: 4 [1555/3978 (39%)]\tLoss: 0.099085\n",
            "Train Epoch: 4 [1556/3978 (39%)]\tLoss: 0.061127\n",
            "Train Epoch: 4 [1557/3978 (39%)]\tLoss: 0.668182\n",
            "Train Epoch: 4 [1558/3978 (39%)]\tLoss: 0.067084\n",
            "Train Epoch: 4 [1559/3978 (39%)]\tLoss: 0.119261\n",
            "Train Epoch: 4 [1560/3978 (39%)]\tLoss: 0.082792\n",
            "Train Epoch: 4 [1561/3978 (39%)]\tLoss: 0.066210\n",
            "Train Epoch: 4 [1562/3978 (39%)]\tLoss: 0.577958\n",
            "Train Epoch: 4 [1563/3978 (39%)]\tLoss: 0.156201\n",
            "Train Epoch: 4 [1564/3978 (39%)]\tLoss: 0.068557\n",
            "Train Epoch: 4 [1565/3978 (39%)]\tLoss: 0.082440\n",
            "Train Epoch: 4 [1566/3978 (39%)]\tLoss: 0.078002\n",
            "Train Epoch: 4 [1567/3978 (39%)]\tLoss: 0.097732\n",
            "Train Epoch: 4 [1568/3978 (39%)]\tLoss: 0.129906\n",
            "Train Epoch: 4 [1569/3978 (39%)]\tLoss: 0.118875\n",
            "Train Epoch: 4 [1570/3978 (39%)]\tLoss: 0.100623\n",
            "Train Epoch: 4 [1571/3978 (39%)]\tLoss: 0.108237\n",
            "Train Epoch: 4 [1572/3978 (40%)]\tLoss: 0.082874\n",
            "Train Epoch: 4 [1573/3978 (40%)]\tLoss: 0.643754\n",
            "Train Epoch: 4 [1574/3978 (40%)]\tLoss: 0.709845\n",
            "Train Epoch: 4 [1575/3978 (40%)]\tLoss: 0.073625\n",
            "Train Epoch: 4 [1576/3978 (40%)]\tLoss: 0.148826\n",
            "Train Epoch: 4 [1577/3978 (40%)]\tLoss: 0.117770\n",
            "Train Epoch: 4 [1578/3978 (40%)]\tLoss: 0.096081\n",
            "Train Epoch: 4 [1579/3978 (40%)]\tLoss: 0.137242\n",
            "Train Epoch: 4 [1580/3978 (40%)]\tLoss: 0.086816\n",
            "Train Epoch: 4 [1581/3978 (40%)]\tLoss: 0.586667\n",
            "Train Epoch: 4 [1582/3978 (40%)]\tLoss: 0.140192\n",
            "Train Epoch: 4 [1583/3978 (40%)]\tLoss: 0.085543\n",
            "Train Epoch: 4 [1584/3978 (40%)]\tLoss: 0.095726\n",
            "Train Epoch: 4 [1585/3978 (40%)]\tLoss: 0.612207\n",
            "Train Epoch: 4 [1586/3978 (40%)]\tLoss: 1.066982\n",
            "Train Epoch: 4 [1587/3978 (40%)]\tLoss: 0.558103\n",
            "Train Epoch: 4 [1588/3978 (40%)]\tLoss: 0.091609\n",
            "Train Epoch: 4 [1589/3978 (40%)]\tLoss: 0.084929\n",
            "Train Epoch: 4 [1590/3978 (40%)]\tLoss: 0.079933\n",
            "Train Epoch: 4 [1591/3978 (40%)]\tLoss: 0.094608\n",
            "Train Epoch: 4 [1592/3978 (40%)]\tLoss: 0.083578\n",
            "Train Epoch: 4 [1593/3978 (40%)]\tLoss: 0.083975\n",
            "Train Epoch: 4 [1594/3978 (40%)]\tLoss: 0.089641\n",
            "Train Epoch: 4 [1595/3978 (40%)]\tLoss: 0.880201\n",
            "Train Epoch: 4 [1596/3978 (40%)]\tLoss: 0.112056\n",
            "Train Epoch: 4 [1597/3978 (40%)]\tLoss: 0.090850\n",
            "Train Epoch: 4 [1598/3978 (40%)]\tLoss: 0.097261\n",
            "Train Epoch: 4 [1599/3978 (40%)]\tLoss: 0.137579\n",
            "Train Epoch: 4 [1600/3978 (40%)]\tLoss: 0.844698\n",
            "Train Epoch: 4 [1601/3978 (40%)]\tLoss: 0.090865\n",
            "Train Epoch: 4 [1602/3978 (40%)]\tLoss: 0.090682\n",
            "Train Epoch: 4 [1603/3978 (40%)]\tLoss: 0.108823\n",
            "Train Epoch: 4 [1604/3978 (40%)]\tLoss: 0.511387\n",
            "Train Epoch: 4 [1605/3978 (40%)]\tLoss: 0.088512\n",
            "Train Epoch: 4 [1606/3978 (40%)]\tLoss: 0.815012\n",
            "Train Epoch: 4 [1607/3978 (40%)]\tLoss: 0.094906\n",
            "Train Epoch: 4 [1608/3978 (40%)]\tLoss: 0.713076\n",
            "Train Epoch: 4 [1609/3978 (40%)]\tLoss: 0.115141\n",
            "Train Epoch: 4 [1610/3978 (40%)]\tLoss: 0.098212\n",
            "Train Epoch: 4 [1611/3978 (40%)]\tLoss: 0.121875\n",
            "Train Epoch: 4 [1612/3978 (41%)]\tLoss: 0.078762\n",
            "Train Epoch: 4 [1613/3978 (41%)]\tLoss: 0.087641\n",
            "Train Epoch: 4 [1614/3978 (41%)]\tLoss: 0.075661\n",
            "Train Epoch: 4 [1615/3978 (41%)]\tLoss: 0.070435\n",
            "Train Epoch: 4 [1616/3978 (41%)]\tLoss: 0.090775\n",
            "Train Epoch: 4 [1617/3978 (41%)]\tLoss: 0.464986\n",
            "Train Epoch: 4 [1618/3978 (41%)]\tLoss: 0.176257\n",
            "Train Epoch: 4 [1619/3978 (41%)]\tLoss: 0.181561\n",
            "Train Epoch: 4 [1620/3978 (41%)]\tLoss: 0.063358\n",
            "Train Epoch: 4 [1621/3978 (41%)]\tLoss: 0.113096\n",
            "Train Epoch: 4 [1622/3978 (41%)]\tLoss: 0.119223\n",
            "Train Epoch: 4 [1623/3978 (41%)]\tLoss: 0.110511\n",
            "Train Epoch: 4 [1624/3978 (41%)]\tLoss: 0.066917\n",
            "Train Epoch: 4 [1625/3978 (41%)]\tLoss: 0.115122\n",
            "Train Epoch: 4 [1626/3978 (41%)]\tLoss: 0.148031\n",
            "Train Epoch: 4 [1627/3978 (41%)]\tLoss: 0.068335\n",
            "Train Epoch: 4 [1628/3978 (41%)]\tLoss: 0.613574\n",
            "Train Epoch: 4 [1629/3978 (41%)]\tLoss: 0.067299\n",
            "Train Epoch: 4 [1630/3978 (41%)]\tLoss: 0.094902\n",
            "Train Epoch: 4 [1631/3978 (41%)]\tLoss: 0.070494\n",
            "Train Epoch: 4 [1632/3978 (41%)]\tLoss: 0.436538\n",
            "Train Epoch: 4 [1633/3978 (41%)]\tLoss: 0.541792\n",
            "Train Epoch: 4 [1634/3978 (41%)]\tLoss: 0.584737\n",
            "Train Epoch: 4 [1635/3978 (41%)]\tLoss: 0.072137\n",
            "Train Epoch: 4 [1636/3978 (41%)]\tLoss: 0.080438\n",
            "Train Epoch: 4 [1637/3978 (41%)]\tLoss: 0.122925\n",
            "Train Epoch: 4 [1638/3978 (41%)]\tLoss: 1.069710\n",
            "Train Epoch: 4 [1639/3978 (41%)]\tLoss: 0.121654\n",
            "Train Epoch: 4 [1640/3978 (41%)]\tLoss: 0.082060\n",
            "Train Epoch: 4 [1641/3978 (41%)]\tLoss: 0.117005\n",
            "Train Epoch: 4 [1642/3978 (41%)]\tLoss: 0.107452\n",
            "Train Epoch: 4 [1643/3978 (41%)]\tLoss: 0.139708\n",
            "Train Epoch: 4 [1644/3978 (41%)]\tLoss: 0.082226\n",
            "Train Epoch: 4 [1645/3978 (41%)]\tLoss: 0.082390\n",
            "Train Epoch: 4 [1646/3978 (41%)]\tLoss: 0.094456\n",
            "Train Epoch: 4 [1647/3978 (41%)]\tLoss: 0.102520\n",
            "Train Epoch: 4 [1648/3978 (41%)]\tLoss: 0.074380\n",
            "Train Epoch: 4 [1649/3978 (41%)]\tLoss: 1.004471\n",
            "Train Epoch: 4 [1650/3978 (41%)]\tLoss: 0.074866\n",
            "Train Epoch: 4 [1651/3978 (42%)]\tLoss: 0.783341\n",
            "Train Epoch: 4 [1652/3978 (42%)]\tLoss: 0.858924\n",
            "Train Epoch: 4 [1653/3978 (42%)]\tLoss: 0.097789\n",
            "Train Epoch: 4 [1654/3978 (42%)]\tLoss: 0.124857\n",
            "Train Epoch: 4 [1655/3978 (42%)]\tLoss: 0.097646\n",
            "Train Epoch: 4 [1656/3978 (42%)]\tLoss: 0.130916\n",
            "Train Epoch: 4 [1657/3978 (42%)]\tLoss: 0.097691\n",
            "Train Epoch: 4 [1658/3978 (42%)]\tLoss: 0.098901\n",
            "Train Epoch: 4 [1659/3978 (42%)]\tLoss: 0.887881\n",
            "Train Epoch: 4 [1660/3978 (42%)]\tLoss: 0.763903\n",
            "Train Epoch: 4 [1661/3978 (42%)]\tLoss: 0.100070\n",
            "Train Epoch: 4 [1662/3978 (42%)]\tLoss: 0.662502\n",
            "Train Epoch: 4 [1663/3978 (42%)]\tLoss: 0.600020\n",
            "Train Epoch: 4 [1664/3978 (42%)]\tLoss: 0.097853\n",
            "Train Epoch: 4 [1665/3978 (42%)]\tLoss: 0.084964\n",
            "Train Epoch: 4 [1666/3978 (42%)]\tLoss: 0.092200\n",
            "Train Epoch: 4 [1667/3978 (42%)]\tLoss: 0.771994\n",
            "Train Epoch: 4 [1668/3978 (42%)]\tLoss: 0.095509\n",
            "Train Epoch: 4 [1669/3978 (42%)]\tLoss: 0.090510\n",
            "Train Epoch: 4 [1670/3978 (42%)]\tLoss: 0.779762\n",
            "Train Epoch: 4 [1671/3978 (42%)]\tLoss: 0.780513\n",
            "Train Epoch: 4 [1672/3978 (42%)]\tLoss: 0.827322\n",
            "Train Epoch: 4 [1673/3978 (42%)]\tLoss: 0.119109\n",
            "Train Epoch: 4 [1674/3978 (42%)]\tLoss: 0.106087\n",
            "Train Epoch: 4 [1675/3978 (42%)]\tLoss: 0.109913\n",
            "Train Epoch: 4 [1676/3978 (42%)]\tLoss: 0.149679\n",
            "Train Epoch: 4 [1677/3978 (42%)]\tLoss: 0.151558\n",
            "Train Epoch: 4 [1678/3978 (42%)]\tLoss: 0.132392\n",
            "Train Epoch: 4 [1679/3978 (42%)]\tLoss: 0.091852\n",
            "Train Epoch: 4 [1680/3978 (42%)]\tLoss: 0.133414\n",
            "Train Epoch: 4 [1681/3978 (42%)]\tLoss: 0.091221\n",
            "Train Epoch: 4 [1682/3978 (42%)]\tLoss: 0.475053\n",
            "Train Epoch: 4 [1683/3978 (42%)]\tLoss: 0.895609\n",
            "Train Epoch: 4 [1684/3978 (42%)]\tLoss: 0.104872\n",
            "Train Epoch: 4 [1685/3978 (42%)]\tLoss: 0.554720\n",
            "Train Epoch: 4 [1686/3978 (42%)]\tLoss: 0.103324\n",
            "Train Epoch: 4 [1687/3978 (42%)]\tLoss: 0.080321\n",
            "Train Epoch: 4 [1688/3978 (42%)]\tLoss: 0.146432\n",
            "Train Epoch: 4 [1689/3978 (42%)]\tLoss: 0.668345\n",
            "Train Epoch: 4 [1690/3978 (42%)]\tLoss: 0.441351\n",
            "Train Epoch: 4 [1691/3978 (43%)]\tLoss: 0.523828\n",
            "Train Epoch: 4 [1692/3978 (43%)]\tLoss: 0.086257\n",
            "Train Epoch: 4 [1693/3978 (43%)]\tLoss: 0.155010\n",
            "Train Epoch: 4 [1694/3978 (43%)]\tLoss: 0.462749\n",
            "Train Epoch: 4 [1695/3978 (43%)]\tLoss: 0.463093\n",
            "Train Epoch: 4 [1696/3978 (43%)]\tLoss: 0.205934\n",
            "Train Epoch: 4 [1697/3978 (43%)]\tLoss: 0.475678\n",
            "Train Epoch: 4 [1698/3978 (43%)]\tLoss: 0.870990\n",
            "Train Epoch: 4 [1699/3978 (43%)]\tLoss: 0.162564\n",
            "Train Epoch: 4 [1700/3978 (43%)]\tLoss: 0.786085\n",
            "Train Epoch: 4 [1701/3978 (43%)]\tLoss: 0.778580\n",
            "Train Epoch: 4 [1702/3978 (43%)]\tLoss: 0.353675\n",
            "Train Epoch: 4 [1703/3978 (43%)]\tLoss: 0.699300\n",
            "Train Epoch: 4 [1704/3978 (43%)]\tLoss: 0.141679\n",
            "Train Epoch: 4 [1705/3978 (43%)]\tLoss: 0.094230\n",
            "Train Epoch: 4 [1706/3978 (43%)]\tLoss: 0.194242\n",
            "Train Epoch: 4 [1707/3978 (43%)]\tLoss: 0.129558\n",
            "Train Epoch: 4 [1708/3978 (43%)]\tLoss: 0.717589\n",
            "Train Epoch: 4 [1709/3978 (43%)]\tLoss: 0.737362\n",
            "Train Epoch: 4 [1710/3978 (43%)]\tLoss: 0.130323\n",
            "Train Epoch: 4 [1711/3978 (43%)]\tLoss: 0.663306\n",
            "Train Epoch: 4 [1712/3978 (43%)]\tLoss: 0.377645\n",
            "Train Epoch: 4 [1713/3978 (43%)]\tLoss: 0.136789\n",
            "Train Epoch: 4 [1714/3978 (43%)]\tLoss: 0.161375\n",
            "Train Epoch: 4 [1715/3978 (43%)]\tLoss: 0.166949\n",
            "Train Epoch: 4 [1716/3978 (43%)]\tLoss: 0.116863\n",
            "Train Epoch: 4 [1717/3978 (43%)]\tLoss: 0.114572\n",
            "Train Epoch: 4 [1718/3978 (43%)]\tLoss: 0.142066\n",
            "Train Epoch: 4 [1719/3978 (43%)]\tLoss: 0.418627\n",
            "Train Epoch: 4 [1720/3978 (43%)]\tLoss: 0.307380\n",
            "Train Epoch: 4 [1721/3978 (43%)]\tLoss: 0.136414\n",
            "Train Epoch: 4 [1722/3978 (43%)]\tLoss: 0.151146\n",
            "Train Epoch: 4 [1723/3978 (43%)]\tLoss: 0.112867\n",
            "Train Epoch: 4 [1724/3978 (43%)]\tLoss: 0.138923\n",
            "Train Epoch: 4 [1725/3978 (43%)]\tLoss: 0.109393\n",
            "Train Epoch: 4 [1726/3978 (43%)]\tLoss: 0.149275\n",
            "Train Epoch: 4 [1727/3978 (43%)]\tLoss: 0.584825\n",
            "Train Epoch: 4 [1728/3978 (43%)]\tLoss: 0.157158\n",
            "Train Epoch: 4 [1729/3978 (43%)]\tLoss: 0.157704\n",
            "Train Epoch: 4 [1730/3978 (43%)]\tLoss: 0.137417\n",
            "Train Epoch: 4 [1731/3978 (44%)]\tLoss: 0.147701\n",
            "Train Epoch: 4 [1732/3978 (44%)]\tLoss: 0.115471\n",
            "Train Epoch: 4 [1733/3978 (44%)]\tLoss: 0.136713\n",
            "Train Epoch: 4 [1734/3978 (44%)]\tLoss: 0.138705\n",
            "Train Epoch: 4 [1735/3978 (44%)]\tLoss: 0.156941\n",
            "Train Epoch: 4 [1736/3978 (44%)]\tLoss: 0.125076\n",
            "Train Epoch: 4 [1737/3978 (44%)]\tLoss: 0.212618\n",
            "Train Epoch: 4 [1738/3978 (44%)]\tLoss: 0.191414\n",
            "Train Epoch: 4 [1739/3978 (44%)]\tLoss: 0.207545\n",
            "Train Epoch: 4 [1740/3978 (44%)]\tLoss: 0.116014\n",
            "Train Epoch: 4 [1741/3978 (44%)]\tLoss: 0.099781\n",
            "Train Epoch: 4 [1742/3978 (44%)]\tLoss: 1.654350\n",
            "Train Epoch: 4 [1743/3978 (44%)]\tLoss: 0.150487\n",
            "Train Epoch: 4 [1744/3978 (44%)]\tLoss: 0.373536\n",
            "Train Epoch: 4 [1745/3978 (44%)]\tLoss: 0.094616\n",
            "Train Epoch: 4 [1746/3978 (44%)]\tLoss: 0.140650\n",
            "Train Epoch: 4 [1747/3978 (44%)]\tLoss: 0.097618\n",
            "Train Epoch: 4 [1748/3978 (44%)]\tLoss: 0.118603\n",
            "Train Epoch: 4 [1749/3978 (44%)]\tLoss: 0.084246\n",
            "Train Epoch: 4 [1750/3978 (44%)]\tLoss: 0.097409\n",
            "Train Epoch: 4 [1751/3978 (44%)]\tLoss: 0.117130\n",
            "Train Epoch: 4 [1752/3978 (44%)]\tLoss: 0.096496\n",
            "Train Epoch: 4 [1753/3978 (44%)]\tLoss: 0.497504\n",
            "Train Epoch: 4 [1754/3978 (44%)]\tLoss: 0.503208\n",
            "Train Epoch: 4 [1755/3978 (44%)]\tLoss: 0.077077\n",
            "Train Epoch: 4 [1756/3978 (44%)]\tLoss: 0.122480\n",
            "Train Epoch: 4 [1757/3978 (44%)]\tLoss: 0.809585\n",
            "Train Epoch: 4 [1758/3978 (44%)]\tLoss: 0.081987\n",
            "Train Epoch: 4 [1759/3978 (44%)]\tLoss: 0.082300\n",
            "Train Epoch: 4 [1760/3978 (44%)]\tLoss: 0.074609\n",
            "Train Epoch: 4 [1761/3978 (44%)]\tLoss: 0.079914\n",
            "Train Epoch: 4 [1762/3978 (44%)]\tLoss: 0.068744\n",
            "Train Epoch: 4 [1763/3978 (44%)]\tLoss: 0.148491\n",
            "Train Epoch: 4 [1764/3978 (44%)]\tLoss: 0.077326\n",
            "Train Epoch: 4 [1765/3978 (44%)]\tLoss: 0.094472\n",
            "Train Epoch: 4 [1766/3978 (44%)]\tLoss: 0.056960\n",
            "Train Epoch: 4 [1767/3978 (44%)]\tLoss: 0.167996\n",
            "Train Epoch: 4 [1768/3978 (44%)]\tLoss: 0.154804\n",
            "Train Epoch: 4 [1769/3978 (44%)]\tLoss: 0.717235\n",
            "Train Epoch: 4 [1770/3978 (44%)]\tLoss: 0.512645\n",
            "Train Epoch: 4 [1771/3978 (45%)]\tLoss: 0.052268\n",
            "Train Epoch: 4 [1772/3978 (45%)]\tLoss: 0.057760\n",
            "Train Epoch: 4 [1773/3978 (45%)]\tLoss: 0.492554\n",
            "Train Epoch: 4 [1774/3978 (45%)]\tLoss: 0.046484\n",
            "Train Epoch: 4 [1775/3978 (45%)]\tLoss: 0.156183\n",
            "Train Epoch: 4 [1776/3978 (45%)]\tLoss: 0.159970\n",
            "Train Epoch: 4 [1777/3978 (45%)]\tLoss: 0.156476\n",
            "Train Epoch: 4 [1778/3978 (45%)]\tLoss: 0.164262\n",
            "Train Epoch: 4 [1779/3978 (45%)]\tLoss: 0.059041\n",
            "Train Epoch: 4 [1780/3978 (45%)]\tLoss: 0.057959\n",
            "Train Epoch: 4 [1781/3978 (45%)]\tLoss: 0.058040\n",
            "Train Epoch: 4 [1782/3978 (45%)]\tLoss: 0.488126\n",
            "Train Epoch: 4 [1783/3978 (45%)]\tLoss: 0.062521\n",
            "Train Epoch: 4 [1784/3978 (45%)]\tLoss: 0.132368\n",
            "Train Epoch: 4 [1785/3978 (45%)]\tLoss: 0.066510\n",
            "Train Epoch: 4 [1786/3978 (45%)]\tLoss: 0.637949\n",
            "Train Epoch: 4 [1787/3978 (45%)]\tLoss: 0.169074\n",
            "Train Epoch: 4 [1788/3978 (45%)]\tLoss: 0.139526\n",
            "Train Epoch: 4 [1789/3978 (45%)]\tLoss: 0.117462\n",
            "Train Epoch: 4 [1790/3978 (45%)]\tLoss: 0.073093\n",
            "Train Epoch: 4 [1791/3978 (45%)]\tLoss: 0.799490\n",
            "Train Epoch: 4 [1792/3978 (45%)]\tLoss: 0.075213\n",
            "Train Epoch: 4 [1793/3978 (45%)]\tLoss: 0.078598\n",
            "Train Epoch: 4 [1794/3978 (45%)]\tLoss: 0.129270\n",
            "Train Epoch: 4 [1795/3978 (45%)]\tLoss: 0.065872\n",
            "Train Epoch: 4 [1796/3978 (45%)]\tLoss: 0.082266\n",
            "Train Epoch: 4 [1797/3978 (45%)]\tLoss: 0.414165\n",
            "Train Epoch: 4 [1798/3978 (45%)]\tLoss: 0.131644\n",
            "Train Epoch: 4 [1799/3978 (45%)]\tLoss: 0.128061\n",
            "Train Epoch: 4 [1800/3978 (45%)]\tLoss: 0.679586\n",
            "Train Epoch: 4 [1801/3978 (45%)]\tLoss: 0.137942\n",
            "Train Epoch: 4 [1802/3978 (45%)]\tLoss: 0.398153\n",
            "Train Epoch: 4 [1803/3978 (45%)]\tLoss: 0.125739\n",
            "Train Epoch: 4 [1804/3978 (45%)]\tLoss: 0.080742\n",
            "Train Epoch: 4 [1805/3978 (45%)]\tLoss: 0.114929\n",
            "Train Epoch: 4 [1806/3978 (45%)]\tLoss: 0.079883\n",
            "Train Epoch: 4 [1807/3978 (45%)]\tLoss: 0.078195\n",
            "Train Epoch: 4 [1808/3978 (45%)]\tLoss: 0.081064\n",
            "Train Epoch: 4 [1809/3978 (45%)]\tLoss: 0.109461\n",
            "Train Epoch: 4 [1810/3978 (46%)]\tLoss: 0.084869\n",
            "Train Epoch: 4 [1811/3978 (46%)]\tLoss: 0.105012\n",
            "Train Epoch: 4 [1812/3978 (46%)]\tLoss: 0.101763\n",
            "Train Epoch: 4 [1813/3978 (46%)]\tLoss: 0.078696\n",
            "Train Epoch: 4 [1814/3978 (46%)]\tLoss: 0.090125\n",
            "Train Epoch: 4 [1815/3978 (46%)]\tLoss: 0.091364\n",
            "Train Epoch: 4 [1816/3978 (46%)]\tLoss: 0.102970\n",
            "Train Epoch: 4 [1817/3978 (46%)]\tLoss: 0.387744\n",
            "Train Epoch: 4 [1818/3978 (46%)]\tLoss: 0.118383\n",
            "Train Epoch: 4 [1819/3978 (46%)]\tLoss: 0.086647\n",
            "Train Epoch: 4 [1820/3978 (46%)]\tLoss: 0.683186\n",
            "Train Epoch: 4 [1821/3978 (46%)]\tLoss: 0.078994\n",
            "Train Epoch: 4 [1822/3978 (46%)]\tLoss: 0.105856\n",
            "Train Epoch: 4 [1823/3978 (46%)]\tLoss: 0.066553\n",
            "Train Epoch: 4 [1824/3978 (46%)]\tLoss: 0.080109\n",
            "Train Epoch: 4 [1825/3978 (46%)]\tLoss: 0.469226\n",
            "Train Epoch: 4 [1826/3978 (46%)]\tLoss: 0.115415\n",
            "Train Epoch: 4 [1827/3978 (46%)]\tLoss: 0.075187\n",
            "Train Epoch: 4 [1828/3978 (46%)]\tLoss: 0.476910\n",
            "Train Epoch: 4 [1829/3978 (46%)]\tLoss: 0.118219\n",
            "Train Epoch: 4 [1830/3978 (46%)]\tLoss: 1.006092\n",
            "Train Epoch: 4 [1831/3978 (46%)]\tLoss: 0.378720\n",
            "Train Epoch: 4 [1832/3978 (46%)]\tLoss: 0.741966\n",
            "Train Epoch: 4 [1833/3978 (46%)]\tLoss: 0.126996\n",
            "Train Epoch: 4 [1834/3978 (46%)]\tLoss: 0.076507\n",
            "Train Epoch: 4 [1835/3978 (46%)]\tLoss: 0.083085\n",
            "Train Epoch: 4 [1836/3978 (46%)]\tLoss: 0.798661\n",
            "Train Epoch: 4 [1837/3978 (46%)]\tLoss: 0.129559\n",
            "Train Epoch: 4 [1838/3978 (46%)]\tLoss: 0.132147\n",
            "Train Epoch: 4 [1839/3978 (46%)]\tLoss: 0.075038\n",
            "Train Epoch: 4 [1840/3978 (46%)]\tLoss: 0.976532\n",
            "Train Epoch: 4 [1841/3978 (46%)]\tLoss: 0.130244\n",
            "Train Epoch: 4 [1842/3978 (46%)]\tLoss: 0.932310\n",
            "Train Epoch: 4 [1843/3978 (46%)]\tLoss: 0.123037\n",
            "Train Epoch: 4 [1844/3978 (46%)]\tLoss: 0.080777\n",
            "Train Epoch: 4 [1845/3978 (46%)]\tLoss: 0.084587\n",
            "Train Epoch: 4 [1846/3978 (46%)]\tLoss: 0.081082\n",
            "Train Epoch: 4 [1847/3978 (46%)]\tLoss: 0.082053\n",
            "Train Epoch: 4 [1848/3978 (46%)]\tLoss: 0.168559\n",
            "Train Epoch: 4 [1849/3978 (46%)]\tLoss: 0.121595\n",
            "Train Epoch: 4 [1850/3978 (47%)]\tLoss: 0.120330\n",
            "Train Epoch: 4 [1851/3978 (47%)]\tLoss: 0.443832\n",
            "Train Epoch: 4 [1852/3978 (47%)]\tLoss: 0.121327\n",
            "Train Epoch: 4 [1853/3978 (47%)]\tLoss: 0.082717\n",
            "Train Epoch: 4 [1854/3978 (47%)]\tLoss: 0.074220\n",
            "Train Epoch: 4 [1855/3978 (47%)]\tLoss: 0.116512\n",
            "Train Epoch: 4 [1856/3978 (47%)]\tLoss: 0.083530\n",
            "Train Epoch: 4 [1857/3978 (47%)]\tLoss: 0.085667\n",
            "Train Epoch: 4 [1858/3978 (47%)]\tLoss: 0.112536\n",
            "Train Epoch: 4 [1859/3978 (47%)]\tLoss: 0.115354\n",
            "Train Epoch: 4 [1860/3978 (47%)]\tLoss: 0.087977\n",
            "Train Epoch: 4 [1861/3978 (47%)]\tLoss: 0.702621\n",
            "Train Epoch: 4 [1862/3978 (47%)]\tLoss: 0.114185\n",
            "Train Epoch: 4 [1863/3978 (47%)]\tLoss: 0.111063\n",
            "Train Epoch: 4 [1864/3978 (47%)]\tLoss: 0.401535\n",
            "Train Epoch: 4 [1865/3978 (47%)]\tLoss: 0.128506\n",
            "Train Epoch: 4 [1866/3978 (47%)]\tLoss: 0.107527\n",
            "Train Epoch: 4 [1867/3978 (47%)]\tLoss: 0.098631\n",
            "Train Epoch: 4 [1868/3978 (47%)]\tLoss: 0.165785\n",
            "Train Epoch: 4 [1869/3978 (47%)]\tLoss: 0.146920\n",
            "Train Epoch: 4 [1870/3978 (47%)]\tLoss: 0.092434\n",
            "Train Epoch: 4 [1871/3978 (47%)]\tLoss: 0.106775\n",
            "Train Epoch: 4 [1872/3978 (47%)]\tLoss: 0.408431\n",
            "Train Epoch: 4 [1873/3978 (47%)]\tLoss: 0.107210\n",
            "Train Epoch: 4 [1874/3978 (47%)]\tLoss: 0.108135\n",
            "Train Epoch: 4 [1875/3978 (47%)]\tLoss: 0.104895\n",
            "Train Epoch: 4 [1876/3978 (47%)]\tLoss: 0.156142\n",
            "Train Epoch: 4 [1877/3978 (47%)]\tLoss: 0.851298\n",
            "Train Epoch: 4 [1878/3978 (47%)]\tLoss: 0.102751\n",
            "Train Epoch: 4 [1879/3978 (47%)]\tLoss: 1.326636\n",
            "Train Epoch: 4 [1880/3978 (47%)]\tLoss: 0.147267\n",
            "Train Epoch: 4 [1881/3978 (47%)]\tLoss: 0.099254\n",
            "Train Epoch: 4 [1882/3978 (47%)]\tLoss: 0.142389\n",
            "Train Epoch: 4 [1883/3978 (47%)]\tLoss: 0.148060\n",
            "Train Epoch: 4 [1884/3978 (47%)]\tLoss: 0.083636\n",
            "Train Epoch: 4 [1885/3978 (47%)]\tLoss: 0.087041\n",
            "Train Epoch: 4 [1886/3978 (47%)]\tLoss: 0.086314\n",
            "Train Epoch: 4 [1887/3978 (47%)]\tLoss: 0.083210\n",
            "Train Epoch: 4 [1888/3978 (47%)]\tLoss: 0.075336\n",
            "Train Epoch: 4 [1889/3978 (47%)]\tLoss: 0.069861\n",
            "Train Epoch: 4 [1890/3978 (48%)]\tLoss: 0.121988\n",
            "Train Epoch: 4 [1891/3978 (48%)]\tLoss: 0.101393\n",
            "Train Epoch: 4 [1892/3978 (48%)]\tLoss: 0.062651\n",
            "Train Epoch: 4 [1893/3978 (48%)]\tLoss: 0.139257\n",
            "Train Epoch: 4 [1894/3978 (48%)]\tLoss: 0.120463\n",
            "Train Epoch: 4 [1895/3978 (48%)]\tLoss: 0.055727\n",
            "Train Epoch: 4 [1896/3978 (48%)]\tLoss: 0.055314\n",
            "Train Epoch: 4 [1897/3978 (48%)]\tLoss: 0.060208\n",
            "Train Epoch: 4 [1898/3978 (48%)]\tLoss: 0.084510\n",
            "Train Epoch: 4 [1899/3978 (48%)]\tLoss: 1.291043\n",
            "Train Epoch: 4 [1900/3978 (48%)]\tLoss: 0.132309\n",
            "Train Epoch: 4 [1901/3978 (48%)]\tLoss: 0.127530\n",
            "Train Epoch: 4 [1902/3978 (48%)]\tLoss: 0.189430\n",
            "Train Epoch: 4 [1903/3978 (48%)]\tLoss: 0.776946\n",
            "Train Epoch: 4 [1904/3978 (48%)]\tLoss: 0.075958\n",
            "Train Epoch: 4 [1905/3978 (48%)]\tLoss: 0.121600\n",
            "Train Epoch: 4 [1906/3978 (48%)]\tLoss: 0.125972\n",
            "Train Epoch: 4 [1907/3978 (48%)]\tLoss: 0.048251\n",
            "Train Epoch: 4 [1908/3978 (48%)]\tLoss: 0.116893\n",
            "Train Epoch: 4 [1909/3978 (48%)]\tLoss: 0.050765\n",
            "Train Epoch: 4 [1910/3978 (48%)]\tLoss: 0.112255\n",
            "Train Epoch: 4 [1911/3978 (48%)]\tLoss: 0.049546\n",
            "Train Epoch: 4 [1912/3978 (48%)]\tLoss: 0.640155\n",
            "Train Epoch: 4 [1913/3978 (48%)]\tLoss: 0.151762\n",
            "Train Epoch: 4 [1914/3978 (48%)]\tLoss: 0.645985\n",
            "Train Epoch: 4 [1915/3978 (48%)]\tLoss: 0.150440\n",
            "Train Epoch: 4 [1916/3978 (48%)]\tLoss: 0.059645\n",
            "Train Epoch: 4 [1917/3978 (48%)]\tLoss: 0.061372\n",
            "Train Epoch: 4 [1918/3978 (48%)]\tLoss: 0.065056\n",
            "Train Epoch: 4 [1919/3978 (48%)]\tLoss: 0.908700\n",
            "Train Epoch: 4 [1920/3978 (48%)]\tLoss: 0.065312\n",
            "Train Epoch: 4 [1921/3978 (48%)]\tLoss: 0.070155\n",
            "Train Epoch: 4 [1922/3978 (48%)]\tLoss: 0.066956\n",
            "Train Epoch: 4 [1923/3978 (48%)]\tLoss: 0.075088\n",
            "Train Epoch: 4 [1924/3978 (48%)]\tLoss: 0.094170\n",
            "Train Epoch: 4 [1925/3978 (48%)]\tLoss: 0.061342\n",
            "Train Epoch: 4 [1926/3978 (48%)]\tLoss: 0.571334\n",
            "Train Epoch: 4 [1927/3978 (48%)]\tLoss: 0.057005\n",
            "Train Epoch: 4 [1928/3978 (48%)]\tLoss: 0.055906\n",
            "Train Epoch: 4 [1929/3978 (48%)]\tLoss: 0.111291\n",
            "Train Epoch: 4 [1930/3978 (49%)]\tLoss: 0.638166\n",
            "Train Epoch: 4 [1931/3978 (49%)]\tLoss: 0.051972\n",
            "Train Epoch: 4 [1932/3978 (49%)]\tLoss: 0.741915\n",
            "Train Epoch: 4 [1933/3978 (49%)]\tLoss: 0.847101\n",
            "Train Epoch: 4 [1934/3978 (49%)]\tLoss: 0.049496\n",
            "Train Epoch: 4 [1935/3978 (49%)]\tLoss: 0.049383\n",
            "Train Epoch: 4 [1936/3978 (49%)]\tLoss: 0.185865\n",
            "Train Epoch: 4 [1937/3978 (49%)]\tLoss: 0.079511\n",
            "Train Epoch: 4 [1938/3978 (49%)]\tLoss: 0.136086\n",
            "Train Epoch: 4 [1939/3978 (49%)]\tLoss: 0.863031\n",
            "Train Epoch: 4 [1940/3978 (49%)]\tLoss: 0.160623\n",
            "Train Epoch: 4 [1941/3978 (49%)]\tLoss: 0.531344\n",
            "Train Epoch: 4 [1942/3978 (49%)]\tLoss: 0.148691\n",
            "Train Epoch: 4 [1943/3978 (49%)]\tLoss: 0.048768\n",
            "Train Epoch: 4 [1944/3978 (49%)]\tLoss: 0.049360\n",
            "Train Epoch: 4 [1945/3978 (49%)]\tLoss: 0.179698\n",
            "Train Epoch: 4 [1946/3978 (49%)]\tLoss: 0.124676\n",
            "Train Epoch: 4 [1947/3978 (49%)]\tLoss: 0.053599\n",
            "Train Epoch: 4 [1948/3978 (49%)]\tLoss: 0.056963\n",
            "Train Epoch: 4 [1949/3978 (49%)]\tLoss: 0.055906\n",
            "Train Epoch: 4 [1950/3978 (49%)]\tLoss: 0.117979\n",
            "Train Epoch: 4 [1951/3978 (49%)]\tLoss: 0.059826\n",
            "Train Epoch: 4 [1952/3978 (49%)]\tLoss: 0.922015\n",
            "Train Epoch: 4 [1953/3978 (49%)]\tLoss: 0.057869\n",
            "Train Epoch: 4 [1954/3978 (49%)]\tLoss: 0.112082\n",
            "Train Epoch: 4 [1955/3978 (49%)]\tLoss: 0.111034\n",
            "Train Epoch: 4 [1956/3978 (49%)]\tLoss: 0.764345\n",
            "Train Epoch: 4 [1957/3978 (49%)]\tLoss: 0.080979\n",
            "Train Epoch: 4 [1958/3978 (49%)]\tLoss: 0.058836\n",
            "Train Epoch: 4 [1959/3978 (49%)]\tLoss: 0.105102\n",
            "Train Epoch: 4 [1960/3978 (49%)]\tLoss: 0.137538\n",
            "Train Epoch: 4 [1961/3978 (49%)]\tLoss: 0.786084\n",
            "Train Epoch: 4 [1962/3978 (49%)]\tLoss: 0.153007\n",
            "Train Epoch: 4 [1963/3978 (49%)]\tLoss: 0.073455\n",
            "Train Epoch: 4 [1964/3978 (49%)]\tLoss: 0.727243\n",
            "Train Epoch: 4 [1965/3978 (49%)]\tLoss: 0.112160\n",
            "Train Epoch: 4 [1966/3978 (49%)]\tLoss: 0.074855\n",
            "Train Epoch: 4 [1967/3978 (49%)]\tLoss: 0.099405\n",
            "Train Epoch: 4 [1968/3978 (49%)]\tLoss: 0.520766\n",
            "Train Epoch: 4 [1969/3978 (49%)]\tLoss: 0.072719\n",
            "Train Epoch: 4 [1970/3978 (50%)]\tLoss: 0.082723\n",
            "Train Epoch: 4 [1971/3978 (50%)]\tLoss: 0.105283\n",
            "Train Epoch: 4 [1972/3978 (50%)]\tLoss: 0.603824\n",
            "Train Epoch: 4 [1973/3978 (50%)]\tLoss: 0.104238\n",
            "Train Epoch: 4 [1974/3978 (50%)]\tLoss: 0.100848\n",
            "Train Epoch: 4 [1975/3978 (50%)]\tLoss: 0.587455\n",
            "Train Epoch: 4 [1976/3978 (50%)]\tLoss: 0.074053\n",
            "Train Epoch: 4 [1977/3978 (50%)]\tLoss: 0.070486\n",
            "Train Epoch: 4 [1978/3978 (50%)]\tLoss: 0.074832\n",
            "Train Epoch: 4 [1979/3978 (50%)]\tLoss: 0.102906\n",
            "Train Epoch: 4 [1980/3978 (50%)]\tLoss: 0.072418\n",
            "Train Epoch: 4 [1981/3978 (50%)]\tLoss: 0.158291\n",
            "Train Epoch: 4 [1982/3978 (50%)]\tLoss: 0.940845\n",
            "Train Epoch: 4 [1983/3978 (50%)]\tLoss: 0.070526\n",
            "Train Epoch: 4 [1984/3978 (50%)]\tLoss: 0.072051\n",
            "Train Epoch: 4 [1985/3978 (50%)]\tLoss: 0.073643\n",
            "Train Epoch: 4 [1986/3978 (50%)]\tLoss: 0.067584\n",
            "Train Epoch: 4 [1987/3978 (50%)]\tLoss: 0.106360\n",
            "Train Epoch: 4 [1988/3978 (50%)]\tLoss: 1.169083\n",
            "Train Epoch: 4 [1989/3978 (50%)]\tLoss: 0.064456\n",
            "Train Epoch: 4 [1990/3978 (50%)]\tLoss: 0.072720\n",
            "Train Epoch: 4 [1991/3978 (50%)]\tLoss: 0.123072\n",
            "Train Epoch: 4 [1992/3978 (50%)]\tLoss: 0.062695\n",
            "Train Epoch: 4 [1993/3978 (50%)]\tLoss: 0.124839\n",
            "Train Epoch: 4 [1994/3978 (50%)]\tLoss: 0.151231\n",
            "Train Epoch: 4 [1995/3978 (50%)]\tLoss: 0.120720\n",
            "Train Epoch: 4 [1996/3978 (50%)]\tLoss: 1.090202\n",
            "Train Epoch: 4 [1997/3978 (50%)]\tLoss: 0.063753\n",
            "Train Epoch: 4 [1998/3978 (50%)]\tLoss: 0.116439\n",
            "Train Epoch: 4 [1999/3978 (50%)]\tLoss: 0.102833\n",
            "Train Epoch: 4 [2000/3978 (50%)]\tLoss: 0.107402\n",
            "Train Epoch: 4 [2001/3978 (50%)]\tLoss: 0.074622\n",
            "Train Epoch: 4 [2002/3978 (50%)]\tLoss: 0.115007\n",
            "Train Epoch: 4 [2003/3978 (50%)]\tLoss: 0.548512\n",
            "Train Epoch: 4 [2004/3978 (50%)]\tLoss: 0.646201\n",
            "Train Epoch: 4 [2005/3978 (50%)]\tLoss: 0.096845\n",
            "Train Epoch: 4 [2006/3978 (50%)]\tLoss: 0.092027\n",
            "Train Epoch: 4 [2007/3978 (50%)]\tLoss: 0.106542\n",
            "Train Epoch: 4 [2008/3978 (50%)]\tLoss: 0.099070\n",
            "Train Epoch: 4 [2009/3978 (51%)]\tLoss: 0.131087\n",
            "Train Epoch: 4 [2010/3978 (51%)]\tLoss: 0.080059\n",
            "Train Epoch: 4 [2011/3978 (51%)]\tLoss: 0.082330\n",
            "Train Epoch: 4 [2012/3978 (51%)]\tLoss: 0.085502\n",
            "Train Epoch: 4 [2013/3978 (51%)]\tLoss: 0.126040\n",
            "Train Epoch: 4 [2014/3978 (51%)]\tLoss: 0.078779\n",
            "Train Epoch: 4 [2015/3978 (51%)]\tLoss: 0.619158\n",
            "Train Epoch: 4 [2016/3978 (51%)]\tLoss: 0.080526\n",
            "Train Epoch: 4 [2017/3978 (51%)]\tLoss: 0.573842\n",
            "Train Epoch: 4 [2018/3978 (51%)]\tLoss: 0.079798\n",
            "Train Epoch: 4 [2019/3978 (51%)]\tLoss: 0.082980\n",
            "Train Epoch: 4 [2020/3978 (51%)]\tLoss: 0.083553\n",
            "Train Epoch: 4 [2021/3978 (51%)]\tLoss: 0.076494\n",
            "Train Epoch: 4 [2022/3978 (51%)]\tLoss: 0.076068\n",
            "Train Epoch: 4 [2023/3978 (51%)]\tLoss: 0.071147\n",
            "Train Epoch: 4 [2024/3978 (51%)]\tLoss: 0.112158\n",
            "Train Epoch: 4 [2025/3978 (51%)]\tLoss: 0.801768\n",
            "Train Epoch: 4 [2026/3978 (51%)]\tLoss: 0.062200\n",
            "Train Epoch: 4 [2027/3978 (51%)]\tLoss: 0.940877\n",
            "Train Epoch: 4 [2028/3978 (51%)]\tLoss: 0.091307\n",
            "Train Epoch: 4 [2029/3978 (51%)]\tLoss: 0.095660\n",
            "Train Epoch: 4 [2030/3978 (51%)]\tLoss: 0.054322\n",
            "Train Epoch: 4 [2031/3978 (51%)]\tLoss: 0.989489\n",
            "Train Epoch: 4 [2032/3978 (51%)]\tLoss: 0.121942\n",
            "Train Epoch: 4 [2033/3978 (51%)]\tLoss: 0.050722\n",
            "Train Epoch: 4 [2034/3978 (51%)]\tLoss: 0.045839\n",
            "Train Epoch: 4 [2035/3978 (51%)]\tLoss: 0.046013\n",
            "Train Epoch: 4 [2036/3978 (51%)]\tLoss: 0.135635\n",
            "Train Epoch: 4 [2037/3978 (51%)]\tLoss: 0.564351\n",
            "Train Epoch: 4 [2038/3978 (51%)]\tLoss: 0.775761\n",
            "Train Epoch: 4 [2039/3978 (51%)]\tLoss: 0.043928\n",
            "Train Epoch: 4 [2040/3978 (51%)]\tLoss: 1.602607\n",
            "Train Epoch: 4 [2041/3978 (51%)]\tLoss: 0.576948\n",
            "Train Epoch: 4 [2042/3978 (51%)]\tLoss: 0.180942\n",
            "Train Epoch: 4 [2043/3978 (51%)]\tLoss: 0.145089\n",
            "Train Epoch: 4 [2044/3978 (51%)]\tLoss: 0.145754\n",
            "Train Epoch: 4 [2045/3978 (51%)]\tLoss: 0.046397\n",
            "Train Epoch: 4 [2046/3978 (51%)]\tLoss: 0.059217\n",
            "Train Epoch: 4 [2047/3978 (51%)]\tLoss: 0.048044\n",
            "Train Epoch: 4 [2048/3978 (51%)]\tLoss: 0.083499\n",
            "Train Epoch: 4 [2049/3978 (52%)]\tLoss: 0.138887\n",
            "Train Epoch: 4 [2050/3978 (52%)]\tLoss: 0.128280\n",
            "Train Epoch: 4 [2051/3978 (52%)]\tLoss: 0.054878\n",
            "Train Epoch: 4 [2052/3978 (52%)]\tLoss: 0.130188\n",
            "Train Epoch: 4 [2053/3978 (52%)]\tLoss: 0.973855\n",
            "Train Epoch: 4 [2054/3978 (52%)]\tLoss: 0.127375\n",
            "Train Epoch: 4 [2055/3978 (52%)]\tLoss: 0.057686\n",
            "Train Epoch: 4 [2056/3978 (52%)]\tLoss: 0.663599\n",
            "Train Epoch: 4 [2057/3978 (52%)]\tLoss: 0.116438\n",
            "Train Epoch: 4 [2058/3978 (52%)]\tLoss: 0.111102\n",
            "Train Epoch: 4 [2059/3978 (52%)]\tLoss: 0.503379\n",
            "Train Epoch: 4 [2060/3978 (52%)]\tLoss: 0.631013\n",
            "Train Epoch: 4 [2061/3978 (52%)]\tLoss: 0.158877\n",
            "Train Epoch: 4 [2062/3978 (52%)]\tLoss: 0.102573\n",
            "Train Epoch: 4 [2063/3978 (52%)]\tLoss: 1.264322\n",
            "Train Epoch: 4 [2064/3978 (52%)]\tLoss: 0.134281\n",
            "Train Epoch: 4 [2065/3978 (52%)]\tLoss: 0.092405\n",
            "Train Epoch: 4 [2066/3978 (52%)]\tLoss: 0.136098\n",
            "Train Epoch: 4 [2067/3978 (52%)]\tLoss: 0.706844\n",
            "Train Epoch: 4 [2068/3978 (52%)]\tLoss: 0.133654\n",
            "Train Epoch: 4 [2069/3978 (52%)]\tLoss: 0.095723\n",
            "Train Epoch: 4 [2070/3978 (52%)]\tLoss: 0.112085\n",
            "Train Epoch: 4 [2071/3978 (52%)]\tLoss: 0.071621\n",
            "Train Epoch: 4 [2072/3978 (52%)]\tLoss: 0.071583\n",
            "Train Epoch: 4 [2073/3978 (52%)]\tLoss: 0.108918\n",
            "Train Epoch: 4 [2074/3978 (52%)]\tLoss: 0.682129\n",
            "Train Epoch: 4 [2075/3978 (52%)]\tLoss: 0.147972\n",
            "Train Epoch: 4 [2076/3978 (52%)]\tLoss: 0.496482\n",
            "Train Epoch: 4 [2077/3978 (52%)]\tLoss: 0.068692\n",
            "Train Epoch: 4 [2078/3978 (52%)]\tLoss: 0.067469\n",
            "Train Epoch: 4 [2079/3978 (52%)]\tLoss: 0.142144\n",
            "Train Epoch: 4 [2080/3978 (52%)]\tLoss: 0.744485\n",
            "Train Epoch: 4 [2081/3978 (52%)]\tLoss: 0.068616\n",
            "Train Epoch: 4 [2082/3978 (52%)]\tLoss: 0.113861\n",
            "Train Epoch: 4 [2083/3978 (52%)]\tLoss: 0.120279\n",
            "Train Epoch: 4 [2084/3978 (52%)]\tLoss: 0.070124\n",
            "Train Epoch: 4 [2085/3978 (52%)]\tLoss: 0.120411\n",
            "Train Epoch: 4 [2086/3978 (52%)]\tLoss: 0.120378\n",
            "Train Epoch: 4 [2087/3978 (52%)]\tLoss: 0.071945\n",
            "Train Epoch: 4 [2088/3978 (52%)]\tLoss: 0.169211\n",
            "Train Epoch: 4 [2089/3978 (53%)]\tLoss: 0.487054\n",
            "Train Epoch: 4 [2090/3978 (53%)]\tLoss: 0.109699\n",
            "Train Epoch: 4 [2091/3978 (53%)]\tLoss: 0.561777\n",
            "Train Epoch: 4 [2092/3978 (53%)]\tLoss: 0.135689\n",
            "Train Epoch: 4 [2093/3978 (53%)]\tLoss: 0.132822\n",
            "Train Epoch: 4 [2094/3978 (53%)]\tLoss: 0.136371\n",
            "Train Epoch: 4 [2095/3978 (53%)]\tLoss: 0.146034\n",
            "Train Epoch: 4 [2096/3978 (53%)]\tLoss: 2.347516\n",
            "Train Epoch: 4 [2097/3978 (53%)]\tLoss: 0.061966\n",
            "Train Epoch: 4 [2098/3978 (53%)]\tLoss: 0.128175\n",
            "Train Epoch: 4 [2099/3978 (53%)]\tLoss: 0.157936\n",
            "Train Epoch: 4 [2100/3978 (53%)]\tLoss: 0.074382\n",
            "Train Epoch: 4 [2101/3978 (53%)]\tLoss: 0.069651\n",
            "Train Epoch: 4 [2102/3978 (53%)]\tLoss: 0.112827\n",
            "Train Epoch: 4 [2103/3978 (53%)]\tLoss: 0.149380\n",
            "Train Epoch: 4 [2104/3978 (53%)]\tLoss: 0.118688\n",
            "Train Epoch: 4 [2105/3978 (53%)]\tLoss: 0.086491\n",
            "Train Epoch: 4 [2106/3978 (53%)]\tLoss: 0.491833\n",
            "Train Epoch: 4 [2107/3978 (53%)]\tLoss: 0.806262\n",
            "Train Epoch: 4 [2108/3978 (53%)]\tLoss: 0.077601\n",
            "Train Epoch: 4 [2109/3978 (53%)]\tLoss: 0.072165\n",
            "Train Epoch: 4 [2110/3978 (53%)]\tLoss: 0.072891\n",
            "Train Epoch: 4 [2111/3978 (53%)]\tLoss: 0.072694\n",
            "Train Epoch: 4 [2112/3978 (53%)]\tLoss: 0.086953\n",
            "Train Epoch: 4 [2113/3978 (53%)]\tLoss: 0.091589\n",
            "Train Epoch: 4 [2114/3978 (53%)]\tLoss: 0.070061\n",
            "Train Epoch: 4 [2115/3978 (53%)]\tLoss: 0.092047\n",
            "Train Epoch: 4 [2116/3978 (53%)]\tLoss: 0.139821\n",
            "Train Epoch: 4 [2117/3978 (53%)]\tLoss: 0.090930\n",
            "Train Epoch: 4 [2118/3978 (53%)]\tLoss: 0.117024\n",
            "Train Epoch: 4 [2119/3978 (53%)]\tLoss: 0.591009\n",
            "Train Epoch: 4 [2120/3978 (53%)]\tLoss: 0.107707\n",
            "Train Epoch: 4 [2121/3978 (53%)]\tLoss: 0.100021\n",
            "Train Epoch: 4 [2122/3978 (53%)]\tLoss: 0.880359\n",
            "Train Epoch: 4 [2123/3978 (53%)]\tLoss: 0.065080\n",
            "Train Epoch: 4 [2124/3978 (53%)]\tLoss: 0.099095\n",
            "Train Epoch: 4 [2125/3978 (53%)]\tLoss: 1.124350\n",
            "Train Epoch: 4 [2126/3978 (53%)]\tLoss: 0.071399\n",
            "Train Epoch: 4 [2127/3978 (53%)]\tLoss: 0.070312\n",
            "Train Epoch: 4 [2128/3978 (53%)]\tLoss: 0.106258\n",
            "Train Epoch: 4 [2129/3978 (54%)]\tLoss: 0.137281\n",
            "Train Epoch: 4 [2130/3978 (54%)]\tLoss: 0.072129\n",
            "Train Epoch: 4 [2131/3978 (54%)]\tLoss: 0.117783\n",
            "Train Epoch: 4 [2132/3978 (54%)]\tLoss: 0.084291\n",
            "Train Epoch: 4 [2133/3978 (54%)]\tLoss: 0.074198\n",
            "Train Epoch: 4 [2134/3978 (54%)]\tLoss: 0.731666\n",
            "Train Epoch: 4 [2135/3978 (54%)]\tLoss: 0.129805\n",
            "Train Epoch: 4 [2136/3978 (54%)]\tLoss: 0.088012\n",
            "Train Epoch: 4 [2137/3978 (54%)]\tLoss: 0.693832\n",
            "Train Epoch: 4 [2138/3978 (54%)]\tLoss: 0.076224\n",
            "Train Epoch: 4 [2139/3978 (54%)]\tLoss: 0.085092\n",
            "Train Epoch: 4 [2140/3978 (54%)]\tLoss: 0.080345\n",
            "Train Epoch: 4 [2141/3978 (54%)]\tLoss: 0.611484\n",
            "Train Epoch: 4 [2142/3978 (54%)]\tLoss: 0.069135\n",
            "Train Epoch: 4 [2143/3978 (54%)]\tLoss: 0.089356\n",
            "Train Epoch: 4 [2144/3978 (54%)]\tLoss: 0.098398\n",
            "Train Epoch: 4 [2145/3978 (54%)]\tLoss: 0.734706\n",
            "Train Epoch: 4 [2146/3978 (54%)]\tLoss: 0.089624\n",
            "Train Epoch: 4 [2147/3978 (54%)]\tLoss: 0.083802\n",
            "Train Epoch: 4 [2148/3978 (54%)]\tLoss: 0.094348\n",
            "Train Epoch: 4 [2149/3978 (54%)]\tLoss: 0.113677\n",
            "Train Epoch: 4 [2150/3978 (54%)]\tLoss: 0.086098\n",
            "Train Epoch: 4 [2151/3978 (54%)]\tLoss: 0.586685\n",
            "Train Epoch: 4 [2152/3978 (54%)]\tLoss: 0.072141\n",
            "Train Epoch: 4 [2153/3978 (54%)]\tLoss: 0.932678\n",
            "Train Epoch: 4 [2154/3978 (54%)]\tLoss: 0.092041\n",
            "Train Epoch: 4 [2155/3978 (54%)]\tLoss: 0.102762\n",
            "Train Epoch: 4 [2156/3978 (54%)]\tLoss: 0.069347\n",
            "Train Epoch: 4 [2157/3978 (54%)]\tLoss: 0.069280\n",
            "Train Epoch: 4 [2158/3978 (54%)]\tLoss: 0.112596\n",
            "Train Epoch: 4 [2159/3978 (54%)]\tLoss: 0.069952\n",
            "Train Epoch: 4 [2160/3978 (54%)]\tLoss: 0.101945\n",
            "Train Epoch: 4 [2161/3978 (54%)]\tLoss: 0.692139\n",
            "Train Epoch: 4 [2162/3978 (54%)]\tLoss: 0.062445\n",
            "Train Epoch: 4 [2163/3978 (54%)]\tLoss: 0.108147\n",
            "Train Epoch: 4 [2164/3978 (54%)]\tLoss: 0.108000\n",
            "Train Epoch: 4 [2165/3978 (54%)]\tLoss: 0.099258\n",
            "Train Epoch: 4 [2166/3978 (54%)]\tLoss: 0.096047\n",
            "Train Epoch: 4 [2167/3978 (54%)]\tLoss: 0.055822\n",
            "Train Epoch: 4 [2168/3978 (54%)]\tLoss: 1.197721\n",
            "Train Epoch: 4 [2169/3978 (55%)]\tLoss: 0.062048\n",
            "Train Epoch: 4 [2170/3978 (55%)]\tLoss: 0.085562\n",
            "Train Epoch: 4 [2171/3978 (55%)]\tLoss: 0.057771\n",
            "Train Epoch: 4 [2172/3978 (55%)]\tLoss: 0.579383\n",
            "Train Epoch: 4 [2173/3978 (55%)]\tLoss: 0.597323\n",
            "Train Epoch: 4 [2174/3978 (55%)]\tLoss: 0.611755\n",
            "Train Epoch: 4 [2175/3978 (55%)]\tLoss: 0.054851\n",
            "Train Epoch: 4 [2176/3978 (55%)]\tLoss: 0.122373\n",
            "Train Epoch: 4 [2177/3978 (55%)]\tLoss: 0.051145\n",
            "Train Epoch: 4 [2178/3978 (55%)]\tLoss: 0.052671\n",
            "Train Epoch: 4 [2179/3978 (55%)]\tLoss: 0.053037\n",
            "Train Epoch: 4 [2180/3978 (55%)]\tLoss: 0.657500\n",
            "Train Epoch: 4 [2181/3978 (55%)]\tLoss: 0.195970\n",
            "Train Epoch: 4 [2182/3978 (55%)]\tLoss: 0.052262\n",
            "Train Epoch: 4 [2183/3978 (55%)]\tLoss: 0.088900\n",
            "Train Epoch: 4 [2184/3978 (55%)]\tLoss: 0.131765\n",
            "Train Epoch: 4 [2185/3978 (55%)]\tLoss: 0.201903\n",
            "Train Epoch: 4 [2186/3978 (55%)]\tLoss: 0.133910\n",
            "Train Epoch: 4 [2187/3978 (55%)]\tLoss: 0.131998\n",
            "Train Epoch: 4 [2188/3978 (55%)]\tLoss: 0.879586\n",
            "Train Epoch: 4 [2189/3978 (55%)]\tLoss: 0.057462\n",
            "Train Epoch: 4 [2190/3978 (55%)]\tLoss: 0.057721\n",
            "Train Epoch: 4 [2191/3978 (55%)]\tLoss: 0.059761\n",
            "Train Epoch: 4 [2192/3978 (55%)]\tLoss: 0.058204\n",
            "Train Epoch: 4 [2193/3978 (55%)]\tLoss: 0.051988\n",
            "Train Epoch: 4 [2194/3978 (55%)]\tLoss: 0.118648\n",
            "Train Epoch: 4 [2195/3978 (55%)]\tLoss: 0.119139\n",
            "Train Epoch: 4 [2196/3978 (55%)]\tLoss: 0.115552\n",
            "Train Epoch: 4 [2197/3978 (55%)]\tLoss: 0.089511\n",
            "Train Epoch: 4 [2198/3978 (55%)]\tLoss: 0.116290\n",
            "Train Epoch: 4 [2199/3978 (55%)]\tLoss: 0.098562\n",
            "Train Epoch: 4 [2200/3978 (55%)]\tLoss: 0.053302\n",
            "Train Epoch: 4 [2201/3978 (55%)]\tLoss: 0.122233\n",
            "Train Epoch: 4 [2202/3978 (55%)]\tLoss: 0.161748\n",
            "Train Epoch: 4 [2203/3978 (55%)]\tLoss: 0.066227\n",
            "Train Epoch: 4 [2204/3978 (55%)]\tLoss: 0.105903\n",
            "Train Epoch: 4 [2205/3978 (55%)]\tLoss: 0.073743\n",
            "Train Epoch: 4 [2206/3978 (55%)]\tLoss: 0.971137\n",
            "Train Epoch: 4 [2207/3978 (55%)]\tLoss: 0.100835\n",
            "Train Epoch: 4 [2208/3978 (56%)]\tLoss: 0.096778\n",
            "Train Epoch: 4 [2209/3978 (56%)]\tLoss: 0.068623\n",
            "Train Epoch: 4 [2210/3978 (56%)]\tLoss: 0.085955\n",
            "Train Epoch: 4 [2211/3978 (56%)]\tLoss: 0.892551\n",
            "Train Epoch: 4 [2212/3978 (56%)]\tLoss: 0.110688\n",
            "Train Epoch: 4 [2213/3978 (56%)]\tLoss: 0.696554\n",
            "Train Epoch: 4 [2214/3978 (56%)]\tLoss: 0.563799\n",
            "Train Epoch: 4 [2215/3978 (56%)]\tLoss: 0.704086\n",
            "Train Epoch: 4 [2216/3978 (56%)]\tLoss: 0.104285\n",
            "Train Epoch: 4 [2217/3978 (56%)]\tLoss: 0.071290\n",
            "Train Epoch: 4 [2218/3978 (56%)]\tLoss: 0.110448\n",
            "Train Epoch: 4 [2219/3978 (56%)]\tLoss: 0.557315\n",
            "Train Epoch: 4 [2220/3978 (56%)]\tLoss: 1.054881\n",
            "Train Epoch: 4 [2221/3978 (56%)]\tLoss: 0.115313\n",
            "Train Epoch: 4 [2222/3978 (56%)]\tLoss: 0.082560\n",
            "Train Epoch: 4 [2223/3978 (56%)]\tLoss: 0.078414\n",
            "Train Epoch: 4 [2224/3978 (56%)]\tLoss: 0.559216\n",
            "Train Epoch: 4 [2225/3978 (56%)]\tLoss: 0.074457\n",
            "Train Epoch: 4 [2226/3978 (56%)]\tLoss: 0.082991\n",
            "Train Epoch: 4 [2227/3978 (56%)]\tLoss: 0.071746\n",
            "Train Epoch: 4 [2228/3978 (56%)]\tLoss: 0.138907\n",
            "Train Epoch: 4 [2229/3978 (56%)]\tLoss: 0.134612\n",
            "Train Epoch: 4 [2230/3978 (56%)]\tLoss: 0.095366\n",
            "Train Epoch: 4 [2231/3978 (56%)]\tLoss: 0.073880\n",
            "Train Epoch: 4 [2232/3978 (56%)]\tLoss: 0.101826\n",
            "Train Epoch: 4 [2233/3978 (56%)]\tLoss: 0.098165\n",
            "Train Epoch: 4 [2234/3978 (56%)]\tLoss: 0.132334\n",
            "Train Epoch: 4 [2235/3978 (56%)]\tLoss: 0.108768\n",
            "Train Epoch: 4 [2236/3978 (56%)]\tLoss: 0.073284\n",
            "Train Epoch: 4 [2237/3978 (56%)]\tLoss: 0.117704\n",
            "Train Epoch: 4 [2238/3978 (56%)]\tLoss: 0.095193\n",
            "Train Epoch: 4 [2239/3978 (56%)]\tLoss: 0.519853\n",
            "Train Epoch: 4 [2240/3978 (56%)]\tLoss: 0.094398\n",
            "Train Epoch: 4 [2241/3978 (56%)]\tLoss: 0.099383\n",
            "Train Epoch: 4 [2242/3978 (56%)]\tLoss: 0.090791\n",
            "Train Epoch: 4 [2243/3978 (56%)]\tLoss: 0.895482\n",
            "Train Epoch: 4 [2244/3978 (56%)]\tLoss: 0.090285\n",
            "Train Epoch: 4 [2245/3978 (56%)]\tLoss: 0.526936\n",
            "Train Epoch: 4 [2246/3978 (56%)]\tLoss: 0.695748\n",
            "Train Epoch: 4 [2247/3978 (56%)]\tLoss: 0.831085\n",
            "Train Epoch: 4 [2248/3978 (57%)]\tLoss: 0.088201\n",
            "Train Epoch: 4 [2249/3978 (57%)]\tLoss: 0.082648\n",
            "Train Epoch: 4 [2250/3978 (57%)]\tLoss: 0.075804\n",
            "Train Epoch: 4 [2251/3978 (57%)]\tLoss: 0.067038\n",
            "Train Epoch: 4 [2252/3978 (57%)]\tLoss: 0.086206\n",
            "Train Epoch: 4 [2253/3978 (57%)]\tLoss: 0.084851\n",
            "Train Epoch: 4 [2254/3978 (57%)]\tLoss: 0.084619\n",
            "Train Epoch: 4 [2255/3978 (57%)]\tLoss: 0.081100\n",
            "Train Epoch: 4 [2256/3978 (57%)]\tLoss: 0.072432\n",
            "Train Epoch: 4 [2257/3978 (57%)]\tLoss: 0.092140\n",
            "Train Epoch: 4 [2258/3978 (57%)]\tLoss: 0.080427\n",
            "Train Epoch: 4 [2259/3978 (57%)]\tLoss: 0.915588\n",
            "Train Epoch: 4 [2260/3978 (57%)]\tLoss: 1.110104\n",
            "Train Epoch: 4 [2261/3978 (57%)]\tLoss: 0.058856\n",
            "Train Epoch: 4 [2262/3978 (57%)]\tLoss: 0.073088\n",
            "Train Epoch: 4 [2263/3978 (57%)]\tLoss: 0.100699\n",
            "Train Epoch: 4 [2264/3978 (57%)]\tLoss: 0.060328\n",
            "Train Epoch: 4 [2265/3978 (57%)]\tLoss: 0.057528\n",
            "Train Epoch: 4 [2266/3978 (57%)]\tLoss: 0.051992\n",
            "Train Epoch: 4 [2267/3978 (57%)]\tLoss: 0.650401\n",
            "Train Epoch: 4 [2268/3978 (57%)]\tLoss: 0.132144\n",
            "Train Epoch: 4 [2269/3978 (57%)]\tLoss: 0.134068\n",
            "Train Epoch: 4 [2270/3978 (57%)]\tLoss: 0.112008\n",
            "Train Epoch: 4 [2271/3978 (57%)]\tLoss: 0.084863\n",
            "Train Epoch: 4 [2272/3978 (57%)]\tLoss: 0.178860\n",
            "Train Epoch: 4 [2273/3978 (57%)]\tLoss: 0.121060\n",
            "Train Epoch: 4 [2274/3978 (57%)]\tLoss: 0.803940\n",
            "Train Epoch: 4 [2275/3978 (57%)]\tLoss: 0.618149\n",
            "Train Epoch: 4 [2276/3978 (57%)]\tLoss: 0.614949\n",
            "Train Epoch: 4 [2277/3978 (57%)]\tLoss: 0.660260\n",
            "Train Epoch: 4 [2278/3978 (57%)]\tLoss: 0.631710\n",
            "Train Epoch: 4 [2279/3978 (57%)]\tLoss: 0.778752\n",
            "Train Epoch: 4 [2280/3978 (57%)]\tLoss: 0.098340\n",
            "Train Epoch: 4 [2281/3978 (57%)]\tLoss: 0.081645\n",
            "Train Epoch: 4 [2282/3978 (57%)]\tLoss: 0.076102\n",
            "Train Epoch: 4 [2283/3978 (57%)]\tLoss: 0.091286\n",
            "Train Epoch: 4 [2284/3978 (57%)]\tLoss: 0.700768\n",
            "Train Epoch: 4 [2285/3978 (57%)]\tLoss: 0.093021\n",
            "Train Epoch: 4 [2286/3978 (57%)]\tLoss: 0.101905\n",
            "Train Epoch: 4 [2287/3978 (57%)]\tLoss: 0.082970\n",
            "Train Epoch: 4 [2288/3978 (58%)]\tLoss: 0.092798\n",
            "Train Epoch: 4 [2289/3978 (58%)]\tLoss: 0.591623\n",
            "Train Epoch: 4 [2290/3978 (58%)]\tLoss: 0.647003\n",
            "Train Epoch: 4 [2291/3978 (58%)]\tLoss: 0.089133\n",
            "Train Epoch: 4 [2292/3978 (58%)]\tLoss: 0.463755\n",
            "Train Epoch: 4 [2293/3978 (58%)]\tLoss: 0.091110\n",
            "Train Epoch: 4 [2294/3978 (58%)]\tLoss: 0.899680\n",
            "Train Epoch: 4 [2295/3978 (58%)]\tLoss: 0.090869\n",
            "Train Epoch: 4 [2296/3978 (58%)]\tLoss: 0.085748\n",
            "Train Epoch: 4 [2297/3978 (58%)]\tLoss: 0.087062\n",
            "Train Epoch: 4 [2298/3978 (58%)]\tLoss: 0.417923\n",
            "Train Epoch: 4 [2299/3978 (58%)]\tLoss: 0.127732\n",
            "Train Epoch: 4 [2300/3978 (58%)]\tLoss: 0.080238\n",
            "Train Epoch: 4 [2301/3978 (58%)]\tLoss: 0.156652\n",
            "Train Epoch: 4 [2302/3978 (58%)]\tLoss: 0.075203\n",
            "Train Epoch: 4 [2303/3978 (58%)]\tLoss: 0.133687\n",
            "Train Epoch: 4 [2304/3978 (58%)]\tLoss: 0.106962\n",
            "Train Epoch: 4 [2305/3978 (58%)]\tLoss: 0.073367\n",
            "Train Epoch: 4 [2306/3978 (58%)]\tLoss: 0.213816\n",
            "Train Epoch: 4 [2307/3978 (58%)]\tLoss: 0.098847\n",
            "Train Epoch: 4 [2308/3978 (58%)]\tLoss: 0.092505\n",
            "Train Epoch: 4 [2309/3978 (58%)]\tLoss: 0.141686\n",
            "Train Epoch: 4 [2310/3978 (58%)]\tLoss: 0.221937\n",
            "Train Epoch: 4 [2311/3978 (58%)]\tLoss: 0.065914\n",
            "Train Epoch: 4 [2312/3978 (58%)]\tLoss: 0.913762\n",
            "Train Epoch: 4 [2313/3978 (58%)]\tLoss: 0.111185\n",
            "Train Epoch: 4 [2314/3978 (58%)]\tLoss: 0.058614\n",
            "Train Epoch: 4 [2315/3978 (58%)]\tLoss: 0.121345\n",
            "Train Epoch: 4 [2316/3978 (58%)]\tLoss: 0.212206\n",
            "Train Epoch: 4 [2317/3978 (58%)]\tLoss: 0.053687\n",
            "Train Epoch: 4 [2318/3978 (58%)]\tLoss: 0.165235\n",
            "Train Epoch: 4 [2319/3978 (58%)]\tLoss: 0.519468\n",
            "Train Epoch: 4 [2320/3978 (58%)]\tLoss: 0.063788\n",
            "Train Epoch: 4 [2321/3978 (58%)]\tLoss: 0.048793\n",
            "Train Epoch: 4 [2322/3978 (58%)]\tLoss: 0.048698\n",
            "Train Epoch: 4 [2323/3978 (58%)]\tLoss: 0.726052\n",
            "Train Epoch: 4 [2324/3978 (58%)]\tLoss: 0.219519\n",
            "Train Epoch: 4 [2325/3978 (58%)]\tLoss: 0.695032\n",
            "Train Epoch: 4 [2326/3978 (58%)]\tLoss: 0.052312\n",
            "Train Epoch: 4 [2327/3978 (58%)]\tLoss: 0.054919\n",
            "Train Epoch: 4 [2328/3978 (59%)]\tLoss: 0.596046\n",
            "Train Epoch: 4 [2329/3978 (59%)]\tLoss: 0.192734\n",
            "Train Epoch: 4 [2330/3978 (59%)]\tLoss: 0.139790\n",
            "Train Epoch: 4 [2331/3978 (59%)]\tLoss: 1.327824\n",
            "Train Epoch: 4 [2332/3978 (59%)]\tLoss: 0.785221\n",
            "Train Epoch: 4 [2333/3978 (59%)]\tLoss: 0.055660\n",
            "Train Epoch: 4 [2334/3978 (59%)]\tLoss: 0.131689\n",
            "Train Epoch: 4 [2335/3978 (59%)]\tLoss: 0.543238\n",
            "Train Epoch: 4 [2336/3978 (59%)]\tLoss: 0.138754\n",
            "Train Epoch: 4 [2337/3978 (59%)]\tLoss: 0.720979\n",
            "Train Epoch: 4 [2338/3978 (59%)]\tLoss: 0.088217\n",
            "Train Epoch: 4 [2339/3978 (59%)]\tLoss: 0.061896\n",
            "Train Epoch: 4 [2340/3978 (59%)]\tLoss: 0.442241\n",
            "Train Epoch: 4 [2341/3978 (59%)]\tLoss: 0.069794\n",
            "Train Epoch: 4 [2342/3978 (59%)]\tLoss: 0.061864\n",
            "Train Epoch: 4 [2343/3978 (59%)]\tLoss: 0.141800\n",
            "Train Epoch: 4 [2344/3978 (59%)]\tLoss: 0.627789\n",
            "Train Epoch: 4 [2345/3978 (59%)]\tLoss: 0.133359\n",
            "Train Epoch: 4 [2346/3978 (59%)]\tLoss: 0.143035\n",
            "Train Epoch: 4 [2347/3978 (59%)]\tLoss: 0.118051\n",
            "Train Epoch: 4 [2348/3978 (59%)]\tLoss: 0.066075\n",
            "Train Epoch: 4 [2349/3978 (59%)]\tLoss: 0.407895\n",
            "Train Epoch: 4 [2350/3978 (59%)]\tLoss: 0.070069\n",
            "Train Epoch: 4 [2351/3978 (59%)]\tLoss: 0.090908\n",
            "Train Epoch: 4 [2352/3978 (59%)]\tLoss: 0.739874\n",
            "Train Epoch: 4 [2353/3978 (59%)]\tLoss: 0.072317\n",
            "Train Epoch: 4 [2354/3978 (59%)]\tLoss: 0.068014\n",
            "Train Epoch: 4 [2355/3978 (59%)]\tLoss: 0.132274\n",
            "Train Epoch: 4 [2356/3978 (59%)]\tLoss: 0.066963\n",
            "Train Epoch: 4 [2357/3978 (59%)]\tLoss: 0.104835\n",
            "Train Epoch: 4 [2358/3978 (59%)]\tLoss: 0.125119\n",
            "Train Epoch: 4 [2359/3978 (59%)]\tLoss: 0.091432\n",
            "Train Epoch: 4 [2360/3978 (59%)]\tLoss: 0.139447\n",
            "Train Epoch: 4 [2361/3978 (59%)]\tLoss: 0.071496\n",
            "Train Epoch: 4 [2362/3978 (59%)]\tLoss: 0.065269\n",
            "Train Epoch: 4 [2363/3978 (59%)]\tLoss: 0.087710\n",
            "Train Epoch: 4 [2364/3978 (59%)]\tLoss: 0.125676\n",
            "Train Epoch: 4 [2365/3978 (59%)]\tLoss: 0.637747\n",
            "Train Epoch: 4 [2366/3978 (59%)]\tLoss: 0.055624\n",
            "Train Epoch: 4 [2367/3978 (60%)]\tLoss: 0.058967\n",
            "Train Epoch: 4 [2368/3978 (60%)]\tLoss: 0.134231\n",
            "Train Epoch: 4 [2369/3978 (60%)]\tLoss: 0.059465\n",
            "Train Epoch: 4 [2370/3978 (60%)]\tLoss: 0.055484\n",
            "Train Epoch: 4 [2371/3978 (60%)]\tLoss: 0.653151\n",
            "Train Epoch: 4 [2372/3978 (60%)]\tLoss: 0.128322\n",
            "Train Epoch: 4 [2373/3978 (60%)]\tLoss: 0.112743\n",
            "Train Epoch: 4 [2374/3978 (60%)]\tLoss: 0.156070\n",
            "Train Epoch: 4 [2375/3978 (60%)]\tLoss: 0.162921\n",
            "Train Epoch: 4 [2376/3978 (60%)]\tLoss: 0.056956\n",
            "Train Epoch: 4 [2377/3978 (60%)]\tLoss: 0.142831\n",
            "Train Epoch: 4 [2378/3978 (60%)]\tLoss: 0.169610\n",
            "Train Epoch: 4 [2379/3978 (60%)]\tLoss: 0.059953\n",
            "Train Epoch: 4 [2380/3978 (60%)]\tLoss: 0.137682\n",
            "Train Epoch: 4 [2381/3978 (60%)]\tLoss: 0.063438\n",
            "Train Epoch: 4 [2382/3978 (60%)]\tLoss: 0.055705\n",
            "Train Epoch: 4 [2383/3978 (60%)]\tLoss: 0.065945\n",
            "Train Epoch: 4 [2384/3978 (60%)]\tLoss: 0.062501\n",
            "Train Epoch: 4 [2385/3978 (60%)]\tLoss: 0.059144\n",
            "Train Epoch: 4 [2386/3978 (60%)]\tLoss: 0.119172\n",
            "Train Epoch: 4 [2387/3978 (60%)]\tLoss: 0.104389\n",
            "Train Epoch: 4 [2388/3978 (60%)]\tLoss: 0.133147\n",
            "Train Epoch: 4 [2389/3978 (60%)]\tLoss: 0.640172\n",
            "Train Epoch: 4 [2390/3978 (60%)]\tLoss: 0.639831\n",
            "Train Epoch: 4 [2391/3978 (60%)]\tLoss: 0.737888\n",
            "Train Epoch: 4 [2392/3978 (60%)]\tLoss: 0.093435\n",
            "Train Epoch: 4 [2393/3978 (60%)]\tLoss: 0.066348\n",
            "Train Epoch: 4 [2394/3978 (60%)]\tLoss: 0.114447\n",
            "Train Epoch: 4 [2395/3978 (60%)]\tLoss: 0.092172\n",
            "Train Epoch: 4 [2396/3978 (60%)]\tLoss: 0.616144\n",
            "Train Epoch: 4 [2397/3978 (60%)]\tLoss: 0.096130\n",
            "Train Epoch: 4 [2398/3978 (60%)]\tLoss: 0.074177\n",
            "Train Epoch: 4 [2399/3978 (60%)]\tLoss: 0.060389\n",
            "Train Epoch: 4 [2400/3978 (60%)]\tLoss: 0.767911\n",
            "Train Epoch: 4 [2401/3978 (60%)]\tLoss: 0.504261\n",
            "Train Epoch: 4 [2402/3978 (60%)]\tLoss: 0.104745\n",
            "Train Epoch: 4 [2403/3978 (60%)]\tLoss: 0.057226\n",
            "Train Epoch: 4 [2404/3978 (60%)]\tLoss: 0.065033\n",
            "Train Epoch: 4 [2405/3978 (60%)]\tLoss: 0.058318\n",
            "Train Epoch: 4 [2406/3978 (60%)]\tLoss: 0.116496\n",
            "Train Epoch: 4 [2407/3978 (61%)]\tLoss: 0.057946\n",
            "Train Epoch: 4 [2408/3978 (61%)]\tLoss: 0.063767\n",
            "Train Epoch: 4 [2409/3978 (61%)]\tLoss: 0.116226\n",
            "Train Epoch: 4 [2410/3978 (61%)]\tLoss: 0.135731\n",
            "Train Epoch: 4 [2411/3978 (61%)]\tLoss: 0.623812\n",
            "Train Epoch: 4 [2412/3978 (61%)]\tLoss: 0.075809\n",
            "Train Epoch: 4 [2413/3978 (61%)]\tLoss: 0.064433\n",
            "Train Epoch: 4 [2414/3978 (61%)]\tLoss: 0.094070\n",
            "Train Epoch: 4 [2415/3978 (61%)]\tLoss: 0.129434\n",
            "Train Epoch: 4 [2416/3978 (61%)]\tLoss: 0.137719\n",
            "Train Epoch: 4 [2417/3978 (61%)]\tLoss: 0.053626\n",
            "Train Epoch: 4 [2418/3978 (61%)]\tLoss: 0.634162\n",
            "Train Epoch: 4 [2419/3978 (61%)]\tLoss: 0.162336\n",
            "Train Epoch: 4 [2420/3978 (61%)]\tLoss: 0.778792\n",
            "Train Epoch: 4 [2421/3978 (61%)]\tLoss: 0.195178\n",
            "Train Epoch: 4 [2422/3978 (61%)]\tLoss: 1.100301\n",
            "Train Epoch: 4 [2423/3978 (61%)]\tLoss: 0.051072\n",
            "Train Epoch: 4 [2424/3978 (61%)]\tLoss: 0.132730\n",
            "Train Epoch: 4 [2425/3978 (61%)]\tLoss: 0.188186\n",
            "Train Epoch: 4 [2426/3978 (61%)]\tLoss: 0.110393\n",
            "Train Epoch: 4 [2427/3978 (61%)]\tLoss: 0.072158\n",
            "Train Epoch: 4 [2428/3978 (61%)]\tLoss: 0.123368\n",
            "Train Epoch: 4 [2429/3978 (61%)]\tLoss: 0.053991\n",
            "Train Epoch: 4 [2430/3978 (61%)]\tLoss: 0.108533\n",
            "Train Epoch: 4 [2431/3978 (61%)]\tLoss: 0.140054\n",
            "Train Epoch: 4 [2432/3978 (61%)]\tLoss: 0.113909\n",
            "Train Epoch: 4 [2433/3978 (61%)]\tLoss: 0.097053\n",
            "Train Epoch: 4 [2434/3978 (61%)]\tLoss: 0.108484\n",
            "Train Epoch: 4 [2435/3978 (61%)]\tLoss: 0.064057\n",
            "Train Epoch: 4 [2436/3978 (61%)]\tLoss: 0.097317\n",
            "Train Epoch: 4 [2437/3978 (61%)]\tLoss: 0.716770\n",
            "Train Epoch: 4 [2438/3978 (61%)]\tLoss: 0.134511\n",
            "Train Epoch: 4 [2439/3978 (61%)]\tLoss: 0.128213\n",
            "Train Epoch: 4 [2440/3978 (61%)]\tLoss: 0.074691\n",
            "Train Epoch: 4 [2441/3978 (61%)]\tLoss: 0.090869\n",
            "Train Epoch: 4 [2442/3978 (61%)]\tLoss: 0.075881\n",
            "Train Epoch: 4 [2443/3978 (61%)]\tLoss: 0.079117\n",
            "Train Epoch: 4 [2444/3978 (61%)]\tLoss: 0.117788\n",
            "Train Epoch: 4 [2445/3978 (61%)]\tLoss: 0.091255\n",
            "Train Epoch: 4 [2446/3978 (61%)]\tLoss: 0.077555\n",
            "Train Epoch: 4 [2447/3978 (62%)]\tLoss: 0.086829\n",
            "Train Epoch: 4 [2448/3978 (62%)]\tLoss: 0.089724\n",
            "Train Epoch: 4 [2449/3978 (62%)]\tLoss: 0.627580\n",
            "Train Epoch: 4 [2450/3978 (62%)]\tLoss: 0.648110\n",
            "Train Epoch: 4 [2451/3978 (62%)]\tLoss: 0.097227\n",
            "Train Epoch: 4 [2452/3978 (62%)]\tLoss: 0.149275\n",
            "Train Epoch: 4 [2453/3978 (62%)]\tLoss: 0.057131\n",
            "Train Epoch: 4 [2454/3978 (62%)]\tLoss: 0.583664\n",
            "Train Epoch: 4 [2455/3978 (62%)]\tLoss: 0.107854\n",
            "Train Epoch: 4 [2456/3978 (62%)]\tLoss: 0.079312\n",
            "Train Epoch: 4 [2457/3978 (62%)]\tLoss: 0.060867\n",
            "Train Epoch: 4 [2458/3978 (62%)]\tLoss: 0.092494\n",
            "Train Epoch: 4 [2459/3978 (62%)]\tLoss: 0.063764\n",
            "Train Epoch: 4 [2460/3978 (62%)]\tLoss: 0.090512\n",
            "Train Epoch: 4 [2461/3978 (62%)]\tLoss: 0.059917\n",
            "Train Epoch: 4 [2462/3978 (62%)]\tLoss: 0.551926\n",
            "Train Epoch: 4 [2463/3978 (62%)]\tLoss: 0.068672\n",
            "Train Epoch: 4 [2464/3978 (62%)]\tLoss: 0.096831\n",
            "Train Epoch: 4 [2465/3978 (62%)]\tLoss: 0.067319\n",
            "Train Epoch: 4 [2466/3978 (62%)]\tLoss: 0.063436\n",
            "Train Epoch: 4 [2467/3978 (62%)]\tLoss: 0.055703\n",
            "Train Epoch: 4 [2468/3978 (62%)]\tLoss: 0.094752\n",
            "Train Epoch: 4 [2469/3978 (62%)]\tLoss: 0.054047\n",
            "Train Epoch: 4 [2470/3978 (62%)]\tLoss: 0.047312\n",
            "Train Epoch: 4 [2471/3978 (62%)]\tLoss: 0.083164\n",
            "Train Epoch: 4 [2472/3978 (62%)]\tLoss: 0.810901\n",
            "Train Epoch: 4 [2473/3978 (62%)]\tLoss: 0.145984\n",
            "Train Epoch: 4 [2474/3978 (62%)]\tLoss: 0.738508\n",
            "Train Epoch: 4 [2475/3978 (62%)]\tLoss: 0.042692\n",
            "Train Epoch: 4 [2476/3978 (62%)]\tLoss: 0.175839\n",
            "Train Epoch: 4 [2477/3978 (62%)]\tLoss: 0.668796\n",
            "Train Epoch: 4 [2478/3978 (62%)]\tLoss: 0.122274\n",
            "Train Epoch: 4 [2479/3978 (62%)]\tLoss: 0.586214\n",
            "Train Epoch: 4 [2480/3978 (62%)]\tLoss: 0.042097\n",
            "Train Epoch: 4 [2481/3978 (62%)]\tLoss: 0.573332\n",
            "Train Epoch: 4 [2482/3978 (62%)]\tLoss: 1.104075\n",
            "Train Epoch: 4 [2483/3978 (62%)]\tLoss: 0.122447\n",
            "Train Epoch: 4 [2484/3978 (62%)]\tLoss: 0.128411\n",
            "Train Epoch: 4 [2485/3978 (62%)]\tLoss: 0.537880\n",
            "Train Epoch: 4 [2486/3978 (62%)]\tLoss: 0.120178\n",
            "Train Epoch: 4 [2487/3978 (63%)]\tLoss: 0.060185\n",
            "Train Epoch: 4 [2488/3978 (63%)]\tLoss: 0.177434\n",
            "Train Epoch: 4 [2489/3978 (63%)]\tLoss: 0.097566\n",
            "Train Epoch: 4 [2490/3978 (63%)]\tLoss: 0.103967\n",
            "Train Epoch: 4 [2491/3978 (63%)]\tLoss: 0.078645\n",
            "Train Epoch: 4 [2492/3978 (63%)]\tLoss: 1.050789\n",
            "Train Epoch: 4 [2493/3978 (63%)]\tLoss: 0.095069\n",
            "Train Epoch: 4 [2494/3978 (63%)]\tLoss: 0.155620\n",
            "Train Epoch: 4 [2495/3978 (63%)]\tLoss: 0.887056\n",
            "Train Epoch: 4 [2496/3978 (63%)]\tLoss: 0.461532\n",
            "Train Epoch: 4 [2497/3978 (63%)]\tLoss: 0.146178\n",
            "Train Epoch: 4 [2498/3978 (63%)]\tLoss: 0.849236\n",
            "Train Epoch: 4 [2499/3978 (63%)]\tLoss: 0.083363\n",
            "Train Epoch: 4 [2500/3978 (63%)]\tLoss: 0.136195\n",
            "Train Epoch: 4 [2501/3978 (63%)]\tLoss: 0.429710\n",
            "Train Epoch: 4 [2502/3978 (63%)]\tLoss: 0.074725\n",
            "Train Epoch: 4 [2503/3978 (63%)]\tLoss: 0.635784\n",
            "Train Epoch: 4 [2504/3978 (63%)]\tLoss: 0.074968\n",
            "Train Epoch: 4 [2505/3978 (63%)]\tLoss: 0.095833\n",
            "Train Epoch: 4 [2506/3978 (63%)]\tLoss: 0.103181\n",
            "Train Epoch: 4 [2507/3978 (63%)]\tLoss: 0.168550\n",
            "Train Epoch: 4 [2508/3978 (63%)]\tLoss: 0.098631\n",
            "Train Epoch: 4 [2509/3978 (63%)]\tLoss: 0.384361\n",
            "Train Epoch: 4 [2510/3978 (63%)]\tLoss: 0.109707\n",
            "Train Epoch: 4 [2511/3978 (63%)]\tLoss: 0.172221\n",
            "Train Epoch: 4 [2512/3978 (63%)]\tLoss: 0.711695\n",
            "Train Epoch: 4 [2513/3978 (63%)]\tLoss: 0.096930\n",
            "Train Epoch: 4 [2514/3978 (63%)]\tLoss: 0.105528\n",
            "Train Epoch: 4 [2515/3978 (63%)]\tLoss: 0.080323\n",
            "Train Epoch: 4 [2516/3978 (63%)]\tLoss: 0.123593\n",
            "Train Epoch: 4 [2517/3978 (63%)]\tLoss: 0.082373\n",
            "Train Epoch: 4 [2518/3978 (63%)]\tLoss: 0.656808\n",
            "Train Epoch: 4 [2519/3978 (63%)]\tLoss: 0.624954\n",
            "Train Epoch: 4 [2520/3978 (63%)]\tLoss: 0.706205\n",
            "Train Epoch: 4 [2521/3978 (63%)]\tLoss: 0.080174\n",
            "Train Epoch: 4 [2522/3978 (63%)]\tLoss: 0.714993\n",
            "Train Epoch: 4 [2523/3978 (63%)]\tLoss: 0.170114\n",
            "Train Epoch: 4 [2524/3978 (63%)]\tLoss: 0.556719\n",
            "Train Epoch: 4 [2525/3978 (63%)]\tLoss: 0.082784\n",
            "Train Epoch: 4 [2526/3978 (63%)]\tLoss: 0.117580\n",
            "Train Epoch: 4 [2527/3978 (64%)]\tLoss: 0.168830\n",
            "Train Epoch: 4 [2528/3978 (64%)]\tLoss: 0.096444\n",
            "Train Epoch: 4 [2529/3978 (64%)]\tLoss: 0.100332\n",
            "Train Epoch: 4 [2530/3978 (64%)]\tLoss: 0.101486\n",
            "Train Epoch: 4 [2531/3978 (64%)]\tLoss: 0.096191\n",
            "Train Epoch: 4 [2532/3978 (64%)]\tLoss: 0.091163\n",
            "Train Epoch: 4 [2533/3978 (64%)]\tLoss: 0.646124\n",
            "Train Epoch: 4 [2534/3978 (64%)]\tLoss: 0.092560\n",
            "Train Epoch: 4 [2535/3978 (64%)]\tLoss: 0.519439\n",
            "Train Epoch: 4 [2536/3978 (64%)]\tLoss: 0.073630\n",
            "Train Epoch: 4 [2537/3978 (64%)]\tLoss: 0.136861\n",
            "Train Epoch: 4 [2538/3978 (64%)]\tLoss: 0.129400\n",
            "Train Epoch: 4 [2539/3978 (64%)]\tLoss: 0.071326\n",
            "Train Epoch: 4 [2540/3978 (64%)]\tLoss: 1.294757\n",
            "Train Epoch: 4 [2541/3978 (64%)]\tLoss: 0.137535\n",
            "Train Epoch: 4 [2542/3978 (64%)]\tLoss: 0.063878\n",
            "Train Epoch: 4 [2543/3978 (64%)]\tLoss: 0.193466\n",
            "Train Epoch: 4 [2544/3978 (64%)]\tLoss: 0.523537\n",
            "Train Epoch: 4 [2545/3978 (64%)]\tLoss: 0.573310\n",
            "Train Epoch: 4 [2546/3978 (64%)]\tLoss: 0.675064\n",
            "Train Epoch: 4 [2547/3978 (64%)]\tLoss: 0.565181\n",
            "Train Epoch: 4 [2548/3978 (64%)]\tLoss: 0.059176\n",
            "Train Epoch: 4 [2549/3978 (64%)]\tLoss: 0.113954\n",
            "Train Epoch: 4 [2550/3978 (64%)]\tLoss: 0.674283\n",
            "Train Epoch: 4 [2551/3978 (64%)]\tLoss: 0.059929\n",
            "Train Epoch: 4 [2552/3978 (64%)]\tLoss: 0.053202\n",
            "Train Epoch: 4 [2553/3978 (64%)]\tLoss: 0.053548\n",
            "Train Epoch: 4 [2554/3978 (64%)]\tLoss: 0.175741\n",
            "Train Epoch: 4 [2555/3978 (64%)]\tLoss: 0.067659\n",
            "Train Epoch: 4 [2556/3978 (64%)]\tLoss: 0.053266\n",
            "Train Epoch: 4 [2557/3978 (64%)]\tLoss: 0.202983\n",
            "Train Epoch: 4 [2558/3978 (64%)]\tLoss: 0.052337\n",
            "Train Epoch: 4 [2559/3978 (64%)]\tLoss: 0.055592\n",
            "Train Epoch: 4 [2560/3978 (64%)]\tLoss: 0.172843\n",
            "Train Epoch: 4 [2561/3978 (64%)]\tLoss: 0.057260\n",
            "Train Epoch: 4 [2562/3978 (64%)]\tLoss: 0.214817\n",
            "Train Epoch: 4 [2563/3978 (64%)]\tLoss: 0.048636\n",
            "Train Epoch: 4 [2564/3978 (64%)]\tLoss: 0.163738\n",
            "Train Epoch: 4 [2565/3978 (64%)]\tLoss: 0.051448\n",
            "Train Epoch: 4 [2566/3978 (65%)]\tLoss: 0.088676\n",
            "Train Epoch: 4 [2567/3978 (65%)]\tLoss: 0.045139\n",
            "Train Epoch: 4 [2568/3978 (65%)]\tLoss: 0.201524\n",
            "Train Epoch: 4 [2569/3978 (65%)]\tLoss: 0.047313\n",
            "Train Epoch: 4 [2570/3978 (65%)]\tLoss: 0.153679\n",
            "Train Epoch: 4 [2571/3978 (65%)]\tLoss: 0.044940\n",
            "Train Epoch: 4 [2572/3978 (65%)]\tLoss: 0.811311\n",
            "Train Epoch: 4 [2573/3978 (65%)]\tLoss: 0.637734\n",
            "Train Epoch: 4 [2574/3978 (65%)]\tLoss: 0.052063\n",
            "Train Epoch: 4 [2575/3978 (65%)]\tLoss: 0.612538\n",
            "Train Epoch: 4 [2576/3978 (65%)]\tLoss: 0.529617\n",
            "Train Epoch: 4 [2577/3978 (65%)]\tLoss: 0.058826\n",
            "Train Epoch: 4 [2578/3978 (65%)]\tLoss: 0.064971\n",
            "Train Epoch: 4 [2579/3978 (65%)]\tLoss: 0.177209\n",
            "Train Epoch: 4 [2580/3978 (65%)]\tLoss: 0.049004\n",
            "Train Epoch: 4 [2581/3978 (65%)]\tLoss: 0.058852\n",
            "Train Epoch: 4 [2582/3978 (65%)]\tLoss: 0.056785\n",
            "Train Epoch: 4 [2583/3978 (65%)]\tLoss: 0.062102\n",
            "Train Epoch: 4 [2584/3978 (65%)]\tLoss: 0.557484\n",
            "Train Epoch: 4 [2585/3978 (65%)]\tLoss: 0.064168\n",
            "Train Epoch: 4 [2586/3978 (65%)]\tLoss: 0.242992\n",
            "Train Epoch: 4 [2587/3978 (65%)]\tLoss: 0.580968\n",
            "Train Epoch: 4 [2588/3978 (65%)]\tLoss: 0.180532\n",
            "Train Epoch: 4 [2589/3978 (65%)]\tLoss: 0.240231\n",
            "Train Epoch: 4 [2590/3978 (65%)]\tLoss: 0.060916\n",
            "Train Epoch: 4 [2591/3978 (65%)]\tLoss: 0.444907\n",
            "Train Epoch: 4 [2592/3978 (65%)]\tLoss: 0.159664\n",
            "Train Epoch: 4 [2593/3978 (65%)]\tLoss: 0.053430\n",
            "Train Epoch: 4 [2594/3978 (65%)]\tLoss: 0.060276\n",
            "Train Epoch: 4 [2595/3978 (65%)]\tLoss: 0.071856\n",
            "Train Epoch: 4 [2596/3978 (65%)]\tLoss: 0.058955\n",
            "Train Epoch: 4 [2597/3978 (65%)]\tLoss: 0.061117\n",
            "Train Epoch: 4 [2598/3978 (65%)]\tLoss: 0.056600\n",
            "Train Epoch: 4 [2599/3978 (65%)]\tLoss: 0.150079\n",
            "Train Epoch: 4 [2600/3978 (65%)]\tLoss: 0.168517\n",
            "Train Epoch: 4 [2601/3978 (65%)]\tLoss: 0.461033\n",
            "Train Epoch: 4 [2602/3978 (65%)]\tLoss: 0.536675\n",
            "Train Epoch: 4 [2603/3978 (65%)]\tLoss: 0.061197\n",
            "Train Epoch: 4 [2604/3978 (65%)]\tLoss: 0.067458\n",
            "Train Epoch: 4 [2605/3978 (65%)]\tLoss: 0.066724\n",
            "Train Epoch: 4 [2606/3978 (66%)]\tLoss: 0.064766\n",
            "Train Epoch: 4 [2607/3978 (66%)]\tLoss: 0.055000\n",
            "Train Epoch: 4 [2608/3978 (66%)]\tLoss: 0.500291\n",
            "Train Epoch: 4 [2609/3978 (66%)]\tLoss: 0.207674\n",
            "Train Epoch: 4 [2610/3978 (66%)]\tLoss: 0.188250\n",
            "Train Epoch: 4 [2611/3978 (66%)]\tLoss: 0.162562\n",
            "Train Epoch: 4 [2612/3978 (66%)]\tLoss: 0.681343\n",
            "Train Epoch: 4 [2613/3978 (66%)]\tLoss: 0.075485\n",
            "Train Epoch: 4 [2614/3978 (66%)]\tLoss: 0.142426\n",
            "Train Epoch: 4 [2615/3978 (66%)]\tLoss: 0.129130\n",
            "Train Epoch: 4 [2616/3978 (66%)]\tLoss: 0.069927\n",
            "Train Epoch: 4 [2617/3978 (66%)]\tLoss: 0.131807\n",
            "Train Epoch: 4 [2618/3978 (66%)]\tLoss: 0.075084\n",
            "Train Epoch: 4 [2619/3978 (66%)]\tLoss: 0.117731\n",
            "Train Epoch: 4 [2620/3978 (66%)]\tLoss: 0.078087\n",
            "Train Epoch: 4 [2621/3978 (66%)]\tLoss: 0.112736\n",
            "Train Epoch: 4 [2622/3978 (66%)]\tLoss: 0.088400\n",
            "Train Epoch: 4 [2623/3978 (66%)]\tLoss: 0.129069\n",
            "Train Epoch: 4 [2624/3978 (66%)]\tLoss: 0.088416\n",
            "Train Epoch: 4 [2625/3978 (66%)]\tLoss: 0.110200\n",
            "Train Epoch: 4 [2626/3978 (66%)]\tLoss: 0.091743\n",
            "Train Epoch: 4 [2627/3978 (66%)]\tLoss: 0.081045\n",
            "Train Epoch: 4 [2628/3978 (66%)]\tLoss: 0.111480\n",
            "Train Epoch: 4 [2629/3978 (66%)]\tLoss: 0.662894\n",
            "Train Epoch: 4 [2630/3978 (66%)]\tLoss: 0.118084\n",
            "Train Epoch: 4 [2631/3978 (66%)]\tLoss: 1.146278\n",
            "Train Epoch: 4 [2632/3978 (66%)]\tLoss: 0.973006\n",
            "Train Epoch: 4 [2633/3978 (66%)]\tLoss: 0.068498\n",
            "Train Epoch: 4 [2634/3978 (66%)]\tLoss: 0.078084\n",
            "Train Epoch: 4 [2635/3978 (66%)]\tLoss: 0.095396\n",
            "Train Epoch: 4 [2636/3978 (66%)]\tLoss: 0.081355\n",
            "Train Epoch: 4 [2637/3978 (66%)]\tLoss: 0.614480\n",
            "Train Epoch: 4 [2638/3978 (66%)]\tLoss: 0.074604\n",
            "Train Epoch: 4 [2639/3978 (66%)]\tLoss: 0.103615\n",
            "Train Epoch: 4 [2640/3978 (66%)]\tLoss: 0.106809\n",
            "Train Epoch: 4 [2641/3978 (66%)]\tLoss: 0.096623\n",
            "Train Epoch: 4 [2642/3978 (66%)]\tLoss: 0.717924\n",
            "Train Epoch: 4 [2643/3978 (66%)]\tLoss: 0.104062\n",
            "Train Epoch: 4 [2644/3978 (66%)]\tLoss: 0.095625\n",
            "Train Epoch: 4 [2645/3978 (66%)]\tLoss: 0.090077\n",
            "Train Epoch: 4 [2646/3978 (67%)]\tLoss: 0.069719\n",
            "Train Epoch: 4 [2647/3978 (67%)]\tLoss: 0.135495\n",
            "Train Epoch: 4 [2648/3978 (67%)]\tLoss: 0.096390\n",
            "Train Epoch: 4 [2649/3978 (67%)]\tLoss: 0.099807\n",
            "Train Epoch: 4 [2650/3978 (67%)]\tLoss: 0.081653\n",
            "Train Epoch: 4 [2651/3978 (67%)]\tLoss: 0.132720\n",
            "Train Epoch: 4 [2652/3978 (67%)]\tLoss: 0.078631\n",
            "Train Epoch: 4 [2653/3978 (67%)]\tLoss: 0.081432\n",
            "Train Epoch: 4 [2654/3978 (67%)]\tLoss: 0.092974\n",
            "Train Epoch: 4 [2655/3978 (67%)]\tLoss: 0.100282\n",
            "Train Epoch: 4 [2656/3978 (67%)]\tLoss: 0.061107\n",
            "Train Epoch: 4 [2657/3978 (67%)]\tLoss: 0.067168\n",
            "Train Epoch: 4 [2658/3978 (67%)]\tLoss: 0.674576\n",
            "Train Epoch: 4 [2659/3978 (67%)]\tLoss: 0.121886\n",
            "Train Epoch: 4 [2660/3978 (67%)]\tLoss: 0.068634\n",
            "Train Epoch: 4 [2661/3978 (67%)]\tLoss: 0.096285\n",
            "Train Epoch: 4 [2662/3978 (67%)]\tLoss: 0.100155\n",
            "Train Epoch: 4 [2663/3978 (67%)]\tLoss: 0.118848\n",
            "Train Epoch: 4 [2664/3978 (67%)]\tLoss: 0.099622\n",
            "Train Epoch: 4 [2665/3978 (67%)]\tLoss: 0.087517\n",
            "Train Epoch: 4 [2666/3978 (67%)]\tLoss: 0.663289\n",
            "Train Epoch: 4 [2667/3978 (67%)]\tLoss: 0.089308\n",
            "Train Epoch: 4 [2668/3978 (67%)]\tLoss: 0.065883\n",
            "Train Epoch: 4 [2669/3978 (67%)]\tLoss: 0.122945\n",
            "Train Epoch: 4 [2670/3978 (67%)]\tLoss: 0.068924\n",
            "Train Epoch: 4 [2671/3978 (67%)]\tLoss: 0.078100\n",
            "Train Epoch: 4 [2672/3978 (67%)]\tLoss: 0.090610\n",
            "Train Epoch: 4 [2673/3978 (67%)]\tLoss: 0.087844\n",
            "Train Epoch: 4 [2674/3978 (67%)]\tLoss: 0.079407\n",
            "Train Epoch: 4 [2675/3978 (67%)]\tLoss: 0.074743\n",
            "Train Epoch: 4 [2676/3978 (67%)]\tLoss: 0.112623\n",
            "Train Epoch: 4 [2677/3978 (67%)]\tLoss: 0.058881\n",
            "Train Epoch: 4 [2678/3978 (67%)]\tLoss: 0.057981\n",
            "Train Epoch: 4 [2679/3978 (67%)]\tLoss: 0.065020\n",
            "Train Epoch: 4 [2680/3978 (67%)]\tLoss: 0.094993\n",
            "Train Epoch: 4 [2681/3978 (67%)]\tLoss: 0.068453\n",
            "Train Epoch: 4 [2682/3978 (67%)]\tLoss: 0.092175\n",
            "Train Epoch: 4 [2683/3978 (67%)]\tLoss: 0.098388\n",
            "Train Epoch: 4 [2684/3978 (67%)]\tLoss: 0.046772\n",
            "Train Epoch: 4 [2685/3978 (67%)]\tLoss: 0.055737\n",
            "Train Epoch: 4 [2686/3978 (68%)]\tLoss: 0.058071\n",
            "Train Epoch: 4 [2687/3978 (68%)]\tLoss: 0.062804\n",
            "Train Epoch: 4 [2688/3978 (68%)]\tLoss: 1.267630\n",
            "Train Epoch: 4 [2689/3978 (68%)]\tLoss: 0.053073\n",
            "Train Epoch: 4 [2690/3978 (68%)]\tLoss: 0.043275\n",
            "Train Epoch: 4 [2691/3978 (68%)]\tLoss: 0.038421\n",
            "Train Epoch: 4 [2692/3978 (68%)]\tLoss: 0.047736\n",
            "Train Epoch: 4 [2693/3978 (68%)]\tLoss: 0.036409\n",
            "Train Epoch: 4 [2694/3978 (68%)]\tLoss: 0.035495\n",
            "Train Epoch: 4 [2695/3978 (68%)]\tLoss: 0.735211\n",
            "Train Epoch: 4 [2696/3978 (68%)]\tLoss: 0.042906\n",
            "Train Epoch: 4 [2697/3978 (68%)]\tLoss: 0.064938\n",
            "Train Epoch: 4 [2698/3978 (68%)]\tLoss: 0.127563\n",
            "Train Epoch: 4 [2699/3978 (68%)]\tLoss: 0.142844\n",
            "Train Epoch: 4 [2700/3978 (68%)]\tLoss: 0.040372\n",
            "Train Epoch: 4 [2701/3978 (68%)]\tLoss: 0.696102\n",
            "Train Epoch: 4 [2702/3978 (68%)]\tLoss: 0.033454\n",
            "Train Epoch: 4 [2703/3978 (68%)]\tLoss: 0.031552\n",
            "Train Epoch: 4 [2704/3978 (68%)]\tLoss: 0.691343\n",
            "Train Epoch: 4 [2705/3978 (68%)]\tLoss: 0.198420\n",
            "Train Epoch: 4 [2706/3978 (68%)]\tLoss: 0.177440\n",
            "Train Epoch: 4 [2707/3978 (68%)]\tLoss: 0.193682\n",
            "Train Epoch: 4 [2708/3978 (68%)]\tLoss: 0.163527\n",
            "Train Epoch: 4 [2709/3978 (68%)]\tLoss: 0.133631\n",
            "Train Epoch: 4 [2710/3978 (68%)]\tLoss: 0.126144\n",
            "Train Epoch: 4 [2711/3978 (68%)]\tLoss: 0.037911\n",
            "Train Epoch: 4 [2712/3978 (68%)]\tLoss: 0.117953\n",
            "Train Epoch: 4 [2713/3978 (68%)]\tLoss: 0.108197\n",
            "Train Epoch: 4 [2714/3978 (68%)]\tLoss: 0.944236\n",
            "Train Epoch: 4 [2715/3978 (68%)]\tLoss: 1.072836\n",
            "Train Epoch: 4 [2716/3978 (68%)]\tLoss: 0.136950\n",
            "Train Epoch: 4 [2717/3978 (68%)]\tLoss: 0.097907\n",
            "Train Epoch: 4 [2718/3978 (68%)]\tLoss: 0.067688\n",
            "Train Epoch: 4 [2719/3978 (68%)]\tLoss: 0.074007\n",
            "Train Epoch: 4 [2720/3978 (68%)]\tLoss: 0.074707\n",
            "Train Epoch: 4 [2721/3978 (68%)]\tLoss: 0.080833\n",
            "Train Epoch: 4 [2722/3978 (68%)]\tLoss: 0.625962\n",
            "Train Epoch: 4 [2723/3978 (68%)]\tLoss: 0.082330\n",
            "Train Epoch: 4 [2724/3978 (68%)]\tLoss: 0.078580\n",
            "Train Epoch: 4 [2725/3978 (69%)]\tLoss: 0.062511\n",
            "Train Epoch: 4 [2726/3978 (69%)]\tLoss: 0.068598\n",
            "Train Epoch: 4 [2727/3978 (69%)]\tLoss: 0.080826\n",
            "Train Epoch: 4 [2728/3978 (69%)]\tLoss: 0.735676\n",
            "Train Epoch: 4 [2729/3978 (69%)]\tLoss: 1.385861\n",
            "Train Epoch: 4 [2730/3978 (69%)]\tLoss: 0.084601\n",
            "Train Epoch: 4 [2731/3978 (69%)]\tLoss: 0.107769\n",
            "Train Epoch: 4 [2732/3978 (69%)]\tLoss: 0.069891\n",
            "Train Epoch: 4 [2733/3978 (69%)]\tLoss: 0.071081\n",
            "Train Epoch: 4 [2734/3978 (69%)]\tLoss: 0.078685\n",
            "Train Epoch: 4 [2735/3978 (69%)]\tLoss: 0.091753\n",
            "Train Epoch: 4 [2736/3978 (69%)]\tLoss: 0.958584\n",
            "Train Epoch: 4 [2737/3978 (69%)]\tLoss: 0.093002\n",
            "Train Epoch: 4 [2738/3978 (69%)]\tLoss: 0.072728\n",
            "Train Epoch: 4 [2739/3978 (69%)]\tLoss: 0.103522\n",
            "Train Epoch: 4 [2740/3978 (69%)]\tLoss: 0.083800\n",
            "Train Epoch: 4 [2741/3978 (69%)]\tLoss: 1.225940\n",
            "Train Epoch: 4 [2742/3978 (69%)]\tLoss: 0.066069\n",
            "Train Epoch: 4 [2743/3978 (69%)]\tLoss: 0.082812\n",
            "Train Epoch: 4 [2744/3978 (69%)]\tLoss: 0.075216\n",
            "Train Epoch: 4 [2745/3978 (69%)]\tLoss: 0.085540\n",
            "Train Epoch: 4 [2746/3978 (69%)]\tLoss: 0.082175\n",
            "Train Epoch: 4 [2747/3978 (69%)]\tLoss: 0.101624\n",
            "Train Epoch: 4 [2748/3978 (69%)]\tLoss: 0.077327\n",
            "Train Epoch: 4 [2749/3978 (69%)]\tLoss: 0.075122\n",
            "Train Epoch: 4 [2750/3978 (69%)]\tLoss: 0.112852\n",
            "Train Epoch: 4 [2751/3978 (69%)]\tLoss: 0.524353\n",
            "Train Epoch: 4 [2752/3978 (69%)]\tLoss: 0.071518\n",
            "Train Epoch: 4 [2753/3978 (69%)]\tLoss: 0.070067\n",
            "Train Epoch: 4 [2754/3978 (69%)]\tLoss: 0.095367\n",
            "Train Epoch: 4 [2755/3978 (69%)]\tLoss: 0.065042\n",
            "Train Epoch: 4 [2756/3978 (69%)]\tLoss: 0.066133\n",
            "Train Epoch: 4 [2757/3978 (69%)]\tLoss: 0.068338\n",
            "Train Epoch: 4 [2758/3978 (69%)]\tLoss: 0.089745\n",
            "Train Epoch: 4 [2759/3978 (69%)]\tLoss: 0.092209\n",
            "Train Epoch: 4 [2760/3978 (69%)]\tLoss: 0.866471\n",
            "Train Epoch: 4 [2761/3978 (69%)]\tLoss: 0.788908\n",
            "Train Epoch: 4 [2762/3978 (69%)]\tLoss: 0.073791\n",
            "Train Epoch: 4 [2763/3978 (69%)]\tLoss: 0.895476\n",
            "Train Epoch: 4 [2764/3978 (69%)]\tLoss: 0.056332\n",
            "Train Epoch: 4 [2765/3978 (70%)]\tLoss: 0.065870\n",
            "Train Epoch: 4 [2766/3978 (70%)]\tLoss: 0.101901\n",
            "Train Epoch: 4 [2767/3978 (70%)]\tLoss: 0.134661\n",
            "Train Epoch: 4 [2768/3978 (70%)]\tLoss: 0.109162\n",
            "Train Epoch: 4 [2769/3978 (70%)]\tLoss: 0.061963\n",
            "Train Epoch: 4 [2770/3978 (70%)]\tLoss: 0.135406\n",
            "Train Epoch: 4 [2771/3978 (70%)]\tLoss: 0.059418\n",
            "Train Epoch: 4 [2772/3978 (70%)]\tLoss: 0.121990\n",
            "Train Epoch: 4 [2773/3978 (70%)]\tLoss: 0.061174\n",
            "Train Epoch: 4 [2774/3978 (70%)]\tLoss: 0.959896\n",
            "Train Epoch: 4 [2775/3978 (70%)]\tLoss: 0.080123\n",
            "Train Epoch: 4 [2776/3978 (70%)]\tLoss: 0.088158\n",
            "Train Epoch: 4 [2777/3978 (70%)]\tLoss: 0.841098\n",
            "Train Epoch: 4 [2778/3978 (70%)]\tLoss: 0.070773\n",
            "Train Epoch: 4 [2779/3978 (70%)]\tLoss: 0.097429\n",
            "Train Epoch: 4 [2780/3978 (70%)]\tLoss: 0.074860\n",
            "Train Epoch: 4 [2781/3978 (70%)]\tLoss: 0.083753\n",
            "Train Epoch: 4 [2782/3978 (70%)]\tLoss: 0.663880\n",
            "Train Epoch: 4 [2783/3978 (70%)]\tLoss: 0.075016\n",
            "Train Epoch: 4 [2784/3978 (70%)]\tLoss: 0.087140\n",
            "Train Epoch: 4 [2785/3978 (70%)]\tLoss: 0.068666\n",
            "Train Epoch: 4 [2786/3978 (70%)]\tLoss: 0.120671\n",
            "Train Epoch: 4 [2787/3978 (70%)]\tLoss: 0.553680\n",
            "Train Epoch: 4 [2788/3978 (70%)]\tLoss: 0.063467\n",
            "Train Epoch: 4 [2789/3978 (70%)]\tLoss: 0.089192\n",
            "Train Epoch: 4 [2790/3978 (70%)]\tLoss: 0.993093\n",
            "Train Epoch: 4 [2791/3978 (70%)]\tLoss: 0.073618\n",
            "Train Epoch: 4 [2792/3978 (70%)]\tLoss: 0.108637\n",
            "Train Epoch: 4 [2793/3978 (70%)]\tLoss: 0.889065\n",
            "Train Epoch: 4 [2794/3978 (70%)]\tLoss: 0.072906\n",
            "Train Epoch: 4 [2795/3978 (70%)]\tLoss: 0.056496\n",
            "Train Epoch: 4 [2796/3978 (70%)]\tLoss: 0.089506\n",
            "Train Epoch: 4 [2797/3978 (70%)]\tLoss: 0.958734\n",
            "Train Epoch: 4 [2798/3978 (70%)]\tLoss: 0.071161\n",
            "Train Epoch: 4 [2799/3978 (70%)]\tLoss: 0.081870\n",
            "Train Epoch: 4 [2800/3978 (70%)]\tLoss: 0.064043\n",
            "Train Epoch: 4 [2801/3978 (70%)]\tLoss: 0.095882\n",
            "Train Epoch: 4 [2802/3978 (70%)]\tLoss: 1.193659\n",
            "Train Epoch: 4 [2803/3978 (70%)]\tLoss: 0.101221\n",
            "Train Epoch: 4 [2804/3978 (70%)]\tLoss: 0.106651\n",
            "Train Epoch: 4 [2805/3978 (71%)]\tLoss: 0.061095\n",
            "Train Epoch: 4 [2806/3978 (71%)]\tLoss: 0.058550\n",
            "Train Epoch: 4 [2807/3978 (71%)]\tLoss: 0.102023\n",
            "Train Epoch: 4 [2808/3978 (71%)]\tLoss: 0.106738\n",
            "Train Epoch: 4 [2809/3978 (71%)]\tLoss: 0.050700\n",
            "Train Epoch: 4 [2810/3978 (71%)]\tLoss: 0.806619\n",
            "Train Epoch: 4 [2811/3978 (71%)]\tLoss: 0.060940\n",
            "Train Epoch: 4 [2812/3978 (71%)]\tLoss: 0.773655\n",
            "Train Epoch: 4 [2813/3978 (71%)]\tLoss: 0.791781\n",
            "Train Epoch: 4 [2814/3978 (71%)]\tLoss: 0.064358\n",
            "Train Epoch: 4 [2815/3978 (71%)]\tLoss: 0.050504\n",
            "Train Epoch: 4 [2816/3978 (71%)]\tLoss: 0.061381\n",
            "Train Epoch: 4 [2817/3978 (71%)]\tLoss: 0.790378\n",
            "Train Epoch: 4 [2818/3978 (71%)]\tLoss: 0.102445\n",
            "Train Epoch: 4 [2819/3978 (71%)]\tLoss: 0.679297\n",
            "Train Epoch: 4 [2820/3978 (71%)]\tLoss: 0.109847\n",
            "Train Epoch: 4 [2821/3978 (71%)]\tLoss: 0.117876\n",
            "Train Epoch: 4 [2822/3978 (71%)]\tLoss: 0.116215\n",
            "Train Epoch: 4 [2823/3978 (71%)]\tLoss: 0.065653\n",
            "Train Epoch: 4 [2824/3978 (71%)]\tLoss: 0.063590\n",
            "Train Epoch: 4 [2825/3978 (71%)]\tLoss: 0.060362\n",
            "Train Epoch: 4 [2826/3978 (71%)]\tLoss: 0.110754\n",
            "Train Epoch: 4 [2827/3978 (71%)]\tLoss: 0.062963\n",
            "Train Epoch: 4 [2828/3978 (71%)]\tLoss: 0.130448\n",
            "Train Epoch: 4 [2829/3978 (71%)]\tLoss: 0.176020\n",
            "Train Epoch: 4 [2830/3978 (71%)]\tLoss: 0.060009\n",
            "Train Epoch: 4 [2831/3978 (71%)]\tLoss: 0.098863\n",
            "Train Epoch: 4 [2832/3978 (71%)]\tLoss: 0.100106\n",
            "Train Epoch: 4 [2833/3978 (71%)]\tLoss: 0.161218\n",
            "Train Epoch: 4 [2834/3978 (71%)]\tLoss: 0.080559\n",
            "Train Epoch: 4 [2835/3978 (71%)]\tLoss: 0.589563\n",
            "Train Epoch: 4 [2836/3978 (71%)]\tLoss: 0.089020\n",
            "Train Epoch: 4 [2837/3978 (71%)]\tLoss: 0.074105\n",
            "Train Epoch: 4 [2838/3978 (71%)]\tLoss: 0.078478\n",
            "Train Epoch: 4 [2839/3978 (71%)]\tLoss: 0.675546\n",
            "Train Epoch: 4 [2840/3978 (71%)]\tLoss: 0.083467\n",
            "Train Epoch: 4 [2841/3978 (71%)]\tLoss: 0.084561\n",
            "Train Epoch: 4 [2842/3978 (71%)]\tLoss: 0.663454\n",
            "Train Epoch: 4 [2843/3978 (71%)]\tLoss: 0.079433\n",
            "Train Epoch: 4 [2844/3978 (71%)]\tLoss: 0.077496\n",
            "Train Epoch: 4 [2845/3978 (72%)]\tLoss: 0.077824\n",
            "Train Epoch: 4 [2846/3978 (72%)]\tLoss: 0.074458\n",
            "Train Epoch: 4 [2847/3978 (72%)]\tLoss: 0.585432\n",
            "Train Epoch: 4 [2848/3978 (72%)]\tLoss: 0.075782\n",
            "Train Epoch: 4 [2849/3978 (72%)]\tLoss: 0.090091\n",
            "Train Epoch: 4 [2850/3978 (72%)]\tLoss: 0.076457\n",
            "Train Epoch: 4 [2851/3978 (72%)]\tLoss: 0.109229\n",
            "Train Epoch: 4 [2852/3978 (72%)]\tLoss: 0.093781\n",
            "Train Epoch: 4 [2853/3978 (72%)]\tLoss: 0.082310\n",
            "Train Epoch: 4 [2854/3978 (72%)]\tLoss: 0.901443\n",
            "Train Epoch: 4 [2855/3978 (72%)]\tLoss: 0.081857\n",
            "Train Epoch: 4 [2856/3978 (72%)]\tLoss: 0.108347\n",
            "Train Epoch: 4 [2857/3978 (72%)]\tLoss: 0.075013\n",
            "Train Epoch: 4 [2858/3978 (72%)]\tLoss: 0.090590\n",
            "Train Epoch: 4 [2859/3978 (72%)]\tLoss: 0.140406\n",
            "Train Epoch: 4 [2860/3978 (72%)]\tLoss: 0.108572\n",
            "Train Epoch: 4 [2861/3978 (72%)]\tLoss: 0.078791\n",
            "Train Epoch: 4 [2862/3978 (72%)]\tLoss: 0.660094\n",
            "Train Epoch: 4 [2863/3978 (72%)]\tLoss: 0.089837\n",
            "Train Epoch: 4 [2864/3978 (72%)]\tLoss: 0.094596\n",
            "Train Epoch: 4 [2865/3978 (72%)]\tLoss: 0.097947\n",
            "Train Epoch: 4 [2866/3978 (72%)]\tLoss: 0.109782\n",
            "Train Epoch: 4 [2867/3978 (72%)]\tLoss: 0.084068\n",
            "Train Epoch: 4 [2868/3978 (72%)]\tLoss: 0.114123\n",
            "Train Epoch: 4 [2869/3978 (72%)]\tLoss: 0.063866\n",
            "Train Epoch: 4 [2870/3978 (72%)]\tLoss: 0.064043\n",
            "Train Epoch: 4 [2871/3978 (72%)]\tLoss: 0.579265\n",
            "Train Epoch: 4 [2872/3978 (72%)]\tLoss: 0.099396\n",
            "Train Epoch: 4 [2873/3978 (72%)]\tLoss: 0.106288\n",
            "Train Epoch: 4 [2874/3978 (72%)]\tLoss: 0.077747\n",
            "Train Epoch: 4 [2875/3978 (72%)]\tLoss: 0.091471\n",
            "Train Epoch: 4 [2876/3978 (72%)]\tLoss: 0.124755\n",
            "Train Epoch: 4 [2877/3978 (72%)]\tLoss: 0.064057\n",
            "Train Epoch: 4 [2878/3978 (72%)]\tLoss: 0.693030\n",
            "Train Epoch: 4 [2879/3978 (72%)]\tLoss: 0.804215\n",
            "Train Epoch: 4 [2880/3978 (72%)]\tLoss: 0.084936\n",
            "Train Epoch: 4 [2881/3978 (72%)]\tLoss: 0.079745\n",
            "Train Epoch: 4 [2882/3978 (72%)]\tLoss: 0.064497\n",
            "Train Epoch: 4 [2883/3978 (72%)]\tLoss: 0.123948\n",
            "Train Epoch: 4 [2884/3978 (72%)]\tLoss: 0.089366\n",
            "Train Epoch: 4 [2885/3978 (73%)]\tLoss: 0.103246\n",
            "Train Epoch: 4 [2886/3978 (73%)]\tLoss: 0.132213\n",
            "Train Epoch: 4 [2887/3978 (73%)]\tLoss: 0.476189\n",
            "Train Epoch: 4 [2888/3978 (73%)]\tLoss: 0.117965\n",
            "Train Epoch: 4 [2889/3978 (73%)]\tLoss: 0.085447\n",
            "Train Epoch: 4 [2890/3978 (73%)]\tLoss: 0.803864\n",
            "Train Epoch: 4 [2891/3978 (73%)]\tLoss: 0.101800\n",
            "Train Epoch: 4 [2892/3978 (73%)]\tLoss: 0.081696\n",
            "Train Epoch: 4 [2893/3978 (73%)]\tLoss: 0.609310\n",
            "Train Epoch: 4 [2894/3978 (73%)]\tLoss: 0.074070\n",
            "Train Epoch: 4 [2895/3978 (73%)]\tLoss: 0.069222\n",
            "Train Epoch: 4 [2896/3978 (73%)]\tLoss: 0.101871\n",
            "Train Epoch: 4 [2897/3978 (73%)]\tLoss: 0.460169\n",
            "Train Epoch: 4 [2898/3978 (73%)]\tLoss: 0.979098\n",
            "Train Epoch: 4 [2899/3978 (73%)]\tLoss: 0.081384\n",
            "Train Epoch: 4 [2900/3978 (73%)]\tLoss: 0.100810\n",
            "Train Epoch: 4 [2901/3978 (73%)]\tLoss: 0.752362\n",
            "Train Epoch: 4 [2902/3978 (73%)]\tLoss: 0.105155\n",
            "Train Epoch: 4 [2903/3978 (73%)]\tLoss: 0.077616\n",
            "Train Epoch: 4 [2904/3978 (73%)]\tLoss: 0.097329\n",
            "Train Epoch: 4 [2905/3978 (73%)]\tLoss: 0.072414\n",
            "Train Epoch: 4 [2906/3978 (73%)]\tLoss: 0.076453\n",
            "Train Epoch: 4 [2907/3978 (73%)]\tLoss: 0.110739\n",
            "Train Epoch: 4 [2908/3978 (73%)]\tLoss: 0.097478\n",
            "Train Epoch: 4 [2909/3978 (73%)]\tLoss: 0.078253\n",
            "Train Epoch: 4 [2910/3978 (73%)]\tLoss: 0.102213\n",
            "Train Epoch: 4 [2911/3978 (73%)]\tLoss: 0.092194\n",
            "Train Epoch: 4 [2912/3978 (73%)]\tLoss: 0.075835\n",
            "Train Epoch: 4 [2913/3978 (73%)]\tLoss: 0.142186\n",
            "Train Epoch: 4 [2914/3978 (73%)]\tLoss: 0.080072\n",
            "Train Epoch: 4 [2915/3978 (73%)]\tLoss: 0.128375\n",
            "Train Epoch: 4 [2916/3978 (73%)]\tLoss: 0.078403\n",
            "Train Epoch: 4 [2917/3978 (73%)]\tLoss: 0.086369\n",
            "Train Epoch: 4 [2918/3978 (73%)]\tLoss: 0.073736\n",
            "Train Epoch: 4 [2919/3978 (73%)]\tLoss: 0.077330\n",
            "Train Epoch: 4 [2920/3978 (73%)]\tLoss: 0.118863\n",
            "Train Epoch: 4 [2921/3978 (73%)]\tLoss: 0.079184\n",
            "Train Epoch: 4 [2922/3978 (73%)]\tLoss: 0.061471\n",
            "Train Epoch: 4 [2923/3978 (73%)]\tLoss: 0.084495\n",
            "Train Epoch: 4 [2924/3978 (74%)]\tLoss: 0.112601\n",
            "Train Epoch: 4 [2925/3978 (74%)]\tLoss: 0.065801\n",
            "Train Epoch: 4 [2926/3978 (74%)]\tLoss: 0.059752\n",
            "Train Epoch: 4 [2927/3978 (74%)]\tLoss: 0.051645\n",
            "Train Epoch: 4 [2928/3978 (74%)]\tLoss: 0.153191\n",
            "Train Epoch: 4 [2929/3978 (74%)]\tLoss: 0.503984\n",
            "Train Epoch: 4 [2930/3978 (74%)]\tLoss: 0.054664\n",
            "Train Epoch: 4 [2931/3978 (74%)]\tLoss: 0.054513\n",
            "Train Epoch: 4 [2932/3978 (74%)]\tLoss: 0.062067\n",
            "Train Epoch: 4 [2933/3978 (74%)]\tLoss: 0.158016\n",
            "Train Epoch: 4 [2934/3978 (74%)]\tLoss: 0.114966\n",
            "Train Epoch: 4 [2935/3978 (74%)]\tLoss: 0.830595\n",
            "Train Epoch: 4 [2936/3978 (74%)]\tLoss: 0.102340\n",
            "Train Epoch: 4 [2937/3978 (74%)]\tLoss: 0.042875\n",
            "Train Epoch: 4 [2938/3978 (74%)]\tLoss: 0.116368\n",
            "Train Epoch: 4 [2939/3978 (74%)]\tLoss: 0.609427\n",
            "Train Epoch: 4 [2940/3978 (74%)]\tLoss: 0.059035\n",
            "Train Epoch: 4 [2941/3978 (74%)]\tLoss: 0.050750\n",
            "Train Epoch: 4 [2942/3978 (74%)]\tLoss: 0.048014\n",
            "Train Epoch: 4 [2943/3978 (74%)]\tLoss: 0.041627\n",
            "Train Epoch: 4 [2944/3978 (74%)]\tLoss: 0.040318\n",
            "Train Epoch: 4 [2945/3978 (74%)]\tLoss: 0.123425\n",
            "Train Epoch: 4 [2946/3978 (74%)]\tLoss: 0.102945\n",
            "Train Epoch: 4 [2947/3978 (74%)]\tLoss: 0.042511\n",
            "Train Epoch: 4 [2948/3978 (74%)]\tLoss: 0.048246\n",
            "Train Epoch: 4 [2949/3978 (74%)]\tLoss: 0.729852\n",
            "Train Epoch: 4 [2950/3978 (74%)]\tLoss: 0.104435\n",
            "Train Epoch: 4 [2951/3978 (74%)]\tLoss: 0.104467\n",
            "Train Epoch: 4 [2952/3978 (74%)]\tLoss: 0.039204\n",
            "Train Epoch: 4 [2953/3978 (74%)]\tLoss: 0.145210\n",
            "Train Epoch: 4 [2954/3978 (74%)]\tLoss: 0.141709\n",
            "Train Epoch: 4 [2955/3978 (74%)]\tLoss: 0.060396\n",
            "Train Epoch: 4 [2956/3978 (74%)]\tLoss: 0.044040\n",
            "Train Epoch: 4 [2957/3978 (74%)]\tLoss: 0.088905\n",
            "Train Epoch: 4 [2958/3978 (74%)]\tLoss: 0.044327\n",
            "Train Epoch: 4 [2959/3978 (74%)]\tLoss: 0.098136\n",
            "Train Epoch: 4 [2960/3978 (74%)]\tLoss: 0.085945\n",
            "Train Epoch: 4 [2961/3978 (74%)]\tLoss: 0.087043\n",
            "Train Epoch: 4 [2962/3978 (74%)]\tLoss: 1.005133\n",
            "Train Epoch: 4 [2963/3978 (74%)]\tLoss: 0.082771\n",
            "Train Epoch: 4 [2964/3978 (75%)]\tLoss: 0.049151\n",
            "Train Epoch: 4 [2965/3978 (75%)]\tLoss: 0.049007\n",
            "Train Epoch: 4 [2966/3978 (75%)]\tLoss: 0.048326\n",
            "Train Epoch: 4 [2967/3978 (75%)]\tLoss: 0.070143\n",
            "Train Epoch: 4 [2968/3978 (75%)]\tLoss: 0.079207\n",
            "Train Epoch: 4 [2969/3978 (75%)]\tLoss: 0.091371\n",
            "Train Epoch: 4 [2970/3978 (75%)]\tLoss: 0.704089\n",
            "Train Epoch: 4 [2971/3978 (75%)]\tLoss: 0.070085\n",
            "Train Epoch: 4 [2972/3978 (75%)]\tLoss: 0.053770\n",
            "Train Epoch: 4 [2973/3978 (75%)]\tLoss: 0.051584\n",
            "Train Epoch: 4 [2974/3978 (75%)]\tLoss: 0.056698\n",
            "Train Epoch: 4 [2975/3978 (75%)]\tLoss: 0.051996\n",
            "Train Epoch: 4 [2976/3978 (75%)]\tLoss: 0.051079\n",
            "Train Epoch: 4 [2977/3978 (75%)]\tLoss: 0.042829\n",
            "Train Epoch: 4 [2978/3978 (75%)]\tLoss: 0.048710\n",
            "Train Epoch: 4 [2979/3978 (75%)]\tLoss: 0.100466\n",
            "Train Epoch: 4 [2980/3978 (75%)]\tLoss: 0.577798\n",
            "Train Epoch: 4 [2981/3978 (75%)]\tLoss: 0.099508\n",
            "Train Epoch: 4 [2982/3978 (75%)]\tLoss: 0.093920\n",
            "Train Epoch: 4 [2983/3978 (75%)]\tLoss: 0.150300\n",
            "Train Epoch: 4 [2984/3978 (75%)]\tLoss: 0.064796\n",
            "Train Epoch: 4 [2985/3978 (75%)]\tLoss: 0.038251\n",
            "Train Epoch: 4 [2986/3978 (75%)]\tLoss: 0.146420\n",
            "Train Epoch: 4 [2987/3978 (75%)]\tLoss: 0.136101\n",
            "Train Epoch: 4 [2988/3978 (75%)]\tLoss: 0.937302\n",
            "Train Epoch: 4 [2989/3978 (75%)]\tLoss: 0.634795\n",
            "Train Epoch: 4 [2990/3978 (75%)]\tLoss: 0.095233\n",
            "Train Epoch: 4 [2991/3978 (75%)]\tLoss: 0.081011\n",
            "Train Epoch: 4 [2992/3978 (75%)]\tLoss: 0.048622\n",
            "Train Epoch: 4 [2993/3978 (75%)]\tLoss: 0.535636\n",
            "Train Epoch: 4 [2994/3978 (75%)]\tLoss: 0.050800\n",
            "Train Epoch: 4 [2995/3978 (75%)]\tLoss: 0.074375\n",
            "Train Epoch: 4 [2996/3978 (75%)]\tLoss: 0.082807\n",
            "Train Epoch: 4 [2997/3978 (75%)]\tLoss: 0.090603\n",
            "Train Epoch: 4 [2998/3978 (75%)]\tLoss: 1.057139\n",
            "Train Epoch: 4 [2999/3978 (75%)]\tLoss: 0.068030\n",
            "Train Epoch: 4 [3000/3978 (75%)]\tLoss: 0.075997\n",
            "Train Epoch: 4 [3001/3978 (75%)]\tLoss: 0.071214\n",
            "Train Epoch: 4 [3002/3978 (75%)]\tLoss: 0.059519\n",
            "Train Epoch: 4 [3003/3978 (75%)]\tLoss: 0.591532\n",
            "Train Epoch: 4 [3004/3978 (76%)]\tLoss: 0.108998\n",
            "Train Epoch: 4 [3005/3978 (76%)]\tLoss: 0.135981\n",
            "Train Epoch: 4 [3006/3978 (76%)]\tLoss: 0.084796\n",
            "Train Epoch: 4 [3007/3978 (76%)]\tLoss: 0.137407\n",
            "Train Epoch: 4 [3008/3978 (76%)]\tLoss: 0.725540\n",
            "Train Epoch: 4 [3009/3978 (76%)]\tLoss: 0.053128\n",
            "Train Epoch: 4 [3010/3978 (76%)]\tLoss: 0.133450\n",
            "Train Epoch: 4 [3011/3978 (76%)]\tLoss: 0.102506\n",
            "Train Epoch: 4 [3012/3978 (76%)]\tLoss: 0.065539\n",
            "Train Epoch: 4 [3013/3978 (76%)]\tLoss: 0.100441\n",
            "Train Epoch: 4 [3014/3978 (76%)]\tLoss: 0.082863\n",
            "Train Epoch: 4 [3015/3978 (76%)]\tLoss: 0.750299\n",
            "Train Epoch: 4 [3016/3978 (76%)]\tLoss: 0.080194\n",
            "Train Epoch: 4 [3017/3978 (76%)]\tLoss: 0.134380\n",
            "Train Epoch: 4 [3018/3978 (76%)]\tLoss: 0.054166\n",
            "Train Epoch: 4 [3019/3978 (76%)]\tLoss: 0.082700\n",
            "Train Epoch: 4 [3020/3978 (76%)]\tLoss: 0.083912\n",
            "Train Epoch: 4 [3021/3978 (76%)]\tLoss: 0.101521\n",
            "Train Epoch: 4 [3022/3978 (76%)]\tLoss: 0.083296\n",
            "Train Epoch: 4 [3023/3978 (76%)]\tLoss: 0.092487\n",
            "Train Epoch: 4 [3024/3978 (76%)]\tLoss: 0.131239\n",
            "Train Epoch: 4 [3025/3978 (76%)]\tLoss: 0.877213\n",
            "Train Epoch: 4 [3026/3978 (76%)]\tLoss: 0.061977\n",
            "Train Epoch: 4 [3027/3978 (76%)]\tLoss: 0.661449\n",
            "Train Epoch: 4 [3028/3978 (76%)]\tLoss: 0.066748\n",
            "Train Epoch: 4 [3029/3978 (76%)]\tLoss: 0.863118\n",
            "Train Epoch: 4 [3030/3978 (76%)]\tLoss: 0.069002\n",
            "Train Epoch: 4 [3031/3978 (76%)]\tLoss: 0.084513\n",
            "Train Epoch: 4 [3032/3978 (76%)]\tLoss: 0.060126\n",
            "Train Epoch: 4 [3033/3978 (76%)]\tLoss: 0.072573\n",
            "Train Epoch: 4 [3034/3978 (76%)]\tLoss: 0.072625\n",
            "Train Epoch: 4 [3035/3978 (76%)]\tLoss: 0.119964\n",
            "Train Epoch: 4 [3036/3978 (76%)]\tLoss: 0.119652\n",
            "Train Epoch: 4 [3037/3978 (76%)]\tLoss: 0.070557\n",
            "Train Epoch: 4 [3038/3978 (76%)]\tLoss: 0.064736\n",
            "Train Epoch: 4 [3039/3978 (76%)]\tLoss: 0.118029\n",
            "Train Epoch: 4 [3040/3978 (76%)]\tLoss: 0.064833\n",
            "Train Epoch: 4 [3041/3978 (76%)]\tLoss: 0.077865\n",
            "Train Epoch: 4 [3042/3978 (76%)]\tLoss: 0.062048\n",
            "Train Epoch: 4 [3043/3978 (76%)]\tLoss: 0.091749\n",
            "Train Epoch: 4 [3044/3978 (77%)]\tLoss: 0.502943\n",
            "Train Epoch: 4 [3045/3978 (77%)]\tLoss: 0.061360\n",
            "Train Epoch: 4 [3046/3978 (77%)]\tLoss: 0.890802\n",
            "Train Epoch: 4 [3047/3978 (77%)]\tLoss: 0.595804\n",
            "Train Epoch: 4 [3048/3978 (77%)]\tLoss: 0.557020\n",
            "Train Epoch: 4 [3049/3978 (77%)]\tLoss: 0.066853\n",
            "Train Epoch: 4 [3050/3978 (77%)]\tLoss: 0.108570\n",
            "Train Epoch: 4 [3051/3978 (77%)]\tLoss: 0.108990\n",
            "Train Epoch: 4 [3052/3978 (77%)]\tLoss: 0.077267\n",
            "Train Epoch: 4 [3053/3978 (77%)]\tLoss: 0.086585\n",
            "Train Epoch: 4 [3054/3978 (77%)]\tLoss: 0.053637\n",
            "Train Epoch: 4 [3055/3978 (77%)]\tLoss: 0.506050\n",
            "Train Epoch: 4 [3056/3978 (77%)]\tLoss: 0.101554\n",
            "Train Epoch: 4 [3057/3978 (77%)]\tLoss: 0.487454\n",
            "Train Epoch: 4 [3058/3978 (77%)]\tLoss: 0.069357\n",
            "Train Epoch: 4 [3059/3978 (77%)]\tLoss: 0.072811\n",
            "Train Epoch: 4 [3060/3978 (77%)]\tLoss: 0.048167\n",
            "Train Epoch: 4 [3061/3978 (77%)]\tLoss: 0.137277\n",
            "Train Epoch: 4 [3062/3978 (77%)]\tLoss: 0.761133\n",
            "Train Epoch: 4 [3063/3978 (77%)]\tLoss: 0.973850\n",
            "Train Epoch: 4 [3064/3978 (77%)]\tLoss: 0.045623\n",
            "Train Epoch: 4 [3065/3978 (77%)]\tLoss: 0.054526\n",
            "Train Epoch: 4 [3066/3978 (77%)]\tLoss: 0.069501\n",
            "Train Epoch: 4 [3067/3978 (77%)]\tLoss: 0.535831\n",
            "Train Epoch: 4 [3068/3978 (77%)]\tLoss: 0.042655\n",
            "Train Epoch: 4 [3069/3978 (77%)]\tLoss: 0.118028\n",
            "Train Epoch: 4 [3070/3978 (77%)]\tLoss: 0.065989\n",
            "Train Epoch: 4 [3071/3978 (77%)]\tLoss: 0.062819\n",
            "Train Epoch: 4 [3072/3978 (77%)]\tLoss: 0.164743\n",
            "Train Epoch: 4 [3073/3978 (77%)]\tLoss: 0.089092\n",
            "Train Epoch: 4 [3074/3978 (77%)]\tLoss: 0.086707\n",
            "Train Epoch: 4 [3075/3978 (77%)]\tLoss: 0.207883\n",
            "Train Epoch: 4 [3076/3978 (77%)]\tLoss: 0.047577\n",
            "Train Epoch: 4 [3077/3978 (77%)]\tLoss: 0.048556\n",
            "Train Epoch: 4 [3078/3978 (77%)]\tLoss: 0.170540\n",
            "Train Epoch: 4 [3079/3978 (77%)]\tLoss: 0.055958\n",
            "Train Epoch: 4 [3080/3978 (77%)]\tLoss: 0.080371\n",
            "Train Epoch: 4 [3081/3978 (77%)]\tLoss: 0.130322\n",
            "Train Epoch: 4 [3082/3978 (77%)]\tLoss: 0.207504\n",
            "Train Epoch: 4 [3083/3978 (78%)]\tLoss: 0.169379\n",
            "Train Epoch: 4 [3084/3978 (78%)]\tLoss: 0.738208\n",
            "Train Epoch: 4 [3085/3978 (78%)]\tLoss: 0.067150\n",
            "Train Epoch: 4 [3086/3978 (78%)]\tLoss: 0.082579\n",
            "Train Epoch: 4 [3087/3978 (78%)]\tLoss: 0.081847\n",
            "Train Epoch: 4 [3088/3978 (78%)]\tLoss: 0.130276\n",
            "Train Epoch: 4 [3089/3978 (78%)]\tLoss: 0.080236\n",
            "Train Epoch: 4 [3090/3978 (78%)]\tLoss: 1.069343\n",
            "Train Epoch: 4 [3091/3978 (78%)]\tLoss: 0.038357\n",
            "Train Epoch: 4 [3092/3978 (78%)]\tLoss: 0.045433\n",
            "Train Epoch: 4 [3093/3978 (78%)]\tLoss: 0.131980\n",
            "Train Epoch: 4 [3094/3978 (78%)]\tLoss: 0.179077\n",
            "Train Epoch: 4 [3095/3978 (78%)]\tLoss: 0.078752\n",
            "Train Epoch: 4 [3096/3978 (78%)]\tLoss: 0.058990\n",
            "Train Epoch: 4 [3097/3978 (78%)]\tLoss: 0.173678\n",
            "Train Epoch: 4 [3098/3978 (78%)]\tLoss: 0.112177\n",
            "Train Epoch: 4 [3099/3978 (78%)]\tLoss: 0.039519\n",
            "Train Epoch: 4 [3100/3978 (78%)]\tLoss: 0.079227\n",
            "Train Epoch: 4 [3101/3978 (78%)]\tLoss: 0.064434\n",
            "Train Epoch: 4 [3102/3978 (78%)]\tLoss: 0.043935\n",
            "Train Epoch: 4 [3103/3978 (78%)]\tLoss: 0.137344\n",
            "Train Epoch: 4 [3104/3978 (78%)]\tLoss: 0.059742\n",
            "Train Epoch: 4 [3105/3978 (78%)]\tLoss: 0.077110\n",
            "Train Epoch: 4 [3106/3978 (78%)]\tLoss: 0.036948\n",
            "Train Epoch: 4 [3107/3978 (78%)]\tLoss: 0.051519\n",
            "Train Epoch: 4 [3108/3978 (78%)]\tLoss: 0.840171\n",
            "Train Epoch: 4 [3109/3978 (78%)]\tLoss: 0.121717\n",
            "Train Epoch: 4 [3110/3978 (78%)]\tLoss: 0.034915\n",
            "Train Epoch: 4 [3111/3978 (78%)]\tLoss: 0.097863\n",
            "Train Epoch: 4 [3112/3978 (78%)]\tLoss: 0.094689\n",
            "Train Epoch: 4 [3113/3978 (78%)]\tLoss: 0.160185\n",
            "Train Epoch: 4 [3114/3978 (78%)]\tLoss: 0.069496\n",
            "Train Epoch: 4 [3115/3978 (78%)]\tLoss: 0.093701\n",
            "Train Epoch: 4 [3116/3978 (78%)]\tLoss: 0.129540\n",
            "Train Epoch: 4 [3117/3978 (78%)]\tLoss: 0.572322\n",
            "Train Epoch: 4 [3118/3978 (78%)]\tLoss: 0.843577\n",
            "Train Epoch: 4 [3119/3978 (78%)]\tLoss: 0.082852\n",
            "Train Epoch: 4 [3120/3978 (78%)]\tLoss: 0.125310\n",
            "Train Epoch: 4 [3121/3978 (78%)]\tLoss: 0.087872\n",
            "Train Epoch: 4 [3122/3978 (78%)]\tLoss: 0.112537\n",
            "Train Epoch: 4 [3123/3978 (79%)]\tLoss: 0.064829\n",
            "Train Epoch: 4 [3124/3978 (79%)]\tLoss: 0.073029\n",
            "Train Epoch: 4 [3125/3978 (79%)]\tLoss: 0.082074\n",
            "Train Epoch: 4 [3126/3978 (79%)]\tLoss: 0.120161\n",
            "Train Epoch: 4 [3127/3978 (79%)]\tLoss: 0.056273\n",
            "Train Epoch: 4 [3128/3978 (79%)]\tLoss: 0.099153\n",
            "Train Epoch: 4 [3129/3978 (79%)]\tLoss: 0.105029\n",
            "Train Epoch: 4 [3130/3978 (79%)]\tLoss: 0.055034\n",
            "Train Epoch: 4 [3131/3978 (79%)]\tLoss: 0.824987\n",
            "Train Epoch: 4 [3132/3978 (79%)]\tLoss: 0.070243\n",
            "Train Epoch: 4 [3133/3978 (79%)]\tLoss: 0.055791\n",
            "Train Epoch: 4 [3134/3978 (79%)]\tLoss: 0.056770\n",
            "Train Epoch: 4 [3135/3978 (79%)]\tLoss: 0.057109\n",
            "Train Epoch: 4 [3136/3978 (79%)]\tLoss: 0.054210\n",
            "Train Epoch: 4 [3137/3978 (79%)]\tLoss: 0.096725\n",
            "Train Epoch: 4 [3138/3978 (79%)]\tLoss: 0.087460\n",
            "Train Epoch: 4 [3139/3978 (79%)]\tLoss: 0.065022\n",
            "Train Epoch: 4 [3140/3978 (79%)]\tLoss: 0.097335\n",
            "Train Epoch: 4 [3141/3978 (79%)]\tLoss: 0.049101\n",
            "Train Epoch: 4 [3142/3978 (79%)]\tLoss: 0.050347\n",
            "Train Epoch: 4 [3143/3978 (79%)]\tLoss: 0.708321\n",
            "Train Epoch: 4 [3144/3978 (79%)]\tLoss: 0.112540\n",
            "Train Epoch: 4 [3145/3978 (79%)]\tLoss: 0.050162\n",
            "Train Epoch: 4 [3146/3978 (79%)]\tLoss: 0.088890\n",
            "Train Epoch: 4 [3147/3978 (79%)]\tLoss: 0.079042\n",
            "Train Epoch: 4 [3148/3978 (79%)]\tLoss: 0.067658\n",
            "Train Epoch: 4 [3149/3978 (79%)]\tLoss: 0.104674\n",
            "Train Epoch: 4 [3150/3978 (79%)]\tLoss: 0.045218\n",
            "Train Epoch: 4 [3151/3978 (79%)]\tLoss: 0.602721\n",
            "Train Epoch: 4 [3152/3978 (79%)]\tLoss: 0.095040\n",
            "Train Epoch: 4 [3153/3978 (79%)]\tLoss: 0.117772\n",
            "Train Epoch: 4 [3154/3978 (79%)]\tLoss: 0.089258\n",
            "Train Epoch: 4 [3155/3978 (79%)]\tLoss: 0.072718\n",
            "Train Epoch: 4 [3156/3978 (79%)]\tLoss: 0.081876\n",
            "Train Epoch: 4 [3157/3978 (79%)]\tLoss: 0.089284\n",
            "Train Epoch: 4 [3158/3978 (79%)]\tLoss: 0.045614\n",
            "Train Epoch: 4 [3159/3978 (79%)]\tLoss: 0.118039\n",
            "Train Epoch: 4 [3160/3978 (79%)]\tLoss: 0.077315\n",
            "Train Epoch: 4 [3161/3978 (79%)]\tLoss: 0.060740\n",
            "Train Epoch: 4 [3162/3978 (79%)]\tLoss: 0.076017\n",
            "Train Epoch: 4 [3163/3978 (80%)]\tLoss: 0.065298\n",
            "Train Epoch: 4 [3164/3978 (80%)]\tLoss: 0.110721\n",
            "Train Epoch: 4 [3165/3978 (80%)]\tLoss: 0.063756\n",
            "Train Epoch: 4 [3166/3978 (80%)]\tLoss: 0.064882\n",
            "Train Epoch: 4 [3167/3978 (80%)]\tLoss: 0.039613\n",
            "Train Epoch: 4 [3168/3978 (80%)]\tLoss: 0.078203\n",
            "Train Epoch: 4 [3169/3978 (80%)]\tLoss: 0.128918\n",
            "Train Epoch: 4 [3170/3978 (80%)]\tLoss: 0.080809\n",
            "Train Epoch: 4 [3171/3978 (80%)]\tLoss: 1.329028\n",
            "Train Epoch: 4 [3172/3978 (80%)]\tLoss: 0.047628\n",
            "Train Epoch: 4 [3173/3978 (80%)]\tLoss: 0.938608\n",
            "Train Epoch: 4 [3174/3978 (80%)]\tLoss: 0.109240\n",
            "Train Epoch: 4 [3175/3978 (80%)]\tLoss: 0.114292\n",
            "Train Epoch: 4 [3176/3978 (80%)]\tLoss: 0.039510\n",
            "Train Epoch: 4 [3177/3978 (80%)]\tLoss: 0.069041\n",
            "Train Epoch: 4 [3178/3978 (80%)]\tLoss: 0.062576\n",
            "Train Epoch: 4 [3179/3978 (80%)]\tLoss: 0.066470\n",
            "Train Epoch: 4 [3180/3978 (80%)]\tLoss: 0.045014\n",
            "Train Epoch: 4 [3181/3978 (80%)]\tLoss: 0.043539\n",
            "Train Epoch: 4 [3182/3978 (80%)]\tLoss: 0.044321\n",
            "Train Epoch: 4 [3183/3978 (80%)]\tLoss: 0.066434\n",
            "Train Epoch: 4 [3184/3978 (80%)]\tLoss: 0.766398\n",
            "Train Epoch: 4 [3185/3978 (80%)]\tLoss: 0.055260\n",
            "Train Epoch: 4 [3186/3978 (80%)]\tLoss: 0.085261\n",
            "Train Epoch: 4 [3187/3978 (80%)]\tLoss: 0.062639\n",
            "Train Epoch: 4 [3188/3978 (80%)]\tLoss: 0.045092\n",
            "Train Epoch: 4 [3189/3978 (80%)]\tLoss: 0.064034\n",
            "Train Epoch: 4 [3190/3978 (80%)]\tLoss: 0.065874\n",
            "Train Epoch: 4 [3191/3978 (80%)]\tLoss: 0.048910\n",
            "Train Epoch: 4 [3192/3978 (80%)]\tLoss: 0.056573\n",
            "Train Epoch: 4 [3193/3978 (80%)]\tLoss: 0.606137\n",
            "Train Epoch: 4 [3194/3978 (80%)]\tLoss: 0.085646\n",
            "Train Epoch: 4 [3195/3978 (80%)]\tLoss: 0.070400\n",
            "Train Epoch: 4 [3196/3978 (80%)]\tLoss: 0.952953\n",
            "Train Epoch: 4 [3197/3978 (80%)]\tLoss: 0.092032\n",
            "Train Epoch: 4 [3198/3978 (80%)]\tLoss: 0.060536\n",
            "Train Epoch: 4 [3199/3978 (80%)]\tLoss: 0.076078\n",
            "Train Epoch: 4 [3200/3978 (80%)]\tLoss: 0.066430\n",
            "Train Epoch: 4 [3201/3978 (80%)]\tLoss: 0.090348\n",
            "Train Epoch: 4 [3202/3978 (80%)]\tLoss: 0.046470\n",
            "Train Epoch: 4 [3203/3978 (81%)]\tLoss: 0.045366\n",
            "Train Epoch: 4 [3204/3978 (81%)]\tLoss: 0.890082\n",
            "Train Epoch: 4 [3205/3978 (81%)]\tLoss: 0.072922\n",
            "Train Epoch: 4 [3206/3978 (81%)]\tLoss: 0.069187\n",
            "Train Epoch: 4 [3207/3978 (81%)]\tLoss: 0.680046\n",
            "Train Epoch: 4 [3208/3978 (81%)]\tLoss: 0.043876\n",
            "Train Epoch: 4 [3209/3978 (81%)]\tLoss: 0.082624\n",
            "Train Epoch: 4 [3210/3978 (81%)]\tLoss: 0.768067\n",
            "Train Epoch: 4 [3211/3978 (81%)]\tLoss: 0.107541\n",
            "Train Epoch: 4 [3212/3978 (81%)]\tLoss: 0.705783\n",
            "Train Epoch: 4 [3213/3978 (81%)]\tLoss: 0.045576\n",
            "Train Epoch: 4 [3214/3978 (81%)]\tLoss: 0.047017\n",
            "Train Epoch: 4 [3215/3978 (81%)]\tLoss: 0.071500\n",
            "Train Epoch: 4 [3216/3978 (81%)]\tLoss: 0.077421\n",
            "Train Epoch: 4 [3217/3978 (81%)]\tLoss: 0.047308\n",
            "Train Epoch: 4 [3218/3978 (81%)]\tLoss: 0.101145\n",
            "Train Epoch: 4 [3219/3978 (81%)]\tLoss: 0.049231\n",
            "Train Epoch: 4 [3220/3978 (81%)]\tLoss: 0.110907\n",
            "Train Epoch: 4 [3221/3978 (81%)]\tLoss: 0.061320\n",
            "Train Epoch: 4 [3222/3978 (81%)]\tLoss: 0.073459\n",
            "Train Epoch: 4 [3223/3978 (81%)]\tLoss: 0.071873\n",
            "Train Epoch: 4 [3224/3978 (81%)]\tLoss: 0.049441\n",
            "Train Epoch: 4 [3225/3978 (81%)]\tLoss: 0.050882\n",
            "Train Epoch: 4 [3226/3978 (81%)]\tLoss: 0.855954\n",
            "Train Epoch: 4 [3227/3978 (81%)]\tLoss: 0.114247\n",
            "Train Epoch: 4 [3228/3978 (81%)]\tLoss: 0.069973\n",
            "Train Epoch: 4 [3229/3978 (81%)]\tLoss: 0.105363\n",
            "Train Epoch: 4 [3230/3978 (81%)]\tLoss: 0.103964\n",
            "Train Epoch: 4 [3231/3978 (81%)]\tLoss: 0.073561\n",
            "Train Epoch: 4 [3232/3978 (81%)]\tLoss: 0.875527\n",
            "Train Epoch: 4 [3233/3978 (81%)]\tLoss: 0.065560\n",
            "Train Epoch: 4 [3234/3978 (81%)]\tLoss: 0.070551\n",
            "Train Epoch: 4 [3235/3978 (81%)]\tLoss: 0.090706\n",
            "Train Epoch: 4 [3236/3978 (81%)]\tLoss: 0.523432\n",
            "Train Epoch: 4 [3237/3978 (81%)]\tLoss: 0.096273\n",
            "Train Epoch: 4 [3238/3978 (81%)]\tLoss: 0.103355\n",
            "Train Epoch: 4 [3239/3978 (81%)]\tLoss: 0.810785\n",
            "Train Epoch: 4 [3240/3978 (81%)]\tLoss: 0.096675\n",
            "Train Epoch: 4 [3241/3978 (81%)]\tLoss: 0.078940\n",
            "Train Epoch: 4 [3242/3978 (81%)]\tLoss: 0.114389\n",
            "Train Epoch: 4 [3243/3978 (82%)]\tLoss: 0.092753\n",
            "Train Epoch: 4 [3244/3978 (82%)]\tLoss: 0.099360\n",
            "Train Epoch: 4 [3245/3978 (82%)]\tLoss: 0.147711\n",
            "Train Epoch: 4 [3246/3978 (82%)]\tLoss: 0.052621\n",
            "Train Epoch: 4 [3247/3978 (82%)]\tLoss: 0.145671\n",
            "Train Epoch: 4 [3248/3978 (82%)]\tLoss: 0.044683\n",
            "Train Epoch: 4 [3249/3978 (82%)]\tLoss: 0.068633\n",
            "Train Epoch: 4 [3250/3978 (82%)]\tLoss: 1.296325\n",
            "Train Epoch: 4 [3251/3978 (82%)]\tLoss: 0.041619\n",
            "Train Epoch: 4 [3252/3978 (82%)]\tLoss: 0.648873\n",
            "Train Epoch: 4 [3253/3978 (82%)]\tLoss: 0.580086\n",
            "Train Epoch: 4 [3254/3978 (82%)]\tLoss: 0.753858\n",
            "Train Epoch: 4 [3255/3978 (82%)]\tLoss: 0.130522\n",
            "Train Epoch: 4 [3256/3978 (82%)]\tLoss: 0.156372\n",
            "Train Epoch: 4 [3257/3978 (82%)]\tLoss: 0.041292\n",
            "Train Epoch: 4 [3258/3978 (82%)]\tLoss: 0.131909\n",
            "Train Epoch: 4 [3259/3978 (82%)]\tLoss: 0.148101\n",
            "Train Epoch: 4 [3260/3978 (82%)]\tLoss: 0.051391\n",
            "Train Epoch: 4 [3261/3978 (82%)]\tLoss: 1.274380\n",
            "Train Epoch: 4 [3262/3978 (82%)]\tLoss: 0.615786\n",
            "Train Epoch: 4 [3263/3978 (82%)]\tLoss: 1.138572\n",
            "Train Epoch: 4 [3264/3978 (82%)]\tLoss: 0.075937\n",
            "Train Epoch: 4 [3265/3978 (82%)]\tLoss: 0.081558\n",
            "Train Epoch: 4 [3266/3978 (82%)]\tLoss: 0.706351\n",
            "Train Epoch: 4 [3267/3978 (82%)]\tLoss: 0.689957\n",
            "Train Epoch: 4 [3268/3978 (82%)]\tLoss: 0.098345\n",
            "Train Epoch: 4 [3269/3978 (82%)]\tLoss: 0.103641\n",
            "Train Epoch: 4 [3270/3978 (82%)]\tLoss: 0.114911\n",
            "Train Epoch: 4 [3271/3978 (82%)]\tLoss: 0.084917\n",
            "Train Epoch: 4 [3272/3978 (82%)]\tLoss: 0.082469\n",
            "Train Epoch: 4 [3273/3978 (82%)]\tLoss: 0.673457\n",
            "Train Epoch: 4 [3274/3978 (82%)]\tLoss: 0.124862\n",
            "Train Epoch: 4 [3275/3978 (82%)]\tLoss: 0.760198\n",
            "Train Epoch: 4 [3276/3978 (82%)]\tLoss: 0.079184\n",
            "Train Epoch: 4 [3277/3978 (82%)]\tLoss: 0.067818\n",
            "Train Epoch: 4 [3278/3978 (82%)]\tLoss: 0.105446\n",
            "Train Epoch: 4 [3279/3978 (82%)]\tLoss: 0.109923\n",
            "Train Epoch: 4 [3280/3978 (82%)]\tLoss: 0.069413\n",
            "Train Epoch: 4 [3281/3978 (82%)]\tLoss: 0.472857\n",
            "Train Epoch: 4 [3282/3978 (83%)]\tLoss: 1.060671\n",
            "Train Epoch: 4 [3283/3978 (83%)]\tLoss: 0.086952\n",
            "Train Epoch: 4 [3284/3978 (83%)]\tLoss: 0.091021\n",
            "Train Epoch: 4 [3285/3978 (83%)]\tLoss: 0.073417\n",
            "Train Epoch: 4 [3286/3978 (83%)]\tLoss: 0.101553\n",
            "Train Epoch: 4 [3287/3978 (83%)]\tLoss: 0.066328\n",
            "Train Epoch: 4 [3288/3978 (83%)]\tLoss: 1.078250\n",
            "Train Epoch: 4 [3289/3978 (83%)]\tLoss: 0.091370\n",
            "Train Epoch: 4 [3290/3978 (83%)]\tLoss: 0.506506\n",
            "Train Epoch: 4 [3291/3978 (83%)]\tLoss: 0.062966\n",
            "Train Epoch: 4 [3292/3978 (83%)]\tLoss: 0.131361\n",
            "Train Epoch: 4 [3293/3978 (83%)]\tLoss: 0.100480\n",
            "Train Epoch: 4 [3294/3978 (83%)]\tLoss: 0.094670\n",
            "Train Epoch: 4 [3295/3978 (83%)]\tLoss: 0.989895\n",
            "Train Epoch: 4 [3296/3978 (83%)]\tLoss: 0.118532\n",
            "Train Epoch: 4 [3297/3978 (83%)]\tLoss: 0.836626\n",
            "Train Epoch: 4 [3298/3978 (83%)]\tLoss: 0.971255\n",
            "Train Epoch: 4 [3299/3978 (83%)]\tLoss: 0.135409\n",
            "Train Epoch: 4 [3300/3978 (83%)]\tLoss: 0.166689\n",
            "Train Epoch: 4 [3301/3978 (83%)]\tLoss: 0.943086\n",
            "Train Epoch: 4 [3302/3978 (83%)]\tLoss: 0.140406\n",
            "Train Epoch: 4 [3303/3978 (83%)]\tLoss: 0.110265\n",
            "Train Epoch: 4 [3304/3978 (83%)]\tLoss: 0.113977\n",
            "Train Epoch: 4 [3305/3978 (83%)]\tLoss: 0.143028\n",
            "Train Epoch: 4 [3306/3978 (83%)]\tLoss: 0.074337\n",
            "Train Epoch: 4 [3307/3978 (83%)]\tLoss: 0.075025\n",
            "Train Epoch: 4 [3308/3978 (83%)]\tLoss: 0.121717\n",
            "Train Epoch: 4 [3309/3978 (83%)]\tLoss: 0.498825\n",
            "Train Epoch: 4 [3310/3978 (83%)]\tLoss: 0.143030\n",
            "Train Epoch: 4 [3311/3978 (83%)]\tLoss: 0.119622\n",
            "Train Epoch: 4 [3312/3978 (83%)]\tLoss: 0.495023\n",
            "Train Epoch: 4 [3313/3978 (83%)]\tLoss: 0.088624\n",
            "Train Epoch: 4 [3314/3978 (83%)]\tLoss: 0.087977\n",
            "Train Epoch: 4 [3315/3978 (83%)]\tLoss: 0.508739\n",
            "Train Epoch: 4 [3316/3978 (83%)]\tLoss: 0.070102\n",
            "Train Epoch: 4 [3317/3978 (83%)]\tLoss: 0.079059\n",
            "Train Epoch: 4 [3318/3978 (83%)]\tLoss: 0.090260\n",
            "Train Epoch: 4 [3319/3978 (83%)]\tLoss: 0.122543\n",
            "Train Epoch: 4 [3320/3978 (83%)]\tLoss: 0.090814\n",
            "Train Epoch: 4 [3321/3978 (83%)]\tLoss: 1.036691\n",
            "Train Epoch: 4 [3322/3978 (84%)]\tLoss: 0.494769\n",
            "Train Epoch: 4 [3323/3978 (84%)]\tLoss: 0.141966\n",
            "Train Epoch: 4 [3324/3978 (84%)]\tLoss: 0.123554\n",
            "Train Epoch: 4 [3325/3978 (84%)]\tLoss: 0.143382\n",
            "Train Epoch: 4 [3326/3978 (84%)]\tLoss: 0.155463\n",
            "Train Epoch: 4 [3327/3978 (84%)]\tLoss: 0.135865\n",
            "Train Epoch: 4 [3328/3978 (84%)]\tLoss: 0.103654\n",
            "Train Epoch: 4 [3329/3978 (84%)]\tLoss: 0.099562\n",
            "Train Epoch: 4 [3330/3978 (84%)]\tLoss: 0.132449\n",
            "Train Epoch: 4 [3331/3978 (84%)]\tLoss: 0.102197\n",
            "Train Epoch: 4 [3332/3978 (84%)]\tLoss: 0.085518\n",
            "Train Epoch: 4 [3333/3978 (84%)]\tLoss: 0.102943\n",
            "Train Epoch: 4 [3334/3978 (84%)]\tLoss: 0.094407\n",
            "Train Epoch: 4 [3335/3978 (84%)]\tLoss: 0.604926\n",
            "Train Epoch: 4 [3336/3978 (84%)]\tLoss: 0.059405\n",
            "Train Epoch: 4 [3337/3978 (84%)]\tLoss: 0.130565\n",
            "Train Epoch: 4 [3338/3978 (84%)]\tLoss: 0.053366\n",
            "Train Epoch: 4 [3339/3978 (84%)]\tLoss: 1.058585\n",
            "Train Epoch: 4 [3340/3978 (84%)]\tLoss: 0.143046\n",
            "Train Epoch: 4 [3341/3978 (84%)]\tLoss: 0.049670\n",
            "Train Epoch: 4 [3342/3978 (84%)]\tLoss: 0.574930\n",
            "Train Epoch: 4 [3343/3978 (84%)]\tLoss: 0.106210\n",
            "Train Epoch: 4 [3344/3978 (84%)]\tLoss: 0.075926\n",
            "Train Epoch: 4 [3345/3978 (84%)]\tLoss: 0.148062\n",
            "Train Epoch: 4 [3346/3978 (84%)]\tLoss: 0.076901\n",
            "Train Epoch: 4 [3347/3978 (84%)]\tLoss: 0.627324\n",
            "Train Epoch: 4 [3348/3978 (84%)]\tLoss: 0.128054\n",
            "Train Epoch: 4 [3349/3978 (84%)]\tLoss: 0.053422\n",
            "Train Epoch: 4 [3350/3978 (84%)]\tLoss: 0.156848\n",
            "Train Epoch: 4 [3351/3978 (84%)]\tLoss: 0.053651\n",
            "Train Epoch: 4 [3352/3978 (84%)]\tLoss: 0.107915\n",
            "Train Epoch: 4 [3353/3978 (84%)]\tLoss: 0.865646\n",
            "Train Epoch: 4 [3354/3978 (84%)]\tLoss: 0.101825\n",
            "Train Epoch: 4 [3355/3978 (84%)]\tLoss: 0.102051\n",
            "Train Epoch: 4 [3356/3978 (84%)]\tLoss: 0.064131\n",
            "Train Epoch: 4 [3357/3978 (84%)]\tLoss: 0.063072\n",
            "Train Epoch: 4 [3358/3978 (84%)]\tLoss: 0.056004\n",
            "Train Epoch: 4 [3359/3978 (84%)]\tLoss: 0.166959\n",
            "Train Epoch: 4 [3360/3978 (84%)]\tLoss: 0.134409\n",
            "Train Epoch: 4 [3361/3978 (84%)]\tLoss: 0.094355\n",
            "Train Epoch: 4 [3362/3978 (85%)]\tLoss: 0.106063\n",
            "Train Epoch: 4 [3363/3978 (85%)]\tLoss: 0.083931\n",
            "Train Epoch: 4 [3364/3978 (85%)]\tLoss: 0.085662\n",
            "Train Epoch: 4 [3365/3978 (85%)]\tLoss: 0.108784\n",
            "Train Epoch: 4 [3366/3978 (85%)]\tLoss: 0.110853\n",
            "Train Epoch: 4 [3367/3978 (85%)]\tLoss: 0.129061\n",
            "Train Epoch: 4 [3368/3978 (85%)]\tLoss: 0.068418\n",
            "Train Epoch: 4 [3369/3978 (85%)]\tLoss: 0.846929\n",
            "Train Epoch: 4 [3370/3978 (85%)]\tLoss: 1.044634\n",
            "Train Epoch: 4 [3371/3978 (85%)]\tLoss: 0.596435\n",
            "Train Epoch: 4 [3372/3978 (85%)]\tLoss: 0.139645\n",
            "Train Epoch: 4 [3373/3978 (85%)]\tLoss: 0.062309\n",
            "Train Epoch: 4 [3374/3978 (85%)]\tLoss: 0.085401\n",
            "Train Epoch: 4 [3375/3978 (85%)]\tLoss: 0.121530\n",
            "Train Epoch: 4 [3376/3978 (85%)]\tLoss: 0.090948\n",
            "Train Epoch: 4 [3377/3978 (85%)]\tLoss: 0.553168\n",
            "Train Epoch: 4 [3378/3978 (85%)]\tLoss: 0.100936\n",
            "Train Epoch: 4 [3379/3978 (85%)]\tLoss: 0.134939\n",
            "Train Epoch: 4 [3380/3978 (85%)]\tLoss: 0.082242\n",
            "Train Epoch: 4 [3381/3978 (85%)]\tLoss: 0.113788\n",
            "Train Epoch: 4 [3382/3978 (85%)]\tLoss: 0.086583\n",
            "Train Epoch: 4 [3383/3978 (85%)]\tLoss: 0.089224\n",
            "Train Epoch: 4 [3384/3978 (85%)]\tLoss: 0.078646\n",
            "Train Epoch: 4 [3385/3978 (85%)]\tLoss: 0.082225\n",
            "Train Epoch: 4 [3386/3978 (85%)]\tLoss: 0.114834\n",
            "Train Epoch: 4 [3387/3978 (85%)]\tLoss: 0.107569\n",
            "Train Epoch: 4 [3388/3978 (85%)]\tLoss: 0.093277\n",
            "Train Epoch: 4 [3389/3978 (85%)]\tLoss: 0.081024\n",
            "Train Epoch: 4 [3390/3978 (85%)]\tLoss: 0.089175\n",
            "Train Epoch: 4 [3391/3978 (85%)]\tLoss: 0.073175\n",
            "Train Epoch: 4 [3392/3978 (85%)]\tLoss: 0.090800\n",
            "Train Epoch: 4 [3393/3978 (85%)]\tLoss: 0.592266\n",
            "Train Epoch: 4 [3394/3978 (85%)]\tLoss: 0.058057\n",
            "Train Epoch: 4 [3395/3978 (85%)]\tLoss: 0.068887\n",
            "Train Epoch: 4 [3396/3978 (85%)]\tLoss: 0.086040\n",
            "Train Epoch: 4 [3397/3978 (85%)]\tLoss: 0.053619\n",
            "Train Epoch: 4 [3398/3978 (85%)]\tLoss: 0.052843\n",
            "Train Epoch: 4 [3399/3978 (85%)]\tLoss: 0.091265\n",
            "Train Epoch: 4 [3400/3978 (85%)]\tLoss: 0.080320\n",
            "Train Epoch: 4 [3401/3978 (85%)]\tLoss: 0.049794\n",
            "Train Epoch: 4 [3402/3978 (86%)]\tLoss: 1.085645\n",
            "Train Epoch: 4 [3403/3978 (86%)]\tLoss: 0.075427\n",
            "Train Epoch: 4 [3404/3978 (86%)]\tLoss: 0.578222\n",
            "Train Epoch: 4 [3405/3978 (86%)]\tLoss: 0.058596\n",
            "Train Epoch: 4 [3406/3978 (86%)]\tLoss: 0.828684\n",
            "Train Epoch: 4 [3407/3978 (86%)]\tLoss: 0.088616\n",
            "Train Epoch: 4 [3408/3978 (86%)]\tLoss: 0.154261\n",
            "Train Epoch: 4 [3409/3978 (86%)]\tLoss: 0.107912\n",
            "Train Epoch: 4 [3410/3978 (86%)]\tLoss: 0.093961\n",
            "Train Epoch: 4 [3411/3978 (86%)]\tLoss: 0.687603\n",
            "Train Epoch: 4 [3412/3978 (86%)]\tLoss: 0.082686\n",
            "Train Epoch: 4 [3413/3978 (86%)]\tLoss: 0.856729\n",
            "Train Epoch: 4 [3414/3978 (86%)]\tLoss: 0.050224\n",
            "Train Epoch: 4 [3415/3978 (86%)]\tLoss: 0.084728\n",
            "Train Epoch: 4 [3416/3978 (86%)]\tLoss: 0.486361\n",
            "Train Epoch: 4 [3417/3978 (86%)]\tLoss: 0.103563\n",
            "Train Epoch: 4 [3418/3978 (86%)]\tLoss: 0.785921\n",
            "Train Epoch: 4 [3419/3978 (86%)]\tLoss: 0.113333\n",
            "Train Epoch: 4 [3420/3978 (86%)]\tLoss: 0.806651\n",
            "Train Epoch: 4 [3421/3978 (86%)]\tLoss: 0.748674\n",
            "Train Epoch: 4 [3422/3978 (86%)]\tLoss: 0.059023\n",
            "Train Epoch: 4 [3423/3978 (86%)]\tLoss: 0.157318\n",
            "Train Epoch: 4 [3424/3978 (86%)]\tLoss: 0.057933\n",
            "Train Epoch: 4 [3425/3978 (86%)]\tLoss: 0.088181\n",
            "Train Epoch: 4 [3426/3978 (86%)]\tLoss: 0.081146\n",
            "Train Epoch: 4 [3427/3978 (86%)]\tLoss: 0.063299\n",
            "Train Epoch: 4 [3428/3978 (86%)]\tLoss: 0.080716\n",
            "Train Epoch: 4 [3429/3978 (86%)]\tLoss: 0.789532\n",
            "Train Epoch: 4 [3430/3978 (86%)]\tLoss: 0.064094\n",
            "Train Epoch: 4 [3431/3978 (86%)]\tLoss: 0.058481\n",
            "Train Epoch: 4 [3432/3978 (86%)]\tLoss: 0.083340\n",
            "Train Epoch: 4 [3433/3978 (86%)]\tLoss: 0.107322\n",
            "Train Epoch: 4 [3434/3978 (86%)]\tLoss: 0.114396\n",
            "Train Epoch: 4 [3435/3978 (86%)]\tLoss: 0.463425\n",
            "Train Epoch: 4 [3436/3978 (86%)]\tLoss: 0.099614\n",
            "Train Epoch: 4 [3437/3978 (86%)]\tLoss: 0.043085\n",
            "Train Epoch: 4 [3438/3978 (86%)]\tLoss: 0.118547\n",
            "Train Epoch: 4 [3439/3978 (86%)]\tLoss: 0.137524\n",
            "Train Epoch: 4 [3440/3978 (86%)]\tLoss: 0.155647\n",
            "Train Epoch: 4 [3441/3978 (87%)]\tLoss: 0.132296\n",
            "Train Epoch: 4 [3442/3978 (87%)]\tLoss: 0.557467\n",
            "Train Epoch: 4 [3443/3978 (87%)]\tLoss: 0.064129\n",
            "Train Epoch: 4 [3444/3978 (87%)]\tLoss: 0.553299\n",
            "Train Epoch: 4 [3445/3978 (87%)]\tLoss: 0.049414\n",
            "Train Epoch: 4 [3446/3978 (87%)]\tLoss: 0.447277\n",
            "Train Epoch: 4 [3447/3978 (87%)]\tLoss: 0.130081\n",
            "Train Epoch: 4 [3448/3978 (87%)]\tLoss: 0.105365\n",
            "Train Epoch: 4 [3449/3978 (87%)]\tLoss: 0.111692\n",
            "Train Epoch: 4 [3450/3978 (87%)]\tLoss: 0.726135\n",
            "Train Epoch: 4 [3451/3978 (87%)]\tLoss: 1.059228\n",
            "Train Epoch: 4 [3452/3978 (87%)]\tLoss: 0.096698\n",
            "Train Epoch: 4 [3453/3978 (87%)]\tLoss: 0.101556\n",
            "Train Epoch: 4 [3454/3978 (87%)]\tLoss: 0.628762\n",
            "Train Epoch: 4 [3455/3978 (87%)]\tLoss: 0.062719\n",
            "Train Epoch: 4 [3456/3978 (87%)]\tLoss: 0.096915\n",
            "Train Epoch: 4 [3457/3978 (87%)]\tLoss: 0.069786\n",
            "Train Epoch: 4 [3458/3978 (87%)]\tLoss: 0.087156\n",
            "Train Epoch: 4 [3459/3978 (87%)]\tLoss: 0.422265\n",
            "Train Epoch: 4 [3460/3978 (87%)]\tLoss: 0.073853\n",
            "Train Epoch: 4 [3461/3978 (87%)]\tLoss: 0.141519\n",
            "Train Epoch: 4 [3462/3978 (87%)]\tLoss: 0.085721\n",
            "Train Epoch: 4 [3463/3978 (87%)]\tLoss: 0.507956\n",
            "Train Epoch: 4 [3464/3978 (87%)]\tLoss: 0.074475\n",
            "Train Epoch: 4 [3465/3978 (87%)]\tLoss: 0.143916\n",
            "Train Epoch: 4 [3466/3978 (87%)]\tLoss: 0.618475\n",
            "Train Epoch: 4 [3467/3978 (87%)]\tLoss: 0.110122\n",
            "Train Epoch: 4 [3468/3978 (87%)]\tLoss: 0.074017\n",
            "Train Epoch: 4 [3469/3978 (87%)]\tLoss: 0.113736\n",
            "Train Epoch: 4 [3470/3978 (87%)]\tLoss: 0.086129\n",
            "Train Epoch: 4 [3471/3978 (87%)]\tLoss: 0.168026\n",
            "Train Epoch: 4 [3472/3978 (87%)]\tLoss: 0.578669\n",
            "Train Epoch: 4 [3473/3978 (87%)]\tLoss: 0.092045\n",
            "Train Epoch: 4 [3474/3978 (87%)]\tLoss: 0.484466\n",
            "Train Epoch: 4 [3475/3978 (87%)]\tLoss: 0.677472\n",
            "Train Epoch: 4 [3476/3978 (87%)]\tLoss: 0.761876\n",
            "Train Epoch: 4 [3477/3978 (87%)]\tLoss: 0.117945\n",
            "Train Epoch: 4 [3478/3978 (87%)]\tLoss: 0.104766\n",
            "Train Epoch: 4 [3479/3978 (87%)]\tLoss: 0.115589\n",
            "Train Epoch: 4 [3480/3978 (87%)]\tLoss: 0.107327\n",
            "Train Epoch: 4 [3481/3978 (88%)]\tLoss: 0.171154\n",
            "Train Epoch: 4 [3482/3978 (88%)]\tLoss: 0.136750\n",
            "Train Epoch: 4 [3483/3978 (88%)]\tLoss: 0.122921\n",
            "Train Epoch: 4 [3484/3978 (88%)]\tLoss: 0.162783\n",
            "Train Epoch: 4 [3485/3978 (88%)]\tLoss: 0.161108\n",
            "Train Epoch: 4 [3486/3978 (88%)]\tLoss: 0.092149\n",
            "Train Epoch: 4 [3487/3978 (88%)]\tLoss: 0.108615\n",
            "Train Epoch: 4 [3488/3978 (88%)]\tLoss: 1.139277\n",
            "Train Epoch: 4 [3489/3978 (88%)]\tLoss: 0.097060\n",
            "Train Epoch: 4 [3490/3978 (88%)]\tLoss: 0.124804\n",
            "Train Epoch: 4 [3491/3978 (88%)]\tLoss: 0.160774\n",
            "Train Epoch: 4 [3492/3978 (88%)]\tLoss: 0.092097\n",
            "Train Epoch: 4 [3493/3978 (88%)]\tLoss: 0.445090\n",
            "Train Epoch: 4 [3494/3978 (88%)]\tLoss: 0.067355\n",
            "Train Epoch: 4 [3495/3978 (88%)]\tLoss: 0.066881\n",
            "Train Epoch: 4 [3496/3978 (88%)]\tLoss: 0.167185\n",
            "Train Epoch: 4 [3497/3978 (88%)]\tLoss: 0.685560\n",
            "Train Epoch: 4 [3498/3978 (88%)]\tLoss: 0.095700\n",
            "Train Epoch: 4 [3499/3978 (88%)]\tLoss: 0.093997\n",
            "Train Epoch: 4 [3500/3978 (88%)]\tLoss: 0.093263\n",
            "Train Epoch: 4 [3501/3978 (88%)]\tLoss: 0.155158\n",
            "Train Epoch: 4 [3502/3978 (88%)]\tLoss: 0.736503\n",
            "Train Epoch: 4 [3503/3978 (88%)]\tLoss: 0.066827\n",
            "Train Epoch: 4 [3504/3978 (88%)]\tLoss: 0.070235\n",
            "Train Epoch: 4 [3505/3978 (88%)]\tLoss: 0.111926\n",
            "Train Epoch: 4 [3506/3978 (88%)]\tLoss: 0.080477\n",
            "Train Epoch: 4 [3507/3978 (88%)]\tLoss: 0.103736\n",
            "Train Epoch: 4 [3508/3978 (88%)]\tLoss: 0.477559\n",
            "Train Epoch: 4 [3509/3978 (88%)]\tLoss: 0.067781\n",
            "Train Epoch: 4 [3510/3978 (88%)]\tLoss: 0.095891\n",
            "Train Epoch: 4 [3511/3978 (88%)]\tLoss: 0.082178\n",
            "Train Epoch: 4 [3512/3978 (88%)]\tLoss: 0.096688\n",
            "Train Epoch: 4 [3513/3978 (88%)]\tLoss: 0.086810\n",
            "Train Epoch: 4 [3514/3978 (88%)]\tLoss: 0.462713\n",
            "Train Epoch: 4 [3515/3978 (88%)]\tLoss: 0.784296\n",
            "Train Epoch: 4 [3516/3978 (88%)]\tLoss: 0.123852\n",
            "Train Epoch: 4 [3517/3978 (88%)]\tLoss: 0.088465\n",
            "Train Epoch: 4 [3518/3978 (88%)]\tLoss: 0.107890\n",
            "Train Epoch: 4 [3519/3978 (88%)]\tLoss: 0.100775\n",
            "Train Epoch: 4 [3520/3978 (88%)]\tLoss: 0.097025\n",
            "Train Epoch: 4 [3521/3978 (89%)]\tLoss: 0.094702\n",
            "Train Epoch: 4 [3522/3978 (89%)]\tLoss: 0.078914\n",
            "Train Epoch: 4 [3523/3978 (89%)]\tLoss: 0.077525\n",
            "Train Epoch: 4 [3524/3978 (89%)]\tLoss: 0.106679\n",
            "Train Epoch: 4 [3525/3978 (89%)]\tLoss: 0.567133\n",
            "Train Epoch: 4 [3526/3978 (89%)]\tLoss: 0.136168\n",
            "Train Epoch: 4 [3527/3978 (89%)]\tLoss: 0.051857\n",
            "Train Epoch: 4 [3528/3978 (89%)]\tLoss: 0.187606\n",
            "Train Epoch: 4 [3529/3978 (89%)]\tLoss: 0.643376\n",
            "Train Epoch: 4 [3530/3978 (89%)]\tLoss: 0.073261\n",
            "Train Epoch: 4 [3531/3978 (89%)]\tLoss: 0.108343\n",
            "Train Epoch: 4 [3532/3978 (89%)]\tLoss: 0.055373\n",
            "Train Epoch: 4 [3533/3978 (89%)]\tLoss: 1.147235\n",
            "Train Epoch: 4 [3534/3978 (89%)]\tLoss: 0.762219\n",
            "Train Epoch: 4 [3535/3978 (89%)]\tLoss: 0.457047\n",
            "Train Epoch: 4 [3536/3978 (89%)]\tLoss: 0.119968\n",
            "Train Epoch: 4 [3537/3978 (89%)]\tLoss: 0.046077\n",
            "Train Epoch: 4 [3538/3978 (89%)]\tLoss: 0.114126\n",
            "Train Epoch: 4 [3539/3978 (89%)]\tLoss: 0.433005\n",
            "Train Epoch: 4 [3540/3978 (89%)]\tLoss: 0.066163\n",
            "Train Epoch: 4 [3541/3978 (89%)]\tLoss: 0.116674\n",
            "Train Epoch: 4 [3542/3978 (89%)]\tLoss: 0.154242\n",
            "Train Epoch: 4 [3543/3978 (89%)]\tLoss: 0.154351\n",
            "Train Epoch: 4 [3544/3978 (89%)]\tLoss: 0.102230\n",
            "Train Epoch: 4 [3545/3978 (89%)]\tLoss: 0.190681\n",
            "Train Epoch: 4 [3546/3978 (89%)]\tLoss: 0.057131\n",
            "Train Epoch: 4 [3547/3978 (89%)]\tLoss: 0.060200\n",
            "Train Epoch: 4 [3548/3978 (89%)]\tLoss: 0.138802\n",
            "Train Epoch: 4 [3549/3978 (89%)]\tLoss: 0.118171\n",
            "Train Epoch: 4 [3550/3978 (89%)]\tLoss: 0.068298\n",
            "Train Epoch: 4 [3551/3978 (89%)]\tLoss: 0.104378\n",
            "Train Epoch: 4 [3552/3978 (89%)]\tLoss: 0.068086\n",
            "Train Epoch: 4 [3553/3978 (89%)]\tLoss: 0.074134\n",
            "Train Epoch: 4 [3554/3978 (89%)]\tLoss: 0.087433\n",
            "Train Epoch: 4 [3555/3978 (89%)]\tLoss: 0.776200\n",
            "Train Epoch: 4 [3556/3978 (89%)]\tLoss: 0.100623\n",
            "Train Epoch: 4 [3557/3978 (89%)]\tLoss: 0.090150\n",
            "Train Epoch: 4 [3558/3978 (89%)]\tLoss: 0.077125\n",
            "Train Epoch: 4 [3559/3978 (89%)]\tLoss: 0.106590\n",
            "Train Epoch: 4 [3560/3978 (89%)]\tLoss: 0.079642\n",
            "Train Epoch: 4 [3561/3978 (90%)]\tLoss: 0.094774\n",
            "Train Epoch: 4 [3562/3978 (90%)]\tLoss: 0.148306\n",
            "Train Epoch: 4 [3563/3978 (90%)]\tLoss: 0.085037\n",
            "Train Epoch: 4 [3564/3978 (90%)]\tLoss: 0.084027\n",
            "Train Epoch: 4 [3565/3978 (90%)]\tLoss: 0.098488\n",
            "Train Epoch: 4 [3566/3978 (90%)]\tLoss: 0.070501\n",
            "Train Epoch: 4 [3567/3978 (90%)]\tLoss: 0.104076\n",
            "Train Epoch: 4 [3568/3978 (90%)]\tLoss: 0.101781\n",
            "Train Epoch: 4 [3569/3978 (90%)]\tLoss: 1.051976\n",
            "Train Epoch: 4 [3570/3978 (90%)]\tLoss: 0.067717\n",
            "Train Epoch: 4 [3571/3978 (90%)]\tLoss: 0.079517\n",
            "Train Epoch: 4 [3572/3978 (90%)]\tLoss: 0.586769\n",
            "Train Epoch: 4 [3573/3978 (90%)]\tLoss: 0.080252\n",
            "Train Epoch: 4 [3574/3978 (90%)]\tLoss: 0.081872\n",
            "Train Epoch: 4 [3575/3978 (90%)]\tLoss: 0.079190\n",
            "Train Epoch: 4 [3576/3978 (90%)]\tLoss: 0.075228\n",
            "Train Epoch: 4 [3577/3978 (90%)]\tLoss: 0.062448\n",
            "Train Epoch: 4 [3578/3978 (90%)]\tLoss: 0.117749\n",
            "Train Epoch: 4 [3579/3978 (90%)]\tLoss: 0.098711\n",
            "Train Epoch: 4 [3580/3978 (90%)]\tLoss: 0.077140\n",
            "Train Epoch: 4 [3581/3978 (90%)]\tLoss: 0.127515\n",
            "Train Epoch: 4 [3582/3978 (90%)]\tLoss: 0.108553\n",
            "Train Epoch: 4 [3583/3978 (90%)]\tLoss: 0.062251\n",
            "Train Epoch: 4 [3584/3978 (90%)]\tLoss: 0.063794\n",
            "Train Epoch: 4 [3585/3978 (90%)]\tLoss: 0.085995\n",
            "Train Epoch: 4 [3586/3978 (90%)]\tLoss: 0.083748\n",
            "Train Epoch: 4 [3587/3978 (90%)]\tLoss: 0.085502\n",
            "Train Epoch: 4 [3588/3978 (90%)]\tLoss: 0.067013\n",
            "Train Epoch: 4 [3589/3978 (90%)]\tLoss: 0.077202\n",
            "Train Epoch: 4 [3590/3978 (90%)]\tLoss: 0.074388\n",
            "Train Epoch: 4 [3591/3978 (90%)]\tLoss: 0.086013\n",
            "Train Epoch: 4 [3592/3978 (90%)]\tLoss: 0.076825\n",
            "Train Epoch: 4 [3593/3978 (90%)]\tLoss: 0.108348\n",
            "Train Epoch: 4 [3594/3978 (90%)]\tLoss: 0.067000\n",
            "Train Epoch: 4 [3595/3978 (90%)]\tLoss: 0.062702\n",
            "Train Epoch: 4 [3596/3978 (90%)]\tLoss: 0.100237\n",
            "Train Epoch: 4 [3597/3978 (90%)]\tLoss: 0.061318\n",
            "Train Epoch: 4 [3598/3978 (90%)]\tLoss: 0.063295\n",
            "Train Epoch: 4 [3599/3978 (90%)]\tLoss: 0.074344\n",
            "Train Epoch: 4 [3600/3978 (90%)]\tLoss: 0.072379\n",
            "Train Epoch: 4 [3601/3978 (91%)]\tLoss: 0.818963\n",
            "Train Epoch: 4 [3602/3978 (91%)]\tLoss: 0.076461\n",
            "Train Epoch: 4 [3603/3978 (91%)]\tLoss: 0.082345\n",
            "Train Epoch: 4 [3604/3978 (91%)]\tLoss: 0.055094\n",
            "Train Epoch: 4 [3605/3978 (91%)]\tLoss: 0.073787\n",
            "Train Epoch: 4 [3606/3978 (91%)]\tLoss: 0.064261\n",
            "Train Epoch: 4 [3607/3978 (91%)]\tLoss: 0.068047\n",
            "Train Epoch: 4 [3608/3978 (91%)]\tLoss: 0.092627\n",
            "Train Epoch: 4 [3609/3978 (91%)]\tLoss: 0.079927\n",
            "Train Epoch: 4 [3610/3978 (91%)]\tLoss: 0.055544\n",
            "Train Epoch: 4 [3611/3978 (91%)]\tLoss: 0.071346\n",
            "Train Epoch: 4 [3612/3978 (91%)]\tLoss: 0.079383\n",
            "Train Epoch: 4 [3613/3978 (91%)]\tLoss: 0.056404\n",
            "Train Epoch: 4 [3614/3978 (91%)]\tLoss: 0.043489\n",
            "Train Epoch: 4 [3615/3978 (91%)]\tLoss: 0.075547\n",
            "Train Epoch: 4 [3616/3978 (91%)]\tLoss: 0.067607\n",
            "Train Epoch: 4 [3617/3978 (91%)]\tLoss: 0.067342\n",
            "Train Epoch: 4 [3618/3978 (91%)]\tLoss: 0.111106\n",
            "Train Epoch: 4 [3619/3978 (91%)]\tLoss: 0.066374\n",
            "Train Epoch: 4 [3620/3978 (91%)]\tLoss: 1.197389\n",
            "Train Epoch: 4 [3621/3978 (91%)]\tLoss: 0.111540\n",
            "Train Epoch: 4 [3622/3978 (91%)]\tLoss: 0.040393\n",
            "Train Epoch: 4 [3623/3978 (91%)]\tLoss: 0.047877\n",
            "Train Epoch: 4 [3624/3978 (91%)]\tLoss: 0.848005\n",
            "Train Epoch: 4 [3625/3978 (91%)]\tLoss: 0.115898\n",
            "Train Epoch: 4 [3626/3978 (91%)]\tLoss: 0.038771\n",
            "Train Epoch: 4 [3627/3978 (91%)]\tLoss: 0.040123\n",
            "Train Epoch: 4 [3628/3978 (91%)]\tLoss: 0.077805\n",
            "Train Epoch: 4 [3629/3978 (91%)]\tLoss: 1.146813\n",
            "Train Epoch: 4 [3630/3978 (91%)]\tLoss: 0.112939\n",
            "Train Epoch: 4 [3631/3978 (91%)]\tLoss: 0.110860\n",
            "Train Epoch: 4 [3632/3978 (91%)]\tLoss: 0.041648\n",
            "Train Epoch: 4 [3633/3978 (91%)]\tLoss: 0.044016\n",
            "Train Epoch: 4 [3634/3978 (91%)]\tLoss: 0.060170\n",
            "Train Epoch: 4 [3635/3978 (91%)]\tLoss: 0.045443\n",
            "Train Epoch: 4 [3636/3978 (91%)]\tLoss: 0.063220\n",
            "Train Epoch: 4 [3637/3978 (91%)]\tLoss: 0.640970\n",
            "Train Epoch: 4 [3638/3978 (91%)]\tLoss: 0.075778\n",
            "Train Epoch: 4 [3639/3978 (91%)]\tLoss: 0.619839\n",
            "Train Epoch: 4 [3640/3978 (92%)]\tLoss: 0.054904\n",
            "Train Epoch: 4 [3641/3978 (92%)]\tLoss: 0.067495\n",
            "Train Epoch: 4 [3642/3978 (92%)]\tLoss: 0.061372\n",
            "Train Epoch: 4 [3643/3978 (92%)]\tLoss: 0.085985\n",
            "Train Epoch: 4 [3644/3978 (92%)]\tLoss: 0.078925\n",
            "Train Epoch: 4 [3645/3978 (92%)]\tLoss: 0.107709\n",
            "Train Epoch: 4 [3646/3978 (92%)]\tLoss: 0.081335\n",
            "Train Epoch: 4 [3647/3978 (92%)]\tLoss: 0.626249\n",
            "Train Epoch: 4 [3648/3978 (92%)]\tLoss: 0.119210\n",
            "Train Epoch: 4 [3649/3978 (92%)]\tLoss: 0.046347\n",
            "Train Epoch: 4 [3650/3978 (92%)]\tLoss: 0.053782\n",
            "Train Epoch: 4 [3651/3978 (92%)]\tLoss: 0.895574\n",
            "Train Epoch: 4 [3652/3978 (92%)]\tLoss: 1.018269\n",
            "Train Epoch: 4 [3653/3978 (92%)]\tLoss: 0.687915\n",
            "Train Epoch: 4 [3654/3978 (92%)]\tLoss: 0.058769\n",
            "Train Epoch: 4 [3655/3978 (92%)]\tLoss: 1.019536\n",
            "Train Epoch: 4 [3656/3978 (92%)]\tLoss: 0.100436\n",
            "Train Epoch: 4 [3657/3978 (92%)]\tLoss: 0.699066\n",
            "Train Epoch: 4 [3658/3978 (92%)]\tLoss: 0.131507\n",
            "Train Epoch: 4 [3659/3978 (92%)]\tLoss: 0.054955\n",
            "Train Epoch: 4 [3660/3978 (92%)]\tLoss: 0.054305\n",
            "Train Epoch: 4 [3661/3978 (92%)]\tLoss: 0.068506\n",
            "Train Epoch: 4 [3662/3978 (92%)]\tLoss: 0.635064\n",
            "Train Epoch: 4 [3663/3978 (92%)]\tLoss: 1.015011\n",
            "Train Epoch: 4 [3664/3978 (92%)]\tLoss: 0.114582\n",
            "Train Epoch: 4 [3665/3978 (92%)]\tLoss: 0.118132\n",
            "Train Epoch: 4 [3666/3978 (92%)]\tLoss: 0.614488\n",
            "Train Epoch: 4 [3667/3978 (92%)]\tLoss: 0.544186\n",
            "Train Epoch: 4 [3668/3978 (92%)]\tLoss: 0.145806\n",
            "Train Epoch: 4 [3669/3978 (92%)]\tLoss: 0.082916\n",
            "Train Epoch: 4 [3670/3978 (92%)]\tLoss: 0.644605\n",
            "Train Epoch: 4 [3671/3978 (92%)]\tLoss: 0.081357\n",
            "Train Epoch: 4 [3672/3978 (92%)]\tLoss: 0.148691\n",
            "Train Epoch: 4 [3673/3978 (92%)]\tLoss: 0.142065\n",
            "Train Epoch: 4 [3674/3978 (92%)]\tLoss: 0.140142\n",
            "Train Epoch: 4 [3675/3978 (92%)]\tLoss: 0.511785\n",
            "Train Epoch: 4 [3676/3978 (92%)]\tLoss: 0.102000\n",
            "Train Epoch: 4 [3677/3978 (92%)]\tLoss: 0.092888\n",
            "Train Epoch: 4 [3678/3978 (92%)]\tLoss: 0.938957\n",
            "Train Epoch: 4 [3679/3978 (92%)]\tLoss: 0.061169\n",
            "Train Epoch: 4 [3680/3978 (93%)]\tLoss: 0.509216\n",
            "Train Epoch: 4 [3681/3978 (93%)]\tLoss: 0.061509\n",
            "Train Epoch: 4 [3682/3978 (93%)]\tLoss: 0.125792\n",
            "Train Epoch: 4 [3683/3978 (93%)]\tLoss: 0.422674\n",
            "Train Epoch: 4 [3684/3978 (93%)]\tLoss: 0.629116\n",
            "Train Epoch: 4 [3685/3978 (93%)]\tLoss: 0.156236\n",
            "Train Epoch: 4 [3686/3978 (93%)]\tLoss: 0.480428\n",
            "Train Epoch: 4 [3687/3978 (93%)]\tLoss: 0.171801\n",
            "Train Epoch: 4 [3688/3978 (93%)]\tLoss: 0.130740\n",
            "Train Epoch: 4 [3689/3978 (93%)]\tLoss: 0.161873\n",
            "Train Epoch: 4 [3690/3978 (93%)]\tLoss: 0.687651\n",
            "Train Epoch: 4 [3691/3978 (93%)]\tLoss: 0.065393\n",
            "Train Epoch: 4 [3692/3978 (93%)]\tLoss: 0.124664\n",
            "Train Epoch: 4 [3693/3978 (93%)]\tLoss: 0.110255\n",
            "Train Epoch: 4 [3694/3978 (93%)]\tLoss: 0.066715\n",
            "Train Epoch: 4 [3695/3978 (93%)]\tLoss: 0.099894\n",
            "Train Epoch: 4 [3696/3978 (93%)]\tLoss: 0.098588\n",
            "Train Epoch: 4 [3697/3978 (93%)]\tLoss: 0.073218\n",
            "Train Epoch: 4 [3698/3978 (93%)]\tLoss: 0.653842\n",
            "Train Epoch: 4 [3699/3978 (93%)]\tLoss: 0.514342\n",
            "Train Epoch: 4 [3700/3978 (93%)]\tLoss: 0.109754\n",
            "Train Epoch: 4 [3701/3978 (93%)]\tLoss: 0.117588\n",
            "Train Epoch: 4 [3702/3978 (93%)]\tLoss: 1.111168\n",
            "Train Epoch: 4 [3703/3978 (93%)]\tLoss: 0.092204\n",
            "Train Epoch: 4 [3704/3978 (93%)]\tLoss: 0.091610\n",
            "Train Epoch: 4 [3705/3978 (93%)]\tLoss: 0.079541\n",
            "Train Epoch: 4 [3706/3978 (93%)]\tLoss: 0.868064\n",
            "Train Epoch: 4 [3707/3978 (93%)]\tLoss: 0.095852\n",
            "Train Epoch: 4 [3708/3978 (93%)]\tLoss: 0.086505\n",
            "Train Epoch: 4 [3709/3978 (93%)]\tLoss: 1.034745\n",
            "Train Epoch: 4 [3710/3978 (93%)]\tLoss: 0.414117\n",
            "Train Epoch: 4 [3711/3978 (93%)]\tLoss: 0.084652\n",
            "Train Epoch: 4 [3712/3978 (93%)]\tLoss: 0.085596\n",
            "Train Epoch: 4 [3713/3978 (93%)]\tLoss: 0.167846\n",
            "Train Epoch: 4 [3714/3978 (93%)]\tLoss: 0.895642\n",
            "Train Epoch: 4 [3715/3978 (93%)]\tLoss: 0.084521\n",
            "Train Epoch: 4 [3716/3978 (93%)]\tLoss: 0.099131\n",
            "Train Epoch: 4 [3717/3978 (93%)]\tLoss: 0.997324\n",
            "Train Epoch: 4 [3718/3978 (93%)]\tLoss: 0.133767\n",
            "Train Epoch: 4 [3719/3978 (93%)]\tLoss: 0.077501\n",
            "Train Epoch: 4 [3720/3978 (94%)]\tLoss: 0.152604\n",
            "Train Epoch: 4 [3721/3978 (94%)]\tLoss: 1.130300\n",
            "Train Epoch: 4 [3722/3978 (94%)]\tLoss: 0.157658\n",
            "Train Epoch: 4 [3723/3978 (94%)]\tLoss: 0.105329\n",
            "Train Epoch: 4 [3724/3978 (94%)]\tLoss: 0.145919\n",
            "Train Epoch: 4 [3725/3978 (94%)]\tLoss: 0.607848\n",
            "Train Epoch: 4 [3726/3978 (94%)]\tLoss: 0.107319\n",
            "Train Epoch: 4 [3727/3978 (94%)]\tLoss: 0.636762\n",
            "Train Epoch: 4 [3728/3978 (94%)]\tLoss: 0.074693\n",
            "Train Epoch: 4 [3729/3978 (94%)]\tLoss: 0.727287\n",
            "Train Epoch: 4 [3730/3978 (94%)]\tLoss: 0.094136\n",
            "Train Epoch: 4 [3731/3978 (94%)]\tLoss: 0.080123\n",
            "Train Epoch: 4 [3732/3978 (94%)]\tLoss: 0.139421\n",
            "Train Epoch: 4 [3733/3978 (94%)]\tLoss: 0.165111\n",
            "Train Epoch: 4 [3734/3978 (94%)]\tLoss: 0.082624\n",
            "Train Epoch: 4 [3735/3978 (94%)]\tLoss: 0.116057\n",
            "Train Epoch: 4 [3736/3978 (94%)]\tLoss: 0.073165\n",
            "Train Epoch: 4 [3737/3978 (94%)]\tLoss: 0.139270\n",
            "Train Epoch: 4 [3738/3978 (94%)]\tLoss: 0.197028\n",
            "Train Epoch: 4 [3739/3978 (94%)]\tLoss: 0.199825\n",
            "Train Epoch: 4 [3740/3978 (94%)]\tLoss: 0.127466\n",
            "Train Epoch: 4 [3741/3978 (94%)]\tLoss: 0.097239\n",
            "Train Epoch: 4 [3742/3978 (94%)]\tLoss: 0.102255\n",
            "Train Epoch: 4 [3743/3978 (94%)]\tLoss: 0.061754\n",
            "Train Epoch: 4 [3744/3978 (94%)]\tLoss: 0.699948\n",
            "Train Epoch: 4 [3745/3978 (94%)]\tLoss: 0.676141\n",
            "Train Epoch: 4 [3746/3978 (94%)]\tLoss: 0.652726\n",
            "Train Epoch: 4 [3747/3978 (94%)]\tLoss: 0.060457\n",
            "Train Epoch: 4 [3748/3978 (94%)]\tLoss: 0.133449\n",
            "Train Epoch: 4 [3749/3978 (94%)]\tLoss: 0.133960\n",
            "Train Epoch: 4 [3750/3978 (94%)]\tLoss: 0.105151\n",
            "Train Epoch: 4 [3751/3978 (94%)]\tLoss: 0.122740\n",
            "Train Epoch: 4 [3752/3978 (94%)]\tLoss: 0.179949\n",
            "Train Epoch: 4 [3753/3978 (94%)]\tLoss: 0.178557\n",
            "Train Epoch: 4 [3754/3978 (94%)]\tLoss: 0.147384\n",
            "Train Epoch: 4 [3755/3978 (94%)]\tLoss: 0.098733\n",
            "Train Epoch: 4 [3756/3978 (94%)]\tLoss: 0.128915\n",
            "Train Epoch: 4 [3757/3978 (94%)]\tLoss: 0.116059\n",
            "Train Epoch: 4 [3758/3978 (94%)]\tLoss: 0.531178\n",
            "Train Epoch: 4 [3759/3978 (94%)]\tLoss: 0.074871\n",
            "Train Epoch: 4 [3760/3978 (95%)]\tLoss: 0.078406\n",
            "Train Epoch: 4 [3761/3978 (95%)]\tLoss: 0.069348\n",
            "Train Epoch: 4 [3762/3978 (95%)]\tLoss: 0.156461\n",
            "Train Epoch: 4 [3763/3978 (95%)]\tLoss: 0.095576\n",
            "Train Epoch: 4 [3764/3978 (95%)]\tLoss: 0.512509\n",
            "Train Epoch: 4 [3765/3978 (95%)]\tLoss: 0.105890\n",
            "Train Epoch: 4 [3766/3978 (95%)]\tLoss: 0.088155\n",
            "Train Epoch: 4 [3767/3978 (95%)]\tLoss: 0.818703\n",
            "Train Epoch: 4 [3768/3978 (95%)]\tLoss: 0.082023\n",
            "Train Epoch: 4 [3769/3978 (95%)]\tLoss: 0.157937\n",
            "Train Epoch: 4 [3770/3978 (95%)]\tLoss: 0.112809\n",
            "Train Epoch: 4 [3771/3978 (95%)]\tLoss: 0.076937\n",
            "Train Epoch: 4 [3772/3978 (95%)]\tLoss: 0.643259\n",
            "Train Epoch: 4 [3773/3978 (95%)]\tLoss: 0.074410\n",
            "Train Epoch: 4 [3774/3978 (95%)]\tLoss: 0.097722\n",
            "Train Epoch: 4 [3775/3978 (95%)]\tLoss: 0.097220\n",
            "Train Epoch: 4 [3776/3978 (95%)]\tLoss: 0.748146\n",
            "Train Epoch: 4 [3777/3978 (95%)]\tLoss: 0.085707\n",
            "Train Epoch: 4 [3778/3978 (95%)]\tLoss: 0.063759\n",
            "Train Epoch: 4 [3779/3978 (95%)]\tLoss: 0.591165\n",
            "Train Epoch: 4 [3780/3978 (95%)]\tLoss: 0.138902\n",
            "Train Epoch: 4 [3781/3978 (95%)]\tLoss: 0.162975\n",
            "Train Epoch: 4 [3782/3978 (95%)]\tLoss: 0.055651\n",
            "Train Epoch: 4 [3783/3978 (95%)]\tLoss: 0.108495\n",
            "Train Epoch: 4 [3784/3978 (95%)]\tLoss: 0.494915\n",
            "Train Epoch: 4 [3785/3978 (95%)]\tLoss: 0.053898\n",
            "Train Epoch: 4 [3786/3978 (95%)]\tLoss: 0.665118\n",
            "Train Epoch: 4 [3787/3978 (95%)]\tLoss: 0.113800\n",
            "Train Epoch: 4 [3788/3978 (95%)]\tLoss: 0.055040\n",
            "Train Epoch: 4 [3789/3978 (95%)]\tLoss: 0.104502\n",
            "Train Epoch: 4 [3790/3978 (95%)]\tLoss: 0.068861\n",
            "Train Epoch: 4 [3791/3978 (95%)]\tLoss: 0.131868\n",
            "Train Epoch: 4 [3792/3978 (95%)]\tLoss: 0.104451\n",
            "Train Epoch: 4 [3793/3978 (95%)]\tLoss: 0.691956\n",
            "Train Epoch: 4 [3794/3978 (95%)]\tLoss: 0.184212\n",
            "Train Epoch: 4 [3795/3978 (95%)]\tLoss: 0.733753\n",
            "Train Epoch: 4 [3796/3978 (95%)]\tLoss: 0.072341\n",
            "Train Epoch: 4 [3797/3978 (95%)]\tLoss: 0.161620\n",
            "Train Epoch: 4 [3798/3978 (95%)]\tLoss: 0.069240\n",
            "Train Epoch: 4 [3799/3978 (96%)]\tLoss: 0.694461\n",
            "Train Epoch: 4 [3800/3978 (96%)]\tLoss: 0.105081\n",
            "Train Epoch: 4 [3801/3978 (96%)]\tLoss: 0.136453\n",
            "Train Epoch: 4 [3802/3978 (96%)]\tLoss: 0.063692\n",
            "Train Epoch: 4 [3803/3978 (96%)]\tLoss: 0.104054\n",
            "Train Epoch: 4 [3804/3978 (96%)]\tLoss: 0.105630\n",
            "Train Epoch: 4 [3805/3978 (96%)]\tLoss: 0.095098\n",
            "Train Epoch: 4 [3806/3978 (96%)]\tLoss: 0.088770\n",
            "Train Epoch: 4 [3807/3978 (96%)]\tLoss: 0.550865\n",
            "Train Epoch: 4 [3808/3978 (96%)]\tLoss: 0.474650\n",
            "Train Epoch: 4 [3809/3978 (96%)]\tLoss: 0.081250\n",
            "Train Epoch: 4 [3810/3978 (96%)]\tLoss: 0.085909\n",
            "Train Epoch: 4 [3811/3978 (96%)]\tLoss: 0.102180\n",
            "Train Epoch: 4 [3812/3978 (96%)]\tLoss: 0.096345\n",
            "Train Epoch: 4 [3813/3978 (96%)]\tLoss: 0.079647\n",
            "Train Epoch: 4 [3814/3978 (96%)]\tLoss: 0.094838\n",
            "Train Epoch: 4 [3815/3978 (96%)]\tLoss: 0.071712\n",
            "Train Epoch: 4 [3816/3978 (96%)]\tLoss: 0.085782\n",
            "Train Epoch: 4 [3817/3978 (96%)]\tLoss: 0.096088\n",
            "Train Epoch: 4 [3818/3978 (96%)]\tLoss: 0.087881\n",
            "Train Epoch: 4 [3819/3978 (96%)]\tLoss: 0.467728\n",
            "Train Epoch: 4 [3820/3978 (96%)]\tLoss: 1.858602\n",
            "Train Epoch: 4 [3821/3978 (96%)]\tLoss: 0.758159\n",
            "Train Epoch: 4 [3822/3978 (96%)]\tLoss: 0.087425\n",
            "Train Epoch: 4 [3823/3978 (96%)]\tLoss: 0.164036\n",
            "Train Epoch: 4 [3824/3978 (96%)]\tLoss: 0.786906\n",
            "Train Epoch: 4 [3825/3978 (96%)]\tLoss: 0.077841\n",
            "Train Epoch: 4 [3826/3978 (96%)]\tLoss: 0.787485\n",
            "Train Epoch: 4 [3827/3978 (96%)]\tLoss: 0.127982\n",
            "Train Epoch: 4 [3828/3978 (96%)]\tLoss: 0.101534\n",
            "Train Epoch: 4 [3829/3978 (96%)]\tLoss: 0.106294\n",
            "Train Epoch: 4 [3830/3978 (96%)]\tLoss: 0.151397\n",
            "Train Epoch: 4 [3831/3978 (96%)]\tLoss: 0.083228\n",
            "Train Epoch: 4 [3832/3978 (96%)]\tLoss: 0.701599\n",
            "Train Epoch: 4 [3833/3978 (96%)]\tLoss: 0.089202\n",
            "Train Epoch: 4 [3834/3978 (96%)]\tLoss: 0.730449\n",
            "Train Epoch: 4 [3835/3978 (96%)]\tLoss: 0.087246\n",
            "Train Epoch: 4 [3836/3978 (96%)]\tLoss: 0.102467\n",
            "Train Epoch: 4 [3837/3978 (96%)]\tLoss: 0.091045\n",
            "Train Epoch: 4 [3838/3978 (96%)]\tLoss: 0.090686\n",
            "Train Epoch: 4 [3839/3978 (97%)]\tLoss: 0.091286\n",
            "Train Epoch: 4 [3840/3978 (97%)]\tLoss: 0.079533\n",
            "Train Epoch: 4 [3841/3978 (97%)]\tLoss: 0.087654\n",
            "Train Epoch: 4 [3842/3978 (97%)]\tLoss: 0.486158\n",
            "Train Epoch: 4 [3843/3978 (97%)]\tLoss: 0.158812\n",
            "Train Epoch: 4 [3844/3978 (97%)]\tLoss: 0.080977\n",
            "Train Epoch: 4 [3845/3978 (97%)]\tLoss: 0.082825\n",
            "Train Epoch: 4 [3846/3978 (97%)]\tLoss: 0.083090\n",
            "Train Epoch: 4 [3847/3978 (97%)]\tLoss: 0.976485\n",
            "Train Epoch: 4 [3848/3978 (97%)]\tLoss: 0.101217\n",
            "Train Epoch: 4 [3849/3978 (97%)]\tLoss: 0.552864\n",
            "Train Epoch: 4 [3850/3978 (97%)]\tLoss: 0.131474\n",
            "Train Epoch: 4 [3851/3978 (97%)]\tLoss: 0.104239\n",
            "Train Epoch: 4 [3852/3978 (97%)]\tLoss: 0.070628\n",
            "Train Epoch: 4 [3853/3978 (97%)]\tLoss: 0.130431\n",
            "Train Epoch: 4 [3854/3978 (97%)]\tLoss: 0.147682\n",
            "Train Epoch: 4 [3855/3978 (97%)]\tLoss: 0.176812\n",
            "Train Epoch: 4 [3856/3978 (97%)]\tLoss: 0.076394\n",
            "Train Epoch: 4 [3857/3978 (97%)]\tLoss: 1.040488\n",
            "Train Epoch: 4 [3858/3978 (97%)]\tLoss: 1.027317\n",
            "Train Epoch: 4 [3859/3978 (97%)]\tLoss: 0.137555\n",
            "Train Epoch: 4 [3860/3978 (97%)]\tLoss: 0.096694\n",
            "Train Epoch: 4 [3861/3978 (97%)]\tLoss: 0.089276\n",
            "Train Epoch: 4 [3862/3978 (97%)]\tLoss: 0.140023\n",
            "Train Epoch: 4 [3863/3978 (97%)]\tLoss: 1.030400\n",
            "Train Epoch: 4 [3864/3978 (97%)]\tLoss: 0.102202\n",
            "Train Epoch: 4 [3865/3978 (97%)]\tLoss: 0.121964\n",
            "Train Epoch: 4 [3866/3978 (97%)]\tLoss: 0.142920\n",
            "Train Epoch: 4 [3867/3978 (97%)]\tLoss: 0.081612\n",
            "Train Epoch: 4 [3868/3978 (97%)]\tLoss: 0.849169\n",
            "Train Epoch: 4 [3869/3978 (97%)]\tLoss: 0.107691\n",
            "Train Epoch: 4 [3870/3978 (97%)]\tLoss: 0.100424\n",
            "Train Epoch: 4 [3871/3978 (97%)]\tLoss: 0.144672\n",
            "Train Epoch: 4 [3872/3978 (97%)]\tLoss: 0.088565\n",
            "Train Epoch: 4 [3873/3978 (97%)]\tLoss: 0.096547\n",
            "Train Epoch: 4 [3874/3978 (97%)]\tLoss: 0.094491\n",
            "Train Epoch: 4 [3875/3978 (97%)]\tLoss: 0.076687\n",
            "Train Epoch: 4 [3876/3978 (97%)]\tLoss: 0.085820\n",
            "Train Epoch: 4 [3877/3978 (97%)]\tLoss: 0.138752\n",
            "Train Epoch: 4 [3878/3978 (97%)]\tLoss: 0.069995\n",
            "Train Epoch: 4 [3879/3978 (98%)]\tLoss: 0.119549\n",
            "Train Epoch: 4 [3880/3978 (98%)]\tLoss: 0.063742\n",
            "Train Epoch: 4 [3881/3978 (98%)]\tLoss: 0.779948\n",
            "Train Epoch: 4 [3882/3978 (98%)]\tLoss: 0.082840\n",
            "Train Epoch: 4 [3883/3978 (98%)]\tLoss: 0.090613\n",
            "Train Epoch: 4 [3884/3978 (98%)]\tLoss: 0.085747\n",
            "Train Epoch: 4 [3885/3978 (98%)]\tLoss: 0.117303\n",
            "Train Epoch: 4 [3886/3978 (98%)]\tLoss: 0.089322\n",
            "Train Epoch: 4 [3887/3978 (98%)]\tLoss: 0.150167\n",
            "Train Epoch: 4 [3888/3978 (98%)]\tLoss: 0.087964\n",
            "Train Epoch: 4 [3889/3978 (98%)]\tLoss: 0.078141\n",
            "Train Epoch: 4 [3890/3978 (98%)]\tLoss: 0.135151\n",
            "Train Epoch: 4 [3891/3978 (98%)]\tLoss: 0.689716\n",
            "Train Epoch: 4 [3892/3978 (98%)]\tLoss: 0.075644\n",
            "Train Epoch: 4 [3893/3978 (98%)]\tLoss: 0.061340\n",
            "Train Epoch: 4 [3894/3978 (98%)]\tLoss: 0.085770\n",
            "Train Epoch: 4 [3895/3978 (98%)]\tLoss: 0.060383\n",
            "Train Epoch: 4 [3896/3978 (98%)]\tLoss: 0.063199\n",
            "Train Epoch: 4 [3897/3978 (98%)]\tLoss: 0.054040\n",
            "Train Epoch: 4 [3898/3978 (98%)]\tLoss: 0.056805\n",
            "Train Epoch: 4 [3899/3978 (98%)]\tLoss: 0.165751\n",
            "Train Epoch: 4 [3900/3978 (98%)]\tLoss: 0.846676\n",
            "Train Epoch: 4 [3901/3978 (98%)]\tLoss: 0.102527\n",
            "Train Epoch: 4 [3902/3978 (98%)]\tLoss: 0.061297\n",
            "Train Epoch: 4 [3903/3978 (98%)]\tLoss: 0.813781\n",
            "Train Epoch: 4 [3904/3978 (98%)]\tLoss: 0.040310\n",
            "Train Epoch: 4 [3905/3978 (98%)]\tLoss: 0.073159\n",
            "Train Epoch: 4 [3906/3978 (98%)]\tLoss: 0.055143\n",
            "Train Epoch: 4 [3907/3978 (98%)]\tLoss: 0.130582\n",
            "Train Epoch: 4 [3908/3978 (98%)]\tLoss: 0.078933\n",
            "Train Epoch: 4 [3909/3978 (98%)]\tLoss: 0.119626\n",
            "Train Epoch: 4 [3910/3978 (98%)]\tLoss: 0.132808\n",
            "Train Epoch: 4 [3911/3978 (98%)]\tLoss: 0.966250\n",
            "Train Epoch: 4 [3912/3978 (98%)]\tLoss: 0.792457\n",
            "Train Epoch: 4 [3913/3978 (98%)]\tLoss: 0.589868\n",
            "Train Epoch: 4 [3914/3978 (98%)]\tLoss: 0.039542\n",
            "Train Epoch: 4 [3915/3978 (98%)]\tLoss: 0.122372\n",
            "Train Epoch: 4 [3916/3978 (98%)]\tLoss: 0.575655\n",
            "Train Epoch: 4 [3917/3978 (98%)]\tLoss: 0.172304\n",
            "Train Epoch: 4 [3918/3978 (98%)]\tLoss: 0.044687\n",
            "Train Epoch: 4 [3919/3978 (99%)]\tLoss: 0.161409\n",
            "Train Epoch: 4 [3920/3978 (99%)]\tLoss: 1.042276\n",
            "Train Epoch: 4 [3921/3978 (99%)]\tLoss: 0.686101\n",
            "Train Epoch: 4 [3922/3978 (99%)]\tLoss: 0.112655\n",
            "Train Epoch: 4 [3923/3978 (99%)]\tLoss: 0.049990\n",
            "Train Epoch: 4 [3924/3978 (99%)]\tLoss: 0.052147\n",
            "Train Epoch: 4 [3925/3978 (99%)]\tLoss: 0.157132\n",
            "Train Epoch: 4 [3926/3978 (99%)]\tLoss: 0.059483\n",
            "Train Epoch: 4 [3927/3978 (99%)]\tLoss: 0.067406\n",
            "Train Epoch: 4 [3928/3978 (99%)]\tLoss: 0.687271\n",
            "Train Epoch: 4 [3929/3978 (99%)]\tLoss: 0.758578\n",
            "Train Epoch: 4 [3930/3978 (99%)]\tLoss: 0.163437\n",
            "Train Epoch: 4 [3931/3978 (99%)]\tLoss: 0.516680\n",
            "Train Epoch: 4 [3932/3978 (99%)]\tLoss: 0.161016\n",
            "Train Epoch: 4 [3933/3978 (99%)]\tLoss: 0.688576\n",
            "Train Epoch: 4 [3934/3978 (99%)]\tLoss: 0.094721\n",
            "Train Epoch: 4 [3935/3978 (99%)]\tLoss: 0.094916\n",
            "Train Epoch: 4 [3936/3978 (99%)]\tLoss: 0.103950\n",
            "Train Epoch: 4 [3937/3978 (99%)]\tLoss: 0.088336\n",
            "Train Epoch: 4 [3938/3978 (99%)]\tLoss: 0.083457\n",
            "Train Epoch: 4 [3939/3978 (99%)]\tLoss: 0.072145\n",
            "Train Epoch: 4 [3940/3978 (99%)]\tLoss: 0.665767\n",
            "Train Epoch: 4 [3941/3978 (99%)]\tLoss: 0.080801\n",
            "Train Epoch: 4 [3942/3978 (99%)]\tLoss: 0.082867\n",
            "Train Epoch: 4 [3943/3978 (99%)]\tLoss: 0.147578\n",
            "Train Epoch: 4 [3944/3978 (99%)]\tLoss: 0.136260\n",
            "Train Epoch: 4 [3945/3978 (99%)]\tLoss: 0.105625\n",
            "Train Epoch: 4 [3946/3978 (99%)]\tLoss: 0.098402\n",
            "Train Epoch: 4 [3947/3978 (99%)]\tLoss: 0.653039\n",
            "Train Epoch: 4 [3948/3978 (99%)]\tLoss: 0.148643\n",
            "Train Epoch: 4 [3949/3978 (99%)]\tLoss: 0.077228\n",
            "Train Epoch: 4 [3950/3978 (99%)]\tLoss: 0.083421\n",
            "Train Epoch: 4 [3951/3978 (99%)]\tLoss: 0.093551\n",
            "Train Epoch: 4 [3952/3978 (99%)]\tLoss: 0.101392\n",
            "Train Epoch: 4 [3953/3978 (99%)]\tLoss: 0.066760\n",
            "Train Epoch: 4 [3954/3978 (99%)]\tLoss: 0.094558\n",
            "Train Epoch: 4 [3955/3978 (99%)]\tLoss: 0.135879\n",
            "Train Epoch: 4 [3956/3978 (99%)]\tLoss: 0.081479\n",
            "Train Epoch: 4 [3957/3978 (99%)]\tLoss: 0.127842\n",
            "Train Epoch: 4 [3958/3978 (99%)]\tLoss: 0.678789\n",
            "Train Epoch: 4 [3959/3978 (100%)]\tLoss: 0.116813\n",
            "Train Epoch: 4 [3960/3978 (100%)]\tLoss: 0.059957\n",
            "Train Epoch: 4 [3961/3978 (100%)]\tLoss: 0.082164\n",
            "Train Epoch: 4 [3962/3978 (100%)]\tLoss: 0.712157\n",
            "Train Epoch: 4 [3963/3978 (100%)]\tLoss: 0.180428\n",
            "Train Epoch: 4 [3964/3978 (100%)]\tLoss: 0.582499\n",
            "Train Epoch: 4 [3965/3978 (100%)]\tLoss: 0.045583\n",
            "Train Epoch: 4 [3966/3978 (100%)]\tLoss: 0.697705\n",
            "Train Epoch: 4 [3967/3978 (100%)]\tLoss: 0.108920\n",
            "Train Epoch: 4 [3968/3978 (100%)]\tLoss: 0.070260\n",
            "Train Epoch: 4 [3969/3978 (100%)]\tLoss: 0.935879\n",
            "Train Epoch: 4 [3970/3978 (100%)]\tLoss: 0.702349\n",
            "Train Epoch: 4 [3971/3978 (100%)]\tLoss: 0.559203\n",
            "Train Epoch: 4 [3972/3978 (100%)]\tLoss: 0.199409\n",
            "Train Epoch: 4 [3973/3978 (100%)]\tLoss: 0.852104\n",
            "Train Epoch: 4 [3974/3978 (100%)]\tLoss: 0.054731\n",
            "Train Epoch: 4 [3975/3978 (100%)]\tLoss: 0.151583\n",
            "Train Epoch: 4 [3976/3978 (100%)]\tLoss: 0.049939\n",
            "Train Epoch: 4 [3977/3978 (100%)]\tLoss: 0.047775\n",
            "Epoch\n",
            "train/train_loss: 0.04777463153004646\n",
            "\n",
            "Train Loss: 0.048, Valid Loss: 0.290640, Accuracy: 0.35\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54f2ee6195c74b9fafdb67e845983b40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='541.284 MB of 541.284 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train/loss</td><td>▁▅▁█▂▁▁▁▁▆▁▁▁▁▁▄▂▂▂▁▂▁▆▂▁▁▁▁▁▅▅▅▁▁▁▁▁▁▁▅</td></tr><tr><td>validation/accuracy</td><td>█▁▁█▁</td></tr><tr><td>validation/loss</td><td>█▃▁▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/loss</td><td>0.04777</td></tr><tr><td>validation/accuracy</td><td>0.3456</td></tr><tr><td>validation/loss</td><td>0.29064</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fresh-sweep-1</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/1pffni86' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/1pffni86</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240829_165728-1pffni86/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 12gc5nz4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240829_173727-12gc5nz4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/12gc5nz4' target=\"_blank\">fearless-sweep-2</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/12gc5nz4' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/12gc5nz4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train Epoch: 3 [2964/3978 (75%)]\tLoss: 0.245029\n",
            "Train Epoch: 3 [2965/3978 (75%)]\tLoss: 0.101555\n",
            "Train Epoch: 3 [2966/3978 (75%)]\tLoss: 0.828174\n",
            "Train Epoch: 3 [2967/3978 (75%)]\tLoss: 0.120521\n",
            "Train Epoch: 3 [2968/3978 (75%)]\tLoss: 0.382769\n",
            "Train Epoch: 3 [2969/3978 (75%)]\tLoss: 0.011121\n",
            "Train Epoch: 3 [2970/3978 (75%)]\tLoss: 0.995120\n",
            "Train Epoch: 3 [2971/3978 (75%)]\tLoss: 0.463876\n",
            "Train Epoch: 3 [2972/3978 (75%)]\tLoss: 0.000028\n",
            "Train Epoch: 3 [2973/3978 (75%)]\tLoss: 2.881766\n",
            "Train Epoch: 3 [2974/3978 (75%)]\tLoss: 0.038454\n",
            "Train Epoch: 3 [2975/3978 (75%)]\tLoss: 2.963338\n",
            "Train Epoch: 3 [2976/3978 (75%)]\tLoss: 0.344100\n",
            "Train Epoch: 3 [2977/3978 (75%)]\tLoss: 2.007914\n",
            "Train Epoch: 3 [2978/3978 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [2979/3978 (75%)]\tLoss: 0.001351\n",
            "Train Epoch: 3 [2980/3978 (75%)]\tLoss: 1.872964\n",
            "Train Epoch: 3 [2981/3978 (75%)]\tLoss: 2.393939\n",
            "Train Epoch: 3 [2982/3978 (75%)]\tLoss: 0.259009\n",
            "Train Epoch: 3 [2983/3978 (75%)]\tLoss: 0.310475\n",
            "Train Epoch: 3 [2984/3978 (75%)]\tLoss: 2.686918\n",
            "Train Epoch: 3 [2985/3978 (75%)]\tLoss: 0.276070\n",
            "Train Epoch: 3 [2986/3978 (75%)]\tLoss: 0.000098\n",
            "Train Epoch: 3 [2987/3978 (75%)]\tLoss: 2.189261\n",
            "Train Epoch: 3 [2988/3978 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [2989/3978 (75%)]\tLoss: 2.668868\n",
            "Train Epoch: 3 [2990/3978 (75%)]\tLoss: 2.491878\n",
            "Train Epoch: 3 [2991/3978 (75%)]\tLoss: 1.977801\n",
            "Train Epoch: 3 [2992/3978 (75%)]\tLoss: 0.037445\n",
            "Train Epoch: 3 [2993/3978 (75%)]\tLoss: 1.525433\n",
            "Train Epoch: 3 [2994/3978 (75%)]\tLoss: 0.723304\n",
            "Train Epoch: 3 [2995/3978 (75%)]\tLoss: 1.566035\n",
            "Train Epoch: 3 [2996/3978 (75%)]\tLoss: 2.385708\n",
            "Train Epoch: 3 [2997/3978 (75%)]\tLoss: 3.783331\n",
            "Train Epoch: 3 [2998/3978 (75%)]\tLoss: 0.003060\n",
            "Train Epoch: 3 [2999/3978 (75%)]\tLoss: 0.170814\n",
            "Train Epoch: 3 [3000/3978 (75%)]\tLoss: 0.005376\n",
            "Train Epoch: 3 [3001/3978 (75%)]\tLoss: 0.009794\n",
            "Train Epoch: 3 [3002/3978 (75%)]\tLoss: 0.033706\n",
            "Train Epoch: 3 [3003/3978 (75%)]\tLoss: 0.761101\n",
            "Train Epoch: 3 [3004/3978 (76%)]\tLoss: 5.291920\n",
            "Train Epoch: 3 [3005/3978 (76%)]\tLoss: 0.000234\n",
            "Train Epoch: 3 [3006/3978 (76%)]\tLoss: 0.118972\n",
            "Train Epoch: 3 [3007/3978 (76%)]\tLoss: 0.024279\n",
            "Train Epoch: 3 [3008/3978 (76%)]\tLoss: 0.179661\n",
            "Train Epoch: 3 [3009/3978 (76%)]\tLoss: 0.606188\n",
            "Train Epoch: 3 [3010/3978 (76%)]\tLoss: 1.493274\n",
            "Train Epoch: 3 [3011/3978 (76%)]\tLoss: 1.043340\n",
            "Train Epoch: 3 [3012/3978 (76%)]\tLoss: 0.739727\n",
            "Train Epoch: 3 [3013/3978 (76%)]\tLoss: 0.167668\n",
            "Train Epoch: 3 [3014/3978 (76%)]\tLoss: 0.005824\n",
            "Train Epoch: 3 [3015/3978 (76%)]\tLoss: 0.000862\n",
            "Train Epoch: 3 [3016/3978 (76%)]\tLoss: 0.005228\n",
            "Train Epoch: 3 [3017/3978 (76%)]\tLoss: 1.766344\n",
            "Train Epoch: 3 [3018/3978 (76%)]\tLoss: 0.000306\n",
            "Train Epoch: 3 [3019/3978 (76%)]\tLoss: 0.420865\n",
            "Train Epoch: 3 [3020/3978 (76%)]\tLoss: 0.256461\n",
            "Train Epoch: 3 [3021/3978 (76%)]\tLoss: 2.257801\n",
            "Train Epoch: 3 [3022/3978 (76%)]\tLoss: 1.160812\n",
            "Train Epoch: 3 [3023/3978 (76%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3024/3978 (76%)]\tLoss: 0.000034\n",
            "Train Epoch: 3 [3025/3978 (76%)]\tLoss: 0.296025\n",
            "Train Epoch: 3 [3026/3978 (76%)]\tLoss: 0.040455\n",
            "Train Epoch: 3 [3027/3978 (76%)]\tLoss: 0.524448\n",
            "Train Epoch: 3 [3028/3978 (76%)]\tLoss: 0.013365\n",
            "Train Epoch: 3 [3029/3978 (76%)]\tLoss: 1.220363\n",
            "Train Epoch: 3 [3030/3978 (76%)]\tLoss: 0.308997\n",
            "Train Epoch: 3 [3031/3978 (76%)]\tLoss: 2.984622\n",
            "Train Epoch: 3 [3032/3978 (76%)]\tLoss: 0.284476\n",
            "Train Epoch: 3 [3033/3978 (76%)]\tLoss: 0.000007\n",
            "Train Epoch: 3 [3034/3978 (76%)]\tLoss: 0.000009\n",
            "Train Epoch: 3 [3035/3978 (76%)]\tLoss: 0.244306\n",
            "Train Epoch: 3 [3036/3978 (76%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3037/3978 (76%)]\tLoss: 0.006854\n",
            "Train Epoch: 3 [3038/3978 (76%)]\tLoss: 3.486790\n",
            "Train Epoch: 3 [3039/3978 (76%)]\tLoss: 0.000456\n",
            "Train Epoch: 3 [3040/3978 (76%)]\tLoss: 1.361517\n",
            "Train Epoch: 3 [3041/3978 (76%)]\tLoss: 0.000007\n",
            "Train Epoch: 3 [3042/3978 (76%)]\tLoss: 0.420190\n",
            "Train Epoch: 3 [3043/3978 (76%)]\tLoss: 1.092982\n",
            "Train Epoch: 3 [3044/3978 (77%)]\tLoss: 1.580248\n",
            "Train Epoch: 3 [3045/3978 (77%)]\tLoss: 0.821578\n",
            "Train Epoch: 3 [3046/3978 (77%)]\tLoss: 0.000005\n",
            "Train Epoch: 3 [3047/3978 (77%)]\tLoss: 5.487091\n",
            "Train Epoch: 3 [3048/3978 (77%)]\tLoss: 1.473479\n",
            "Train Epoch: 3 [3049/3978 (77%)]\tLoss: 1.224083\n",
            "Train Epoch: 3 [3050/3978 (77%)]\tLoss: 0.193175\n",
            "Train Epoch: 3 [3051/3978 (77%)]\tLoss: 0.741538\n",
            "Train Epoch: 3 [3052/3978 (77%)]\tLoss: 4.064745\n",
            "Train Epoch: 3 [3053/3978 (77%)]\tLoss: 0.641473\n",
            "Train Epoch: 3 [3054/3978 (77%)]\tLoss: 1.482235\n",
            "Train Epoch: 3 [3055/3978 (77%)]\tLoss: 4.428496\n",
            "Train Epoch: 3 [3056/3978 (77%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3057/3978 (77%)]\tLoss: 0.000103\n",
            "Train Epoch: 3 [3058/3978 (77%)]\tLoss: 0.001699\n",
            "Train Epoch: 3 [3059/3978 (77%)]\tLoss: 0.001674\n",
            "Train Epoch: 3 [3060/3978 (77%)]\tLoss: 1.126810\n",
            "Train Epoch: 3 [3061/3978 (77%)]\tLoss: 0.004349\n",
            "Train Epoch: 3 [3062/3978 (77%)]\tLoss: 0.312919\n",
            "Train Epoch: 3 [3063/3978 (77%)]\tLoss: 0.000475\n",
            "Train Epoch: 3 [3064/3978 (77%)]\tLoss: 0.380467\n",
            "Train Epoch: 3 [3065/3978 (77%)]\tLoss: 0.817962\n",
            "Train Epoch: 3 [3066/3978 (77%)]\tLoss: 1.070204\n",
            "Train Epoch: 3 [3067/3978 (77%)]\tLoss: 1.838010\n",
            "Train Epoch: 3 [3068/3978 (77%)]\tLoss: 0.033334\n",
            "Train Epoch: 3 [3069/3978 (77%)]\tLoss: 1.121631\n",
            "Train Epoch: 3 [3070/3978 (77%)]\tLoss: 1.240251\n",
            "Train Epoch: 3 [3071/3978 (77%)]\tLoss: 0.605642\n",
            "Train Epoch: 3 [3072/3978 (77%)]\tLoss: 0.855402\n",
            "Train Epoch: 3 [3073/3978 (77%)]\tLoss: 0.004578\n",
            "Train Epoch: 3 [3074/3978 (77%)]\tLoss: 1.042753\n",
            "Train Epoch: 3 [3075/3978 (77%)]\tLoss: 1.619818\n",
            "Train Epoch: 3 [3076/3978 (77%)]\tLoss: 0.000721\n",
            "Train Epoch: 3 [3077/3978 (77%)]\tLoss: 0.006428\n",
            "Train Epoch: 3 [3078/3978 (77%)]\tLoss: 0.013446\n",
            "Train Epoch: 3 [3079/3978 (77%)]\tLoss: 0.000012\n",
            "Train Epoch: 3 [3080/3978 (77%)]\tLoss: 5.777092\n",
            "Train Epoch: 3 [3081/3978 (77%)]\tLoss: 0.428910\n",
            "Train Epoch: 3 [3082/3978 (77%)]\tLoss: 2.328527\n",
            "Train Epoch: 3 [3083/3978 (78%)]\tLoss: 0.217083\n",
            "Train Epoch: 3 [3084/3978 (78%)]\tLoss: 2.805967\n",
            "Train Epoch: 3 [3085/3978 (78%)]\tLoss: 0.000350\n",
            "Train Epoch: 3 [3086/3978 (78%)]\tLoss: 1.773064\n",
            "Train Epoch: 3 [3087/3978 (78%)]\tLoss: 0.000273\n",
            "Train Epoch: 3 [3088/3978 (78%)]\tLoss: 1.541026\n",
            "Train Epoch: 3 [3089/3978 (78%)]\tLoss: 1.963966\n",
            "Train Epoch: 3 [3090/3978 (78%)]\tLoss: 1.330996\n",
            "Train Epoch: 3 [3091/3978 (78%)]\tLoss: 0.730057\n",
            "Train Epoch: 3 [3092/3978 (78%)]\tLoss: 1.055530\n",
            "Train Epoch: 3 [3093/3978 (78%)]\tLoss: 0.842824\n",
            "Train Epoch: 3 [3094/3978 (78%)]\tLoss: 0.006757\n",
            "Train Epoch: 3 [3095/3978 (78%)]\tLoss: 1.482726\n",
            "Train Epoch: 3 [3096/3978 (78%)]\tLoss: 0.007341\n",
            "Train Epoch: 3 [3097/3978 (78%)]\tLoss: 0.000030\n",
            "Train Epoch: 3 [3098/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3099/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3100/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3101/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3102/3978 (78%)]\tLoss: 3.381528\n",
            "Train Epoch: 3 [3103/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3104/3978 (78%)]\tLoss: 1.968861\n",
            "Train Epoch: 3 [3105/3978 (78%)]\tLoss: 1.780268\n",
            "Train Epoch: 3 [3106/3978 (78%)]\tLoss: 0.000005\n",
            "Train Epoch: 3 [3107/3978 (78%)]\tLoss: 0.002235\n",
            "Train Epoch: 3 [3108/3978 (78%)]\tLoss: 5.062533\n",
            "Train Epoch: 3 [3109/3978 (78%)]\tLoss: 0.105842\n",
            "Train Epoch: 3 [3110/3978 (78%)]\tLoss: 0.704250\n",
            "Train Epoch: 3 [3111/3978 (78%)]\tLoss: 0.000094\n",
            "Train Epoch: 3 [3112/3978 (78%)]\tLoss: 0.940986\n",
            "Train Epoch: 3 [3113/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3114/3978 (78%)]\tLoss: 1.276149\n",
            "Train Epoch: 3 [3115/3978 (78%)]\tLoss: 0.016065\n",
            "Train Epoch: 3 [3116/3978 (78%)]\tLoss: 2.372891\n",
            "Train Epoch: 3 [3117/3978 (78%)]\tLoss: 0.002884\n",
            "Train Epoch: 3 [3118/3978 (78%)]\tLoss: 0.000005\n",
            "Train Epoch: 3 [3119/3978 (78%)]\tLoss: 1.420605\n",
            "Train Epoch: 3 [3120/3978 (78%)]\tLoss: 1.199082\n",
            "Train Epoch: 3 [3121/3978 (78%)]\tLoss: 0.166244\n",
            "Train Epoch: 3 [3122/3978 (78%)]\tLoss: 2.404864\n",
            "Train Epoch: 3 [3123/3978 (79%)]\tLoss: 0.853612\n",
            "Train Epoch: 3 [3124/3978 (79%)]\tLoss: 0.617639\n",
            "Train Epoch: 3 [3125/3978 (79%)]\tLoss: 0.010620\n",
            "Train Epoch: 3 [3126/3978 (79%)]\tLoss: 0.161029\n",
            "Train Epoch: 3 [3127/3978 (79%)]\tLoss: 0.000477\n",
            "Train Epoch: 3 [3128/3978 (79%)]\tLoss: 0.000004\n",
            "Train Epoch: 3 [3129/3978 (79%)]\tLoss: 2.781284\n",
            "Train Epoch: 3 [3130/3978 (79%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3131/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3132/3978 (79%)]\tLoss: 0.681527\n",
            "Train Epoch: 3 [3133/3978 (79%)]\tLoss: 0.888997\n",
            "Train Epoch: 3 [3134/3978 (79%)]\tLoss: 0.509268\n",
            "Train Epoch: 3 [3135/3978 (79%)]\tLoss: 0.000116\n",
            "Train Epoch: 3 [3136/3978 (79%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3137/3978 (79%)]\tLoss: 0.000020\n",
            "Train Epoch: 3 [3138/3978 (79%)]\tLoss: 1.406308\n",
            "Train Epoch: 3 [3139/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3140/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3141/3978 (79%)]\tLoss: 2.869787\n",
            "Train Epoch: 3 [3142/3978 (79%)]\tLoss: 3.525562\n",
            "Train Epoch: 3 [3143/3978 (79%)]\tLoss: 2.689077\n",
            "Train Epoch: 3 [3144/3978 (79%)]\tLoss: 1.553951\n",
            "Train Epoch: 3 [3145/3978 (79%)]\tLoss: 2.866699\n",
            "Train Epoch: 3 [3146/3978 (79%)]\tLoss: 0.025577\n",
            "Train Epoch: 3 [3147/3978 (79%)]\tLoss: 0.000012\n",
            "Train Epoch: 3 [3148/3978 (79%)]\tLoss: 2.581687\n",
            "Train Epoch: 3 [3149/3978 (79%)]\tLoss: 1.938895\n",
            "Train Epoch: 3 [3150/3978 (79%)]\tLoss: 3.007851\n",
            "Train Epoch: 3 [3151/3978 (79%)]\tLoss: 1.554345\n",
            "Train Epoch: 3 [3152/3978 (79%)]\tLoss: 0.000039\n",
            "Train Epoch: 3 [3153/3978 (79%)]\tLoss: 0.015020\n",
            "Train Epoch: 3 [3154/3978 (79%)]\tLoss: 2.052462\n",
            "Train Epoch: 3 [3155/3978 (79%)]\tLoss: 0.941290\n",
            "Train Epoch: 3 [3156/3978 (79%)]\tLoss: 2.496584\n",
            "Train Epoch: 3 [3157/3978 (79%)]\tLoss: 1.716238\n",
            "Train Epoch: 3 [3158/3978 (79%)]\tLoss: 0.935354\n",
            "Train Epoch: 3 [3159/3978 (79%)]\tLoss: 0.023195\n",
            "Train Epoch: 3 [3160/3978 (79%)]\tLoss: 0.009434\n",
            "Train Epoch: 3 [3161/3978 (79%)]\tLoss: 1.191921\n",
            "Train Epoch: 3 [3162/3978 (79%)]\tLoss: 2.511903\n",
            "Train Epoch: 3 [3163/3978 (80%)]\tLoss: 0.003517\n",
            "Train Epoch: 3 [3164/3978 (80%)]\tLoss: 0.154984\n",
            "Train Epoch: 3 [3165/3978 (80%)]\tLoss: 0.777138\n",
            "Train Epoch: 3 [3166/3978 (80%)]\tLoss: 0.457525\n",
            "Train Epoch: 3 [3167/3978 (80%)]\tLoss: 0.002116\n",
            "Train Epoch: 3 [3168/3978 (80%)]\tLoss: 0.342975\n",
            "Train Epoch: 3 [3169/3978 (80%)]\tLoss: 2.741576\n",
            "Train Epoch: 3 [3170/3978 (80%)]\tLoss: 0.000115\n",
            "Train Epoch: 3 [3171/3978 (80%)]\tLoss: 0.006921\n",
            "Train Epoch: 3 [3172/3978 (80%)]\tLoss: 0.002394\n",
            "Train Epoch: 3 [3173/3978 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3174/3978 (80%)]\tLoss: 0.603194\n",
            "Train Epoch: 3 [3175/3978 (80%)]\tLoss: 2.761030\n",
            "Train Epoch: 3 [3176/3978 (80%)]\tLoss: 1.290832\n",
            "Train Epoch: 3 [3177/3978 (80%)]\tLoss: 1.447598\n",
            "Train Epoch: 3 [3178/3978 (80%)]\tLoss: 0.222147\n",
            "Train Epoch: 3 [3179/3978 (80%)]\tLoss: 0.010473\n",
            "Train Epoch: 3 [3180/3978 (80%)]\tLoss: 0.002571\n",
            "Train Epoch: 3 [3181/3978 (80%)]\tLoss: 0.101688\n",
            "Train Epoch: 3 [3182/3978 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3183/3978 (80%)]\tLoss: 0.001902\n",
            "Train Epoch: 3 [3184/3978 (80%)]\tLoss: 1.015029\n",
            "Train Epoch: 3 [3185/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3186/3978 (80%)]\tLoss: 3.175114\n",
            "Train Epoch: 3 [3187/3978 (80%)]\tLoss: 0.022579\n",
            "Train Epoch: 3 [3188/3978 (80%)]\tLoss: 0.001573\n",
            "Train Epoch: 3 [3189/3978 (80%)]\tLoss: 1.506063\n",
            "Train Epoch: 3 [3190/3978 (80%)]\tLoss: 0.007276\n",
            "Train Epoch: 3 [3191/3978 (80%)]\tLoss: 0.141350\n",
            "Train Epoch: 3 [3192/3978 (80%)]\tLoss: 0.983124\n",
            "Train Epoch: 3 [3193/3978 (80%)]\tLoss: 0.080775\n",
            "Train Epoch: 3 [3194/3978 (80%)]\tLoss: 0.930444\n",
            "Train Epoch: 3 [3195/3978 (80%)]\tLoss: 0.478067\n",
            "Train Epoch: 3 [3196/3978 (80%)]\tLoss: 1.271879\n",
            "Train Epoch: 3 [3197/3978 (80%)]\tLoss: 0.001242\n",
            "Train Epoch: 3 [3198/3978 (80%)]\tLoss: 0.005826\n",
            "Train Epoch: 3 [3199/3978 (80%)]\tLoss: 1.360348\n",
            "Train Epoch: 3 [3200/3978 (80%)]\tLoss: 2.211418\n",
            "Train Epoch: 3 [3201/3978 (80%)]\tLoss: 0.346036\n",
            "Train Epoch: 3 [3202/3978 (80%)]\tLoss: 0.223658\n",
            "Train Epoch: 3 [3203/3978 (81%)]\tLoss: 0.009242\n",
            "Train Epoch: 3 [3204/3978 (81%)]\tLoss: 0.136284\n",
            "Train Epoch: 3 [3205/3978 (81%)]\tLoss: 5.491411\n",
            "Train Epoch: 3 [3206/3978 (81%)]\tLoss: 1.431929\n",
            "Train Epoch: 3 [3207/3978 (81%)]\tLoss: 0.007345\n",
            "Train Epoch: 3 [3208/3978 (81%)]\tLoss: 0.032514\n",
            "Train Epoch: 3 [3209/3978 (81%)]\tLoss: 0.011855\n",
            "Train Epoch: 3 [3210/3978 (81%)]\tLoss: 0.232635\n",
            "Train Epoch: 3 [3211/3978 (81%)]\tLoss: 0.008319\n",
            "Train Epoch: 3 [3212/3978 (81%)]\tLoss: 1.167053\n",
            "Train Epoch: 3 [3213/3978 (81%)]\tLoss: 0.410373\n",
            "Train Epoch: 3 [3214/3978 (81%)]\tLoss: 0.001630\n",
            "Train Epoch: 3 [3215/3978 (81%)]\tLoss: 0.007264\n",
            "Train Epoch: 3 [3216/3978 (81%)]\tLoss: 6.096152\n",
            "Train Epoch: 3 [3217/3978 (81%)]\tLoss: 0.000015\n",
            "Train Epoch: 3 [3218/3978 (81%)]\tLoss: 0.709284\n",
            "Train Epoch: 3 [3219/3978 (81%)]\tLoss: 0.425879\n",
            "Train Epoch: 3 [3220/3978 (81%)]\tLoss: 0.000004\n",
            "Train Epoch: 3 [3221/3978 (81%)]\tLoss: 0.844467\n",
            "Train Epoch: 3 [3222/3978 (81%)]\tLoss: 0.000575\n",
            "Train Epoch: 3 [3223/3978 (81%)]\tLoss: 1.155452\n",
            "Train Epoch: 3 [3224/3978 (81%)]\tLoss: 0.036453\n",
            "Train Epoch: 3 [3225/3978 (81%)]\tLoss: 4.068954\n",
            "Train Epoch: 3 [3226/3978 (81%)]\tLoss: 0.516099\n",
            "Train Epoch: 3 [3227/3978 (81%)]\tLoss: 0.366096\n",
            "Train Epoch: 3 [3228/3978 (81%)]\tLoss: 0.029113\n",
            "Train Epoch: 3 [3229/3978 (81%)]\tLoss: 0.699135\n",
            "Train Epoch: 3 [3230/3978 (81%)]\tLoss: 0.035304\n",
            "Train Epoch: 3 [3231/3978 (81%)]\tLoss: 0.024833\n",
            "Train Epoch: 3 [3232/3978 (81%)]\tLoss: 1.304051\n",
            "Train Epoch: 3 [3233/3978 (81%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3234/3978 (81%)]\tLoss: 1.809371\n",
            "Train Epoch: 3 [3235/3978 (81%)]\tLoss: 0.248610\n",
            "Train Epoch: 3 [3236/3978 (81%)]\tLoss: 0.383184\n",
            "Train Epoch: 3 [3237/3978 (81%)]\tLoss: 0.259588\n",
            "Train Epoch: 3 [3238/3978 (81%)]\tLoss: 1.701866\n",
            "Train Epoch: 3 [3239/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3240/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3241/3978 (81%)]\tLoss: 2.439111\n",
            "Train Epoch: 3 [3242/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3243/3978 (82%)]\tLoss: 0.000019\n",
            "Train Epoch: 3 [3244/3978 (82%)]\tLoss: 1.029240\n",
            "Train Epoch: 3 [3245/3978 (82%)]\tLoss: 1.199953\n",
            "Train Epoch: 3 [3246/3978 (82%)]\tLoss: 2.293633\n",
            "Train Epoch: 3 [3247/3978 (82%)]\tLoss: 0.183092\n",
            "Train Epoch: 3 [3248/3978 (82%)]\tLoss: 1.114046\n",
            "Train Epoch: 3 [3249/3978 (82%)]\tLoss: 0.001232\n",
            "Train Epoch: 3 [3250/3978 (82%)]\tLoss: 0.427081\n",
            "Train Epoch: 3 [3251/3978 (82%)]\tLoss: 2.448550\n",
            "Train Epoch: 3 [3252/3978 (82%)]\tLoss: 2.488026\n",
            "Train Epoch: 3 [3253/3978 (82%)]\tLoss: 0.001469\n",
            "Train Epoch: 3 [3254/3978 (82%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3255/3978 (82%)]\tLoss: 1.146897\n",
            "Train Epoch: 3 [3256/3978 (82%)]\tLoss: 0.036307\n",
            "Train Epoch: 3 [3257/3978 (82%)]\tLoss: 0.047568\n",
            "Train Epoch: 3 [3258/3978 (82%)]\tLoss: 0.002745\n",
            "Train Epoch: 3 [3259/3978 (82%)]\tLoss: 0.002118\n",
            "Train Epoch: 3 [3260/3978 (82%)]\tLoss: 0.182280\n",
            "Train Epoch: 3 [3261/3978 (82%)]\tLoss: 0.013999\n",
            "Train Epoch: 3 [3262/3978 (82%)]\tLoss: 0.013692\n",
            "Train Epoch: 3 [3263/3978 (82%)]\tLoss: 0.742397\n",
            "Train Epoch: 3 [3264/3978 (82%)]\tLoss: 0.081843\n",
            "Train Epoch: 3 [3265/3978 (82%)]\tLoss: 0.000517\n",
            "Train Epoch: 3 [3266/3978 (82%)]\tLoss: 0.000292\n",
            "Train Epoch: 3 [3267/3978 (82%)]\tLoss: 0.028740\n",
            "Train Epoch: 3 [3268/3978 (82%)]\tLoss: 0.000457\n",
            "Train Epoch: 3 [3269/3978 (82%)]\tLoss: 0.006985\n",
            "Train Epoch: 3 [3270/3978 (82%)]\tLoss: 0.067071\n",
            "Train Epoch: 3 [3271/3978 (82%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3272/3978 (82%)]\tLoss: 1.039962\n",
            "Train Epoch: 3 [3273/3978 (82%)]\tLoss: 0.040567\n",
            "Train Epoch: 3 [3274/3978 (82%)]\tLoss: 2.309961\n",
            "Train Epoch: 3 [3275/3978 (82%)]\tLoss: 0.569606\n",
            "Train Epoch: 3 [3276/3978 (82%)]\tLoss: 0.092721\n",
            "Train Epoch: 3 [3277/3978 (82%)]\tLoss: 0.002485\n",
            "Train Epoch: 3 [3278/3978 (82%)]\tLoss: 0.634296\n",
            "Train Epoch: 3 [3279/3978 (82%)]\tLoss: 0.002716\n",
            "Train Epoch: 3 [3280/3978 (82%)]\tLoss: 0.004248\n",
            "Train Epoch: 3 [3281/3978 (82%)]\tLoss: 0.001190\n",
            "Train Epoch: 3 [3282/3978 (83%)]\tLoss: 0.026810\n",
            "Train Epoch: 3 [3283/3978 (83%)]\tLoss: 0.050939\n",
            "Train Epoch: 3 [3284/3978 (83%)]\tLoss: 1.085437\n",
            "Train Epoch: 3 [3285/3978 (83%)]\tLoss: 0.271559\n",
            "Train Epoch: 3 [3286/3978 (83%)]\tLoss: 3.350334\n",
            "Train Epoch: 3 [3287/3978 (83%)]\tLoss: 0.588282\n",
            "Train Epoch: 3 [3288/3978 (83%)]\tLoss: 0.403494\n",
            "Train Epoch: 3 [3289/3978 (83%)]\tLoss: 0.000005\n",
            "Train Epoch: 3 [3290/3978 (83%)]\tLoss: 3.818049\n",
            "Train Epoch: 3 [3291/3978 (83%)]\tLoss: 3.296038\n",
            "Train Epoch: 3 [3292/3978 (83%)]\tLoss: 0.801763\n",
            "Train Epoch: 3 [3293/3978 (83%)]\tLoss: 0.709618\n",
            "Train Epoch: 3 [3294/3978 (83%)]\tLoss: 1.211954\n",
            "Train Epoch: 3 [3295/3978 (83%)]\tLoss: 0.604502\n",
            "Train Epoch: 3 [3296/3978 (83%)]\tLoss: 0.740357\n",
            "Train Epoch: 3 [3297/3978 (83%)]\tLoss: 1.298295\n",
            "Train Epoch: 3 [3298/3978 (83%)]\tLoss: 0.038719\n",
            "Train Epoch: 3 [3299/3978 (83%)]\tLoss: 0.254734\n",
            "Train Epoch: 3 [3300/3978 (83%)]\tLoss: 0.365846\n",
            "Train Epoch: 3 [3301/3978 (83%)]\tLoss: 0.011751\n",
            "Train Epoch: 3 [3302/3978 (83%)]\tLoss: 0.298158\n",
            "Train Epoch: 3 [3303/3978 (83%)]\tLoss: 0.020588\n",
            "Train Epoch: 3 [3304/3978 (83%)]\tLoss: 0.009630\n",
            "Train Epoch: 3 [3305/3978 (83%)]\tLoss: 0.007937\n",
            "Train Epoch: 3 [3306/3978 (83%)]\tLoss: 0.044415\n",
            "Train Epoch: 3 [3307/3978 (83%)]\tLoss: 0.011967\n",
            "Train Epoch: 3 [3308/3978 (83%)]\tLoss: 3.002827\n",
            "Train Epoch: 3 [3309/3978 (83%)]\tLoss: 2.618542\n",
            "Train Epoch: 3 [3310/3978 (83%)]\tLoss: 0.000561\n",
            "Train Epoch: 3 [3311/3978 (83%)]\tLoss: 0.125596\n",
            "Train Epoch: 3 [3312/3978 (83%)]\tLoss: 2.720125\n",
            "Train Epoch: 3 [3313/3978 (83%)]\tLoss: 0.061754\n",
            "Train Epoch: 3 [3314/3978 (83%)]\tLoss: 0.064709\n",
            "Train Epoch: 3 [3315/3978 (83%)]\tLoss: 0.008580\n",
            "Train Epoch: 3 [3316/3978 (83%)]\tLoss: 1.455783\n",
            "Train Epoch: 3 [3317/3978 (83%)]\tLoss: 0.023452\n",
            "Train Epoch: 3 [3318/3978 (83%)]\tLoss: 2.088642\n",
            "Train Epoch: 3 [3319/3978 (83%)]\tLoss: 0.038519\n",
            "Train Epoch: 3 [3320/3978 (83%)]\tLoss: 2.200572\n",
            "Train Epoch: 3 [3321/3978 (83%)]\tLoss: 2.441272\n",
            "Train Epoch: 3 [3322/3978 (84%)]\tLoss: 0.993915\n",
            "Train Epoch: 3 [3323/3978 (84%)]\tLoss: 0.942537\n",
            "Train Epoch: 3 [3324/3978 (84%)]\tLoss: 1.496230\n",
            "Train Epoch: 3 [3325/3978 (84%)]\tLoss: 0.000272\n",
            "Train Epoch: 3 [3326/3978 (84%)]\tLoss: 0.297370\n",
            "Train Epoch: 3 [3327/3978 (84%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3328/3978 (84%)]\tLoss: 1.406438\n",
            "Train Epoch: 3 [3329/3978 (84%)]\tLoss: 3.404174\n",
            "Train Epoch: 3 [3330/3978 (84%)]\tLoss: 5.346520\n",
            "Train Epoch: 3 [3331/3978 (84%)]\tLoss: 1.051743\n",
            "Train Epoch: 3 [3332/3978 (84%)]\tLoss: 0.000209\n",
            "Train Epoch: 3 [3333/3978 (84%)]\tLoss: 0.113239\n",
            "Train Epoch: 3 [3334/3978 (84%)]\tLoss: 0.020538\n",
            "Train Epoch: 3 [3335/3978 (84%)]\tLoss: 0.354963\n",
            "Train Epoch: 3 [3336/3978 (84%)]\tLoss: 0.043617\n",
            "Train Epoch: 3 [3337/3978 (84%)]\tLoss: 1.138627\n",
            "Train Epoch: 3 [3338/3978 (84%)]\tLoss: 0.064566\n",
            "Train Epoch: 3 [3339/3978 (84%)]\tLoss: 1.640996\n",
            "Train Epoch: 3 [3340/3978 (84%)]\tLoss: 0.215723\n",
            "Train Epoch: 3 [3341/3978 (84%)]\tLoss: 3.548908\n",
            "Train Epoch: 3 [3342/3978 (84%)]\tLoss: 0.000977\n",
            "Train Epoch: 3 [3343/3978 (84%)]\tLoss: 0.768217\n",
            "Train Epoch: 3 [3344/3978 (84%)]\tLoss: 0.298649\n",
            "Train Epoch: 3 [3345/3978 (84%)]\tLoss: 0.040879\n",
            "Train Epoch: 3 [3346/3978 (84%)]\tLoss: 0.004531\n",
            "Train Epoch: 3 [3347/3978 (84%)]\tLoss: 0.010752\n",
            "Train Epoch: 3 [3348/3978 (84%)]\tLoss: 0.049747\n",
            "Train Epoch: 3 [3349/3978 (84%)]\tLoss: 0.000154\n",
            "Train Epoch: 3 [3350/3978 (84%)]\tLoss: 0.542378\n",
            "Train Epoch: 3 [3351/3978 (84%)]\tLoss: 0.000015\n",
            "Train Epoch: 3 [3352/3978 (84%)]\tLoss: 0.265112\n",
            "Train Epoch: 3 [3353/3978 (84%)]\tLoss: 0.823643\n",
            "Train Epoch: 3 [3354/3978 (84%)]\tLoss: 0.000547\n",
            "Train Epoch: 3 [3355/3978 (84%)]\tLoss: 8.532463\n",
            "Train Epoch: 3 [3356/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3357/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3358/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3359/3978 (84%)]\tLoss: 6.574726\n",
            "Train Epoch: 3 [3360/3978 (84%)]\tLoss: 8.190929\n",
            "Train Epoch: 3 [3361/3978 (84%)]\tLoss: 2.561873\n",
            "Train Epoch: 3 [3362/3978 (85%)]\tLoss: 0.909367\n",
            "Train Epoch: 3 [3363/3978 (85%)]\tLoss: 2.312783\n",
            "Train Epoch: 3 [3364/3978 (85%)]\tLoss: 0.284944\n",
            "Train Epoch: 3 [3365/3978 (85%)]\tLoss: 0.000032\n",
            "Train Epoch: 3 [3366/3978 (85%)]\tLoss: 1.874952\n",
            "Train Epoch: 3 [3367/3978 (85%)]\tLoss: 1.225264\n",
            "Train Epoch: 3 [3368/3978 (85%)]\tLoss: 0.002398\n",
            "Train Epoch: 3 [3369/3978 (85%)]\tLoss: 1.055938\n",
            "Train Epoch: 3 [3370/3978 (85%)]\tLoss: 0.021818\n",
            "Train Epoch: 3 [3371/3978 (85%)]\tLoss: 0.602912\n",
            "Train Epoch: 3 [3372/3978 (85%)]\tLoss: 0.041602\n",
            "Train Epoch: 3 [3373/3978 (85%)]\tLoss: 1.076584\n",
            "Train Epoch: 3 [3374/3978 (85%)]\tLoss: 1.479684\n",
            "Train Epoch: 3 [3375/3978 (85%)]\tLoss: 1.528699\n",
            "Train Epoch: 3 [3376/3978 (85%)]\tLoss: 0.001105\n",
            "Train Epoch: 3 [3377/3978 (85%)]\tLoss: 0.000828\n",
            "Train Epoch: 3 [3378/3978 (85%)]\tLoss: 0.250452\n",
            "Train Epoch: 3 [3379/3978 (85%)]\tLoss: 0.619608\n",
            "Train Epoch: 3 [3380/3978 (85%)]\tLoss: 0.583681\n",
            "Train Epoch: 3 [3381/3978 (85%)]\tLoss: 1.608157\n",
            "Train Epoch: 3 [3382/3978 (85%)]\tLoss: 0.000059\n",
            "Train Epoch: 3 [3383/3978 (85%)]\tLoss: 0.310305\n",
            "Train Epoch: 3 [3384/3978 (85%)]\tLoss: 0.000006\n",
            "Train Epoch: 3 [3385/3978 (85%)]\tLoss: 2.673047\n",
            "Train Epoch: 3 [3386/3978 (85%)]\tLoss: 0.929570\n",
            "Train Epoch: 3 [3387/3978 (85%)]\tLoss: 0.131623\n",
            "Train Epoch: 3 [3388/3978 (85%)]\tLoss: 0.282237\n",
            "Train Epoch: 3 [3389/3978 (85%)]\tLoss: 0.024495\n",
            "Train Epoch: 3 [3390/3978 (85%)]\tLoss: 0.009895\n",
            "Train Epoch: 3 [3391/3978 (85%)]\tLoss: 0.148097\n",
            "Train Epoch: 3 [3392/3978 (85%)]\tLoss: 0.125644\n",
            "Train Epoch: 3 [3393/3978 (85%)]\tLoss: 0.444864\n",
            "Train Epoch: 3 [3394/3978 (85%)]\tLoss: 1.215082\n",
            "Train Epoch: 3 [3395/3978 (85%)]\tLoss: 0.009807\n",
            "Train Epoch: 3 [3396/3978 (85%)]\tLoss: 2.141115\n",
            "Train Epoch: 3 [3397/3978 (85%)]\tLoss: 1.497184\n",
            "Train Epoch: 3 [3398/3978 (85%)]\tLoss: 0.089805\n",
            "Train Epoch: 3 [3399/3978 (85%)]\tLoss: 0.107970\n",
            "Train Epoch: 3 [3400/3978 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3401/3978 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3402/3978 (86%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3403/3978 (86%)]\tLoss: 2.652837\n",
            "Train Epoch: 3 [3404/3978 (86%)]\tLoss: 2.895320\n",
            "Train Epoch: 3 [3405/3978 (86%)]\tLoss: 1.918338\n",
            "Train Epoch: 3 [3406/3978 (86%)]\tLoss: 1.925041\n",
            "Train Epoch: 3 [3407/3978 (86%)]\tLoss: 0.001619\n",
            "Train Epoch: 3 [3408/3978 (86%)]\tLoss: 1.026469\n",
            "Train Epoch: 3 [3409/3978 (86%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3410/3978 (86%)]\tLoss: 0.213342\n",
            "Train Epoch: 3 [3411/3978 (86%)]\tLoss: 1.795720\n",
            "Train Epoch: 3 [3412/3978 (86%)]\tLoss: 1.461394\n",
            "Train Epoch: 3 [3413/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3414/3978 (86%)]\tLoss: 1.188026\n",
            "Train Epoch: 3 [3415/3978 (86%)]\tLoss: 0.175951\n",
            "Train Epoch: 3 [3416/3978 (86%)]\tLoss: 0.016285\n",
            "Train Epoch: 3 [3417/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3418/3978 (86%)]\tLoss: 0.000012\n",
            "Train Epoch: 3 [3419/3978 (86%)]\tLoss: 0.013160\n",
            "Train Epoch: 3 [3420/3978 (86%)]\tLoss: 3.239168\n",
            "Train Epoch: 3 [3421/3978 (86%)]\tLoss: 0.009594\n",
            "Train Epoch: 3 [3422/3978 (86%)]\tLoss: 0.016812\n",
            "Train Epoch: 3 [3423/3978 (86%)]\tLoss: 0.064837\n",
            "Train Epoch: 3 [3424/3978 (86%)]\tLoss: 1.518893\n",
            "Train Epoch: 3 [3425/3978 (86%)]\tLoss: 0.001895\n",
            "Train Epoch: 3 [3426/3978 (86%)]\tLoss: 0.943668\n",
            "Train Epoch: 3 [3427/3978 (86%)]\tLoss: 1.854888\n",
            "Train Epoch: 3 [3428/3978 (86%)]\tLoss: 0.018667\n",
            "Train Epoch: 3 [3429/3978 (86%)]\tLoss: 0.481048\n",
            "Train Epoch: 3 [3430/3978 (86%)]\tLoss: 0.373259\n",
            "Train Epoch: 3 [3431/3978 (86%)]\tLoss: 0.104651\n",
            "Train Epoch: 3 [3432/3978 (86%)]\tLoss: 1.096898\n",
            "Train Epoch: 3 [3433/3978 (86%)]\tLoss: 4.669427\n",
            "Train Epoch: 3 [3434/3978 (86%)]\tLoss: 0.000039\n",
            "Train Epoch: 3 [3435/3978 (86%)]\tLoss: 3.769694\n",
            "Train Epoch: 3 [3436/3978 (86%)]\tLoss: 0.000311\n",
            "Train Epoch: 3 [3437/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3438/3978 (86%)]\tLoss: 1.938909\n",
            "Train Epoch: 3 [3439/3978 (86%)]\tLoss: 0.924275\n",
            "Train Epoch: 3 [3440/3978 (86%)]\tLoss: 0.000533\n",
            "Train Epoch: 3 [3441/3978 (87%)]\tLoss: 0.006949\n",
            "Train Epoch: 3 [3442/3978 (87%)]\tLoss: 0.764801\n",
            "Train Epoch: 3 [3443/3978 (87%)]\tLoss: 0.671159\n",
            "Train Epoch: 3 [3444/3978 (87%)]\tLoss: 3.310347\n",
            "Train Epoch: 3 [3445/3978 (87%)]\tLoss: 0.788160\n",
            "Train Epoch: 3 [3446/3978 (87%)]\tLoss: 0.358390\n",
            "Train Epoch: 3 [3447/3978 (87%)]\tLoss: 2.323730\n",
            "Train Epoch: 3 [3448/3978 (87%)]\tLoss: 0.070209\n",
            "Train Epoch: 3 [3449/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3450/3978 (87%)]\tLoss: 2.384216\n",
            "Train Epoch: 3 [3451/3978 (87%)]\tLoss: 1.521861\n",
            "Train Epoch: 3 [3452/3978 (87%)]\tLoss: 1.595261\n",
            "Train Epoch: 3 [3453/3978 (87%)]\tLoss: 2.122325\n",
            "Train Epoch: 3 [3454/3978 (87%)]\tLoss: 0.080710\n",
            "Train Epoch: 3 [3455/3978 (87%)]\tLoss: 1.864277\n",
            "Train Epoch: 3 [3456/3978 (87%)]\tLoss: 6.397217\n",
            "Train Epoch: 3 [3457/3978 (87%)]\tLoss: 0.409975\n",
            "Train Epoch: 3 [3458/3978 (87%)]\tLoss: 0.008431\n",
            "Train Epoch: 3 [3459/3978 (87%)]\tLoss: 0.330781\n",
            "Train Epoch: 3 [3460/3978 (87%)]\tLoss: 0.014938\n",
            "Train Epoch: 3 [3461/3978 (87%)]\tLoss: 2.193649\n",
            "Train Epoch: 3 [3462/3978 (87%)]\tLoss: 0.021393\n",
            "Train Epoch: 3 [3463/3978 (87%)]\tLoss: 0.535610\n",
            "Train Epoch: 3 [3464/3978 (87%)]\tLoss: 0.574362\n",
            "Train Epoch: 3 [3465/3978 (87%)]\tLoss: 0.104634\n",
            "Train Epoch: 3 [3466/3978 (87%)]\tLoss: 0.026176\n",
            "Train Epoch: 3 [3467/3978 (87%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3468/3978 (87%)]\tLoss: 0.000209\n",
            "Train Epoch: 3 [3469/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3470/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3471/3978 (87%)]\tLoss: 5.070814\n",
            "Train Epoch: 3 [3472/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3473/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3474/3978 (87%)]\tLoss: 3.555761\n",
            "Train Epoch: 3 [3475/3978 (87%)]\tLoss: 2.487884\n",
            "Train Epoch: 3 [3476/3978 (87%)]\tLoss: 0.001842\n",
            "Train Epoch: 3 [3477/3978 (87%)]\tLoss: 0.214593\n",
            "Train Epoch: 3 [3478/3978 (87%)]\tLoss: 2.065319\n",
            "Train Epoch: 3 [3479/3978 (87%)]\tLoss: 2.944963\n",
            "Train Epoch: 3 [3480/3978 (87%)]\tLoss: 0.000234\n",
            "Train Epoch: 3 [3481/3978 (88%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3482/3978 (88%)]\tLoss: 0.423026\n",
            "Train Epoch: 3 [3483/3978 (88%)]\tLoss: 0.005031\n",
            "Train Epoch: 3 [3484/3978 (88%)]\tLoss: 2.821090\n",
            "Train Epoch: 3 [3485/3978 (88%)]\tLoss: 1.765786\n",
            "Train Epoch: 3 [3486/3978 (88%)]\tLoss: 1.897990\n",
            "Train Epoch: 3 [3487/3978 (88%)]\tLoss: 2.762975\n",
            "Train Epoch: 3 [3488/3978 (88%)]\tLoss: 0.000170\n",
            "Train Epoch: 3 [3489/3978 (88%)]\tLoss: 0.515197\n",
            "Train Epoch: 3 [3490/3978 (88%)]\tLoss: 0.525034\n",
            "Train Epoch: 3 [3491/3978 (88%)]\tLoss: 0.766399\n",
            "Train Epoch: 3 [3492/3978 (88%)]\tLoss: 0.039444\n",
            "Train Epoch: 3 [3493/3978 (88%)]\tLoss: 1.652059\n",
            "Train Epoch: 3 [3494/3978 (88%)]\tLoss: 1.997855\n",
            "Train Epoch: 3 [3495/3978 (88%)]\tLoss: 1.339504\n",
            "Train Epoch: 3 [3496/3978 (88%)]\tLoss: 0.655820\n",
            "Train Epoch: 3 [3497/3978 (88%)]\tLoss: 0.684379\n",
            "Train Epoch: 3 [3498/3978 (88%)]\tLoss: 0.043170\n",
            "Train Epoch: 3 [3499/3978 (88%)]\tLoss: 0.722318\n",
            "Train Epoch: 3 [3500/3978 (88%)]\tLoss: 0.428080\n",
            "Train Epoch: 3 [3501/3978 (88%)]\tLoss: 0.328467\n",
            "Train Epoch: 3 [3502/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3503/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3504/3978 (88%)]\tLoss: 0.868117\n",
            "Train Epoch: 3 [3505/3978 (88%)]\tLoss: 1.812602\n",
            "Train Epoch: 3 [3506/3978 (88%)]\tLoss: 1.389580\n",
            "Train Epoch: 3 [3507/3978 (88%)]\tLoss: 1.249856\n",
            "Train Epoch: 3 [3508/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3509/3978 (88%)]\tLoss: 0.000044\n",
            "Train Epoch: 3 [3510/3978 (88%)]\tLoss: 0.226086\n",
            "Train Epoch: 3 [3511/3978 (88%)]\tLoss: 0.908543\n",
            "Train Epoch: 3 [3512/3978 (88%)]\tLoss: 1.067719\n",
            "Train Epoch: 3 [3513/3978 (88%)]\tLoss: 0.341061\n",
            "Train Epoch: 3 [3514/3978 (88%)]\tLoss: 0.521943\n",
            "Train Epoch: 3 [3515/3978 (88%)]\tLoss: 0.119091\n",
            "Train Epoch: 3 [3516/3978 (88%)]\tLoss: 0.592636\n",
            "Train Epoch: 3 [3517/3978 (88%)]\tLoss: 4.774924\n",
            "Train Epoch: 3 [3518/3978 (88%)]\tLoss: 0.286293\n",
            "Train Epoch: 3 [3519/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3520/3978 (88%)]\tLoss: 1.721342\n",
            "Train Epoch: 3 [3521/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3522/3978 (89%)]\tLoss: 0.480010\n",
            "Train Epoch: 3 [3523/3978 (89%)]\tLoss: 0.996769\n",
            "Train Epoch: 3 [3524/3978 (89%)]\tLoss: 2.581419\n",
            "Train Epoch: 3 [3525/3978 (89%)]\tLoss: 3.702060\n",
            "Train Epoch: 3 [3526/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3527/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3528/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3529/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3530/3978 (89%)]\tLoss: 4.358490\n",
            "Train Epoch: 3 [3531/3978 (89%)]\tLoss: 0.000190\n",
            "Train Epoch: 3 [3532/3978 (89%)]\tLoss: 4.482927\n",
            "Train Epoch: 3 [3533/3978 (89%)]\tLoss: 0.105620\n",
            "Train Epoch: 3 [3534/3978 (89%)]\tLoss: 3.917670\n",
            "Train Epoch: 3 [3535/3978 (89%)]\tLoss: 3.449991\n",
            "Train Epoch: 3 [3536/3978 (89%)]\tLoss: 0.844046\n",
            "Train Epoch: 3 [3537/3978 (89%)]\tLoss: 4.263706\n",
            "Train Epoch: 3 [3538/3978 (89%)]\tLoss: 2.933893\n",
            "Train Epoch: 3 [3539/3978 (89%)]\tLoss: 1.814523\n",
            "Train Epoch: 3 [3540/3978 (89%)]\tLoss: 1.588810\n",
            "Train Epoch: 3 [3541/3978 (89%)]\tLoss: 1.515070\n",
            "Train Epoch: 3 [3542/3978 (89%)]\tLoss: 0.066795\n",
            "Train Epoch: 3 [3543/3978 (89%)]\tLoss: 2.945917\n",
            "Train Epoch: 3 [3544/3978 (89%)]\tLoss: 0.001348\n",
            "Train Epoch: 3 [3545/3978 (89%)]\tLoss: 0.181678\n",
            "Train Epoch: 3 [3546/3978 (89%)]\tLoss: 1.316458\n",
            "Train Epoch: 3 [3547/3978 (89%)]\tLoss: 0.671420\n",
            "Train Epoch: 3 [3548/3978 (89%)]\tLoss: 0.044352\n",
            "Train Epoch: 3 [3549/3978 (89%)]\tLoss: 2.499222\n",
            "Train Epoch: 3 [3550/3978 (89%)]\tLoss: 0.002132\n",
            "Train Epoch: 3 [3551/3978 (89%)]\tLoss: 0.578913\n",
            "Train Epoch: 3 [3552/3978 (89%)]\tLoss: 2.384683\n",
            "Train Epoch: 3 [3553/3978 (89%)]\tLoss: 0.436940\n",
            "Train Epoch: 3 [3554/3978 (89%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3555/3978 (89%)]\tLoss: 0.000349\n",
            "Train Epoch: 3 [3556/3978 (89%)]\tLoss: 0.000119\n",
            "Train Epoch: 3 [3557/3978 (89%)]\tLoss: 1.648871\n",
            "Train Epoch: 3 [3558/3978 (89%)]\tLoss: 2.037119\n",
            "Train Epoch: 3 [3559/3978 (89%)]\tLoss: 1.738320\n",
            "Train Epoch: 3 [3560/3978 (89%)]\tLoss: 2.895886\n",
            "Train Epoch: 3 [3561/3978 (90%)]\tLoss: 0.276873\n",
            "Train Epoch: 3 [3562/3978 (90%)]\tLoss: 2.612703\n",
            "Train Epoch: 3 [3563/3978 (90%)]\tLoss: 3.134883\n",
            "Train Epoch: 3 [3564/3978 (90%)]\tLoss: 1.198399\n",
            "Train Epoch: 3 [3565/3978 (90%)]\tLoss: 0.790213\n",
            "Train Epoch: 3 [3566/3978 (90%)]\tLoss: 1.303842\n",
            "Train Epoch: 3 [3567/3978 (90%)]\tLoss: 0.883970\n",
            "Train Epoch: 3 [3568/3978 (90%)]\tLoss: 0.000043\n",
            "Train Epoch: 3 [3569/3978 (90%)]\tLoss: 0.000013\n",
            "Train Epoch: 3 [3570/3978 (90%)]\tLoss: 0.017243\n",
            "Train Epoch: 3 [3571/3978 (90%)]\tLoss: 4.350423\n",
            "Train Epoch: 3 [3572/3978 (90%)]\tLoss: 1.342165\n",
            "Train Epoch: 3 [3573/3978 (90%)]\tLoss: 1.681460\n",
            "Train Epoch: 3 [3574/3978 (90%)]\tLoss: 0.000025\n",
            "Train Epoch: 3 [3575/3978 (90%)]\tLoss: 0.162519\n",
            "Train Epoch: 3 [3576/3978 (90%)]\tLoss: 0.001424\n",
            "Train Epoch: 3 [3577/3978 (90%)]\tLoss: 0.382922\n",
            "Train Epoch: 3 [3578/3978 (90%)]\tLoss: 0.659440\n",
            "Train Epoch: 3 [3579/3978 (90%)]\tLoss: 0.442065\n",
            "Train Epoch: 3 [3580/3978 (90%)]\tLoss: 0.747118\n",
            "Train Epoch: 3 [3581/3978 (90%)]\tLoss: 1.701331\n",
            "Train Epoch: 3 [3582/3978 (90%)]\tLoss: 0.150280\n",
            "Train Epoch: 3 [3583/3978 (90%)]\tLoss: 2.507711\n",
            "Train Epoch: 3 [3584/3978 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3585/3978 (90%)]\tLoss: 2.796902\n",
            "Train Epoch: 3 [3586/3978 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3587/3978 (90%)]\tLoss: 9.153379\n",
            "Train Epoch: 3 [3588/3978 (90%)]\tLoss: 1.107304\n",
            "Train Epoch: 3 [3589/3978 (90%)]\tLoss: 0.093658\n",
            "Train Epoch: 3 [3590/3978 (90%)]\tLoss: 0.079421\n",
            "Train Epoch: 3 [3591/3978 (90%)]\tLoss: 2.480918\n",
            "Train Epoch: 3 [3592/3978 (90%)]\tLoss: 2.431625\n",
            "Train Epoch: 3 [3593/3978 (90%)]\tLoss: 4.205664\n",
            "Train Epoch: 3 [3594/3978 (90%)]\tLoss: 0.156017\n",
            "Train Epoch: 3 [3595/3978 (90%)]\tLoss: 0.125978\n",
            "Train Epoch: 3 [3596/3978 (90%)]\tLoss: 0.026552\n",
            "Train Epoch: 3 [3597/3978 (90%)]\tLoss: 0.652171\n",
            "Train Epoch: 3 [3598/3978 (90%)]\tLoss: 0.037418\n",
            "Train Epoch: 3 [3599/3978 (90%)]\tLoss: 0.334160\n",
            "Train Epoch: 3 [3600/3978 (90%)]\tLoss: 0.000016\n",
            "Train Epoch: 3 [3601/3978 (91%)]\tLoss: 0.872980\n",
            "Train Epoch: 3 [3602/3978 (91%)]\tLoss: 0.832076\n",
            "Train Epoch: 3 [3603/3978 (91%)]\tLoss: 0.000007\n",
            "Train Epoch: 3 [3604/3978 (91%)]\tLoss: 0.165000\n",
            "Train Epoch: 3 [3605/3978 (91%)]\tLoss: 0.002922\n",
            "Train Epoch: 3 [3606/3978 (91%)]\tLoss: 1.081342\n",
            "Train Epoch: 3 [3607/3978 (91%)]\tLoss: 0.161797\n",
            "Train Epoch: 3 [3608/3978 (91%)]\tLoss: 3.906134\n",
            "Train Epoch: 3 [3609/3978 (91%)]\tLoss: 6.570473\n",
            "Train Epoch: 3 [3610/3978 (91%)]\tLoss: 0.015697\n",
            "Train Epoch: 3 [3611/3978 (91%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3612/3978 (91%)]\tLoss: 0.252898\n",
            "Train Epoch: 3 [3613/3978 (91%)]\tLoss: 0.318197\n",
            "Train Epoch: 3 [3614/3978 (91%)]\tLoss: 1.876156\n",
            "Train Epoch: 3 [3615/3978 (91%)]\tLoss: 0.125463\n",
            "Train Epoch: 3 [3616/3978 (91%)]\tLoss: 0.258525\n",
            "Train Epoch: 3 [3617/3978 (91%)]\tLoss: 0.000065\n",
            "Train Epoch: 3 [3618/3978 (91%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3619/3978 (91%)]\tLoss: 11.215664\n",
            "Train Epoch: 3 [3620/3978 (91%)]\tLoss: 3.074187\n",
            "Train Epoch: 3 [3621/3978 (91%)]\tLoss: 0.000047\n",
            "Train Epoch: 3 [3622/3978 (91%)]\tLoss: 4.436035\n",
            "Train Epoch: 3 [3623/3978 (91%)]\tLoss: 2.784138\n",
            "Train Epoch: 3 [3624/3978 (91%)]\tLoss: 2.176072\n",
            "Train Epoch: 3 [3625/3978 (91%)]\tLoss: 0.523184\n",
            "Train Epoch: 3 [3626/3978 (91%)]\tLoss: 1.906366\n",
            "Train Epoch: 3 [3627/3978 (91%)]\tLoss: 1.315274\n",
            "Train Epoch: 3 [3628/3978 (91%)]\tLoss: 0.394310\n",
            "Train Epoch: 3 [3629/3978 (91%)]\tLoss: 1.257868\n",
            "Train Epoch: 3 [3630/3978 (91%)]\tLoss: 3.139080\n",
            "Train Epoch: 3 [3631/3978 (91%)]\tLoss: 0.014645\n",
            "Train Epoch: 3 [3632/3978 (91%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3633/3978 (91%)]\tLoss: 1.044299\n",
            "Train Epoch: 3 [3634/3978 (91%)]\tLoss: 0.545696\n",
            "Train Epoch: 3 [3635/3978 (91%)]\tLoss: 0.028469\n",
            "Train Epoch: 3 [3636/3978 (91%)]\tLoss: 0.380584\n",
            "Train Epoch: 3 [3637/3978 (91%)]\tLoss: 0.008807\n",
            "Train Epoch: 3 [3638/3978 (91%)]\tLoss: 3.632907\n",
            "Train Epoch: 3 [3639/3978 (91%)]\tLoss: 1.139809\n",
            "Train Epoch: 3 [3640/3978 (92%)]\tLoss: 0.028637\n",
            "Train Epoch: 3 [3641/3978 (92%)]\tLoss: 0.303036\n",
            "Train Epoch: 3 [3642/3978 (92%)]\tLoss: 0.035483\n",
            "Train Epoch: 3 [3643/3978 (92%)]\tLoss: 0.000081\n",
            "Train Epoch: 3 [3644/3978 (92%)]\tLoss: 0.014072\n",
            "Train Epoch: 3 [3645/3978 (92%)]\tLoss: 0.066019\n",
            "Train Epoch: 3 [3646/3978 (92%)]\tLoss: 0.005571\n",
            "Train Epoch: 3 [3647/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3648/3978 (92%)]\tLoss: 0.002005\n",
            "Train Epoch: 3 [3649/3978 (92%)]\tLoss: 0.000123\n",
            "Train Epoch: 3 [3650/3978 (92%)]\tLoss: 0.000004\n",
            "Train Epoch: 3 [3651/3978 (92%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3652/3978 (92%)]\tLoss: 0.876355\n",
            "Train Epoch: 3 [3653/3978 (92%)]\tLoss: 1.281912\n",
            "Train Epoch: 3 [3654/3978 (92%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3655/3978 (92%)]\tLoss: 1.950491\n",
            "Train Epoch: 3 [3656/3978 (92%)]\tLoss: 0.002494\n",
            "Train Epoch: 3 [3657/3978 (92%)]\tLoss: 0.060098\n",
            "Train Epoch: 3 [3658/3978 (92%)]\tLoss: 0.000023\n",
            "Train Epoch: 3 [3659/3978 (92%)]\tLoss: 7.868700\n",
            "Train Epoch: 3 [3660/3978 (92%)]\tLoss: 2.148606\n",
            "Train Epoch: 3 [3661/3978 (92%)]\tLoss: 0.047694\n",
            "Train Epoch: 3 [3662/3978 (92%)]\tLoss: 0.000335\n",
            "Train Epoch: 3 [3663/3978 (92%)]\tLoss: 2.195173\n",
            "Train Epoch: 3 [3664/3978 (92%)]\tLoss: 0.028159\n",
            "Train Epoch: 3 [3665/3978 (92%)]\tLoss: 0.038694\n",
            "Train Epoch: 3 [3666/3978 (92%)]\tLoss: 0.000186\n",
            "Train Epoch: 3 [3667/3978 (92%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3668/3978 (92%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3669/3978 (92%)]\tLoss: 2.278924\n",
            "Train Epoch: 3 [3670/3978 (92%)]\tLoss: 1.015978\n",
            "Train Epoch: 3 [3671/3978 (92%)]\tLoss: 0.294749\n",
            "Train Epoch: 3 [3672/3978 (92%)]\tLoss: 0.000974\n",
            "Train Epoch: 3 [3673/3978 (92%)]\tLoss: 0.020612\n",
            "Train Epoch: 3 [3674/3978 (92%)]\tLoss: 0.055314\n",
            "Train Epoch: 3 [3675/3978 (92%)]\tLoss: 3.240341\n",
            "Train Epoch: 3 [3676/3978 (92%)]\tLoss: 0.505390\n",
            "Train Epoch: 3 [3677/3978 (92%)]\tLoss: 0.197205\n",
            "Train Epoch: 3 [3678/3978 (92%)]\tLoss: 0.904929\n",
            "Train Epoch: 3 [3679/3978 (92%)]\tLoss: 0.007872\n",
            "Train Epoch: 3 [3680/3978 (93%)]\tLoss: 0.414694\n",
            "Train Epoch: 3 [3681/3978 (93%)]\tLoss: 1.092645\n",
            "Train Epoch: 3 [3682/3978 (93%)]\tLoss: 0.321094\n",
            "Train Epoch: 3 [3683/3978 (93%)]\tLoss: 0.046530\n",
            "Train Epoch: 3 [3684/3978 (93%)]\tLoss: 0.581293\n",
            "Train Epoch: 3 [3685/3978 (93%)]\tLoss: 0.295467\n",
            "Train Epoch: 3 [3686/3978 (93%)]\tLoss: 0.396911\n",
            "Train Epoch: 3 [3687/3978 (93%)]\tLoss: 0.659657\n",
            "Train Epoch: 3 [3688/3978 (93%)]\tLoss: 1.058208\n",
            "Train Epoch: 3 [3689/3978 (93%)]\tLoss: 0.000111\n",
            "Train Epoch: 3 [3690/3978 (93%)]\tLoss: 0.711677\n",
            "Train Epoch: 3 [3691/3978 (93%)]\tLoss: 4.598504\n",
            "Train Epoch: 3 [3692/3978 (93%)]\tLoss: 0.207529\n",
            "Train Epoch: 3 [3693/3978 (93%)]\tLoss: 0.125633\n",
            "Train Epoch: 3 [3694/3978 (93%)]\tLoss: 0.777608\n",
            "Train Epoch: 3 [3695/3978 (93%)]\tLoss: 0.811962\n",
            "Train Epoch: 3 [3696/3978 (93%)]\tLoss: 0.015423\n",
            "Train Epoch: 3 [3697/3978 (93%)]\tLoss: 0.172526\n",
            "Train Epoch: 3 [3698/3978 (93%)]\tLoss: 0.457143\n",
            "Train Epoch: 3 [3699/3978 (93%)]\tLoss: 0.574027\n",
            "Train Epoch: 3 [3700/3978 (93%)]\tLoss: 1.968169\n",
            "Train Epoch: 3 [3701/3978 (93%)]\tLoss: 0.478882\n",
            "Train Epoch: 3 [3702/3978 (93%)]\tLoss: 0.720438\n",
            "Train Epoch: 3 [3703/3978 (93%)]\tLoss: 0.018324\n",
            "Train Epoch: 3 [3704/3978 (93%)]\tLoss: 6.696979\n",
            "Train Epoch: 3 [3705/3978 (93%)]\tLoss: 0.301287\n",
            "Train Epoch: 3 [3706/3978 (93%)]\tLoss: 1.074579\n",
            "Train Epoch: 3 [3707/3978 (93%)]\tLoss: 2.407458\n",
            "Train Epoch: 3 [3708/3978 (93%)]\tLoss: 0.052565\n",
            "Train Epoch: 3 [3709/3978 (93%)]\tLoss: 2.950641\n",
            "Train Epoch: 3 [3710/3978 (93%)]\tLoss: 0.002482\n",
            "Train Epoch: 3 [3711/3978 (93%)]\tLoss: 0.221494\n",
            "Train Epoch: 3 [3712/3978 (93%)]\tLoss: 0.205000\n",
            "Train Epoch: 3 [3713/3978 (93%)]\tLoss: 1.670823\n",
            "Train Epoch: 3 [3714/3978 (93%)]\tLoss: 1.372022\n",
            "Train Epoch: 3 [3715/3978 (93%)]\tLoss: 0.792559\n",
            "Train Epoch: 3 [3716/3978 (93%)]\tLoss: 0.486202\n",
            "Train Epoch: 3 [3717/3978 (93%)]\tLoss: 0.000738\n",
            "Train Epoch: 3 [3718/3978 (93%)]\tLoss: 0.979354\n",
            "Train Epoch: 3 [3719/3978 (93%)]\tLoss: 0.132412\n",
            "Train Epoch: 3 [3720/3978 (94%)]\tLoss: 0.372764\n",
            "Train Epoch: 3 [3721/3978 (94%)]\tLoss: 0.400354\n",
            "Train Epoch: 3 [3722/3978 (94%)]\tLoss: 1.137778\n",
            "Train Epoch: 3 [3723/3978 (94%)]\tLoss: 1.383988\n",
            "Train Epoch: 3 [3724/3978 (94%)]\tLoss: 0.000331\n",
            "Train Epoch: 3 [3725/3978 (94%)]\tLoss: 0.002029\n",
            "Train Epoch: 3 [3726/3978 (94%)]\tLoss: 0.519331\n",
            "Train Epoch: 3 [3727/3978 (94%)]\tLoss: 0.382104\n",
            "Train Epoch: 3 [3728/3978 (94%)]\tLoss: 0.023830\n",
            "Train Epoch: 3 [3729/3978 (94%)]\tLoss: 1.215379\n",
            "Train Epoch: 3 [3730/3978 (94%)]\tLoss: 6.231869\n",
            "Train Epoch: 3 [3731/3978 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3732/3978 (94%)]\tLoss: 0.007168\n",
            "Train Epoch: 3 [3733/3978 (94%)]\tLoss: 0.160216\n",
            "Train Epoch: 3 [3734/3978 (94%)]\tLoss: 2.044588\n",
            "Train Epoch: 3 [3735/3978 (94%)]\tLoss: 1.301574\n",
            "Train Epoch: 3 [3736/3978 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3737/3978 (94%)]\tLoss: 0.002892\n",
            "Train Epoch: 3 [3738/3978 (94%)]\tLoss: 1.006473\n",
            "Train Epoch: 3 [3739/3978 (94%)]\tLoss: 0.000092\n",
            "Train Epoch: 3 [3740/3978 (94%)]\tLoss: 1.677160\n",
            "Train Epoch: 3 [3741/3978 (94%)]\tLoss: 0.001963\n",
            "Train Epoch: 3 [3742/3978 (94%)]\tLoss: 0.280810\n",
            "Train Epoch: 3 [3743/3978 (94%)]\tLoss: 0.172768\n",
            "Train Epoch: 3 [3744/3978 (94%)]\tLoss: 0.004729\n",
            "Train Epoch: 3 [3745/3978 (94%)]\tLoss: 1.572270\n",
            "Train Epoch: 3 [3746/3978 (94%)]\tLoss: 0.011570\n",
            "Train Epoch: 3 [3747/3978 (94%)]\tLoss: 0.894547\n",
            "Train Epoch: 3 [3748/3978 (94%)]\tLoss: 0.000070\n",
            "Train Epoch: 3 [3749/3978 (94%)]\tLoss: 0.009060\n",
            "Train Epoch: 3 [3750/3978 (94%)]\tLoss: 0.466798\n",
            "Train Epoch: 3 [3751/3978 (94%)]\tLoss: 0.866340\n",
            "Train Epoch: 3 [3752/3978 (94%)]\tLoss: 1.079607\n",
            "Train Epoch: 3 [3753/3978 (94%)]\tLoss: 0.836456\n",
            "Train Epoch: 3 [3754/3978 (94%)]\tLoss: 0.758576\n",
            "Train Epoch: 3 [3755/3978 (94%)]\tLoss: 4.803925\n",
            "Train Epoch: 3 [3756/3978 (94%)]\tLoss: 0.032932\n",
            "Train Epoch: 3 [3757/3978 (94%)]\tLoss: 0.023502\n",
            "Train Epoch: 3 [3758/3978 (94%)]\tLoss: 1.833646\n",
            "Train Epoch: 3 [3759/3978 (94%)]\tLoss: 1.036500\n",
            "Train Epoch: 3 [3760/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3761/3978 (95%)]\tLoss: 0.166498\n",
            "Train Epoch: 3 [3762/3978 (95%)]\tLoss: 0.091026\n",
            "Train Epoch: 3 [3763/3978 (95%)]\tLoss: 0.262591\n",
            "Train Epoch: 3 [3764/3978 (95%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3765/3978 (95%)]\tLoss: 2.990863\n",
            "Train Epoch: 3 [3766/3978 (95%)]\tLoss: 0.123342\n",
            "Train Epoch: 3 [3767/3978 (95%)]\tLoss: 0.006131\n",
            "Train Epoch: 3 [3768/3978 (95%)]\tLoss: 0.034613\n",
            "Train Epoch: 3 [3769/3978 (95%)]\tLoss: 1.381795\n",
            "Train Epoch: 3 [3770/3978 (95%)]\tLoss: 0.039142\n",
            "Train Epoch: 3 [3771/3978 (95%)]\tLoss: 0.052876\n",
            "Train Epoch: 3 [3772/3978 (95%)]\tLoss: 1.705974\n",
            "Train Epoch: 3 [3773/3978 (95%)]\tLoss: 0.500794\n",
            "Train Epoch: 3 [3774/3978 (95%)]\tLoss: 0.275725\n",
            "Train Epoch: 3 [3775/3978 (95%)]\tLoss: 0.826688\n",
            "Train Epoch: 3 [3776/3978 (95%)]\tLoss: 1.183828\n",
            "Train Epoch: 3 [3777/3978 (95%)]\tLoss: 1.089957\n",
            "Train Epoch: 3 [3778/3978 (95%)]\tLoss: 0.882956\n",
            "Train Epoch: 3 [3779/3978 (95%)]\tLoss: 0.051470\n",
            "Train Epoch: 3 [3780/3978 (95%)]\tLoss: 0.193056\n",
            "Train Epoch: 3 [3781/3978 (95%)]\tLoss: 2.669797\n",
            "Train Epoch: 3 [3782/3978 (95%)]\tLoss: 0.103872\n",
            "Train Epoch: 3 [3783/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3784/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3785/3978 (95%)]\tLoss: 2.246352\n",
            "Train Epoch: 3 [3786/3978 (95%)]\tLoss: 2.660279\n",
            "Train Epoch: 3 [3787/3978 (95%)]\tLoss: 0.000209\n",
            "Train Epoch: 3 [3788/3978 (95%)]\tLoss: 1.760556\n",
            "Train Epoch: 3 [3789/3978 (95%)]\tLoss: 0.004678\n",
            "Train Epoch: 3 [3790/3978 (95%)]\tLoss: 0.910291\n",
            "Train Epoch: 3 [3791/3978 (95%)]\tLoss: 0.169474\n",
            "Train Epoch: 3 [3792/3978 (95%)]\tLoss: 0.648895\n",
            "Train Epoch: 3 [3793/3978 (95%)]\tLoss: 2.112956\n",
            "Train Epoch: 3 [3794/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3795/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3796/3978 (95%)]\tLoss: 3.308658\n",
            "Train Epoch: 3 [3797/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3798/3978 (95%)]\tLoss: 3.356175\n",
            "Train Epoch: 3 [3799/3978 (96%)]\tLoss: 3.698615\n",
            "Train Epoch: 3 [3800/3978 (96%)]\tLoss: 2.961821\n",
            "Train Epoch: 3 [3801/3978 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3802/3978 (96%)]\tLoss: 1.656709\n",
            "Train Epoch: 3 [3803/3978 (96%)]\tLoss: 0.000630\n",
            "Train Epoch: 3 [3804/3978 (96%)]\tLoss: 0.581399\n",
            "Train Epoch: 3 [3805/3978 (96%)]\tLoss: 0.179314\n",
            "Train Epoch: 3 [3806/3978 (96%)]\tLoss: 0.003564\n",
            "Train Epoch: 3 [3807/3978 (96%)]\tLoss: 0.001664\n",
            "Train Epoch: 3 [3808/3978 (96%)]\tLoss: 0.953584\n",
            "Train Epoch: 3 [3809/3978 (96%)]\tLoss: 0.210449\n",
            "Train Epoch: 3 [3810/3978 (96%)]\tLoss: 0.058316\n",
            "Train Epoch: 3 [3811/3978 (96%)]\tLoss: 0.000260\n",
            "Train Epoch: 3 [3812/3978 (96%)]\tLoss: 3.978329\n",
            "Train Epoch: 3 [3813/3978 (96%)]\tLoss: 0.000037\n",
            "Train Epoch: 3 [3814/3978 (96%)]\tLoss: 0.760202\n",
            "Train Epoch: 3 [3815/3978 (96%)]\tLoss: 0.190622\n",
            "Train Epoch: 3 [3816/3978 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3817/3978 (96%)]\tLoss: 0.000072\n",
            "Train Epoch: 3 [3818/3978 (96%)]\tLoss: 0.486603\n",
            "Train Epoch: 3 [3819/3978 (96%)]\tLoss: 6.135267\n",
            "Train Epoch: 3 [3820/3978 (96%)]\tLoss: 0.682017\n",
            "Train Epoch: 3 [3821/3978 (96%)]\tLoss: 0.980049\n",
            "Train Epoch: 3 [3822/3978 (96%)]\tLoss: 0.001007\n",
            "Train Epoch: 3 [3823/3978 (96%)]\tLoss: 1.798217\n",
            "Train Epoch: 3 [3824/3978 (96%)]\tLoss: 0.006581\n",
            "Train Epoch: 3 [3825/3978 (96%)]\tLoss: 0.141330\n",
            "Train Epoch: 3 [3826/3978 (96%)]\tLoss: 4.259458\n",
            "Train Epoch: 3 [3827/3978 (96%)]\tLoss: 2.996830\n",
            "Train Epoch: 3 [3828/3978 (96%)]\tLoss: 3.921542\n",
            "Train Epoch: 3 [3829/3978 (96%)]\tLoss: 0.000281\n",
            "Train Epoch: 3 [3830/3978 (96%)]\tLoss: 3.307492\n",
            "Train Epoch: 3 [3831/3978 (96%)]\tLoss: 0.939008\n",
            "Train Epoch: 3 [3832/3978 (96%)]\tLoss: 0.542290\n",
            "Train Epoch: 3 [3833/3978 (96%)]\tLoss: 0.104456\n",
            "Train Epoch: 3 [3834/3978 (96%)]\tLoss: 3.848726\n",
            "Train Epoch: 3 [3835/3978 (96%)]\tLoss: 0.982121\n",
            "Train Epoch: 3 [3836/3978 (96%)]\tLoss: 1.395509\n",
            "Train Epoch: 3 [3837/3978 (96%)]\tLoss: 1.689005\n",
            "Train Epoch: 3 [3838/3978 (96%)]\tLoss: 4.503709\n",
            "Train Epoch: 3 [3839/3978 (97%)]\tLoss: 0.828376\n",
            "Train Epoch: 3 [3840/3978 (97%)]\tLoss: 0.954442\n",
            "Train Epoch: 3 [3841/3978 (97%)]\tLoss: 0.123397\n",
            "Train Epoch: 3 [3842/3978 (97%)]\tLoss: 0.035808\n",
            "Train Epoch: 3 [3843/3978 (97%)]\tLoss: 0.537210\n",
            "Train Epoch: 3 [3844/3978 (97%)]\tLoss: 0.000007\n",
            "Train Epoch: 3 [3845/3978 (97%)]\tLoss: 1.553308\n",
            "Train Epoch: 3 [3846/3978 (97%)]\tLoss: 0.696172\n",
            "Train Epoch: 3 [3847/3978 (97%)]\tLoss: 0.383282\n",
            "Train Epoch: 3 [3848/3978 (97%)]\tLoss: 0.327240\n",
            "Train Epoch: 3 [3849/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3850/3978 (97%)]\tLoss: 3.632438\n",
            "Train Epoch: 3 [3851/3978 (97%)]\tLoss: 6.077579\n",
            "Train Epoch: 3 [3852/3978 (97%)]\tLoss: 2.809573\n",
            "Train Epoch: 3 [3853/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3854/3978 (97%)]\tLoss: 4.666968\n",
            "Train Epoch: 3 [3855/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3856/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3857/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3858/3978 (97%)]\tLoss: 3.049469\n",
            "Train Epoch: 3 [3859/3978 (97%)]\tLoss: 2.182247\n",
            "Train Epoch: 3 [3860/3978 (97%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3861/3978 (97%)]\tLoss: 0.905205\n",
            "Train Epoch: 3 [3862/3978 (97%)]\tLoss: 2.530173\n",
            "Train Epoch: 3 [3863/3978 (97%)]\tLoss: 1.759431\n",
            "Train Epoch: 3 [3864/3978 (97%)]\tLoss: 1.832291\n",
            "Train Epoch: 3 [3865/3978 (97%)]\tLoss: 2.402757\n",
            "Train Epoch: 3 [3866/3978 (97%)]\tLoss: 1.268904\n",
            "Train Epoch: 3 [3867/3978 (97%)]\tLoss: 0.859950\n",
            "Train Epoch: 3 [3868/3978 (97%)]\tLoss: 0.320934\n",
            "Train Epoch: 3 [3869/3978 (97%)]\tLoss: 0.834300\n",
            "Train Epoch: 3 [3870/3978 (97%)]\tLoss: 1.840790\n",
            "Train Epoch: 3 [3871/3978 (97%)]\tLoss: 1.650269\n",
            "Train Epoch: 3 [3872/3978 (97%)]\tLoss: 0.001602\n",
            "Train Epoch: 3 [3873/3978 (97%)]\tLoss: 5.038210\n",
            "Train Epoch: 3 [3874/3978 (97%)]\tLoss: 0.038510\n",
            "Train Epoch: 3 [3875/3978 (97%)]\tLoss: 0.459578\n",
            "Train Epoch: 3 [3876/3978 (97%)]\tLoss: 3.915187\n",
            "Train Epoch: 3 [3877/3978 (97%)]\tLoss: 5.212698\n",
            "Train Epoch: 3 [3878/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3879/3978 (98%)]\tLoss: 2.699388\n",
            "Train Epoch: 3 [3880/3978 (98%)]\tLoss: 3.831924\n",
            "Train Epoch: 3 [3881/3978 (98%)]\tLoss: 0.015981\n",
            "Train Epoch: 3 [3882/3978 (98%)]\tLoss: 2.258161\n",
            "Train Epoch: 3 [3883/3978 (98%)]\tLoss: 1.284860\n",
            "Train Epoch: 3 [3884/3978 (98%)]\tLoss: 0.346081\n",
            "Train Epoch: 3 [3885/3978 (98%)]\tLoss: 0.003429\n",
            "Train Epoch: 3 [3886/3978 (98%)]\tLoss: 3.321557\n",
            "Train Epoch: 3 [3887/3978 (98%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3888/3978 (98%)]\tLoss: 3.280103\n",
            "Train Epoch: 3 [3889/3978 (98%)]\tLoss: 3.678715\n",
            "Train Epoch: 3 [3890/3978 (98%)]\tLoss: 0.539645\n",
            "Train Epoch: 3 [3891/3978 (98%)]\tLoss: 0.015569\n",
            "Train Epoch: 3 [3892/3978 (98%)]\tLoss: 0.044352\n",
            "Train Epoch: 3 [3893/3978 (98%)]\tLoss: 0.566149\n",
            "Train Epoch: 3 [3894/3978 (98%)]\tLoss: 0.124742\n",
            "Train Epoch: 3 [3895/3978 (98%)]\tLoss: 2.823656\n",
            "Train Epoch: 3 [3896/3978 (98%)]\tLoss: 0.008412\n",
            "Train Epoch: 3 [3897/3978 (98%)]\tLoss: 2.672923\n",
            "Train Epoch: 3 [3898/3978 (98%)]\tLoss: 0.050566\n",
            "Train Epoch: 3 [3899/3978 (98%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3900/3978 (98%)]\tLoss: 3.059352\n",
            "Train Epoch: 3 [3901/3978 (98%)]\tLoss: 2.127690\n",
            "Train Epoch: 3 [3902/3978 (98%)]\tLoss: 1.815461\n",
            "Train Epoch: 3 [3903/3978 (98%)]\tLoss: 0.053408\n",
            "Train Epoch: 3 [3904/3978 (98%)]\tLoss: 0.151488\n",
            "Train Epoch: 3 [3905/3978 (98%)]\tLoss: 0.000004\n",
            "Train Epoch: 3 [3906/3978 (98%)]\tLoss: 0.791900\n",
            "Train Epoch: 3 [3907/3978 (98%)]\tLoss: 0.727645\n",
            "Train Epoch: 3 [3908/3978 (98%)]\tLoss: 6.353634\n",
            "Train Epoch: 3 [3909/3978 (98%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3910/3978 (98%)]\tLoss: 0.001324\n",
            "Train Epoch: 3 [3911/3978 (98%)]\tLoss: 0.049128\n",
            "Train Epoch: 3 [3912/3978 (98%)]\tLoss: 0.973718\n",
            "Train Epoch: 3 [3913/3978 (98%)]\tLoss: 2.896414\n",
            "Train Epoch: 3 [3914/3978 (98%)]\tLoss: 0.621634\n",
            "Train Epoch: 3 [3915/3978 (98%)]\tLoss: 0.000314\n",
            "Train Epoch: 3 [3916/3978 (98%)]\tLoss: 1.883572\n",
            "Train Epoch: 3 [3917/3978 (98%)]\tLoss: 4.563656\n",
            "Train Epoch: 3 [3918/3978 (98%)]\tLoss: 0.701377\n",
            "Train Epoch: 3 [3919/3978 (99%)]\tLoss: 0.033825\n",
            "Train Epoch: 3 [3920/3978 (99%)]\tLoss: 0.015463\n",
            "Train Epoch: 3 [3921/3978 (99%)]\tLoss: 1.210705\n",
            "Train Epoch: 3 [3922/3978 (99%)]\tLoss: 1.879645\n",
            "Train Epoch: 3 [3923/3978 (99%)]\tLoss: 0.006250\n",
            "Train Epoch: 3 [3924/3978 (99%)]\tLoss: 4.039692\n",
            "Train Epoch: 3 [3925/3978 (99%)]\tLoss: 0.025607\n",
            "Train Epoch: 3 [3926/3978 (99%)]\tLoss: 0.252401\n",
            "Train Epoch: 3 [3927/3978 (99%)]\tLoss: 0.598185\n",
            "Train Epoch: 3 [3928/3978 (99%)]\tLoss: 0.522213\n",
            "Train Epoch: 3 [3929/3978 (99%)]\tLoss: 0.188471\n",
            "Train Epoch: 3 [3930/3978 (99%)]\tLoss: 2.097822\n",
            "Train Epoch: 3 [3931/3978 (99%)]\tLoss: 0.022937\n",
            "Train Epoch: 3 [3932/3978 (99%)]\tLoss: 0.029598\n",
            "Train Epoch: 3 [3933/3978 (99%)]\tLoss: 0.816658\n",
            "Train Epoch: 3 [3934/3978 (99%)]\tLoss: 0.025983\n",
            "Train Epoch: 3 [3935/3978 (99%)]\tLoss: 0.025819\n",
            "Train Epoch: 3 [3936/3978 (99%)]\tLoss: 0.749634\n",
            "Train Epoch: 3 [3937/3978 (99%)]\tLoss: 2.049113\n",
            "Train Epoch: 3 [3938/3978 (99%)]\tLoss: 0.012464\n",
            "Train Epoch: 3 [3939/3978 (99%)]\tLoss: 0.030929\n",
            "Train Epoch: 3 [3940/3978 (99%)]\tLoss: 0.237035\n",
            "Train Epoch: 3 [3941/3978 (99%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3942/3978 (99%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3943/3978 (99%)]\tLoss: 1.326196\n",
            "Train Epoch: 3 [3944/3978 (99%)]\tLoss: 3.858738\n",
            "Train Epoch: 3 [3945/3978 (99%)]\tLoss: 1.238550\n",
            "Train Epoch: 3 [3946/3978 (99%)]\tLoss: 0.062288\n",
            "Train Epoch: 3 [3947/3978 (99%)]\tLoss: 0.005484\n",
            "Train Epoch: 3 [3948/3978 (99%)]\tLoss: 1.079783\n",
            "Train Epoch: 3 [3949/3978 (99%)]\tLoss: 3.095068\n",
            "Train Epoch: 3 [3950/3978 (99%)]\tLoss: 2.589947\n",
            "Train Epoch: 3 [3951/3978 (99%)]\tLoss: 3.473873\n",
            "Train Epoch: 3 [3952/3978 (99%)]\tLoss: 0.849663\n",
            "Train Epoch: 3 [3953/3978 (99%)]\tLoss: 0.000110\n",
            "Train Epoch: 3 [3954/3978 (99%)]\tLoss: 2.071558\n",
            "Train Epoch: 3 [3955/3978 (99%)]\tLoss: 0.792061\n",
            "Train Epoch: 3 [3956/3978 (99%)]\tLoss: 1.722098\n",
            "Train Epoch: 3 [3957/3978 (99%)]\tLoss: 1.190715\n",
            "Train Epoch: 3 [3958/3978 (99%)]\tLoss: 0.063197\n",
            "Train Epoch: 3 [3959/3978 (100%)]\tLoss: 1.143937\n",
            "Train Epoch: 3 [3960/3978 (100%)]\tLoss: 2.149204\n",
            "Train Epoch: 3 [3961/3978 (100%)]\tLoss: 0.094483\n",
            "Train Epoch: 3 [3962/3978 (100%)]\tLoss: 4.339266\n",
            "Train Epoch: 3 [3963/3978 (100%)]\tLoss: 0.922294\n",
            "Train Epoch: 3 [3964/3978 (100%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3965/3978 (100%)]\tLoss: 1.756319\n",
            "Train Epoch: 3 [3966/3978 (100%)]\tLoss: 0.150517\n",
            "Train Epoch: 3 [3967/3978 (100%)]\tLoss: 0.707611\n",
            "Train Epoch: 3 [3968/3978 (100%)]\tLoss: 1.704707\n",
            "Train Epoch: 3 [3969/3978 (100%)]\tLoss: 2.575433\n",
            "Train Epoch: 3 [3970/3978 (100%)]\tLoss: 2.477828\n",
            "Train Epoch: 3 [3971/3978 (100%)]\tLoss: 2.128528\n",
            "Train Epoch: 3 [3972/3978 (100%)]\tLoss: 1.416228\n",
            "Train Epoch: 3 [3973/3978 (100%)]\tLoss: 0.685920\n",
            "Train Epoch: 3 [3974/3978 (100%)]\tLoss: 1.468216\n",
            "Train Epoch: 3 [3975/3978 (100%)]\tLoss: 1.644666\n",
            "Train Epoch: 3 [3976/3978 (100%)]\tLoss: 0.015258\n",
            "Train Epoch: 3 [3977/3978 (100%)]\tLoss: 0.643971\n",
            "Epoch\n",
            "train/train_loss: 0.6439714431762695\n",
            "\n",
            "Train Loss: 0.644, Valid Loss: 0.872925, Accuracy: 0.05\n",
            "Train Epoch: 4 [0/3978 (0%)]\tLoss: 1.941568\n",
            "Train Epoch: 4 [1/3978 (0%)]\tLoss: 0.957650\n",
            "Train Epoch: 4 [2/3978 (0%)]\tLoss: 1.272979\n",
            "Train Epoch: 4 [3/3978 (0%)]\tLoss: 0.322430\n",
            "Train Epoch: 4 [4/3978 (0%)]\tLoss: 0.778846\n",
            "Train Epoch: 4 [5/3978 (0%)]\tLoss: 0.050313\n",
            "Train Epoch: 4 [6/3978 (0%)]\tLoss: 1.238949\n",
            "Train Epoch: 4 [7/3978 (0%)]\tLoss: 0.023053\n",
            "Train Epoch: 4 [8/3978 (0%)]\tLoss: 2.191658\n",
            "Train Epoch: 4 [9/3978 (0%)]\tLoss: 0.094248\n",
            "Train Epoch: 4 [10/3978 (0%)]\tLoss: 0.030616\n",
            "Train Epoch: 4 [11/3978 (0%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [12/3978 (0%)]\tLoss: 2.581305\n",
            "Train Epoch: 4 [13/3978 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [14/3978 (0%)]\tLoss: 0.141150\n",
            "Train Epoch: 4 [15/3978 (0%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [16/3978 (0%)]\tLoss: 0.581312\n",
            "Train Epoch: 4 [17/3978 (0%)]\tLoss: 4.624665\n",
            "Train Epoch: 4 [18/3978 (0%)]\tLoss: 1.992338\n",
            "Train Epoch: 4 [19/3978 (0%)]\tLoss: 3.258499\n",
            "Train Epoch: 4 [20/3978 (1%)]\tLoss: 0.117516\n",
            "Train Epoch: 4 [21/3978 (1%)]\tLoss: 0.165693\n",
            "Train Epoch: 4 [22/3978 (1%)]\tLoss: 1.134304\n",
            "Train Epoch: 4 [23/3978 (1%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [24/3978 (1%)]\tLoss: 3.475490\n",
            "Train Epoch: 4 [25/3978 (1%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [26/3978 (1%)]\tLoss: 1.704107\n",
            "Train Epoch: 4 [27/3978 (1%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [28/3978 (1%)]\tLoss: 0.003145\n",
            "Train Epoch: 4 [29/3978 (1%)]\tLoss: 0.014038\n",
            "Train Epoch: 4 [30/3978 (1%)]\tLoss: 0.903871\n",
            "Train Epoch: 4 [31/3978 (1%)]\tLoss: 3.558224\n",
            "Train Epoch: 4 [32/3978 (1%)]\tLoss: 5.760739\n",
            "Train Epoch: 4 [33/3978 (1%)]\tLoss: 0.010357\n",
            "Train Epoch: 4 [34/3978 (1%)]\tLoss: 0.001885\n",
            "Train Epoch: 4 [35/3978 (1%)]\tLoss: 0.000895\n",
            "Train Epoch: 4 [36/3978 (1%)]\tLoss: 0.103996\n",
            "Train Epoch: 4 [37/3978 (1%)]\tLoss: 1.163483\n",
            "Train Epoch: 4 [38/3978 (1%)]\tLoss: 1.916041\n",
            "Train Epoch: 4 [39/3978 (1%)]\tLoss: 1.943936\n",
            "Train Epoch: 4 [40/3978 (1%)]\tLoss: 0.000108\n",
            "Train Epoch: 4 [41/3978 (1%)]\tLoss: 0.090114\n",
            "Train Epoch: 4 [42/3978 (1%)]\tLoss: 0.017069\n",
            "Train Epoch: 4 [43/3978 (1%)]\tLoss: 0.129573\n",
            "Train Epoch: 4 [44/3978 (1%)]\tLoss: 0.052185\n",
            "Train Epoch: 4 [45/3978 (1%)]\tLoss: 0.246887\n",
            "Train Epoch: 4 [46/3978 (1%)]\tLoss: 0.263620\n",
            "Train Epoch: 4 [47/3978 (1%)]\tLoss: 0.000354\n",
            "Train Epoch: 4 [48/3978 (1%)]\tLoss: 0.121956\n",
            "Train Epoch: 4 [49/3978 (1%)]\tLoss: 0.192181\n",
            "Train Epoch: 4 [50/3978 (1%)]\tLoss: 2.686925\n",
            "Train Epoch: 4 [51/3978 (1%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [52/3978 (1%)]\tLoss: 0.903476\n",
            "Train Epoch: 4 [53/3978 (1%)]\tLoss: 1.275963\n",
            "Train Epoch: 4 [54/3978 (1%)]\tLoss: 1.475843\n",
            "Train Epoch: 4 [55/3978 (1%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [56/3978 (1%)]\tLoss: 0.952518\n",
            "Train Epoch: 4 [57/3978 (1%)]\tLoss: 0.696443\n",
            "Train Epoch: 4 [58/3978 (1%)]\tLoss: 0.103944\n",
            "Train Epoch: 4 [59/3978 (1%)]\tLoss: 0.481518\n",
            "Train Epoch: 4 [60/3978 (2%)]\tLoss: 0.144082\n",
            "Train Epoch: 4 [61/3978 (2%)]\tLoss: 0.332385\n",
            "Train Epoch: 4 [62/3978 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [63/3978 (2%)]\tLoss: 4.172985\n",
            "Train Epoch: 4 [64/3978 (2%)]\tLoss: 4.421968\n",
            "Train Epoch: 4 [65/3978 (2%)]\tLoss: 5.439345\n",
            "Train Epoch: 4 [66/3978 (2%)]\tLoss: 4.253529\n",
            "Train Epoch: 4 [67/3978 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [68/3978 (2%)]\tLoss: 2.800335\n",
            "Train Epoch: 4 [69/3978 (2%)]\tLoss: 2.566208\n",
            "Train Epoch: 4 [70/3978 (2%)]\tLoss: 0.000145\n",
            "Train Epoch: 4 [71/3978 (2%)]\tLoss: 2.016906\n",
            "Train Epoch: 4 [72/3978 (2%)]\tLoss: 2.098853\n",
            "Train Epoch: 4 [73/3978 (2%)]\tLoss: 0.841567\n",
            "Train Epoch: 4 [74/3978 (2%)]\tLoss: 0.010969\n",
            "Train Epoch: 4 [75/3978 (2%)]\tLoss: 0.000240\n",
            "Train Epoch: 4 [76/3978 (2%)]\tLoss: 1.341962\n",
            "Train Epoch: 4 [77/3978 (2%)]\tLoss: 0.352194\n",
            "Train Epoch: 4 [78/3978 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [79/3978 (2%)]\tLoss: 4.443105\n",
            "Train Epoch: 4 [80/3978 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [81/3978 (2%)]\tLoss: 1.216834\n",
            "Train Epoch: 4 [82/3978 (2%)]\tLoss: 4.547299\n",
            "Train Epoch: 4 [83/3978 (2%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [84/3978 (2%)]\tLoss: 0.000144\n",
            "Train Epoch: 4 [85/3978 (2%)]\tLoss: 2.961170\n",
            "Train Epoch: 4 [86/3978 (2%)]\tLoss: 0.056292\n",
            "Train Epoch: 4 [87/3978 (2%)]\tLoss: 2.101187\n",
            "Train Epoch: 4 [88/3978 (2%)]\tLoss: 0.000093\n",
            "Train Epoch: 4 [89/3978 (2%)]\tLoss: 0.642997\n",
            "Train Epoch: 4 [90/3978 (2%)]\tLoss: 1.470129\n",
            "Train Epoch: 4 [91/3978 (2%)]\tLoss: 0.042330\n",
            "Train Epoch: 4 [92/3978 (2%)]\tLoss: 0.833901\n",
            "Train Epoch: 4 [93/3978 (2%)]\tLoss: 6.502247\n",
            "Train Epoch: 4 [94/3978 (2%)]\tLoss: 0.153113\n",
            "Train Epoch: 4 [95/3978 (2%)]\tLoss: 0.732077\n",
            "Train Epoch: 4 [96/3978 (2%)]\tLoss: 1.058061\n",
            "Train Epoch: 4 [97/3978 (2%)]\tLoss: 0.851275\n",
            "Train Epoch: 4 [98/3978 (2%)]\tLoss: 1.105029\n",
            "Train Epoch: 4 [99/3978 (2%)]\tLoss: 1.371101\n",
            "Train Epoch: 4 [100/3978 (3%)]\tLoss: 0.036757\n",
            "Train Epoch: 4 [101/3978 (3%)]\tLoss: 0.271615\n",
            "Train Epoch: 4 [102/3978 (3%)]\tLoss: 0.066882\n",
            "Train Epoch: 4 [103/3978 (3%)]\tLoss: 0.711271\n",
            "Train Epoch: 4 [104/3978 (3%)]\tLoss: 0.000127\n",
            "Train Epoch: 4 [105/3978 (3%)]\tLoss: 2.703595\n",
            "Train Epoch: 4 [106/3978 (3%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [107/3978 (3%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [108/3978 (3%)]\tLoss: 1.614887\n",
            "Train Epoch: 4 [109/3978 (3%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [110/3978 (3%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [111/3978 (3%)]\tLoss: 1.473246\n",
            "Train Epoch: 4 [112/3978 (3%)]\tLoss: 0.001806\n",
            "Train Epoch: 4 [113/3978 (3%)]\tLoss: 1.266751\n",
            "Train Epoch: 4 [114/3978 (3%)]\tLoss: 1.154553\n",
            "Train Epoch: 4 [115/3978 (3%)]\tLoss: 0.005574\n",
            "Train Epoch: 4 [116/3978 (3%)]\tLoss: 0.967587\n",
            "Train Epoch: 4 [117/3978 (3%)]\tLoss: 0.361043\n",
            "Train Epoch: 4 [118/3978 (3%)]\tLoss: 1.476144\n",
            "Train Epoch: 4 [119/3978 (3%)]\tLoss: 0.222964\n",
            "Train Epoch: 4 [120/3978 (3%)]\tLoss: 0.891329\n",
            "Train Epoch: 4 [121/3978 (3%)]\tLoss: 1.279332\n",
            "Train Epoch: 4 [122/3978 (3%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [123/3978 (3%)]\tLoss: 1.080533\n",
            "Train Epoch: 4 [124/3978 (3%)]\tLoss: 1.508498\n",
            "Train Epoch: 4 [125/3978 (3%)]\tLoss: 5.896956\n",
            "Train Epoch: 4 [126/3978 (3%)]\tLoss: 0.005603\n",
            "Train Epoch: 4 [127/3978 (3%)]\tLoss: 0.000324\n",
            "Train Epoch: 4 [128/3978 (3%)]\tLoss: 0.621527\n",
            "Train Epoch: 4 [129/3978 (3%)]\tLoss: 0.000120\n",
            "Train Epoch: 4 [130/3978 (3%)]\tLoss: 1.025110\n",
            "Train Epoch: 4 [131/3978 (3%)]\tLoss: 0.024672\n",
            "Train Epoch: 4 [132/3978 (3%)]\tLoss: 0.729308\n",
            "Train Epoch: 4 [133/3978 (3%)]\tLoss: 0.619510\n",
            "Train Epoch: 4 [134/3978 (3%)]\tLoss: 0.076184\n",
            "Train Epoch: 4 [135/3978 (3%)]\tLoss: 0.465330\n",
            "Train Epoch: 4 [136/3978 (3%)]\tLoss: 0.000069\n",
            "Train Epoch: 4 [137/3978 (3%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [138/3978 (3%)]\tLoss: 3.228342\n",
            "Train Epoch: 4 [139/3978 (3%)]\tLoss: 3.514165\n",
            "Train Epoch: 4 [140/3978 (4%)]\tLoss: 0.012629\n",
            "Train Epoch: 4 [141/3978 (4%)]\tLoss: 1.238763\n",
            "Train Epoch: 4 [142/3978 (4%)]\tLoss: 0.027093\n",
            "Train Epoch: 4 [143/3978 (4%)]\tLoss: 0.000136\n",
            "Train Epoch: 4 [144/3978 (4%)]\tLoss: 0.033631\n",
            "Train Epoch: 4 [145/3978 (4%)]\tLoss: 0.241309\n",
            "Train Epoch: 4 [146/3978 (4%)]\tLoss: 0.287571\n",
            "Train Epoch: 4 [147/3978 (4%)]\tLoss: 0.096048\n",
            "Train Epoch: 4 [148/3978 (4%)]\tLoss: 0.415144\n",
            "Train Epoch: 4 [149/3978 (4%)]\tLoss: 10.280566\n",
            "Train Epoch: 4 [150/3978 (4%)]\tLoss: 0.345435\n",
            "Train Epoch: 4 [151/3978 (4%)]\tLoss: 1.302715\n",
            "Train Epoch: 4 [152/3978 (4%)]\tLoss: 0.016526\n",
            "Train Epoch: 4 [153/3978 (4%)]\tLoss: 0.105442\n",
            "Train Epoch: 4 [154/3978 (4%)]\tLoss: 1.082437\n",
            "Train Epoch: 4 [155/3978 (4%)]\tLoss: 0.000784\n",
            "Train Epoch: 4 [156/3978 (4%)]\tLoss: 0.493021\n",
            "Train Epoch: 4 [157/3978 (4%)]\tLoss: 0.257124\n",
            "Train Epoch: 4 [158/3978 (4%)]\tLoss: 0.000021\n",
            "Train Epoch: 4 [159/3978 (4%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [160/3978 (4%)]\tLoss: 0.000197\n",
            "Train Epoch: 4 [161/3978 (4%)]\tLoss: 2.149359\n",
            "Train Epoch: 4 [162/3978 (4%)]\tLoss: 0.000717\n",
            "Train Epoch: 4 [163/3978 (4%)]\tLoss: 2.140809\n",
            "Train Epoch: 4 [164/3978 (4%)]\tLoss: 5.481382\n",
            "Train Epoch: 4 [165/3978 (4%)]\tLoss: 0.000748\n",
            "Train Epoch: 4 [166/3978 (4%)]\tLoss: 0.000137\n",
            "Train Epoch: 4 [167/3978 (4%)]\tLoss: 0.948687\n",
            "Train Epoch: 4 [168/3978 (4%)]\tLoss: 0.004879\n",
            "Train Epoch: 4 [169/3978 (4%)]\tLoss: 0.309094\n",
            "Train Epoch: 4 [170/3978 (4%)]\tLoss: 0.714871\n",
            "Train Epoch: 4 [171/3978 (4%)]\tLoss: 0.231010\n",
            "Train Epoch: 4 [172/3978 (4%)]\tLoss: 0.148062\n",
            "Train Epoch: 4 [173/3978 (4%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [174/3978 (4%)]\tLoss: 0.087047\n",
            "Train Epoch: 4 [175/3978 (4%)]\tLoss: 0.696641\n",
            "Train Epoch: 4 [176/3978 (4%)]\tLoss: 0.671114\n",
            "Train Epoch: 4 [177/3978 (4%)]\tLoss: 0.190195\n",
            "Train Epoch: 4 [178/3978 (4%)]\tLoss: 1.927546\n",
            "Train Epoch: 4 [179/3978 (4%)]\tLoss: 0.017454\n",
            "Train Epoch: 4 [180/3978 (5%)]\tLoss: 4.954041\n",
            "Train Epoch: 4 [181/3978 (5%)]\tLoss: 1.019943\n",
            "Train Epoch: 4 [182/3978 (5%)]\tLoss: 0.203865\n",
            "Train Epoch: 4 [183/3978 (5%)]\tLoss: 0.151119\n",
            "Train Epoch: 4 [184/3978 (5%)]\tLoss: 0.001960\n",
            "Train Epoch: 4 [185/3978 (5%)]\tLoss: 1.549680\n",
            "Train Epoch: 4 [186/3978 (5%)]\tLoss: 0.838879\n",
            "Train Epoch: 4 [187/3978 (5%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [188/3978 (5%)]\tLoss: 0.057021\n",
            "Train Epoch: 4 [189/3978 (5%)]\tLoss: 3.450874\n",
            "Train Epoch: 4 [190/3978 (5%)]\tLoss: 0.962633\n",
            "Train Epoch: 4 [191/3978 (5%)]\tLoss: 0.220243\n",
            "Train Epoch: 4 [192/3978 (5%)]\tLoss: 0.715127\n",
            "Train Epoch: 4 [193/3978 (5%)]\tLoss: 0.659102\n",
            "Train Epoch: 4 [194/3978 (5%)]\tLoss: 0.210020\n",
            "Train Epoch: 4 [195/3978 (5%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [196/3978 (5%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [197/3978 (5%)]\tLoss: 0.000201\n",
            "Train Epoch: 4 [198/3978 (5%)]\tLoss: 1.137392\n",
            "Train Epoch: 4 [199/3978 (5%)]\tLoss: 0.000048\n",
            "Train Epoch: 4 [200/3978 (5%)]\tLoss: 1.020347\n",
            "Train Epoch: 4 [201/3978 (5%)]\tLoss: 4.497331\n",
            "Train Epoch: 4 [202/3978 (5%)]\tLoss: 0.032090\n",
            "Train Epoch: 4 [203/3978 (5%)]\tLoss: 0.789658\n",
            "Train Epoch: 4 [204/3978 (5%)]\tLoss: 0.000691\n",
            "Train Epoch: 4 [205/3978 (5%)]\tLoss: 4.902226\n",
            "Train Epoch: 4 [206/3978 (5%)]\tLoss: 0.000096\n",
            "Train Epoch: 4 [207/3978 (5%)]\tLoss: 0.346684\n",
            "Train Epoch: 4 [208/3978 (5%)]\tLoss: 0.197624\n",
            "Train Epoch: 4 [209/3978 (5%)]\tLoss: 0.036937\n",
            "Train Epoch: 4 [210/3978 (5%)]\tLoss: 1.052161\n",
            "Train Epoch: 4 [211/3978 (5%)]\tLoss: 0.154730\n",
            "Train Epoch: 4 [212/3978 (5%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [213/3978 (5%)]\tLoss: 0.001408\n",
            "Train Epoch: 4 [214/3978 (5%)]\tLoss: 0.013609\n",
            "Train Epoch: 4 [215/3978 (5%)]\tLoss: 0.253726\n",
            "Train Epoch: 4 [216/3978 (5%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [217/3978 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [218/3978 (5%)]\tLoss: 1.743026\n",
            "Train Epoch: 4 [219/3978 (6%)]\tLoss: 0.520243\n",
            "Train Epoch: 4 [220/3978 (6%)]\tLoss: 0.875404\n",
            "Train Epoch: 4 [221/3978 (6%)]\tLoss: 1.680962\n",
            "Train Epoch: 4 [222/3978 (6%)]\tLoss: 0.785446\n",
            "Train Epoch: 4 [223/3978 (6%)]\tLoss: 0.071768\n",
            "Train Epoch: 4 [224/3978 (6%)]\tLoss: 0.932602\n",
            "Train Epoch: 4 [225/3978 (6%)]\tLoss: 2.176561\n",
            "Train Epoch: 4 [226/3978 (6%)]\tLoss: 0.002813\n",
            "Train Epoch: 4 [227/3978 (6%)]\tLoss: 1.776627\n",
            "Train Epoch: 4 [228/3978 (6%)]\tLoss: 4.252856\n",
            "Train Epoch: 4 [229/3978 (6%)]\tLoss: 2.847798\n",
            "Train Epoch: 4 [230/3978 (6%)]\tLoss: 3.226589\n",
            "Train Epoch: 4 [231/3978 (6%)]\tLoss: 0.463107\n",
            "Train Epoch: 4 [232/3978 (6%)]\tLoss: 2.058487\n",
            "Train Epoch: 4 [233/3978 (6%)]\tLoss: 0.042441\n",
            "Train Epoch: 4 [234/3978 (6%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [235/3978 (6%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [236/3978 (6%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [237/3978 (6%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [238/3978 (6%)]\tLoss: 0.001279\n",
            "Train Epoch: 4 [239/3978 (6%)]\tLoss: 2.183192\n",
            "Train Epoch: 4 [240/3978 (6%)]\tLoss: 3.032393\n",
            "Train Epoch: 4 [241/3978 (6%)]\tLoss: 0.000100\n",
            "Train Epoch: 4 [242/3978 (6%)]\tLoss: 5.334054\n",
            "Train Epoch: 4 [243/3978 (6%)]\tLoss: 2.959639\n",
            "Train Epoch: 4 [244/3978 (6%)]\tLoss: 1.201985\n",
            "Train Epoch: 4 [245/3978 (6%)]\tLoss: 2.772753\n",
            "Train Epoch: 4 [246/3978 (6%)]\tLoss: 5.802176\n",
            "Train Epoch: 4 [247/3978 (6%)]\tLoss: 0.670958\n",
            "Train Epoch: 4 [248/3978 (6%)]\tLoss: 4.547396\n",
            "Train Epoch: 4 [249/3978 (6%)]\tLoss: 4.886158\n",
            "Train Epoch: 4 [250/3978 (6%)]\tLoss: 0.342981\n",
            "Train Epoch: 4 [251/3978 (6%)]\tLoss: 2.612682\n",
            "Train Epoch: 4 [252/3978 (6%)]\tLoss: 0.580747\n",
            "Train Epoch: 4 [253/3978 (6%)]\tLoss: 0.175522\n",
            "Train Epoch: 4 [254/3978 (6%)]\tLoss: 1.944040\n",
            "Train Epoch: 4 [255/3978 (6%)]\tLoss: 2.968914\n",
            "Train Epoch: 4 [256/3978 (6%)]\tLoss: 1.880699\n",
            "Train Epoch: 4 [257/3978 (6%)]\tLoss: 1.523878\n",
            "Train Epoch: 4 [258/3978 (6%)]\tLoss: 0.218335\n",
            "Train Epoch: 4 [259/3978 (7%)]\tLoss: 0.126366\n",
            "Train Epoch: 4 [260/3978 (7%)]\tLoss: 4.333349\n",
            "Train Epoch: 4 [261/3978 (7%)]\tLoss: 2.716127\n",
            "Train Epoch: 4 [262/3978 (7%)]\tLoss: 2.678244\n",
            "Train Epoch: 4 [263/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [264/3978 (7%)]\tLoss: 3.552677\n",
            "Train Epoch: 4 [265/3978 (7%)]\tLoss: 4.223663\n",
            "Train Epoch: 4 [266/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [267/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [268/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [269/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [270/3978 (7%)]\tLoss: 1.259661\n",
            "Train Epoch: 4 [271/3978 (7%)]\tLoss: 1.621784\n",
            "Train Epoch: 4 [272/3978 (7%)]\tLoss: 0.008650\n",
            "Train Epoch: 4 [273/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [274/3978 (7%)]\tLoss: 0.004271\n",
            "Train Epoch: 4 [275/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [276/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [277/3978 (7%)]\tLoss: 2.874954\n",
            "Train Epoch: 4 [278/3978 (7%)]\tLoss: 3.279191\n",
            "Train Epoch: 4 [279/3978 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [280/3978 (7%)]\tLoss: 1.387806\n",
            "Train Epoch: 4 [281/3978 (7%)]\tLoss: 2.011082\n",
            "Train Epoch: 4 [282/3978 (7%)]\tLoss: 0.047470\n",
            "Train Epoch: 4 [283/3978 (7%)]\tLoss: 0.000259\n",
            "Train Epoch: 4 [284/3978 (7%)]\tLoss: 0.541781\n",
            "Train Epoch: 4 [285/3978 (7%)]\tLoss: 0.390072\n",
            "Train Epoch: 4 [286/3978 (7%)]\tLoss: 0.001348\n",
            "Train Epoch: 4 [287/3978 (7%)]\tLoss: 0.010414\n",
            "Train Epoch: 4 [288/3978 (7%)]\tLoss: 1.441921\n",
            "Train Epoch: 4 [289/3978 (7%)]\tLoss: 4.492504\n",
            "Train Epoch: 4 [290/3978 (7%)]\tLoss: 0.482957\n",
            "Train Epoch: 4 [291/3978 (7%)]\tLoss: 1.006092\n",
            "Train Epoch: 4 [292/3978 (7%)]\tLoss: 0.063240\n",
            "Train Epoch: 4 [293/3978 (7%)]\tLoss: 0.072096\n",
            "Train Epoch: 4 [294/3978 (7%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [295/3978 (7%)]\tLoss: 1.292588\n",
            "Train Epoch: 4 [296/3978 (7%)]\tLoss: 0.000035\n",
            "Train Epoch: 4 [297/3978 (7%)]\tLoss: 1.858297\n",
            "Train Epoch: 4 [298/3978 (7%)]\tLoss: 0.009809\n",
            "Train Epoch: 4 [299/3978 (8%)]\tLoss: 2.144700\n",
            "Train Epoch: 4 [300/3978 (8%)]\tLoss: 0.048669\n",
            "Train Epoch: 4 [301/3978 (8%)]\tLoss: 1.273174\n",
            "Train Epoch: 4 [302/3978 (8%)]\tLoss: 0.003344\n",
            "Train Epoch: 4 [303/3978 (8%)]\tLoss: 0.005738\n",
            "Train Epoch: 4 [304/3978 (8%)]\tLoss: 0.053820\n",
            "Train Epoch: 4 [305/3978 (8%)]\tLoss: 0.108792\n",
            "Train Epoch: 4 [306/3978 (8%)]\tLoss: 0.000039\n",
            "Train Epoch: 4 [307/3978 (8%)]\tLoss: 0.991417\n",
            "Train Epoch: 4 [308/3978 (8%)]\tLoss: 0.701893\n",
            "Train Epoch: 4 [309/3978 (8%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [310/3978 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [311/3978 (8%)]\tLoss: 0.000901\n",
            "Train Epoch: 4 [312/3978 (8%)]\tLoss: 1.568013\n",
            "Train Epoch: 4 [313/3978 (8%)]\tLoss: 0.519785\n",
            "Train Epoch: 4 [314/3978 (8%)]\tLoss: 1.725071\n",
            "Train Epoch: 4 [315/3978 (8%)]\tLoss: 0.925224\n",
            "Train Epoch: 4 [316/3978 (8%)]\tLoss: 0.429693\n",
            "Train Epoch: 4 [317/3978 (8%)]\tLoss: 0.109175\n",
            "Train Epoch: 4 [318/3978 (8%)]\tLoss: 1.227169\n",
            "Train Epoch: 4 [319/3978 (8%)]\tLoss: 0.865871\n",
            "Train Epoch: 4 [320/3978 (8%)]\tLoss: 0.825055\n",
            "Train Epoch: 4 [321/3978 (8%)]\tLoss: 5.465872\n",
            "Train Epoch: 4 [322/3978 (8%)]\tLoss: 1.244180\n",
            "Train Epoch: 4 [323/3978 (8%)]\tLoss: 5.634395\n",
            "Train Epoch: 4 [324/3978 (8%)]\tLoss: 0.002942\n",
            "Train Epoch: 4 [325/3978 (8%)]\tLoss: 0.000513\n",
            "Train Epoch: 4 [326/3978 (8%)]\tLoss: 0.008895\n",
            "Train Epoch: 4 [327/3978 (8%)]\tLoss: 1.051841\n",
            "Train Epoch: 4 [328/3978 (8%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [329/3978 (8%)]\tLoss: 2.935825\n",
            "Train Epoch: 4 [330/3978 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [331/3978 (8%)]\tLoss: 1.545447\n",
            "Train Epoch: 4 [332/3978 (8%)]\tLoss: 1.205232\n",
            "Train Epoch: 4 [333/3978 (8%)]\tLoss: 0.741800\n",
            "Train Epoch: 4 [334/3978 (8%)]\tLoss: 1.118635\n",
            "Train Epoch: 4 [335/3978 (8%)]\tLoss: 0.898520\n",
            "Train Epoch: 4 [336/3978 (8%)]\tLoss: 1.052577\n",
            "Train Epoch: 4 [337/3978 (8%)]\tLoss: 0.002906\n",
            "Train Epoch: 4 [338/3978 (8%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [339/3978 (9%)]\tLoss: 0.704497\n",
            "Train Epoch: 4 [340/3978 (9%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [341/3978 (9%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [342/3978 (9%)]\tLoss: 0.751525\n",
            "Train Epoch: 4 [343/3978 (9%)]\tLoss: 0.004112\n",
            "Train Epoch: 4 [344/3978 (9%)]\tLoss: 0.641942\n",
            "Train Epoch: 4 [345/3978 (9%)]\tLoss: 0.657708\n",
            "Train Epoch: 4 [346/3978 (9%)]\tLoss: 0.334656\n",
            "Train Epoch: 4 [347/3978 (9%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [348/3978 (9%)]\tLoss: 0.000629\n",
            "Train Epoch: 4 [349/3978 (9%)]\tLoss: 3.086635\n",
            "Train Epoch: 4 [350/3978 (9%)]\tLoss: 0.096800\n",
            "Train Epoch: 4 [351/3978 (9%)]\tLoss: 0.026583\n",
            "Train Epoch: 4 [352/3978 (9%)]\tLoss: 0.137147\n",
            "Train Epoch: 4 [353/3978 (9%)]\tLoss: 0.029237\n",
            "Train Epoch: 4 [354/3978 (9%)]\tLoss: 0.000035\n",
            "Train Epoch: 4 [355/3978 (9%)]\tLoss: 0.571421\n",
            "Train Epoch: 4 [356/3978 (9%)]\tLoss: 0.007031\n",
            "Train Epoch: 4 [357/3978 (9%)]\tLoss: 0.945422\n",
            "Train Epoch: 4 [358/3978 (9%)]\tLoss: 1.268569\n",
            "Train Epoch: 4 [359/3978 (9%)]\tLoss: 0.002388\n",
            "Train Epoch: 4 [360/3978 (9%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [361/3978 (9%)]\tLoss: 1.572804\n",
            "Train Epoch: 4 [362/3978 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [363/3978 (9%)]\tLoss: 1.982100\n",
            "Train Epoch: 4 [364/3978 (9%)]\tLoss: 2.213646\n",
            "Train Epoch: 4 [365/3978 (9%)]\tLoss: 1.188085\n",
            "Train Epoch: 4 [366/3978 (9%)]\tLoss: 1.425664\n",
            "Train Epoch: 4 [367/3978 (9%)]\tLoss: 0.115056\n",
            "Train Epoch: 4 [368/3978 (9%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [369/3978 (9%)]\tLoss: 0.000261\n",
            "Train Epoch: 4 [370/3978 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [371/3978 (9%)]\tLoss: 2.023996\n",
            "Train Epoch: 4 [372/3978 (9%)]\tLoss: 1.608768\n",
            "Train Epoch: 4 [373/3978 (9%)]\tLoss: 3.388966\n",
            "Train Epoch: 4 [374/3978 (9%)]\tLoss: 2.300049\n",
            "Train Epoch: 4 [375/3978 (9%)]\tLoss: 0.105591\n",
            "Train Epoch: 4 [376/3978 (9%)]\tLoss: 0.618385\n",
            "Train Epoch: 4 [377/3978 (9%)]\tLoss: 0.834844\n",
            "Train Epoch: 4 [378/3978 (10%)]\tLoss: 0.003113\n",
            "Train Epoch: 4 [379/3978 (10%)]\tLoss: 0.471604\n",
            "Train Epoch: 4 [380/3978 (10%)]\tLoss: 0.566498\n",
            "Train Epoch: 4 [381/3978 (10%)]\tLoss: 0.122061\n",
            "Train Epoch: 4 [382/3978 (10%)]\tLoss: 0.000798\n",
            "Train Epoch: 4 [383/3978 (10%)]\tLoss: 2.073136\n",
            "Train Epoch: 4 [384/3978 (10%)]\tLoss: 0.352838\n",
            "Train Epoch: 4 [385/3978 (10%)]\tLoss: 0.972881\n",
            "Train Epoch: 4 [386/3978 (10%)]\tLoss: 0.425053\n",
            "Train Epoch: 4 [387/3978 (10%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [388/3978 (10%)]\tLoss: 0.002156\n",
            "Train Epoch: 4 [389/3978 (10%)]\tLoss: 2.437522\n",
            "Train Epoch: 4 [390/3978 (10%)]\tLoss: 0.135891\n",
            "Train Epoch: 4 [391/3978 (10%)]\tLoss: 0.000574\n",
            "Train Epoch: 4 [392/3978 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [393/3978 (10%)]\tLoss: 0.012844\n",
            "Train Epoch: 4 [394/3978 (10%)]\tLoss: 0.335619\n",
            "Train Epoch: 4 [395/3978 (10%)]\tLoss: 0.002071\n",
            "Train Epoch: 4 [396/3978 (10%)]\tLoss: 1.922330\n",
            "Train Epoch: 4 [397/3978 (10%)]\tLoss: 0.720192\n",
            "Train Epoch: 4 [398/3978 (10%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [399/3978 (10%)]\tLoss: 0.447415\n",
            "Train Epoch: 4 [400/3978 (10%)]\tLoss: 0.497574\n",
            "Train Epoch: 4 [401/3978 (10%)]\tLoss: 0.001607\n",
            "Train Epoch: 4 [402/3978 (10%)]\tLoss: 0.045960\n",
            "Train Epoch: 4 [403/3978 (10%)]\tLoss: 0.160313\n",
            "Train Epoch: 4 [404/3978 (10%)]\tLoss: 2.193891\n",
            "Train Epoch: 4 [405/3978 (10%)]\tLoss: 4.155935\n",
            "Train Epoch: 4 [406/3978 (10%)]\tLoss: 1.766884\n",
            "Train Epoch: 4 [407/3978 (10%)]\tLoss: 0.806310\n",
            "Train Epoch: 4 [408/3978 (10%)]\tLoss: 5.654158\n",
            "Train Epoch: 4 [409/3978 (10%)]\tLoss: 0.500413\n",
            "Train Epoch: 4 [410/3978 (10%)]\tLoss: 0.553994\n",
            "Train Epoch: 4 [411/3978 (10%)]\tLoss: 0.000144\n",
            "Train Epoch: 4 [412/3978 (10%)]\tLoss: 1.513324\n",
            "Train Epoch: 4 [413/3978 (10%)]\tLoss: 2.053980\n",
            "Train Epoch: 4 [414/3978 (10%)]\tLoss: 1.570588\n",
            "Train Epoch: 4 [415/3978 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [416/3978 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [417/3978 (10%)]\tLoss: 2.724495\n",
            "Train Epoch: 4 [418/3978 (11%)]\tLoss: 1.235352\n",
            "Train Epoch: 4 [419/3978 (11%)]\tLoss: 0.027993\n",
            "Train Epoch: 4 [420/3978 (11%)]\tLoss: 0.005692\n",
            "Train Epoch: 4 [421/3978 (11%)]\tLoss: 0.655977\n",
            "Train Epoch: 4 [422/3978 (11%)]\tLoss: 0.625813\n",
            "Train Epoch: 4 [423/3978 (11%)]\tLoss: 2.245274\n",
            "Train Epoch: 4 [424/3978 (11%)]\tLoss: 0.789938\n",
            "Train Epoch: 4 [425/3978 (11%)]\tLoss: 1.031805\n",
            "Train Epoch: 4 [426/3978 (11%)]\tLoss: 0.056916\n",
            "Train Epoch: 4 [427/3978 (11%)]\tLoss: 0.003397\n",
            "Train Epoch: 4 [428/3978 (11%)]\tLoss: 1.732860\n",
            "Train Epoch: 4 [429/3978 (11%)]\tLoss: 1.902343\n",
            "Train Epoch: 4 [430/3978 (11%)]\tLoss: 0.617058\n",
            "Train Epoch: 4 [431/3978 (11%)]\tLoss: 0.234587\n",
            "Train Epoch: 4 [432/3978 (11%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [433/3978 (11%)]\tLoss: 0.759215\n",
            "Train Epoch: 4 [434/3978 (11%)]\tLoss: 0.106182\n",
            "Train Epoch: 4 [435/3978 (11%)]\tLoss: 0.000305\n",
            "Train Epoch: 4 [436/3978 (11%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [437/3978 (11%)]\tLoss: 0.000022\n",
            "Train Epoch: 4 [438/3978 (11%)]\tLoss: 3.067953\n",
            "Train Epoch: 4 [439/3978 (11%)]\tLoss: 0.105726\n",
            "Train Epoch: 4 [440/3978 (11%)]\tLoss: 0.028153\n",
            "Train Epoch: 4 [441/3978 (11%)]\tLoss: 1.324829\n",
            "Train Epoch: 4 [442/3978 (11%)]\tLoss: 4.382824\n",
            "Train Epoch: 4 [443/3978 (11%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [444/3978 (11%)]\tLoss: 0.001511\n",
            "Train Epoch: 4 [445/3978 (11%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [446/3978 (11%)]\tLoss: 2.845344\n",
            "Train Epoch: 4 [447/3978 (11%)]\tLoss: 0.180217\n",
            "Train Epoch: 4 [448/3978 (11%)]\tLoss: 3.088229\n",
            "Train Epoch: 4 [449/3978 (11%)]\tLoss: 0.053704\n",
            "Train Epoch: 4 [450/3978 (11%)]\tLoss: 0.720728\n",
            "Train Epoch: 4 [451/3978 (11%)]\tLoss: 8.369507\n",
            "Train Epoch: 4 [452/3978 (11%)]\tLoss: 0.021443\n",
            "Train Epoch: 4 [453/3978 (11%)]\tLoss: 0.490083\n",
            "Train Epoch: 4 [454/3978 (11%)]\tLoss: 6.849584\n",
            "Train Epoch: 4 [455/3978 (11%)]\tLoss: 0.040340\n",
            "Train Epoch: 4 [456/3978 (11%)]\tLoss: 0.010116\n",
            "Train Epoch: 4 [457/3978 (11%)]\tLoss: 0.000018\n",
            "Train Epoch: 4 [458/3978 (12%)]\tLoss: 2.743088\n",
            "Train Epoch: 4 [459/3978 (12%)]\tLoss: 0.000463\n",
            "Train Epoch: 4 [460/3978 (12%)]\tLoss: 2.128720\n",
            "Train Epoch: 4 [461/3978 (12%)]\tLoss: 0.009623\n",
            "Train Epoch: 4 [462/3978 (12%)]\tLoss: 4.026439\n",
            "Train Epoch: 4 [463/3978 (12%)]\tLoss: 1.529524\n",
            "Train Epoch: 4 [464/3978 (12%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [465/3978 (12%)]\tLoss: 2.242566\n",
            "Train Epoch: 4 [466/3978 (12%)]\tLoss: 1.095277\n",
            "Train Epoch: 4 [467/3978 (12%)]\tLoss: 0.045362\n",
            "Train Epoch: 4 [468/3978 (12%)]\tLoss: 1.731096\n",
            "Train Epoch: 4 [469/3978 (12%)]\tLoss: 1.110778\n",
            "Train Epoch: 4 [470/3978 (12%)]\tLoss: 1.117186\n",
            "Train Epoch: 4 [471/3978 (12%)]\tLoss: 1.143899\n",
            "Train Epoch: 4 [472/3978 (12%)]\tLoss: 0.994947\n",
            "Train Epoch: 4 [473/3978 (12%)]\tLoss: 4.688739\n",
            "Train Epoch: 4 [474/3978 (12%)]\tLoss: 0.323400\n",
            "Train Epoch: 4 [475/3978 (12%)]\tLoss: 0.939514\n",
            "Train Epoch: 4 [476/3978 (12%)]\tLoss: 2.231060\n",
            "Train Epoch: 4 [477/3978 (12%)]\tLoss: 0.000192\n",
            "Train Epoch: 4 [478/3978 (12%)]\tLoss: 0.684455\n",
            "Train Epoch: 4 [479/3978 (12%)]\tLoss: 0.014148\n",
            "Train Epoch: 4 [480/3978 (12%)]\tLoss: 0.451012\n",
            "Train Epoch: 4 [481/3978 (12%)]\tLoss: 0.036250\n",
            "Train Epoch: 4 [482/3978 (12%)]\tLoss: 5.658319\n",
            "Train Epoch: 4 [483/3978 (12%)]\tLoss: 0.891293\n",
            "Train Epoch: 4 [484/3978 (12%)]\tLoss: 0.340380\n",
            "Train Epoch: 4 [485/3978 (12%)]\tLoss: 1.020257\n",
            "Train Epoch: 4 [486/3978 (12%)]\tLoss: 3.554020\n",
            "Train Epoch: 4 [487/3978 (12%)]\tLoss: 0.021980\n",
            "Train Epoch: 4 [488/3978 (12%)]\tLoss: 2.428566\n",
            "Train Epoch: 4 [489/3978 (12%)]\tLoss: 0.044708\n",
            "Train Epoch: 4 [490/3978 (12%)]\tLoss: 0.635033\n",
            "Train Epoch: 4 [491/3978 (12%)]\tLoss: 0.000236\n",
            "Train Epoch: 4 [492/3978 (12%)]\tLoss: 0.006294\n",
            "Train Epoch: 4 [493/3978 (12%)]\tLoss: 0.004101\n",
            "Train Epoch: 4 [494/3978 (12%)]\tLoss: 0.849676\n",
            "Train Epoch: 4 [495/3978 (12%)]\tLoss: 1.679985\n",
            "Train Epoch: 4 [496/3978 (12%)]\tLoss: 0.981765\n",
            "Train Epoch: 4 [497/3978 (12%)]\tLoss: 0.601789\n",
            "Train Epoch: 4 [498/3978 (13%)]\tLoss: 0.411665\n",
            "Train Epoch: 4 [499/3978 (13%)]\tLoss: 0.158938\n",
            "Train Epoch: 4 [500/3978 (13%)]\tLoss: 0.215118\n",
            "Train Epoch: 4 [501/3978 (13%)]\tLoss: 0.190852\n",
            "Train Epoch: 4 [502/3978 (13%)]\tLoss: 0.498234\n",
            "Train Epoch: 4 [503/3978 (13%)]\tLoss: 0.227668\n",
            "Train Epoch: 4 [504/3978 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [505/3978 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [506/3978 (13%)]\tLoss: 1.683644\n",
            "Train Epoch: 4 [507/3978 (13%)]\tLoss: 0.553908\n",
            "Train Epoch: 4 [508/3978 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [509/3978 (13%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [510/3978 (13%)]\tLoss: 0.357857\n",
            "Train Epoch: 4 [511/3978 (13%)]\tLoss: 0.884620\n",
            "Train Epoch: 4 [512/3978 (13%)]\tLoss: 0.657653\n",
            "Train Epoch: 4 [513/3978 (13%)]\tLoss: 0.462671\n",
            "Train Epoch: 4 [514/3978 (13%)]\tLoss: 0.002275\n",
            "Train Epoch: 4 [515/3978 (13%)]\tLoss: 0.032344\n",
            "Train Epoch: 4 [516/3978 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [517/3978 (13%)]\tLoss: 0.206526\n",
            "Train Epoch: 4 [518/3978 (13%)]\tLoss: 1.323233\n",
            "Train Epoch: 4 [519/3978 (13%)]\tLoss: 0.000193\n",
            "Train Epoch: 4 [520/3978 (13%)]\tLoss: 0.001982\n",
            "Train Epoch: 4 [521/3978 (13%)]\tLoss: 5.035865\n",
            "Train Epoch: 4 [522/3978 (13%)]\tLoss: 0.000908\n",
            "Train Epoch: 4 [523/3978 (13%)]\tLoss: 1.740080\n",
            "Train Epoch: 4 [524/3978 (13%)]\tLoss: 0.245963\n",
            "Train Epoch: 4 [525/3978 (13%)]\tLoss: 1.195139\n",
            "Train Epoch: 4 [526/3978 (13%)]\tLoss: 0.960276\n",
            "Train Epoch: 4 [527/3978 (13%)]\tLoss: 5.413631\n",
            "Train Epoch: 4 [528/3978 (13%)]\tLoss: 0.040658\n",
            "Train Epoch: 4 [529/3978 (13%)]\tLoss: 0.036072\n",
            "Train Epoch: 4 [530/3978 (13%)]\tLoss: 0.113433\n",
            "Train Epoch: 4 [531/3978 (13%)]\tLoss: 2.725613\n",
            "Train Epoch: 4 [532/3978 (13%)]\tLoss: 0.001960\n",
            "Train Epoch: 4 [533/3978 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [534/3978 (13%)]\tLoss: 2.604376\n",
            "Train Epoch: 4 [535/3978 (13%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [536/3978 (13%)]\tLoss: 1.780917\n",
            "Train Epoch: 4 [537/3978 (13%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [538/3978 (14%)]\tLoss: 0.873395\n",
            "Train Epoch: 4 [539/3978 (14%)]\tLoss: 0.006153\n",
            "Train Epoch: 4 [540/3978 (14%)]\tLoss: 2.877177\n",
            "Train Epoch: 4 [541/3978 (14%)]\tLoss: 0.194837\n",
            "Train Epoch: 4 [542/3978 (14%)]\tLoss: 0.017048\n",
            "Train Epoch: 4 [543/3978 (14%)]\tLoss: 0.001800\n",
            "Train Epoch: 4 [544/3978 (14%)]\tLoss: 0.002347\n",
            "Train Epoch: 4 [545/3978 (14%)]\tLoss: 0.000029\n",
            "Train Epoch: 4 [546/3978 (14%)]\tLoss: 2.348743\n",
            "Train Epoch: 4 [547/3978 (14%)]\tLoss: 0.000130\n",
            "Train Epoch: 4 [548/3978 (14%)]\tLoss: 1.763842\n",
            "Train Epoch: 4 [549/3978 (14%)]\tLoss: 4.069177\n",
            "Train Epoch: 4 [550/3978 (14%)]\tLoss: 2.321973\n",
            "Train Epoch: 4 [551/3978 (14%)]\tLoss: 1.577049\n",
            "Train Epoch: 4 [552/3978 (14%)]\tLoss: 2.383500\n",
            "Train Epoch: 4 [553/3978 (14%)]\tLoss: 1.204090\n",
            "Train Epoch: 4 [554/3978 (14%)]\tLoss: 0.892679\n",
            "Train Epoch: 4 [555/3978 (14%)]\tLoss: 0.053319\n",
            "Train Epoch: 4 [556/3978 (14%)]\tLoss: 2.411995\n",
            "Train Epoch: 4 [557/3978 (14%)]\tLoss: 3.428270\n",
            "Train Epoch: 4 [558/3978 (14%)]\tLoss: 1.674688\n",
            "Train Epoch: 4 [559/3978 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [560/3978 (14%)]\tLoss: 1.066598\n",
            "Train Epoch: 4 [561/3978 (14%)]\tLoss: 1.077574\n",
            "Train Epoch: 4 [562/3978 (14%)]\tLoss: 2.373957\n",
            "Train Epoch: 4 [563/3978 (14%)]\tLoss: 0.014244\n",
            "Train Epoch: 4 [564/3978 (14%)]\tLoss: 0.002557\n",
            "Train Epoch: 4 [565/3978 (14%)]\tLoss: 0.000738\n",
            "Train Epoch: 4 [566/3978 (14%)]\tLoss: 0.001357\n",
            "Train Epoch: 4 [567/3978 (14%)]\tLoss: 1.413820\n",
            "Train Epoch: 4 [568/3978 (14%)]\tLoss: 1.065689\n",
            "Train Epoch: 4 [569/3978 (14%)]\tLoss: 1.929614\n",
            "Train Epoch: 4 [570/3978 (14%)]\tLoss: 0.000247\n",
            "Train Epoch: 4 [571/3978 (14%)]\tLoss: 0.951036\n",
            "Train Epoch: 4 [572/3978 (14%)]\tLoss: 0.150100\n",
            "Train Epoch: 4 [573/3978 (14%)]\tLoss: 0.062130\n",
            "Train Epoch: 4 [574/3978 (14%)]\tLoss: 0.990570\n",
            "Train Epoch: 4 [575/3978 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [576/3978 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [577/3978 (15%)]\tLoss: 1.027792\n",
            "Train Epoch: 4 [578/3978 (15%)]\tLoss: 1.465461\n",
            "Train Epoch: 4 [579/3978 (15%)]\tLoss: 0.002890\n",
            "Train Epoch: 4 [580/3978 (15%)]\tLoss: 1.487395\n",
            "Train Epoch: 4 [581/3978 (15%)]\tLoss: 0.021257\n",
            "Train Epoch: 4 [582/3978 (15%)]\tLoss: 2.154553\n",
            "Train Epoch: 4 [583/3978 (15%)]\tLoss: 0.002443\n",
            "Train Epoch: 4 [584/3978 (15%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [585/3978 (15%)]\tLoss: 1.886855\n",
            "Train Epoch: 4 [586/3978 (15%)]\tLoss: 4.267090\n",
            "Train Epoch: 4 [587/3978 (15%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [588/3978 (15%)]\tLoss: 1.533325\n",
            "Train Epoch: 4 [589/3978 (15%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [590/3978 (15%)]\tLoss: 6.707130\n",
            "Train Epoch: 4 [591/3978 (15%)]\tLoss: 0.170296\n",
            "Train Epoch: 4 [592/3978 (15%)]\tLoss: 0.325891\n",
            "Train Epoch: 4 [593/3978 (15%)]\tLoss: 0.230425\n",
            "Train Epoch: 4 [594/3978 (15%)]\tLoss: 1.237084\n",
            "Train Epoch: 4 [595/3978 (15%)]\tLoss: 0.023002\n",
            "Train Epoch: 4 [596/3978 (15%)]\tLoss: 0.059665\n",
            "Train Epoch: 4 [597/3978 (15%)]\tLoss: 1.556718\n",
            "Train Epoch: 4 [598/3978 (15%)]\tLoss: 0.005224\n",
            "Train Epoch: 4 [599/3978 (15%)]\tLoss: 3.154572\n",
            "Train Epoch: 4 [600/3978 (15%)]\tLoss: 0.000626\n",
            "Train Epoch: 4 [601/3978 (15%)]\tLoss: 0.000156\n",
            "Train Epoch: 4 [602/3978 (15%)]\tLoss: 1.009009\n",
            "Train Epoch: 4 [603/3978 (15%)]\tLoss: 0.105537\n",
            "Train Epoch: 4 [604/3978 (15%)]\tLoss: 0.080638\n",
            "Train Epoch: 4 [605/3978 (15%)]\tLoss: 0.418399\n",
            "Train Epoch: 4 [606/3978 (15%)]\tLoss: 0.394593\n",
            "Train Epoch: 4 [607/3978 (15%)]\tLoss: 0.322779\n",
            "Train Epoch: 4 [608/3978 (15%)]\tLoss: 0.516370\n",
            "Train Epoch: 4 [609/3978 (15%)]\tLoss: 0.331627\n",
            "Train Epoch: 4 [610/3978 (15%)]\tLoss: 2.303433\n",
            "Train Epoch: 4 [611/3978 (15%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [612/3978 (15%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [613/3978 (15%)]\tLoss: 2.919649\n",
            "Train Epoch: 4 [614/3978 (15%)]\tLoss: 2.649876\n",
            "Train Epoch: 4 [615/3978 (15%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [616/3978 (15%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [617/3978 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [618/3978 (16%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [619/3978 (16%)]\tLoss: 1.632943\n",
            "Train Epoch: 4 [620/3978 (16%)]\tLoss: 0.000028\n",
            "Train Epoch: 4 [621/3978 (16%)]\tLoss: 0.059129\n",
            "Train Epoch: 4 [622/3978 (16%)]\tLoss: 3.654271\n",
            "Train Epoch: 4 [623/3978 (16%)]\tLoss: 0.364857\n",
            "Train Epoch: 4 [624/3978 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [625/3978 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [626/3978 (16%)]\tLoss: 0.931980\n",
            "Train Epoch: 4 [627/3978 (16%)]\tLoss: 2.666471\n",
            "Train Epoch: 4 [628/3978 (16%)]\tLoss: 1.346653\n",
            "Train Epoch: 4 [629/3978 (16%)]\tLoss: 1.699387\n",
            "Train Epoch: 4 [630/3978 (16%)]\tLoss: 2.420446\n",
            "Train Epoch: 4 [631/3978 (16%)]\tLoss: 0.034864\n",
            "Train Epoch: 4 [632/3978 (16%)]\tLoss: 6.286618\n",
            "Train Epoch: 4 [633/3978 (16%)]\tLoss: 0.787483\n",
            "Train Epoch: 4 [634/3978 (16%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [635/3978 (16%)]\tLoss: 0.008897\n",
            "Train Epoch: 4 [636/3978 (16%)]\tLoss: 0.004517\n",
            "Train Epoch: 4 [637/3978 (16%)]\tLoss: 0.000535\n",
            "Train Epoch: 4 [638/3978 (16%)]\tLoss: 0.013422\n",
            "Train Epoch: 4 [639/3978 (16%)]\tLoss: 0.002698\n",
            "Train Epoch: 4 [640/3978 (16%)]\tLoss: 1.551042\n",
            "Train Epoch: 4 [641/3978 (16%)]\tLoss: 3.039290\n",
            "Train Epoch: 4 [642/3978 (16%)]\tLoss: 0.509001\n",
            "Train Epoch: 4 [643/3978 (16%)]\tLoss: 6.940611\n",
            "Train Epoch: 4 [644/3978 (16%)]\tLoss: 0.663234\n",
            "Train Epoch: 4 [645/3978 (16%)]\tLoss: 0.000807\n",
            "Train Epoch: 4 [646/3978 (16%)]\tLoss: 2.358915\n",
            "Train Epoch: 4 [647/3978 (16%)]\tLoss: 0.005128\n",
            "Train Epoch: 4 [648/3978 (16%)]\tLoss: 0.007924\n",
            "Train Epoch: 4 [649/3978 (16%)]\tLoss: 0.132812\n",
            "Train Epoch: 4 [650/3978 (16%)]\tLoss: 0.918384\n",
            "Train Epoch: 4 [651/3978 (16%)]\tLoss: 0.000472\n",
            "Train Epoch: 4 [652/3978 (16%)]\tLoss: 0.020083\n",
            "Train Epoch: 4 [653/3978 (16%)]\tLoss: 0.978406\n",
            "Train Epoch: 4 [654/3978 (16%)]\tLoss: 0.042541\n",
            "Train Epoch: 4 [655/3978 (16%)]\tLoss: 0.497607\n",
            "Train Epoch: 4 [656/3978 (16%)]\tLoss: 0.072473\n",
            "Train Epoch: 4 [657/3978 (17%)]\tLoss: 0.771055\n",
            "Train Epoch: 4 [658/3978 (17%)]\tLoss: 0.004448\n",
            "Train Epoch: 4 [659/3978 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [660/3978 (17%)]\tLoss: 0.000035\n",
            "Train Epoch: 4 [661/3978 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [662/3978 (17%)]\tLoss: 2.099383\n",
            "Train Epoch: 4 [663/3978 (17%)]\tLoss: 1.164909\n",
            "Train Epoch: 4 [664/3978 (17%)]\tLoss: 3.464302\n",
            "Train Epoch: 4 [665/3978 (17%)]\tLoss: 5.701550\n",
            "Train Epoch: 4 [666/3978 (17%)]\tLoss: 3.475507\n",
            "Train Epoch: 4 [667/3978 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [668/3978 (17%)]\tLoss: 0.253781\n",
            "Train Epoch: 4 [669/3978 (17%)]\tLoss: 2.526039\n",
            "Train Epoch: 4 [670/3978 (17%)]\tLoss: 0.000390\n",
            "Train Epoch: 4 [671/3978 (17%)]\tLoss: 0.009619\n",
            "Train Epoch: 4 [672/3978 (17%)]\tLoss: 1.353863\n",
            "Train Epoch: 4 [673/3978 (17%)]\tLoss: 0.001073\n",
            "Train Epoch: 4 [674/3978 (17%)]\tLoss: 2.622886\n",
            "Train Epoch: 4 [675/3978 (17%)]\tLoss: 2.712651\n",
            "Train Epoch: 4 [676/3978 (17%)]\tLoss: 0.459761\n",
            "Train Epoch: 4 [677/3978 (17%)]\tLoss: 3.382237\n",
            "Train Epoch: 4 [678/3978 (17%)]\tLoss: 0.004208\n",
            "Train Epoch: 4 [679/3978 (17%)]\tLoss: 0.108957\n",
            "Train Epoch: 4 [680/3978 (17%)]\tLoss: 0.330496\n",
            "Train Epoch: 4 [681/3978 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [682/3978 (17%)]\tLoss: 1.836167\n",
            "Train Epoch: 4 [683/3978 (17%)]\tLoss: 0.004655\n",
            "Train Epoch: 4 [684/3978 (17%)]\tLoss: 0.000992\n",
            "Train Epoch: 4 [685/3978 (17%)]\tLoss: 3.071465\n",
            "Train Epoch: 4 [686/3978 (17%)]\tLoss: 0.000606\n",
            "Train Epoch: 4 [687/3978 (17%)]\tLoss: 0.204550\n",
            "Train Epoch: 4 [688/3978 (17%)]\tLoss: 1.797069\n",
            "Train Epoch: 4 [689/3978 (17%)]\tLoss: 0.181685\n",
            "Train Epoch: 4 [690/3978 (17%)]\tLoss: 0.450030\n",
            "Train Epoch: 4 [691/3978 (17%)]\tLoss: 2.461569\n",
            "Train Epoch: 4 [692/3978 (17%)]\tLoss: 0.021969\n",
            "Train Epoch: 4 [693/3978 (17%)]\tLoss: 0.192578\n",
            "Train Epoch: 4 [694/3978 (17%)]\tLoss: 1.012559\n",
            "Train Epoch: 4 [695/3978 (17%)]\tLoss: 1.068472\n",
            "Train Epoch: 4 [696/3978 (17%)]\tLoss: 2.154376\n",
            "Train Epoch: 4 [697/3978 (18%)]\tLoss: 0.000054\n",
            "Train Epoch: 4 [698/3978 (18%)]\tLoss: 0.210728\n",
            "Train Epoch: 4 [699/3978 (18%)]\tLoss: 0.015548\n",
            "Train Epoch: 4 [700/3978 (18%)]\tLoss: 1.534327\n",
            "Train Epoch: 4 [701/3978 (18%)]\tLoss: 2.993871\n",
            "Train Epoch: 4 [702/3978 (18%)]\tLoss: 2.072590\n",
            "Train Epoch: 4 [703/3978 (18%)]\tLoss: 0.080189\n",
            "Train Epoch: 4 [704/3978 (18%)]\tLoss: 2.962935\n",
            "Train Epoch: 4 [705/3978 (18%)]\tLoss: 0.005437\n",
            "Train Epoch: 4 [706/3978 (18%)]\tLoss: 1.783136\n",
            "Train Epoch: 4 [707/3978 (18%)]\tLoss: 0.299274\n",
            "Train Epoch: 4 [708/3978 (18%)]\tLoss: 0.040530\n",
            "Train Epoch: 4 [709/3978 (18%)]\tLoss: 0.006113\n",
            "Train Epoch: 4 [710/3978 (18%)]\tLoss: 1.781268\n",
            "Train Epoch: 4 [711/3978 (18%)]\tLoss: 0.855642\n",
            "Train Epoch: 4 [712/3978 (18%)]\tLoss: 0.582538\n",
            "Train Epoch: 4 [713/3978 (18%)]\tLoss: 0.004414\n",
            "Train Epoch: 4 [714/3978 (18%)]\tLoss: 0.750758\n",
            "Train Epoch: 4 [715/3978 (18%)]\tLoss: 0.344114\n",
            "Train Epoch: 4 [716/3978 (18%)]\tLoss: 0.533443\n",
            "Train Epoch: 4 [717/3978 (18%)]\tLoss: 0.000283\n",
            "Train Epoch: 4 [718/3978 (18%)]\tLoss: 0.618109\n",
            "Train Epoch: 4 [719/3978 (18%)]\tLoss: 0.081621\n",
            "Train Epoch: 4 [720/3978 (18%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [721/3978 (18%)]\tLoss: 1.155127\n",
            "Train Epoch: 4 [722/3978 (18%)]\tLoss: 1.928435\n",
            "Train Epoch: 4 [723/3978 (18%)]\tLoss: 0.178860\n",
            "Train Epoch: 4 [724/3978 (18%)]\tLoss: 0.041784\n",
            "Train Epoch: 4 [725/3978 (18%)]\tLoss: 1.067145\n",
            "Train Epoch: 4 [726/3978 (18%)]\tLoss: 3.274313\n",
            "Train Epoch: 4 [727/3978 (18%)]\tLoss: 0.002903\n",
            "Train Epoch: 4 [728/3978 (18%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [729/3978 (18%)]\tLoss: 1.168593\n",
            "Train Epoch: 4 [730/3978 (18%)]\tLoss: 0.000475\n",
            "Train Epoch: 4 [731/3978 (18%)]\tLoss: 0.001505\n",
            "Train Epoch: 4 [732/3978 (18%)]\tLoss: 0.180996\n",
            "Train Epoch: 4 [733/3978 (18%)]\tLoss: 0.009348\n",
            "Train Epoch: 4 [734/3978 (18%)]\tLoss: 0.002065\n",
            "Train Epoch: 4 [735/3978 (18%)]\tLoss: 0.017022\n",
            "Train Epoch: 4 [736/3978 (19%)]\tLoss: 0.744392\n",
            "Train Epoch: 4 [737/3978 (19%)]\tLoss: 4.342071\n",
            "Train Epoch: 4 [738/3978 (19%)]\tLoss: 0.280110\n",
            "Train Epoch: 4 [739/3978 (19%)]\tLoss: 0.330683\n",
            "Train Epoch: 4 [740/3978 (19%)]\tLoss: 0.000259\n",
            "Train Epoch: 4 [741/3978 (19%)]\tLoss: 0.595364\n",
            "Train Epoch: 4 [742/3978 (19%)]\tLoss: 4.431965\n",
            "Train Epoch: 4 [743/3978 (19%)]\tLoss: 3.209100\n",
            "Train Epoch: 4 [744/3978 (19%)]\tLoss: 1.261604\n",
            "Train Epoch: 4 [745/3978 (19%)]\tLoss: 0.001826\n",
            "Train Epoch: 4 [746/3978 (19%)]\tLoss: 0.342052\n",
            "Train Epoch: 4 [747/3978 (19%)]\tLoss: 0.001552\n",
            "Train Epoch: 4 [748/3978 (19%)]\tLoss: 1.497281\n",
            "Train Epoch: 4 [749/3978 (19%)]\tLoss: 0.931476\n",
            "Train Epoch: 4 [750/3978 (19%)]\tLoss: 0.504398\n",
            "Train Epoch: 4 [751/3978 (19%)]\tLoss: 0.347982\n",
            "Train Epoch: 4 [752/3978 (19%)]\tLoss: 0.013650\n",
            "Train Epoch: 4 [753/3978 (19%)]\tLoss: 0.199422\n",
            "Train Epoch: 4 [754/3978 (19%)]\tLoss: 2.330198\n",
            "Train Epoch: 4 [755/3978 (19%)]\tLoss: 2.284618\n",
            "Train Epoch: 4 [756/3978 (19%)]\tLoss: 0.013018\n",
            "Train Epoch: 4 [757/3978 (19%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [758/3978 (19%)]\tLoss: 2.318739\n",
            "Train Epoch: 4 [759/3978 (19%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [760/3978 (19%)]\tLoss: 3.572324\n",
            "Train Epoch: 4 [761/3978 (19%)]\tLoss: 0.276579\n",
            "Train Epoch: 4 [762/3978 (19%)]\tLoss: 0.043553\n",
            "Train Epoch: 4 [763/3978 (19%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [764/3978 (19%)]\tLoss: 0.137345\n",
            "Train Epoch: 4 [765/3978 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [766/3978 (19%)]\tLoss: 1.043308\n",
            "Train Epoch: 4 [767/3978 (19%)]\tLoss: 1.767160\n",
            "Train Epoch: 4 [768/3978 (19%)]\tLoss: 5.016231\n",
            "Train Epoch: 4 [769/3978 (19%)]\tLoss: 2.071136\n",
            "Train Epoch: 4 [770/3978 (19%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [771/3978 (19%)]\tLoss: 3.745090\n",
            "Train Epoch: 4 [772/3978 (19%)]\tLoss: 1.103032\n",
            "Train Epoch: 4 [773/3978 (19%)]\tLoss: 5.395103\n",
            "Train Epoch: 4 [774/3978 (19%)]\tLoss: 1.078610\n",
            "Train Epoch: 4 [775/3978 (19%)]\tLoss: 0.463321\n",
            "Train Epoch: 4 [776/3978 (20%)]\tLoss: 2.445311\n",
            "Train Epoch: 4 [777/3978 (20%)]\tLoss: 0.023061\n",
            "Train Epoch: 4 [778/3978 (20%)]\tLoss: 0.021547\n",
            "Train Epoch: 4 [779/3978 (20%)]\tLoss: 1.129772\n",
            "Train Epoch: 4 [780/3978 (20%)]\tLoss: 0.023782\n",
            "Train Epoch: 4 [781/3978 (20%)]\tLoss: 0.571798\n",
            "Train Epoch: 4 [782/3978 (20%)]\tLoss: 0.003613\n",
            "Train Epoch: 4 [783/3978 (20%)]\tLoss: 2.123222\n",
            "Train Epoch: 4 [784/3978 (20%)]\tLoss: 0.097596\n",
            "Train Epoch: 4 [785/3978 (20%)]\tLoss: 0.000206\n",
            "Train Epoch: 4 [786/3978 (20%)]\tLoss: 3.089900\n",
            "Train Epoch: 4 [787/3978 (20%)]\tLoss: 0.000172\n",
            "Train Epoch: 4 [788/3978 (20%)]\tLoss: 0.242121\n",
            "Train Epoch: 4 [789/3978 (20%)]\tLoss: 2.163608\n",
            "Train Epoch: 4 [790/3978 (20%)]\tLoss: 1.702020\n",
            "Train Epoch: 4 [791/3978 (20%)]\tLoss: 0.919071\n",
            "Train Epoch: 4 [792/3978 (20%)]\tLoss: 0.225095\n",
            "Train Epoch: 4 [793/3978 (20%)]\tLoss: 0.255930\n",
            "Train Epoch: 4 [794/3978 (20%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [795/3978 (20%)]\tLoss: 1.935782\n",
            "Train Epoch: 4 [796/3978 (20%)]\tLoss: 0.000527\n",
            "Train Epoch: 4 [797/3978 (20%)]\tLoss: 1.912210\n",
            "Train Epoch: 4 [798/3978 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [799/3978 (20%)]\tLoss: 1.551562\n",
            "Train Epoch: 4 [800/3978 (20%)]\tLoss: 0.000209\n",
            "Train Epoch: 4 [801/3978 (20%)]\tLoss: 0.353597\n",
            "Train Epoch: 4 [802/3978 (20%)]\tLoss: 0.000385\n",
            "Train Epoch: 4 [803/3978 (20%)]\tLoss: 0.771194\n",
            "Train Epoch: 4 [804/3978 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [805/3978 (20%)]\tLoss: 5.700278\n",
            "Train Epoch: 4 [806/3978 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [807/3978 (20%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [808/3978 (20%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [809/3978 (20%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [810/3978 (20%)]\tLoss: 1.116386\n",
            "Train Epoch: 4 [811/3978 (20%)]\tLoss: 0.208460\n",
            "Train Epoch: 4 [812/3978 (20%)]\tLoss: 1.576112\n",
            "Train Epoch: 4 [813/3978 (20%)]\tLoss: 0.242692\n",
            "Train Epoch: 4 [814/3978 (20%)]\tLoss: 0.545267\n",
            "Train Epoch: 4 [815/3978 (20%)]\tLoss: 0.002057\n",
            "Train Epoch: 4 [816/3978 (21%)]\tLoss: 0.517721\n",
            "Train Epoch: 4 [817/3978 (21%)]\tLoss: 0.970985\n",
            "Train Epoch: 4 [818/3978 (21%)]\tLoss: 0.938617\n",
            "Train Epoch: 4 [819/3978 (21%)]\tLoss: 3.612371\n",
            "Train Epoch: 4 [820/3978 (21%)]\tLoss: 1.174959\n",
            "Train Epoch: 4 [821/3978 (21%)]\tLoss: 0.056136\n",
            "Train Epoch: 4 [822/3978 (21%)]\tLoss: 0.147598\n",
            "Train Epoch: 4 [823/3978 (21%)]\tLoss: 0.000119\n",
            "Train Epoch: 4 [824/3978 (21%)]\tLoss: 0.001389\n",
            "Train Epoch: 4 [825/3978 (21%)]\tLoss: 1.923383\n",
            "Train Epoch: 4 [826/3978 (21%)]\tLoss: 0.708992\n",
            "Train Epoch: 4 [827/3978 (21%)]\tLoss: 0.001074\n",
            "Train Epoch: 4 [828/3978 (21%)]\tLoss: 0.229987\n",
            "Train Epoch: 4 [829/3978 (21%)]\tLoss: 0.001568\n",
            "Train Epoch: 4 [830/3978 (21%)]\tLoss: 6.854183\n",
            "Train Epoch: 4 [831/3978 (21%)]\tLoss: 0.000924\n",
            "Train Epoch: 4 [832/3978 (21%)]\tLoss: 0.563498\n",
            "Train Epoch: 4 [833/3978 (21%)]\tLoss: 0.093853\n",
            "Train Epoch: 4 [834/3978 (21%)]\tLoss: 1.858317\n",
            "Train Epoch: 4 [835/3978 (21%)]\tLoss: 0.789026\n",
            "Train Epoch: 4 [836/3978 (21%)]\tLoss: 0.000709\n",
            "Train Epoch: 4 [837/3978 (21%)]\tLoss: 1.160951\n",
            "Train Epoch: 4 [838/3978 (21%)]\tLoss: 0.542558\n",
            "Train Epoch: 4 [839/3978 (21%)]\tLoss: 6.297919\n",
            "Train Epoch: 4 [840/3978 (21%)]\tLoss: 3.170294\n",
            "Train Epoch: 4 [841/3978 (21%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [842/3978 (21%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [843/3978 (21%)]\tLoss: 1.357944\n",
            "Train Epoch: 4 [844/3978 (21%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [845/3978 (21%)]\tLoss: 1.868059\n",
            "Train Epoch: 4 [846/3978 (21%)]\tLoss: 0.006983\n",
            "Train Epoch: 4 [847/3978 (21%)]\tLoss: 2.828763\n",
            "Train Epoch: 4 [848/3978 (21%)]\tLoss: 1.631123\n",
            "Train Epoch: 4 [849/3978 (21%)]\tLoss: 0.000160\n",
            "Train Epoch: 4 [850/3978 (21%)]\tLoss: 0.756876\n",
            "Train Epoch: 4 [851/3978 (21%)]\tLoss: 1.120120\n",
            "Train Epoch: 4 [852/3978 (21%)]\tLoss: 0.006245\n",
            "Train Epoch: 4 [853/3978 (21%)]\tLoss: 0.001684\n",
            "Train Epoch: 4 [854/3978 (21%)]\tLoss: 0.759367\n",
            "Train Epoch: 4 [855/3978 (21%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [856/3978 (22%)]\tLoss: 1.940008\n",
            "Train Epoch: 4 [857/3978 (22%)]\tLoss: 2.868991\n",
            "Train Epoch: 4 [858/3978 (22%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [859/3978 (22%)]\tLoss: 0.000636\n",
            "Train Epoch: 4 [860/3978 (22%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [861/3978 (22%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [862/3978 (22%)]\tLoss: 0.000396\n",
            "Train Epoch: 4 [863/3978 (22%)]\tLoss: 0.000328\n",
            "Train Epoch: 4 [864/3978 (22%)]\tLoss: 0.945632\n",
            "Train Epoch: 4 [865/3978 (22%)]\tLoss: 1.239349\n",
            "Train Epoch: 4 [866/3978 (22%)]\tLoss: 0.957835\n",
            "Train Epoch: 4 [867/3978 (22%)]\tLoss: 0.517938\n",
            "Train Epoch: 4 [868/3978 (22%)]\tLoss: 3.112246\n",
            "Train Epoch: 4 [869/3978 (22%)]\tLoss: 2.720601\n",
            "Train Epoch: 4 [870/3978 (22%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [871/3978 (22%)]\tLoss: 2.889789\n",
            "Train Epoch: 4 [872/3978 (22%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [873/3978 (22%)]\tLoss: 1.172834\n",
            "Train Epoch: 4 [874/3978 (22%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [875/3978 (22%)]\tLoss: 6.303908\n",
            "Train Epoch: 4 [876/3978 (22%)]\tLoss: 3.003520\n",
            "Train Epoch: 4 [877/3978 (22%)]\tLoss: 1.124953\n",
            "Train Epoch: 4 [878/3978 (22%)]\tLoss: 1.203973\n",
            "Train Epoch: 4 [879/3978 (22%)]\tLoss: 0.264309\n",
            "Train Epoch: 4 [880/3978 (22%)]\tLoss: 0.776340\n",
            "Train Epoch: 4 [881/3978 (22%)]\tLoss: 0.000054\n",
            "Train Epoch: 4 [882/3978 (22%)]\tLoss: 0.006176\n",
            "Train Epoch: 4 [883/3978 (22%)]\tLoss: 1.397979\n",
            "Train Epoch: 4 [884/3978 (22%)]\tLoss: 1.356765\n",
            "Train Epoch: 4 [885/3978 (22%)]\tLoss: 1.242692\n",
            "Train Epoch: 4 [886/3978 (22%)]\tLoss: 1.746413\n",
            "Train Epoch: 4 [887/3978 (22%)]\tLoss: 1.079077\n",
            "Train Epoch: 4 [888/3978 (22%)]\tLoss: 0.000101\n",
            "Train Epoch: 4 [889/3978 (22%)]\tLoss: 0.281581\n",
            "Train Epoch: 4 [890/3978 (22%)]\tLoss: 1.348013\n",
            "Train Epoch: 4 [891/3978 (22%)]\tLoss: 0.122749\n",
            "Train Epoch: 4 [892/3978 (22%)]\tLoss: 1.456245\n",
            "Train Epoch: 4 [893/3978 (22%)]\tLoss: 0.706772\n",
            "Train Epoch: 4 [894/3978 (22%)]\tLoss: 2.549141\n",
            "Train Epoch: 4 [895/3978 (22%)]\tLoss: 0.122840\n",
            "Train Epoch: 4 [896/3978 (23%)]\tLoss: 1.151992\n",
            "Train Epoch: 4 [897/3978 (23%)]\tLoss: 0.800625\n",
            "Train Epoch: 4 [898/3978 (23%)]\tLoss: 0.796337\n",
            "Train Epoch: 4 [899/3978 (23%)]\tLoss: 0.479563\n",
            "Train Epoch: 4 [900/3978 (23%)]\tLoss: 0.753720\n",
            "Train Epoch: 4 [901/3978 (23%)]\tLoss: 0.296051\n",
            "Train Epoch: 4 [902/3978 (23%)]\tLoss: 0.000050\n",
            "Train Epoch: 4 [903/3978 (23%)]\tLoss: 1.274075\n",
            "Train Epoch: 4 [904/3978 (23%)]\tLoss: 1.904379\n",
            "Train Epoch: 4 [905/3978 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [906/3978 (23%)]\tLoss: 2.712341\n",
            "Train Epoch: 4 [907/3978 (23%)]\tLoss: 3.221953\n",
            "Train Epoch: 4 [908/3978 (23%)]\tLoss: 0.000015\n",
            "Train Epoch: 4 [909/3978 (23%)]\tLoss: 0.552428\n",
            "Train Epoch: 4 [910/3978 (23%)]\tLoss: 0.018077\n",
            "Train Epoch: 4 [911/3978 (23%)]\tLoss: 1.813955\n",
            "Train Epoch: 4 [912/3978 (23%)]\tLoss: 4.093043\n",
            "Train Epoch: 4 [913/3978 (23%)]\tLoss: 0.011194\n",
            "Train Epoch: 4 [914/3978 (23%)]\tLoss: 2.668234\n",
            "Train Epoch: 4 [915/3978 (23%)]\tLoss: 1.540582\n",
            "Train Epoch: 4 [916/3978 (23%)]\tLoss: 2.144193\n",
            "Train Epoch: 4 [917/3978 (23%)]\tLoss: 2.417917\n",
            "Train Epoch: 4 [918/3978 (23%)]\tLoss: 0.239086\n",
            "Train Epoch: 4 [919/3978 (23%)]\tLoss: 0.006762\n",
            "Train Epoch: 4 [920/3978 (23%)]\tLoss: 0.857428\n",
            "Train Epoch: 4 [921/3978 (23%)]\tLoss: 0.329321\n",
            "Train Epoch: 4 [922/3978 (23%)]\tLoss: 0.616874\n",
            "Train Epoch: 4 [923/3978 (23%)]\tLoss: 0.793304\n",
            "Train Epoch: 4 [924/3978 (23%)]\tLoss: 1.398241\n",
            "Train Epoch: 4 [925/3978 (23%)]\tLoss: 2.097025\n",
            "Train Epoch: 4 [926/3978 (23%)]\tLoss: 0.934303\n",
            "Train Epoch: 4 [927/3978 (23%)]\tLoss: 2.996094\n",
            "Train Epoch: 4 [928/3978 (23%)]\tLoss: 0.104987\n",
            "Train Epoch: 4 [929/3978 (23%)]\tLoss: 0.001281\n",
            "Train Epoch: 4 [930/3978 (23%)]\tLoss: 0.000552\n",
            "Train Epoch: 4 [931/3978 (23%)]\tLoss: 0.136474\n",
            "Train Epoch: 4 [932/3978 (23%)]\tLoss: 0.090049\n",
            "Train Epoch: 4 [933/3978 (23%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [934/3978 (23%)]\tLoss: 3.093074\n",
            "Train Epoch: 4 [935/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [936/3978 (24%)]\tLoss: 3.311271\n",
            "Train Epoch: 4 [937/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [938/3978 (24%)]\tLoss: 0.753481\n",
            "Train Epoch: 4 [939/3978 (24%)]\tLoss: 0.784676\n",
            "Train Epoch: 4 [940/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [941/3978 (24%)]\tLoss: 0.354251\n",
            "Train Epoch: 4 [942/3978 (24%)]\tLoss: 0.236688\n",
            "Train Epoch: 4 [943/3978 (24%)]\tLoss: 4.117083\n",
            "Train Epoch: 4 [944/3978 (24%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [945/3978 (24%)]\tLoss: 0.165053\n",
            "Train Epoch: 4 [946/3978 (24%)]\tLoss: 0.000121\n",
            "Train Epoch: 4 [947/3978 (24%)]\tLoss: 0.000183\n",
            "Train Epoch: 4 [948/3978 (24%)]\tLoss: 1.369121\n",
            "Train Epoch: 4 [949/3978 (24%)]\tLoss: 0.000022\n",
            "Train Epoch: 4 [950/3978 (24%)]\tLoss: 1.689279\n",
            "Train Epoch: 4 [951/3978 (24%)]\tLoss: 3.088279\n",
            "Train Epoch: 4 [952/3978 (24%)]\tLoss: 1.684961\n",
            "Train Epoch: 4 [953/3978 (24%)]\tLoss: 0.426056\n",
            "Train Epoch: 4 [954/3978 (24%)]\tLoss: 1.424930\n",
            "Train Epoch: 4 [955/3978 (24%)]\tLoss: 1.186342\n",
            "Train Epoch: 4 [956/3978 (24%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [957/3978 (24%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [958/3978 (24%)]\tLoss: 1.429260\n",
            "Train Epoch: 4 [959/3978 (24%)]\tLoss: 1.490781\n",
            "Train Epoch: 4 [960/3978 (24%)]\tLoss: 0.659441\n",
            "Train Epoch: 4 [961/3978 (24%)]\tLoss: 0.069683\n",
            "Train Epoch: 4 [962/3978 (24%)]\tLoss: 0.476426\n",
            "Train Epoch: 4 [963/3978 (24%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [964/3978 (24%)]\tLoss: 0.000021\n",
            "Train Epoch: 4 [965/3978 (24%)]\tLoss: 1.612665\n",
            "Train Epoch: 4 [966/3978 (24%)]\tLoss: 2.155779\n",
            "Train Epoch: 4 [967/3978 (24%)]\tLoss: 0.000035\n",
            "Train Epoch: 4 [968/3978 (24%)]\tLoss: 1.209730\n",
            "Train Epoch: 4 [969/3978 (24%)]\tLoss: 0.528202\n",
            "Train Epoch: 4 [970/3978 (24%)]\tLoss: 0.000147\n",
            "Train Epoch: 4 [971/3978 (24%)]\tLoss: 0.000061\n",
            "Train Epoch: 4 [972/3978 (24%)]\tLoss: 1.186613\n",
            "Train Epoch: 4 [973/3978 (24%)]\tLoss: 0.002377\n",
            "Train Epoch: 4 [974/3978 (24%)]\tLoss: 0.017340\n",
            "Train Epoch: 4 [975/3978 (25%)]\tLoss: 3.122695\n",
            "Train Epoch: 4 [976/3978 (25%)]\tLoss: 3.805772\n",
            "Train Epoch: 4 [977/3978 (25%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [978/3978 (25%)]\tLoss: 2.734424\n",
            "Train Epoch: 4 [979/3978 (25%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [980/3978 (25%)]\tLoss: 0.000250\n",
            "Train Epoch: 4 [981/3978 (25%)]\tLoss: 5.984927\n",
            "Train Epoch: 4 [982/3978 (25%)]\tLoss: 0.381503\n",
            "Train Epoch: 4 [983/3978 (25%)]\tLoss: 0.127354\n",
            "Train Epoch: 4 [984/3978 (25%)]\tLoss: 0.182472\n",
            "Train Epoch: 4 [985/3978 (25%)]\tLoss: 0.311325\n",
            "Train Epoch: 4 [986/3978 (25%)]\tLoss: 7.355475\n",
            "Train Epoch: 4 [987/3978 (25%)]\tLoss: 1.806462\n",
            "Train Epoch: 4 [988/3978 (25%)]\tLoss: 2.905501\n",
            "Train Epoch: 4 [989/3978 (25%)]\tLoss: 1.221774\n",
            "Train Epoch: 4 [990/3978 (25%)]\tLoss: 0.000648\n",
            "Train Epoch: 4 [991/3978 (25%)]\tLoss: 0.384288\n",
            "Train Epoch: 4 [992/3978 (25%)]\tLoss: 0.008289\n",
            "Train Epoch: 4 [993/3978 (25%)]\tLoss: 5.585107\n",
            "Train Epoch: 4 [994/3978 (25%)]\tLoss: 2.081118\n",
            "Train Epoch: 4 [995/3978 (25%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [996/3978 (25%)]\tLoss: 0.000042\n",
            "Train Epoch: 4 [997/3978 (25%)]\tLoss: 1.902496\n",
            "Train Epoch: 4 [998/3978 (25%)]\tLoss: 3.888311\n",
            "Train Epoch: 4 [999/3978 (25%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1000/3978 (25%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1001/3978 (25%)]\tLoss: 1.651295\n",
            "Train Epoch: 4 [1002/3978 (25%)]\tLoss: 2.792874\n",
            "Train Epoch: 4 [1003/3978 (25%)]\tLoss: 0.000386\n",
            "Train Epoch: 4 [1004/3978 (25%)]\tLoss: 2.203964\n",
            "Train Epoch: 4 [1005/3978 (25%)]\tLoss: 1.092243\n",
            "Train Epoch: 4 [1006/3978 (25%)]\tLoss: 1.432494\n",
            "Train Epoch: 4 [1007/3978 (25%)]\tLoss: 2.084493\n",
            "Train Epoch: 4 [1008/3978 (25%)]\tLoss: 1.023121\n",
            "Train Epoch: 4 [1009/3978 (25%)]\tLoss: 1.705663\n",
            "Train Epoch: 4 [1010/3978 (25%)]\tLoss: 1.228919\n",
            "Train Epoch: 4 [1011/3978 (25%)]\tLoss: 1.642449\n",
            "Train Epoch: 4 [1012/3978 (25%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1013/3978 (25%)]\tLoss: 0.460008\n",
            "Train Epoch: 4 [1014/3978 (25%)]\tLoss: 0.089078\n",
            "Train Epoch: 4 [1015/3978 (26%)]\tLoss: 0.001706\n",
            "Train Epoch: 4 [1016/3978 (26%)]\tLoss: 0.023036\n",
            "Train Epoch: 4 [1017/3978 (26%)]\tLoss: 0.663063\n",
            "Train Epoch: 4 [1018/3978 (26%)]\tLoss: 1.648172\n",
            "Train Epoch: 4 [1019/3978 (26%)]\tLoss: 0.004965\n",
            "Train Epoch: 4 [1020/3978 (26%)]\tLoss: 0.382668\n",
            "Train Epoch: 4 [1021/3978 (26%)]\tLoss: 0.875530\n",
            "Train Epoch: 4 [1022/3978 (26%)]\tLoss: 0.808710\n",
            "Train Epoch: 4 [1023/3978 (26%)]\tLoss: 1.964124\n",
            "Train Epoch: 4 [1024/3978 (26%)]\tLoss: 0.000128\n",
            "Train Epoch: 4 [1025/3978 (26%)]\tLoss: 3.706638\n",
            "Train Epoch: 4 [1026/3978 (26%)]\tLoss: 2.658995\n",
            "Train Epoch: 4 [1027/3978 (26%)]\tLoss: 0.105314\n",
            "Train Epoch: 4 [1028/3978 (26%)]\tLoss: 0.133001\n",
            "Train Epoch: 4 [1029/3978 (26%)]\tLoss: 0.140351\n",
            "Train Epoch: 4 [1030/3978 (26%)]\tLoss: 0.179958\n",
            "Train Epoch: 4 [1031/3978 (26%)]\tLoss: 0.077550\n",
            "Train Epoch: 4 [1032/3978 (26%)]\tLoss: 0.200881\n",
            "Train Epoch: 4 [1033/3978 (26%)]\tLoss: 0.004220\n",
            "Train Epoch: 4 [1034/3978 (26%)]\tLoss: 0.680705\n",
            "Train Epoch: 4 [1035/3978 (26%)]\tLoss: 0.026354\n",
            "Train Epoch: 4 [1036/3978 (26%)]\tLoss: 0.136256\n",
            "Train Epoch: 4 [1037/3978 (26%)]\tLoss: 1.623910\n",
            "Train Epoch: 4 [1038/3978 (26%)]\tLoss: 2.424318\n",
            "Train Epoch: 4 [1039/3978 (26%)]\tLoss: 1.618964\n",
            "Train Epoch: 4 [1040/3978 (26%)]\tLoss: 1.761565\n",
            "Train Epoch: 4 [1041/3978 (26%)]\tLoss: 0.133765\n",
            "Train Epoch: 4 [1042/3978 (26%)]\tLoss: 0.229553\n",
            "Train Epoch: 4 [1043/3978 (26%)]\tLoss: 0.394811\n",
            "Train Epoch: 4 [1044/3978 (26%)]\tLoss: 0.545929\n",
            "Train Epoch: 4 [1045/3978 (26%)]\tLoss: 0.527718\n",
            "Train Epoch: 4 [1046/3978 (26%)]\tLoss: 1.020772\n",
            "Train Epoch: 4 [1047/3978 (26%)]\tLoss: 0.069345\n",
            "Train Epoch: 4 [1048/3978 (26%)]\tLoss: 1.865567\n",
            "Train Epoch: 4 [1049/3978 (26%)]\tLoss: 0.089515\n",
            "Train Epoch: 4 [1050/3978 (26%)]\tLoss: 0.220056\n",
            "Train Epoch: 4 [1051/3978 (26%)]\tLoss: 0.623498\n",
            "Train Epoch: 4 [1052/3978 (26%)]\tLoss: 0.000602\n",
            "Train Epoch: 4 [1053/3978 (26%)]\tLoss: 2.018336\n",
            "Train Epoch: 4 [1054/3978 (26%)]\tLoss: 3.656353\n",
            "Train Epoch: 4 [1055/3978 (27%)]\tLoss: 0.257854\n",
            "Train Epoch: 4 [1056/3978 (27%)]\tLoss: 2.760827\n",
            "Train Epoch: 4 [1057/3978 (27%)]\tLoss: 0.101699\n",
            "Train Epoch: 4 [1058/3978 (27%)]\tLoss: 3.750436\n",
            "Train Epoch: 4 [1059/3978 (27%)]\tLoss: 0.869159\n",
            "Train Epoch: 4 [1060/3978 (27%)]\tLoss: 1.308813\n",
            "Train Epoch: 4 [1061/3978 (27%)]\tLoss: 2.327441\n",
            "Train Epoch: 4 [1062/3978 (27%)]\tLoss: 0.385163\n",
            "Train Epoch: 4 [1063/3978 (27%)]\tLoss: 0.284014\n",
            "Train Epoch: 4 [1064/3978 (27%)]\tLoss: 0.899211\n",
            "Train Epoch: 4 [1065/3978 (27%)]\tLoss: 0.435844\n",
            "Train Epoch: 4 [1066/3978 (27%)]\tLoss: 1.459982\n",
            "Train Epoch: 4 [1067/3978 (27%)]\tLoss: 0.000288\n",
            "Train Epoch: 4 [1068/3978 (27%)]\tLoss: 1.651413\n",
            "Train Epoch: 4 [1069/3978 (27%)]\tLoss: 0.816285\n",
            "Train Epoch: 4 [1070/3978 (27%)]\tLoss: 2.096020\n",
            "Train Epoch: 4 [1071/3978 (27%)]\tLoss: 0.193519\n",
            "Train Epoch: 4 [1072/3978 (27%)]\tLoss: 0.000945\n",
            "Train Epoch: 4 [1073/3978 (27%)]\tLoss: 1.149434\n",
            "Train Epoch: 4 [1074/3978 (27%)]\tLoss: 1.497327\n",
            "Train Epoch: 4 [1075/3978 (27%)]\tLoss: 0.056161\n",
            "Train Epoch: 4 [1076/3978 (27%)]\tLoss: 1.595986\n",
            "Train Epoch: 4 [1077/3978 (27%)]\tLoss: 4.026970\n",
            "Train Epoch: 4 [1078/3978 (27%)]\tLoss: 0.480213\n",
            "Train Epoch: 4 [1079/3978 (27%)]\tLoss: 0.870777\n",
            "Train Epoch: 4 [1080/3978 (27%)]\tLoss: 0.168596\n",
            "Train Epoch: 4 [1081/3978 (27%)]\tLoss: 0.777755\n",
            "Train Epoch: 4 [1082/3978 (27%)]\tLoss: 2.528439\n",
            "Train Epoch: 4 [1083/3978 (27%)]\tLoss: 1.132201\n",
            "Train Epoch: 4 [1084/3978 (27%)]\tLoss: 0.008239\n",
            "Train Epoch: 4 [1085/3978 (27%)]\tLoss: 5.241790\n",
            "Train Epoch: 4 [1086/3978 (27%)]\tLoss: 0.899918\n",
            "Train Epoch: 4 [1087/3978 (27%)]\tLoss: 1.042015\n",
            "Train Epoch: 4 [1088/3978 (27%)]\tLoss: 0.939774\n",
            "Train Epoch: 4 [1089/3978 (27%)]\tLoss: 1.418444\n",
            "Train Epoch: 4 [1090/3978 (27%)]\tLoss: 1.576608\n",
            "Train Epoch: 4 [1091/3978 (27%)]\tLoss: 2.462563\n",
            "Train Epoch: 4 [1092/3978 (27%)]\tLoss: 1.430218\n",
            "Train Epoch: 4 [1093/3978 (27%)]\tLoss: 2.598179\n",
            "Train Epoch: 4 [1094/3978 (28%)]\tLoss: 1.026399\n",
            "Train Epoch: 4 [1095/3978 (28%)]\tLoss: 0.585292\n",
            "Train Epoch: 4 [1096/3978 (28%)]\tLoss: 0.006891\n",
            "Train Epoch: 4 [1097/3978 (28%)]\tLoss: 1.685105\n",
            "Train Epoch: 4 [1098/3978 (28%)]\tLoss: 1.780910\n",
            "Train Epoch: 4 [1099/3978 (28%)]\tLoss: 0.023804\n",
            "Train Epoch: 4 [1100/3978 (28%)]\tLoss: 1.074486\n",
            "Train Epoch: 4 [1101/3978 (28%)]\tLoss: 0.682756\n",
            "Train Epoch: 4 [1102/3978 (28%)]\tLoss: 0.520768\n",
            "Train Epoch: 4 [1103/3978 (28%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1104/3978 (28%)]\tLoss: 1.450477\n",
            "Train Epoch: 4 [1105/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1106/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1107/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1108/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1109/3978 (28%)]\tLoss: 3.148479\n",
            "Train Epoch: 4 [1110/3978 (28%)]\tLoss: 2.456326\n",
            "Train Epoch: 4 [1111/3978 (28%)]\tLoss: 1.172506\n",
            "Train Epoch: 4 [1112/3978 (28%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [1113/3978 (28%)]\tLoss: 0.000257\n",
            "Train Epoch: 4 [1114/3978 (28%)]\tLoss: 0.518308\n",
            "Train Epoch: 4 [1115/3978 (28%)]\tLoss: 0.001112\n",
            "Train Epoch: 4 [1116/3978 (28%)]\tLoss: 0.002592\n",
            "Train Epoch: 4 [1117/3978 (28%)]\tLoss: 0.005712\n",
            "Train Epoch: 4 [1118/3978 (28%)]\tLoss: 2.081739\n",
            "Train Epoch: 4 [1119/3978 (28%)]\tLoss: 2.018090\n",
            "Train Epoch: 4 [1120/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1121/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1122/3978 (28%)]\tLoss: 1.099907\n",
            "Train Epoch: 4 [1123/3978 (28%)]\tLoss: 4.840884\n",
            "Train Epoch: 4 [1124/3978 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1125/3978 (28%)]\tLoss: 0.599625\n",
            "Train Epoch: 4 [1126/3978 (28%)]\tLoss: 1.321762\n",
            "Train Epoch: 4 [1127/3978 (28%)]\tLoss: 0.285454\n",
            "Train Epoch: 4 [1128/3978 (28%)]\tLoss: 1.719875\n",
            "Train Epoch: 4 [1129/3978 (28%)]\tLoss: 0.038319\n",
            "Train Epoch: 4 [1130/3978 (28%)]\tLoss: 0.000332\n",
            "Train Epoch: 4 [1131/3978 (28%)]\tLoss: 2.852962\n",
            "Train Epoch: 4 [1132/3978 (28%)]\tLoss: 7.020209\n",
            "Train Epoch: 4 [1133/3978 (28%)]\tLoss: 6.161354\n",
            "Train Epoch: 4 [1134/3978 (29%)]\tLoss: 3.544910\n",
            "Train Epoch: 4 [1135/3978 (29%)]\tLoss: 0.072743\n",
            "Train Epoch: 4 [1136/3978 (29%)]\tLoss: 0.001272\n",
            "Train Epoch: 4 [1137/3978 (29%)]\tLoss: 3.037651\n",
            "Train Epoch: 4 [1138/3978 (29%)]\tLoss: 0.021713\n",
            "Train Epoch: 4 [1139/3978 (29%)]\tLoss: 0.000390\n",
            "Train Epoch: 4 [1140/3978 (29%)]\tLoss: 1.909677\n",
            "Train Epoch: 4 [1141/3978 (29%)]\tLoss: 9.727895\n",
            "Train Epoch: 4 [1142/3978 (29%)]\tLoss: 0.027425\n",
            "Train Epoch: 4 [1143/3978 (29%)]\tLoss: 2.214785\n",
            "Train Epoch: 4 [1144/3978 (29%)]\tLoss: 0.221624\n",
            "Train Epoch: 4 [1145/3978 (29%)]\tLoss: 2.481260\n",
            "Train Epoch: 4 [1146/3978 (29%)]\tLoss: 0.254496\n",
            "Train Epoch: 4 [1147/3978 (29%)]\tLoss: 6.273154\n",
            "Train Epoch: 4 [1148/3978 (29%)]\tLoss: 0.788281\n",
            "Train Epoch: 4 [1149/3978 (29%)]\tLoss: 0.301279\n",
            "Train Epoch: 4 [1150/3978 (29%)]\tLoss: 0.151374\n",
            "Train Epoch: 4 [1151/3978 (29%)]\tLoss: 0.054718\n",
            "Train Epoch: 4 [1152/3978 (29%)]\tLoss: 1.604261\n",
            "Train Epoch: 4 [1153/3978 (29%)]\tLoss: 1.773371\n",
            "Train Epoch: 4 [1154/3978 (29%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1155/3978 (29%)]\tLoss: 0.000976\n",
            "Train Epoch: 4 [1156/3978 (29%)]\tLoss: 1.285635\n",
            "Train Epoch: 4 [1157/3978 (29%)]\tLoss: 0.070832\n",
            "Train Epoch: 4 [1158/3978 (29%)]\tLoss: 0.573620\n",
            "Train Epoch: 4 [1159/3978 (29%)]\tLoss: 2.479129\n",
            "Train Epoch: 4 [1160/3978 (29%)]\tLoss: 0.085283\n",
            "Train Epoch: 4 [1161/3978 (29%)]\tLoss: 0.193823\n",
            "Train Epoch: 4 [1162/3978 (29%)]\tLoss: 0.408151\n",
            "Train Epoch: 4 [1163/3978 (29%)]\tLoss: 0.231349\n",
            "Train Epoch: 4 [1164/3978 (29%)]\tLoss: 0.000989\n",
            "Train Epoch: 4 [1165/3978 (29%)]\tLoss: 0.000134\n",
            "Train Epoch: 4 [1166/3978 (29%)]\tLoss: 0.751604\n",
            "Train Epoch: 4 [1167/3978 (29%)]\tLoss: 2.285269\n",
            "Train Epoch: 4 [1168/3978 (29%)]\tLoss: 0.001221\n",
            "Train Epoch: 4 [1169/3978 (29%)]\tLoss: 0.140615\n",
            "Train Epoch: 4 [1170/3978 (29%)]\tLoss: 4.836946\n",
            "Train Epoch: 4 [1171/3978 (29%)]\tLoss: 0.839573\n",
            "Train Epoch: 4 [1172/3978 (29%)]\tLoss: 0.190528\n",
            "Train Epoch: 4 [1173/3978 (29%)]\tLoss: 0.124093\n",
            "Train Epoch: 4 [1174/3978 (30%)]\tLoss: 1.069473\n",
            "Train Epoch: 4 [1175/3978 (30%)]\tLoss: 0.000292\n",
            "Train Epoch: 4 [1176/3978 (30%)]\tLoss: 1.174745\n",
            "Train Epoch: 4 [1177/3978 (30%)]\tLoss: 0.061548\n",
            "Train Epoch: 4 [1178/3978 (30%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [1179/3978 (30%)]\tLoss: 0.019193\n",
            "Train Epoch: 4 [1180/3978 (30%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [1181/3978 (30%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [1182/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1183/3978 (30%)]\tLoss: 3.193287\n",
            "Train Epoch: 4 [1184/3978 (30%)]\tLoss: 5.226271\n",
            "Train Epoch: 4 [1185/3978 (30%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [1186/3978 (30%)]\tLoss: 2.106841\n",
            "Train Epoch: 4 [1187/3978 (30%)]\tLoss: 1.065465\n",
            "Train Epoch: 4 [1188/3978 (30%)]\tLoss: 0.361172\n",
            "Train Epoch: 4 [1189/3978 (30%)]\tLoss: 3.609088\n",
            "Train Epoch: 4 [1190/3978 (30%)]\tLoss: 1.772478\n",
            "Train Epoch: 4 [1191/3978 (30%)]\tLoss: 3.923856\n",
            "Train Epoch: 4 [1192/3978 (30%)]\tLoss: 1.984035\n",
            "Train Epoch: 4 [1193/3978 (30%)]\tLoss: 2.510897\n",
            "Train Epoch: 4 [1194/3978 (30%)]\tLoss: 0.191294\n",
            "Train Epoch: 4 [1195/3978 (30%)]\tLoss: 0.413978\n",
            "Train Epoch: 4 [1196/3978 (30%)]\tLoss: 1.125087\n",
            "Train Epoch: 4 [1197/3978 (30%)]\tLoss: 2.213041\n",
            "Train Epoch: 4 [1198/3978 (30%)]\tLoss: 0.666183\n",
            "Train Epoch: 4 [1199/3978 (30%)]\tLoss: 1.378156\n",
            "Train Epoch: 4 [1200/3978 (30%)]\tLoss: 0.336953\n",
            "Train Epoch: 4 [1201/3978 (30%)]\tLoss: 0.137238\n",
            "Train Epoch: 4 [1202/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1203/3978 (30%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [1204/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1205/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1206/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1207/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1208/3978 (30%)]\tLoss: 3.882099\n",
            "Train Epoch: 4 [1209/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1210/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1211/3978 (30%)]\tLoss: 2.859924\n",
            "Train Epoch: 4 [1212/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1213/3978 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1214/3978 (31%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1215/3978 (31%)]\tLoss: 0.990355\n",
            "Train Epoch: 4 [1216/3978 (31%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1217/3978 (31%)]\tLoss: 0.003084\n",
            "Train Epoch: 4 [1218/3978 (31%)]\tLoss: 3.733712\n",
            "Train Epoch: 4 [1219/3978 (31%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [1220/3978 (31%)]\tLoss: 0.000091\n",
            "Train Epoch: 4 [1221/3978 (31%)]\tLoss: 0.283770\n",
            "Train Epoch: 4 [1222/3978 (31%)]\tLoss: 1.613427\n",
            "Train Epoch: 4 [1223/3978 (31%)]\tLoss: 0.000303\n",
            "Train Epoch: 4 [1224/3978 (31%)]\tLoss: 7.016985\n",
            "Train Epoch: 4 [1225/3978 (31%)]\tLoss: 0.001110\n",
            "Train Epoch: 4 [1226/3978 (31%)]\tLoss: 3.738958\n",
            "Train Epoch: 4 [1227/3978 (31%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [1228/3978 (31%)]\tLoss: 0.004684\n",
            "Train Epoch: 4 [1229/3978 (31%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1230/3978 (31%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1231/3978 (31%)]\tLoss: 0.590362\n",
            "Train Epoch: 4 [1232/3978 (31%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1233/3978 (31%)]\tLoss: 2.157475\n",
            "Train Epoch: 4 [1234/3978 (31%)]\tLoss: 0.002864\n",
            "Train Epoch: 4 [1235/3978 (31%)]\tLoss: 6.033080\n",
            "Train Epoch: 4 [1236/3978 (31%)]\tLoss: 0.352307\n",
            "Train Epoch: 4 [1237/3978 (31%)]\tLoss: 5.420817\n",
            "Train Epoch: 4 [1238/3978 (31%)]\tLoss: 1.674618\n",
            "Train Epoch: 4 [1239/3978 (31%)]\tLoss: 2.200119\n",
            "Train Epoch: 4 [1240/3978 (31%)]\tLoss: 1.157947\n",
            "Train Epoch: 4 [1241/3978 (31%)]\tLoss: 1.778062\n",
            "Train Epoch: 4 [1242/3978 (31%)]\tLoss: 0.083477\n",
            "Train Epoch: 4 [1243/3978 (31%)]\tLoss: 1.759005\n",
            "Train Epoch: 4 [1244/3978 (31%)]\tLoss: 3.076490\n",
            "Train Epoch: 4 [1245/3978 (31%)]\tLoss: 2.086924\n",
            "Train Epoch: 4 [1246/3978 (31%)]\tLoss: 1.024709\n",
            "Train Epoch: 4 [1247/3978 (31%)]\tLoss: 1.491473\n",
            "Train Epoch: 4 [1248/3978 (31%)]\tLoss: 1.625069\n",
            "Train Epoch: 4 [1249/3978 (31%)]\tLoss: 5.679457\n",
            "Train Epoch: 4 [1250/3978 (31%)]\tLoss: 0.001244\n",
            "Train Epoch: 4 [1251/3978 (31%)]\tLoss: 0.074886\n",
            "Train Epoch: 4 [1252/3978 (31%)]\tLoss: 2.321935\n",
            "Train Epoch: 4 [1253/3978 (31%)]\tLoss: 1.206977\n",
            "Train Epoch: 4 [1254/3978 (32%)]\tLoss: 0.004820\n",
            "Train Epoch: 4 [1255/3978 (32%)]\tLoss: 0.707278\n",
            "Train Epoch: 4 [1256/3978 (32%)]\tLoss: 0.417945\n",
            "Train Epoch: 4 [1257/3978 (32%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [1258/3978 (32%)]\tLoss: 1.691414\n",
            "Train Epoch: 4 [1259/3978 (32%)]\tLoss: 0.000102\n",
            "Train Epoch: 4 [1260/3978 (32%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [1261/3978 (32%)]\tLoss: 0.046700\n",
            "Train Epoch: 4 [1262/3978 (32%)]\tLoss: 0.920978\n",
            "Train Epoch: 4 [1263/3978 (32%)]\tLoss: 0.000160\n",
            "Train Epoch: 4 [1264/3978 (32%)]\tLoss: 4.744950\n",
            "Train Epoch: 4 [1265/3978 (32%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1266/3978 (32%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1267/3978 (32%)]\tLoss: 0.501107\n",
            "Train Epoch: 4 [1268/3978 (32%)]\tLoss: 0.757748\n",
            "Train Epoch: 4 [1269/3978 (32%)]\tLoss: 0.003564\n",
            "Train Epoch: 4 [1270/3978 (32%)]\tLoss: 0.014204\n",
            "Train Epoch: 4 [1271/3978 (32%)]\tLoss: 1.234431\n",
            "Train Epoch: 4 [1272/3978 (32%)]\tLoss: 0.004430\n",
            "Train Epoch: 4 [1273/3978 (32%)]\tLoss: 3.402144\n",
            "Train Epoch: 4 [1274/3978 (32%)]\tLoss: 0.490794\n",
            "Train Epoch: 4 [1275/3978 (32%)]\tLoss: 0.290014\n",
            "Train Epoch: 4 [1276/3978 (32%)]\tLoss: 0.040544\n",
            "Train Epoch: 4 [1277/3978 (32%)]\tLoss: 0.000128\n",
            "Train Epoch: 4 [1278/3978 (32%)]\tLoss: 0.558249\n",
            "Train Epoch: 4 [1279/3978 (32%)]\tLoss: 0.526379\n",
            "Train Epoch: 4 [1280/3978 (32%)]\tLoss: 0.014786\n",
            "Train Epoch: 4 [1281/3978 (32%)]\tLoss: 0.005656\n",
            "Train Epoch: 4 [1282/3978 (32%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1283/3978 (32%)]\tLoss: 0.002046\n",
            "Train Epoch: 4 [1284/3978 (32%)]\tLoss: 0.201017\n",
            "Train Epoch: 4 [1285/3978 (32%)]\tLoss: 3.282299\n",
            "Train Epoch: 4 [1286/3978 (32%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [1287/3978 (32%)]\tLoss: 0.037793\n",
            "Train Epoch: 4 [1288/3978 (32%)]\tLoss: 0.929277\n",
            "Train Epoch: 4 [1289/3978 (32%)]\tLoss: 0.030458\n",
            "Train Epoch: 4 [1290/3978 (32%)]\tLoss: 0.976985\n",
            "Train Epoch: 4 [1291/3978 (32%)]\tLoss: 0.158211\n",
            "Train Epoch: 4 [1292/3978 (32%)]\tLoss: 2.675939\n",
            "Train Epoch: 4 [1293/3978 (33%)]\tLoss: 0.653477\n",
            "Train Epoch: 4 [1294/3978 (33%)]\tLoss: 0.461555\n",
            "Train Epoch: 4 [1295/3978 (33%)]\tLoss: 0.003035\n",
            "Train Epoch: 4 [1296/3978 (33%)]\tLoss: 0.000445\n",
            "Train Epoch: 4 [1297/3978 (33%)]\tLoss: 1.242017\n",
            "Train Epoch: 4 [1298/3978 (33%)]\tLoss: 0.011466\n",
            "Train Epoch: 4 [1299/3978 (33%)]\tLoss: 0.000036\n",
            "Train Epoch: 4 [1300/3978 (33%)]\tLoss: 0.000063\n",
            "Train Epoch: 4 [1301/3978 (33%)]\tLoss: 0.578696\n",
            "Train Epoch: 4 [1302/3978 (33%)]\tLoss: 2.034900\n",
            "Train Epoch: 4 [1303/3978 (33%)]\tLoss: 0.269832\n",
            "Train Epoch: 4 [1304/3978 (33%)]\tLoss: 0.949988\n",
            "Train Epoch: 4 [1305/3978 (33%)]\tLoss: 0.058547\n",
            "Train Epoch: 4 [1306/3978 (33%)]\tLoss: 0.543968\n",
            "Train Epoch: 4 [1307/3978 (33%)]\tLoss: 0.626488\n",
            "Train Epoch: 4 [1308/3978 (33%)]\tLoss: 1.704107\n",
            "Train Epoch: 4 [1309/3978 (33%)]\tLoss: 1.991367\n",
            "Train Epoch: 4 [1310/3978 (33%)]\tLoss: 1.272740\n",
            "Train Epoch: 4 [1311/3978 (33%)]\tLoss: 1.774536\n",
            "Train Epoch: 4 [1312/3978 (33%)]\tLoss: 0.000916\n",
            "Train Epoch: 4 [1313/3978 (33%)]\tLoss: 1.449607\n",
            "Train Epoch: 4 [1314/3978 (33%)]\tLoss: 1.798985\n",
            "Train Epoch: 4 [1315/3978 (33%)]\tLoss: 1.656885\n",
            "Train Epoch: 4 [1316/3978 (33%)]\tLoss: 1.069030\n",
            "Train Epoch: 4 [1317/3978 (33%)]\tLoss: 0.041763\n",
            "Train Epoch: 4 [1318/3978 (33%)]\tLoss: 1.563546\n",
            "Train Epoch: 4 [1319/3978 (33%)]\tLoss: 2.797909\n",
            "Train Epoch: 4 [1320/3978 (33%)]\tLoss: 0.349566\n",
            "Train Epoch: 4 [1321/3978 (33%)]\tLoss: 0.115245\n",
            "Train Epoch: 4 [1322/3978 (33%)]\tLoss: 0.000515\n",
            "Train Epoch: 4 [1323/3978 (33%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1324/3978 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1325/3978 (33%)]\tLoss: 3.788242\n",
            "Train Epoch: 4 [1326/3978 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1327/3978 (33%)]\tLoss: 4.278285\n",
            "Train Epoch: 4 [1328/3978 (33%)]\tLoss: 3.810382\n",
            "Train Epoch: 4 [1329/3978 (33%)]\tLoss: 0.001855\n",
            "Train Epoch: 4 [1330/3978 (33%)]\tLoss: 2.775633\n",
            "Train Epoch: 4 [1331/3978 (33%)]\tLoss: 2.825295\n",
            "Train Epoch: 4 [1332/3978 (33%)]\tLoss: 3.752032\n",
            "Train Epoch: 4 [1333/3978 (34%)]\tLoss: 5.105653\n",
            "Train Epoch: 4 [1334/3978 (34%)]\tLoss: 1.413557\n",
            "Train Epoch: 4 [1335/3978 (34%)]\tLoss: 1.533470\n",
            "Train Epoch: 4 [1336/3978 (34%)]\tLoss: 0.002893\n",
            "Train Epoch: 4 [1337/3978 (34%)]\tLoss: 1.620474\n",
            "Train Epoch: 4 [1338/3978 (34%)]\tLoss: 0.000112\n",
            "Train Epoch: 4 [1339/3978 (34%)]\tLoss: 4.305050\n",
            "Train Epoch: 4 [1340/3978 (34%)]\tLoss: 6.567914\n",
            "Train Epoch: 4 [1341/3978 (34%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [1342/3978 (34%)]\tLoss: 0.001002\n",
            "Train Epoch: 4 [1343/3978 (34%)]\tLoss: 0.426107\n",
            "Train Epoch: 4 [1344/3978 (34%)]\tLoss: 0.302195\n",
            "Train Epoch: 4 [1345/3978 (34%)]\tLoss: 3.164197\n",
            "Train Epoch: 4 [1346/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1347/3978 (34%)]\tLoss: 2.538372\n",
            "Train Epoch: 4 [1348/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1349/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1350/3978 (34%)]\tLoss: 2.393800\n",
            "Train Epoch: 4 [1351/3978 (34%)]\tLoss: 1.424496\n",
            "Train Epoch: 4 [1352/3978 (34%)]\tLoss: 0.570448\n",
            "Train Epoch: 4 [1353/3978 (34%)]\tLoss: 0.280737\n",
            "Train Epoch: 4 [1354/3978 (34%)]\tLoss: 0.009214\n",
            "Train Epoch: 4 [1355/3978 (34%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [1356/3978 (34%)]\tLoss: 2.273523\n",
            "Train Epoch: 4 [1357/3978 (34%)]\tLoss: 2.034737\n",
            "Train Epoch: 4 [1358/3978 (34%)]\tLoss: 1.456890\n",
            "Train Epoch: 4 [1359/3978 (34%)]\tLoss: 1.776191\n",
            "Train Epoch: 4 [1360/3978 (34%)]\tLoss: 0.347132\n",
            "Train Epoch: 4 [1361/3978 (34%)]\tLoss: 1.858881\n",
            "Train Epoch: 4 [1362/3978 (34%)]\tLoss: 0.055793\n",
            "Train Epoch: 4 [1363/3978 (34%)]\tLoss: 2.006372\n",
            "Train Epoch: 4 [1364/3978 (34%)]\tLoss: 1.673733\n",
            "Train Epoch: 4 [1365/3978 (34%)]\tLoss: 1.338893\n",
            "Train Epoch: 4 [1366/3978 (34%)]\tLoss: 0.596051\n",
            "Train Epoch: 4 [1367/3978 (34%)]\tLoss: 0.000028\n",
            "Train Epoch: 4 [1368/3978 (34%)]\tLoss: 0.162806\n",
            "Train Epoch: 4 [1369/3978 (34%)]\tLoss: 0.028923\n",
            "Train Epoch: 4 [1370/3978 (34%)]\tLoss: 0.028659\n",
            "Train Epoch: 4 [1371/3978 (34%)]\tLoss: 0.002684\n",
            "Train Epoch: 4 [1372/3978 (34%)]\tLoss: 1.351125\n",
            "Train Epoch: 4 [1373/3978 (35%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [1374/3978 (35%)]\tLoss: 1.372062\n",
            "Train Epoch: 4 [1375/3978 (35%)]\tLoss: 0.055780\n",
            "Train Epoch: 4 [1376/3978 (35%)]\tLoss: 0.045848\n",
            "Train Epoch: 4 [1377/3978 (35%)]\tLoss: 0.455491\n",
            "Train Epoch: 4 [1378/3978 (35%)]\tLoss: 0.004392\n",
            "Train Epoch: 4 [1379/3978 (35%)]\tLoss: 0.947902\n",
            "Train Epoch: 4 [1380/3978 (35%)]\tLoss: 9.084742\n",
            "Train Epoch: 4 [1381/3978 (35%)]\tLoss: 0.109724\n",
            "Train Epoch: 4 [1382/3978 (35%)]\tLoss: 2.847447\n",
            "Train Epoch: 4 [1383/3978 (35%)]\tLoss: 1.288488\n",
            "Train Epoch: 4 [1384/3978 (35%)]\tLoss: 0.003667\n",
            "Train Epoch: 4 [1385/3978 (35%)]\tLoss: 0.001796\n",
            "Train Epoch: 4 [1386/3978 (35%)]\tLoss: 0.225724\n",
            "Train Epoch: 4 [1387/3978 (35%)]\tLoss: 0.322761\n",
            "Train Epoch: 4 [1388/3978 (35%)]\tLoss: 0.000027\n",
            "Train Epoch: 4 [1389/3978 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1390/3978 (35%)]\tLoss: 0.000226\n",
            "Train Epoch: 4 [1391/3978 (35%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1392/3978 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1393/3978 (35%)]\tLoss: 0.053096\n",
            "Train Epoch: 4 [1394/3978 (35%)]\tLoss: 1.841910\n",
            "Train Epoch: 4 [1395/3978 (35%)]\tLoss: 8.857557\n",
            "Train Epoch: 4 [1396/3978 (35%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [1397/3978 (35%)]\tLoss: 2.438527\n",
            "Train Epoch: 4 [1398/3978 (35%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1399/3978 (35%)]\tLoss: 4.940038\n",
            "Train Epoch: 4 [1400/3978 (35%)]\tLoss: 0.866478\n",
            "Train Epoch: 4 [1401/3978 (35%)]\tLoss: 0.012642\n",
            "Train Epoch: 4 [1402/3978 (35%)]\tLoss: 0.704988\n",
            "Train Epoch: 4 [1403/3978 (35%)]\tLoss: 1.322823\n",
            "Train Epoch: 4 [1404/3978 (35%)]\tLoss: 0.759746\n",
            "Train Epoch: 4 [1405/3978 (35%)]\tLoss: 0.065243\n",
            "Train Epoch: 4 [1406/3978 (35%)]\tLoss: 1.575391\n",
            "Train Epoch: 4 [1407/3978 (35%)]\tLoss: 0.000108\n",
            "Train Epoch: 4 [1408/3978 (35%)]\tLoss: 5.158938\n",
            "Train Epoch: 4 [1409/3978 (35%)]\tLoss: 0.395890\n",
            "Train Epoch: 4 [1410/3978 (35%)]\tLoss: 0.020229\n",
            "Train Epoch: 4 [1411/3978 (35%)]\tLoss: 4.609406\n",
            "Train Epoch: 4 [1412/3978 (35%)]\tLoss: 4.679523\n",
            "Train Epoch: 4 [1413/3978 (36%)]\tLoss: 0.156530\n",
            "Train Epoch: 4 [1414/3978 (36%)]\tLoss: 1.716398\n",
            "Train Epoch: 4 [1415/3978 (36%)]\tLoss: 0.095555\n",
            "Train Epoch: 4 [1416/3978 (36%)]\tLoss: 0.056476\n",
            "Train Epoch: 4 [1417/3978 (36%)]\tLoss: 0.013229\n",
            "Train Epoch: 4 [1418/3978 (36%)]\tLoss: 0.073594\n",
            "Train Epoch: 4 [1419/3978 (36%)]\tLoss: 0.203621\n",
            "Train Epoch: 4 [1420/3978 (36%)]\tLoss: 0.498744\n",
            "Train Epoch: 4 [1421/3978 (36%)]\tLoss: 0.703354\n",
            "Train Epoch: 4 [1422/3978 (36%)]\tLoss: 0.036361\n",
            "Train Epoch: 4 [1423/3978 (36%)]\tLoss: 0.471325\n",
            "Train Epoch: 4 [1424/3978 (36%)]\tLoss: 0.544595\n",
            "Train Epoch: 4 [1425/3978 (36%)]\tLoss: 0.128910\n",
            "Train Epoch: 4 [1426/3978 (36%)]\tLoss: 0.162744\n",
            "Train Epoch: 4 [1427/3978 (36%)]\tLoss: 0.175167\n",
            "Train Epoch: 4 [1428/3978 (36%)]\tLoss: 0.004446\n",
            "Train Epoch: 4 [1429/3978 (36%)]\tLoss: 2.392653\n",
            "Train Epoch: 4 [1430/3978 (36%)]\tLoss: 1.327088\n",
            "Train Epoch: 4 [1431/3978 (36%)]\tLoss: 0.091926\n",
            "Train Epoch: 4 [1432/3978 (36%)]\tLoss: 0.093097\n",
            "Train Epoch: 4 [1433/3978 (36%)]\tLoss: 0.675668\n",
            "Train Epoch: 4 [1434/3978 (36%)]\tLoss: 0.003899\n",
            "Train Epoch: 4 [1435/3978 (36%)]\tLoss: 0.038990\n",
            "Train Epoch: 4 [1436/3978 (36%)]\tLoss: 0.003723\n",
            "Train Epoch: 4 [1437/3978 (36%)]\tLoss: 0.019949\n",
            "Train Epoch: 4 [1438/3978 (36%)]\tLoss: 0.035991\n",
            "Train Epoch: 4 [1439/3978 (36%)]\tLoss: 0.013418\n",
            "Train Epoch: 4 [1440/3978 (36%)]\tLoss: 0.176357\n",
            "Train Epoch: 4 [1441/3978 (36%)]\tLoss: 0.000408\n",
            "Train Epoch: 4 [1442/3978 (36%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1443/3978 (36%)]\tLoss: 0.001558\n",
            "Train Epoch: 4 [1444/3978 (36%)]\tLoss: 2.794004\n",
            "Train Epoch: 4 [1445/3978 (36%)]\tLoss: 1.345908\n",
            "Train Epoch: 4 [1446/3978 (36%)]\tLoss: 1.335308\n",
            "Train Epoch: 4 [1447/3978 (36%)]\tLoss: 0.004333\n",
            "Train Epoch: 4 [1448/3978 (36%)]\tLoss: 1.108755\n",
            "Train Epoch: 4 [1449/3978 (36%)]\tLoss: 0.742913\n",
            "Train Epoch: 4 [1450/3978 (36%)]\tLoss: 1.195486\n",
            "Train Epoch: 4 [1451/3978 (36%)]\tLoss: 2.022094\n",
            "Train Epoch: 4 [1452/3978 (37%)]\tLoss: 1.884711\n",
            "Train Epoch: 4 [1453/3978 (37%)]\tLoss: 5.725173\n",
            "Train Epoch: 4 [1454/3978 (37%)]\tLoss: 0.019287\n",
            "Train Epoch: 4 [1455/3978 (37%)]\tLoss: 0.285276\n",
            "Train Epoch: 4 [1456/3978 (37%)]\tLoss: 3.015307\n",
            "Train Epoch: 4 [1457/3978 (37%)]\tLoss: 8.363861\n",
            "Train Epoch: 4 [1458/3978 (37%)]\tLoss: 1.286780\n",
            "Train Epoch: 4 [1459/3978 (37%)]\tLoss: 4.147762\n",
            "Train Epoch: 4 [1460/3978 (37%)]\tLoss: 0.862032\n",
            "Train Epoch: 4 [1461/3978 (37%)]\tLoss: 4.097960\n",
            "Train Epoch: 4 [1462/3978 (37%)]\tLoss: 0.666424\n",
            "Train Epoch: 4 [1463/3978 (37%)]\tLoss: 0.003847\n",
            "Train Epoch: 4 [1464/3978 (37%)]\tLoss: 1.354012\n",
            "Train Epoch: 4 [1465/3978 (37%)]\tLoss: 0.172131\n",
            "Train Epoch: 4 [1466/3978 (37%)]\tLoss: 2.385964\n",
            "Train Epoch: 4 [1467/3978 (37%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1468/3978 (37%)]\tLoss: 0.106501\n",
            "Train Epoch: 4 [1469/3978 (37%)]\tLoss: 2.322948\n",
            "Train Epoch: 4 [1470/3978 (37%)]\tLoss: 2.892159\n",
            "Train Epoch: 4 [1471/3978 (37%)]\tLoss: 0.041441\n",
            "Train Epoch: 4 [1472/3978 (37%)]\tLoss: 0.115601\n",
            "Train Epoch: 4 [1473/3978 (37%)]\tLoss: 1.003775\n",
            "Train Epoch: 4 [1474/3978 (37%)]\tLoss: 0.230486\n",
            "Train Epoch: 4 [1475/3978 (37%)]\tLoss: 3.164913\n",
            "Train Epoch: 4 [1476/3978 (37%)]\tLoss: 0.043317\n",
            "Train Epoch: 4 [1477/3978 (37%)]\tLoss: 1.213671\n",
            "Train Epoch: 4 [1478/3978 (37%)]\tLoss: 1.139402\n",
            "Train Epoch: 4 [1479/3978 (37%)]\tLoss: 0.244150\n",
            "Train Epoch: 4 [1480/3978 (37%)]\tLoss: 1.963536\n",
            "Train Epoch: 4 [1481/3978 (37%)]\tLoss: 0.599263\n",
            "Train Epoch: 4 [1482/3978 (37%)]\tLoss: 0.934663\n",
            "Train Epoch: 4 [1483/3978 (37%)]\tLoss: 0.757631\n",
            "Train Epoch: 4 [1484/3978 (37%)]\tLoss: 0.864438\n",
            "Train Epoch: 4 [1485/3978 (37%)]\tLoss: 0.080452\n",
            "Train Epoch: 4 [1486/3978 (37%)]\tLoss: 1.131020\n",
            "Train Epoch: 4 [1487/3978 (37%)]\tLoss: 0.302366\n",
            "Train Epoch: 4 [1488/3978 (37%)]\tLoss: 0.898779\n",
            "Train Epoch: 4 [1489/3978 (37%)]\tLoss: 0.887675\n",
            "Train Epoch: 4 [1490/3978 (37%)]\tLoss: 1.599505\n",
            "Train Epoch: 4 [1491/3978 (37%)]\tLoss: 0.298273\n",
            "Train Epoch: 4 [1492/3978 (38%)]\tLoss: 0.052593\n",
            "Train Epoch: 4 [1493/3978 (38%)]\tLoss: 0.004008\n",
            "Train Epoch: 4 [1494/3978 (38%)]\tLoss: 3.363706\n",
            "Train Epoch: 4 [1495/3978 (38%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1496/3978 (38%)]\tLoss: 1.438283\n",
            "Train Epoch: 4 [1497/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1498/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1499/3978 (38%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [1500/3978 (38%)]\tLoss: 2.311653\n",
            "Train Epoch: 4 [1501/3978 (38%)]\tLoss: 1.654095\n",
            "Train Epoch: 4 [1502/3978 (38%)]\tLoss: 0.993946\n",
            "Train Epoch: 4 [1503/3978 (38%)]\tLoss: 1.192757\n",
            "Train Epoch: 4 [1504/3978 (38%)]\tLoss: 0.100931\n",
            "Train Epoch: 4 [1505/3978 (38%)]\tLoss: 0.852744\n",
            "Train Epoch: 4 [1506/3978 (38%)]\tLoss: 2.397804\n",
            "Train Epoch: 4 [1507/3978 (38%)]\tLoss: 0.321258\n",
            "Train Epoch: 4 [1508/3978 (38%)]\tLoss: 1.948096\n",
            "Train Epoch: 4 [1509/3978 (38%)]\tLoss: 0.800940\n",
            "Train Epoch: 4 [1510/3978 (38%)]\tLoss: 0.007520\n",
            "Train Epoch: 4 [1511/3978 (38%)]\tLoss: 0.023754\n",
            "Train Epoch: 4 [1512/3978 (38%)]\tLoss: 0.643930\n",
            "Train Epoch: 4 [1513/3978 (38%)]\tLoss: 0.962864\n",
            "Train Epoch: 4 [1514/3978 (38%)]\tLoss: 1.180429\n",
            "Train Epoch: 4 [1515/3978 (38%)]\tLoss: 0.000107\n",
            "Train Epoch: 4 [1516/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1517/3978 (38%)]\tLoss: 1.951908\n",
            "Train Epoch: 4 [1518/3978 (38%)]\tLoss: 0.000614\n",
            "Train Epoch: 4 [1519/3978 (38%)]\tLoss: 0.009735\n",
            "Train Epoch: 4 [1520/3978 (38%)]\tLoss: 2.238191\n",
            "Train Epoch: 4 [1521/3978 (38%)]\tLoss: 1.580857\n",
            "Train Epoch: 4 [1522/3978 (38%)]\tLoss: 2.121969\n",
            "Train Epoch: 4 [1523/3978 (38%)]\tLoss: 2.096439\n",
            "Train Epoch: 4 [1524/3978 (38%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [1525/3978 (38%)]\tLoss: 0.208424\n",
            "Train Epoch: 4 [1526/3978 (38%)]\tLoss: 5.420264\n",
            "Train Epoch: 4 [1527/3978 (38%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1528/3978 (38%)]\tLoss: 1.602040\n",
            "Train Epoch: 4 [1529/3978 (38%)]\tLoss: 2.226115\n",
            "Train Epoch: 4 [1530/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1531/3978 (38%)]\tLoss: 2.079794\n",
            "Train Epoch: 4 [1532/3978 (39%)]\tLoss: 0.920036\n",
            "Train Epoch: 4 [1533/3978 (39%)]\tLoss: 0.011660\n",
            "Train Epoch: 4 [1534/3978 (39%)]\tLoss: 0.024383\n",
            "Train Epoch: 4 [1535/3978 (39%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [1536/3978 (39%)]\tLoss: 0.004899\n",
            "Train Epoch: 4 [1537/3978 (39%)]\tLoss: 0.457099\n",
            "Train Epoch: 4 [1538/3978 (39%)]\tLoss: 0.910341\n",
            "Train Epoch: 4 [1539/3978 (39%)]\tLoss: 0.005446\n",
            "Train Epoch: 4 [1540/3978 (39%)]\tLoss: 3.219516\n",
            "Train Epoch: 4 [1541/3978 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1542/3978 (39%)]\tLoss: 3.812399\n",
            "Train Epoch: 4 [1543/3978 (39%)]\tLoss: 0.005964\n",
            "Train Epoch: 4 [1544/3978 (39%)]\tLoss: 2.566549\n",
            "Train Epoch: 4 [1545/3978 (39%)]\tLoss: 2.304432\n",
            "Train Epoch: 4 [1546/3978 (39%)]\tLoss: 0.000192\n",
            "Train Epoch: 4 [1547/3978 (39%)]\tLoss: 0.095303\n",
            "Train Epoch: 4 [1548/3978 (39%)]\tLoss: 0.494654\n",
            "Train Epoch: 4 [1549/3978 (39%)]\tLoss: 3.511693\n",
            "Train Epoch: 4 [1550/3978 (39%)]\tLoss: 1.351091\n",
            "Train Epoch: 4 [1551/3978 (39%)]\tLoss: 0.019527\n",
            "Train Epoch: 4 [1552/3978 (39%)]\tLoss: 0.196925\n",
            "Train Epoch: 4 [1553/3978 (39%)]\tLoss: 2.262313\n",
            "Train Epoch: 4 [1554/3978 (39%)]\tLoss: 1.829395\n",
            "Train Epoch: 4 [1555/3978 (39%)]\tLoss: 0.025675\n",
            "Train Epoch: 4 [1556/3978 (39%)]\tLoss: 0.015472\n",
            "Train Epoch: 4 [1557/3978 (39%)]\tLoss: 0.008439\n",
            "Train Epoch: 4 [1558/3978 (39%)]\tLoss: 0.030893\n",
            "Train Epoch: 4 [1559/3978 (39%)]\tLoss: 0.462500\n",
            "Train Epoch: 4 [1560/3978 (39%)]\tLoss: 0.336641\n",
            "Train Epoch: 4 [1561/3978 (39%)]\tLoss: 0.000382\n",
            "Train Epoch: 4 [1562/3978 (39%)]\tLoss: 0.194216\n",
            "Train Epoch: 4 [1563/3978 (39%)]\tLoss: 0.063494\n",
            "Train Epoch: 4 [1564/3978 (39%)]\tLoss: 0.004142\n",
            "Train Epoch: 4 [1565/3978 (39%)]\tLoss: 0.003566\n",
            "Train Epoch: 4 [1566/3978 (39%)]\tLoss: 0.837563\n",
            "Train Epoch: 4 [1567/3978 (39%)]\tLoss: 0.000022\n",
            "Train Epoch: 4 [1568/3978 (39%)]\tLoss: 0.350503\n",
            "Train Epoch: 4 [1569/3978 (39%)]\tLoss: 3.552984\n",
            "Train Epoch: 4 [1570/3978 (39%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [1571/3978 (39%)]\tLoss: 0.547593\n",
            "Train Epoch: 4 [1572/3978 (40%)]\tLoss: 0.809620\n",
            "Train Epoch: 4 [1573/3978 (40%)]\tLoss: 0.099917\n",
            "Train Epoch: 4 [1574/3978 (40%)]\tLoss: 0.199643\n",
            "Train Epoch: 4 [1575/3978 (40%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [1576/3978 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1577/3978 (40%)]\tLoss: 2.309865\n",
            "Train Epoch: 4 [1578/3978 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1579/3978 (40%)]\tLoss: 1.851388\n",
            "Train Epoch: 4 [1580/3978 (40%)]\tLoss: 5.258038\n",
            "Train Epoch: 4 [1581/3978 (40%)]\tLoss: 0.000973\n",
            "Train Epoch: 4 [1582/3978 (40%)]\tLoss: 0.089977\n",
            "Train Epoch: 4 [1583/3978 (40%)]\tLoss: 4.119000\n",
            "Train Epoch: 4 [1584/3978 (40%)]\tLoss: 0.577611\n",
            "Train Epoch: 4 [1585/3978 (40%)]\tLoss: 3.453998\n",
            "Train Epoch: 4 [1586/3978 (40%)]\tLoss: 0.049198\n",
            "Train Epoch: 4 [1587/3978 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1588/3978 (40%)]\tLoss: 2.787783\n",
            "Train Epoch: 4 [1589/3978 (40%)]\tLoss: 3.599075\n",
            "Train Epoch: 4 [1590/3978 (40%)]\tLoss: 2.962398\n",
            "Train Epoch: 4 [1591/3978 (40%)]\tLoss: 1.019614\n",
            "Train Epoch: 4 [1592/3978 (40%)]\tLoss: 1.156280\n",
            "Train Epoch: 4 [1593/3978 (40%)]\tLoss: 0.006499\n",
            "Train Epoch: 4 [1594/3978 (40%)]\tLoss: 0.965145\n",
            "Train Epoch: 4 [1595/3978 (40%)]\tLoss: 1.187733\n",
            "Train Epoch: 4 [1596/3978 (40%)]\tLoss: 1.204263\n",
            "Train Epoch: 4 [1597/3978 (40%)]\tLoss: 0.617633\n",
            "Train Epoch: 4 [1598/3978 (40%)]\tLoss: 0.577918\n",
            "Train Epoch: 4 [1599/3978 (40%)]\tLoss: 0.657430\n",
            "Train Epoch: 4 [1600/3978 (40%)]\tLoss: 0.330611\n",
            "Train Epoch: 4 [1601/3978 (40%)]\tLoss: 0.710000\n",
            "Train Epoch: 4 [1602/3978 (40%)]\tLoss: 1.671292\n",
            "Train Epoch: 4 [1603/3978 (40%)]\tLoss: 0.000604\n",
            "Train Epoch: 4 [1604/3978 (40%)]\tLoss: 0.026908\n",
            "Train Epoch: 4 [1605/3978 (40%)]\tLoss: 0.044083\n",
            "Train Epoch: 4 [1606/3978 (40%)]\tLoss: 8.656293\n",
            "Train Epoch: 4 [1607/3978 (40%)]\tLoss: 0.002151\n",
            "Train Epoch: 4 [1608/3978 (40%)]\tLoss: 1.028145\n",
            "Train Epoch: 4 [1609/3978 (40%)]\tLoss: 0.007592\n",
            "Train Epoch: 4 [1610/3978 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1611/3978 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1612/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1613/3978 (41%)]\tLoss: 3.483815\n",
            "Train Epoch: 4 [1614/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1615/3978 (41%)]\tLoss: 3.526177\n",
            "Train Epoch: 4 [1616/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1617/3978 (41%)]\tLoss: 1.037390\n",
            "Train Epoch: 4 [1618/3978 (41%)]\tLoss: 2.320971\n",
            "Train Epoch: 4 [1619/3978 (41%)]\tLoss: 1.730574\n",
            "Train Epoch: 4 [1620/3978 (41%)]\tLoss: 0.117239\n",
            "Train Epoch: 4 [1621/3978 (41%)]\tLoss: 0.471003\n",
            "Train Epoch: 4 [1622/3978 (41%)]\tLoss: 0.003137\n",
            "Train Epoch: 4 [1623/3978 (41%)]\tLoss: 1.920653\n",
            "Train Epoch: 4 [1624/3978 (41%)]\tLoss: 0.001249\n",
            "Train Epoch: 4 [1625/3978 (41%)]\tLoss: 2.273787\n",
            "Train Epoch: 4 [1626/3978 (41%)]\tLoss: 3.400359\n",
            "Train Epoch: 4 [1627/3978 (41%)]\tLoss: 0.012014\n",
            "Train Epoch: 4 [1628/3978 (41%)]\tLoss: 0.000056\n",
            "Train Epoch: 4 [1629/3978 (41%)]\tLoss: 2.114896\n",
            "Train Epoch: 4 [1630/3978 (41%)]\tLoss: 0.157325\n",
            "Train Epoch: 4 [1631/3978 (41%)]\tLoss: 0.043209\n",
            "Train Epoch: 4 [1632/3978 (41%)]\tLoss: 0.197675\n",
            "Train Epoch: 4 [1633/3978 (41%)]\tLoss: 0.062313\n",
            "Train Epoch: 4 [1634/3978 (41%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [1635/3978 (41%)]\tLoss: 2.693801\n",
            "Train Epoch: 4 [1636/3978 (41%)]\tLoss: 1.793762\n",
            "Train Epoch: 4 [1637/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1638/3978 (41%)]\tLoss: 1.608138\n",
            "Train Epoch: 4 [1639/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1640/3978 (41%)]\tLoss: 0.078228\n",
            "Train Epoch: 4 [1641/3978 (41%)]\tLoss: 2.478558\n",
            "Train Epoch: 4 [1642/3978 (41%)]\tLoss: 0.690890\n",
            "Train Epoch: 4 [1643/3978 (41%)]\tLoss: 0.084766\n",
            "Train Epoch: 4 [1644/3978 (41%)]\tLoss: 2.732967\n",
            "Train Epoch: 4 [1645/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1646/3978 (41%)]\tLoss: 2.191399\n",
            "Train Epoch: 4 [1647/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1648/3978 (41%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1649/3978 (41%)]\tLoss: 1.643919\n",
            "Train Epoch: 4 [1650/3978 (41%)]\tLoss: 2.991448\n",
            "Train Epoch: 4 [1651/3978 (42%)]\tLoss: 3.778101\n",
            "Train Epoch: 4 [1652/3978 (42%)]\tLoss: 3.703505\n",
            "Train Epoch: 4 [1653/3978 (42%)]\tLoss: 0.071770\n",
            "Train Epoch: 4 [1654/3978 (42%)]\tLoss: 3.332907\n",
            "Train Epoch: 4 [1655/3978 (42%)]\tLoss: 2.203250\n",
            "Train Epoch: 4 [1656/3978 (42%)]\tLoss: 0.069003\n",
            "Train Epoch: 4 [1657/3978 (42%)]\tLoss: 0.008386\n",
            "Train Epoch: 4 [1658/3978 (42%)]\tLoss: 1.595975\n",
            "Train Epoch: 4 [1659/3978 (42%)]\tLoss: 1.273809\n",
            "Train Epoch: 4 [1660/3978 (42%)]\tLoss: 1.513769\n",
            "Train Epoch: 4 [1661/3978 (42%)]\tLoss: 3.070009\n",
            "Train Epoch: 4 [1662/3978 (42%)]\tLoss: 0.959125\n",
            "Train Epoch: 4 [1663/3978 (42%)]\tLoss: 1.108931\n",
            "Train Epoch: 4 [1664/3978 (42%)]\tLoss: 2.082554\n",
            "Train Epoch: 4 [1665/3978 (42%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1666/3978 (42%)]\tLoss: 0.645256\n",
            "Train Epoch: 4 [1667/3978 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1668/3978 (42%)]\tLoss: 4.841986\n",
            "Train Epoch: 4 [1669/3978 (42%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [1670/3978 (42%)]\tLoss: 0.002275\n",
            "Train Epoch: 4 [1671/3978 (42%)]\tLoss: 0.760982\n",
            "Train Epoch: 4 [1672/3978 (42%)]\tLoss: 1.402018\n",
            "Train Epoch: 4 [1673/3978 (42%)]\tLoss: 1.041598\n",
            "Train Epoch: 4 [1674/3978 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1675/3978 (42%)]\tLoss: 0.059348\n",
            "Train Epoch: 4 [1676/3978 (42%)]\tLoss: 1.465780\n",
            "Train Epoch: 4 [1677/3978 (42%)]\tLoss: 0.224758\n",
            "Train Epoch: 4 [1678/3978 (42%)]\tLoss: 0.499632\n",
            "Train Epoch: 4 [1679/3978 (42%)]\tLoss: 0.090636\n",
            "Train Epoch: 4 [1680/3978 (42%)]\tLoss: 0.025076\n",
            "Train Epoch: 4 [1681/3978 (42%)]\tLoss: 0.089907\n",
            "Train Epoch: 4 [1682/3978 (42%)]\tLoss: 0.565565\n",
            "Train Epoch: 4 [1683/3978 (42%)]\tLoss: 0.123758\n",
            "Train Epoch: 4 [1684/3978 (42%)]\tLoss: 1.365291\n",
            "Train Epoch: 4 [1685/3978 (42%)]\tLoss: 0.682311\n",
            "Train Epoch: 4 [1686/3978 (42%)]\tLoss: 0.171593\n",
            "Train Epoch: 4 [1687/3978 (42%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [1688/3978 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1689/3978 (42%)]\tLoss: 0.000056\n",
            "Train Epoch: 4 [1690/3978 (42%)]\tLoss: 2.297489\n",
            "Train Epoch: 4 [1691/3978 (43%)]\tLoss: 1.960340\n",
            "Train Epoch: 4 [1692/3978 (43%)]\tLoss: 0.853673\n",
            "Train Epoch: 4 [1693/3978 (43%)]\tLoss: 0.194521\n",
            "Train Epoch: 4 [1694/3978 (43%)]\tLoss: 0.117420\n",
            "Train Epoch: 4 [1695/3978 (43%)]\tLoss: 0.182875\n",
            "Train Epoch: 4 [1696/3978 (43%)]\tLoss: 3.341342\n",
            "Train Epoch: 4 [1697/3978 (43%)]\tLoss: 6.735494\n",
            "Train Epoch: 4 [1698/3978 (43%)]\tLoss: 1.360405\n",
            "Train Epoch: 4 [1699/3978 (43%)]\tLoss: 0.550122\n",
            "Train Epoch: 4 [1700/3978 (43%)]\tLoss: 0.174520\n",
            "Train Epoch: 4 [1701/3978 (43%)]\tLoss: 1.216268\n",
            "Train Epoch: 4 [1702/3978 (43%)]\tLoss: 1.227766\n",
            "Train Epoch: 4 [1703/3978 (43%)]\tLoss: 3.472311\n",
            "Train Epoch: 4 [1704/3978 (43%)]\tLoss: 3.390468\n",
            "Train Epoch: 4 [1705/3978 (43%)]\tLoss: 0.004195\n",
            "Train Epoch: 4 [1706/3978 (43%)]\tLoss: 0.056682\n",
            "Train Epoch: 4 [1707/3978 (43%)]\tLoss: 0.163611\n",
            "Train Epoch: 4 [1708/3978 (43%)]\tLoss: 0.001210\n",
            "Train Epoch: 4 [1709/3978 (43%)]\tLoss: 0.143926\n",
            "Train Epoch: 4 [1710/3978 (43%)]\tLoss: 0.063292\n",
            "Train Epoch: 4 [1711/3978 (43%)]\tLoss: 0.075467\n",
            "Train Epoch: 4 [1712/3978 (43%)]\tLoss: 1.606515\n",
            "Train Epoch: 4 [1713/3978 (43%)]\tLoss: 0.000292\n",
            "Train Epoch: 4 [1714/3978 (43%)]\tLoss: 0.001918\n",
            "Train Epoch: 4 [1715/3978 (43%)]\tLoss: 1.384955\n",
            "Train Epoch: 4 [1716/3978 (43%)]\tLoss: 0.427842\n",
            "Train Epoch: 4 [1717/3978 (43%)]\tLoss: 0.007685\n",
            "Train Epoch: 4 [1718/3978 (43%)]\tLoss: 0.000101\n",
            "Train Epoch: 4 [1719/3978 (43%)]\tLoss: 0.756779\n",
            "Train Epoch: 4 [1720/3978 (43%)]\tLoss: 2.566434\n",
            "Train Epoch: 4 [1721/3978 (43%)]\tLoss: 0.069241\n",
            "Train Epoch: 4 [1722/3978 (43%)]\tLoss: 0.002224\n",
            "Train Epoch: 4 [1723/3978 (43%)]\tLoss: 7.774749\n",
            "Train Epoch: 4 [1724/3978 (43%)]\tLoss: 0.334781\n",
            "Train Epoch: 4 [1725/3978 (43%)]\tLoss: 0.644983\n",
            "Train Epoch: 4 [1726/3978 (43%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [1727/3978 (43%)]\tLoss: 0.000176\n",
            "Train Epoch: 4 [1728/3978 (43%)]\tLoss: 0.033783\n",
            "Train Epoch: 4 [1729/3978 (43%)]\tLoss: 0.154388\n",
            "Train Epoch: 4 [1730/3978 (43%)]\tLoss: 1.148387\n",
            "Train Epoch: 4 [1731/3978 (44%)]\tLoss: 1.122902\n",
            "Train Epoch: 4 [1732/3978 (44%)]\tLoss: 0.000067\n",
            "Train Epoch: 4 [1733/3978 (44%)]\tLoss: 0.265625\n",
            "Train Epoch: 4 [1734/3978 (44%)]\tLoss: 0.702816\n",
            "Train Epoch: 4 [1735/3978 (44%)]\tLoss: 0.904694\n",
            "Train Epoch: 4 [1736/3978 (44%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1737/3978 (44%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1738/3978 (44%)]\tLoss: 0.006336\n",
            "Train Epoch: 4 [1739/3978 (44%)]\tLoss: 2.889026\n",
            "Train Epoch: 4 [1740/3978 (44%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [1741/3978 (44%)]\tLoss: 0.458916\n",
            "Train Epoch: 4 [1742/3978 (44%)]\tLoss: 0.036529\n",
            "Train Epoch: 4 [1743/3978 (44%)]\tLoss: 0.315949\n",
            "Train Epoch: 4 [1744/3978 (44%)]\tLoss: 2.072152\n",
            "Train Epoch: 4 [1745/3978 (44%)]\tLoss: 1.697354\n",
            "Train Epoch: 4 [1746/3978 (44%)]\tLoss: 2.888678\n",
            "Train Epoch: 4 [1747/3978 (44%)]\tLoss: 0.610949\n",
            "Train Epoch: 4 [1748/3978 (44%)]\tLoss: 0.376357\n",
            "Train Epoch: 4 [1749/3978 (44%)]\tLoss: 0.064901\n",
            "Train Epoch: 4 [1750/3978 (44%)]\tLoss: 1.053153\n",
            "Train Epoch: 4 [1751/3978 (44%)]\tLoss: 1.747371\n",
            "Train Epoch: 4 [1752/3978 (44%)]\tLoss: 0.431933\n",
            "Train Epoch: 4 [1753/3978 (44%)]\tLoss: 0.276859\n",
            "Train Epoch: 4 [1754/3978 (44%)]\tLoss: 0.751429\n",
            "Train Epoch: 4 [1755/3978 (44%)]\tLoss: 0.000783\n",
            "Train Epoch: 4 [1756/3978 (44%)]\tLoss: 1.105547\n",
            "Train Epoch: 4 [1757/3978 (44%)]\tLoss: 2.290286\n",
            "Train Epoch: 4 [1758/3978 (44%)]\tLoss: 0.000269\n",
            "Train Epoch: 4 [1759/3978 (44%)]\tLoss: 0.670591\n",
            "Train Epoch: 4 [1760/3978 (44%)]\tLoss: 0.489098\n",
            "Train Epoch: 4 [1761/3978 (44%)]\tLoss: 0.748758\n",
            "Train Epoch: 4 [1762/3978 (44%)]\tLoss: 0.889335\n",
            "Train Epoch: 4 [1763/3978 (44%)]\tLoss: 0.414851\n",
            "Train Epoch: 4 [1764/3978 (44%)]\tLoss: 2.793326\n",
            "Train Epoch: 4 [1765/3978 (44%)]\tLoss: 1.027585\n",
            "Train Epoch: 4 [1766/3978 (44%)]\tLoss: 0.000113\n",
            "Train Epoch: 4 [1767/3978 (44%)]\tLoss: 2.518489\n",
            "Train Epoch: 4 [1768/3978 (44%)]\tLoss: 0.002961\n",
            "Train Epoch: 4 [1769/3978 (44%)]\tLoss: 0.105699\n",
            "Train Epoch: 4 [1770/3978 (44%)]\tLoss: 0.125049\n",
            "Train Epoch: 4 [1771/3978 (45%)]\tLoss: 0.382745\n",
            "Train Epoch: 4 [1772/3978 (45%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1773/3978 (45%)]\tLoss: 0.035268\n",
            "Train Epoch: 4 [1774/3978 (45%)]\tLoss: 0.012310\n",
            "Train Epoch: 4 [1775/3978 (45%)]\tLoss: 1.919540\n",
            "Train Epoch: 4 [1776/3978 (45%)]\tLoss: 3.536221\n",
            "Train Epoch: 4 [1777/3978 (45%)]\tLoss: 0.817754\n",
            "Train Epoch: 4 [1778/3978 (45%)]\tLoss: 3.352239\n",
            "Train Epoch: 4 [1779/3978 (45%)]\tLoss: 1.916631\n",
            "Train Epoch: 4 [1780/3978 (45%)]\tLoss: 0.296906\n",
            "Train Epoch: 4 [1781/3978 (45%)]\tLoss: 1.236272\n",
            "Train Epoch: 4 [1782/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1783/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1784/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1785/3978 (45%)]\tLoss: 2.386977\n",
            "Train Epoch: 4 [1786/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1787/3978 (45%)]\tLoss: 3.712337\n",
            "Train Epoch: 4 [1788/3978 (45%)]\tLoss: 2.651409\n",
            "Train Epoch: 4 [1789/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1790/3978 (45%)]\tLoss: 2.051087\n",
            "Train Epoch: 4 [1791/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1792/3978 (45%)]\tLoss: 0.002827\n",
            "Train Epoch: 4 [1793/3978 (45%)]\tLoss: 0.431429\n",
            "Train Epoch: 4 [1794/3978 (45%)]\tLoss: 0.438644\n",
            "Train Epoch: 4 [1795/3978 (45%)]\tLoss: 2.748212\n",
            "Train Epoch: 4 [1796/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1797/3978 (45%)]\tLoss: 0.719507\n",
            "Train Epoch: 4 [1798/3978 (45%)]\tLoss: 4.061517\n",
            "Train Epoch: 4 [1799/3978 (45%)]\tLoss: 0.055995\n",
            "Train Epoch: 4 [1800/3978 (45%)]\tLoss: 0.023356\n",
            "Train Epoch: 4 [1801/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1802/3978 (45%)]\tLoss: 0.461896\n",
            "Train Epoch: 4 [1803/3978 (45%)]\tLoss: 0.082890\n",
            "Train Epoch: 4 [1804/3978 (45%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [1805/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1806/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1807/3978 (45%)]\tLoss: 2.588299\n",
            "Train Epoch: 4 [1808/3978 (45%)]\tLoss: 1.568825\n",
            "Train Epoch: 4 [1809/3978 (45%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [1810/3978 (46%)]\tLoss: 0.000037\n",
            "Train Epoch: 4 [1811/3978 (46%)]\tLoss: 3.669163\n",
            "Train Epoch: 4 [1812/3978 (46%)]\tLoss: 1.308028\n",
            "Train Epoch: 4 [1813/3978 (46%)]\tLoss: 0.627716\n",
            "Train Epoch: 4 [1814/3978 (46%)]\tLoss: 1.304686\n",
            "Train Epoch: 4 [1815/3978 (46%)]\tLoss: 0.346551\n",
            "Train Epoch: 4 [1816/3978 (46%)]\tLoss: 0.236242\n",
            "Train Epoch: 4 [1817/3978 (46%)]\tLoss: 0.000049\n",
            "Train Epoch: 4 [1818/3978 (46%)]\tLoss: 1.628848\n",
            "Train Epoch: 4 [1819/3978 (46%)]\tLoss: 0.836861\n",
            "Train Epoch: 4 [1820/3978 (46%)]\tLoss: 1.447348\n",
            "Train Epoch: 4 [1821/3978 (46%)]\tLoss: 0.529067\n",
            "Train Epoch: 4 [1822/3978 (46%)]\tLoss: 0.790519\n",
            "Train Epoch: 4 [1823/3978 (46%)]\tLoss: 0.809928\n",
            "Train Epoch: 4 [1824/3978 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1825/3978 (46%)]\tLoss: 1.464342\n",
            "Train Epoch: 4 [1826/3978 (46%)]\tLoss: 1.290655\n",
            "Train Epoch: 4 [1827/3978 (46%)]\tLoss: 0.201648\n",
            "Train Epoch: 4 [1828/3978 (46%)]\tLoss: 2.967027\n",
            "Train Epoch: 4 [1829/3978 (46%)]\tLoss: 0.022277\n",
            "Train Epoch: 4 [1830/3978 (46%)]\tLoss: 0.386681\n",
            "Train Epoch: 4 [1831/3978 (46%)]\tLoss: 0.247972\n",
            "Train Epoch: 4 [1832/3978 (46%)]\tLoss: 0.437776\n",
            "Train Epoch: 4 [1833/3978 (46%)]\tLoss: 1.026845\n",
            "Train Epoch: 4 [1834/3978 (46%)]\tLoss: 1.078681\n",
            "Train Epoch: 4 [1835/3978 (46%)]\tLoss: 1.396986\n",
            "Train Epoch: 4 [1836/3978 (46%)]\tLoss: 0.003352\n",
            "Train Epoch: 4 [1837/3978 (46%)]\tLoss: 6.393919\n",
            "Train Epoch: 4 [1838/3978 (46%)]\tLoss: 0.673741\n",
            "Train Epoch: 4 [1839/3978 (46%)]\tLoss: 0.426741\n",
            "Train Epoch: 4 [1840/3978 (46%)]\tLoss: 0.008956\n",
            "Train Epoch: 4 [1841/3978 (46%)]\tLoss: 0.442934\n",
            "Train Epoch: 4 [1842/3978 (46%)]\tLoss: 0.408990\n",
            "Train Epoch: 4 [1843/3978 (46%)]\tLoss: 0.013332\n",
            "Train Epoch: 4 [1844/3978 (46%)]\tLoss: 0.153187\n",
            "Train Epoch: 4 [1845/3978 (46%)]\tLoss: 0.724623\n",
            "Train Epoch: 4 [1846/3978 (46%)]\tLoss: 3.698045\n",
            "Train Epoch: 4 [1847/3978 (46%)]\tLoss: 0.002655\n",
            "Train Epoch: 4 [1848/3978 (46%)]\tLoss: 0.041266\n",
            "Train Epoch: 4 [1849/3978 (46%)]\tLoss: 0.049703\n",
            "Train Epoch: 4 [1850/3978 (47%)]\tLoss: 0.750231\n",
            "Train Epoch: 4 [1851/3978 (47%)]\tLoss: 0.714489\n",
            "Train Epoch: 4 [1852/3978 (47%)]\tLoss: 0.742626\n",
            "Train Epoch: 4 [1853/3978 (47%)]\tLoss: 0.382135\n",
            "Train Epoch: 4 [1854/3978 (47%)]\tLoss: 1.177100\n",
            "Train Epoch: 4 [1855/3978 (47%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [1856/3978 (47%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1857/3978 (47%)]\tLoss: 0.000281\n",
            "Train Epoch: 4 [1858/3978 (47%)]\tLoss: 2.532784\n",
            "Train Epoch: 4 [1859/3978 (47%)]\tLoss: 0.929566\n",
            "Train Epoch: 4 [1860/3978 (47%)]\tLoss: 0.679930\n",
            "Train Epoch: 4 [1861/3978 (47%)]\tLoss: 0.637801\n",
            "Train Epoch: 4 [1862/3978 (47%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [1863/3978 (47%)]\tLoss: 0.666489\n",
            "Train Epoch: 4 [1864/3978 (47%)]\tLoss: 0.000109\n",
            "Train Epoch: 4 [1865/3978 (47%)]\tLoss: 0.726634\n",
            "Train Epoch: 4 [1866/3978 (47%)]\tLoss: 0.002831\n",
            "Train Epoch: 4 [1867/3978 (47%)]\tLoss: 0.001567\n",
            "Train Epoch: 4 [1868/3978 (47%)]\tLoss: 0.002209\n",
            "Train Epoch: 4 [1869/3978 (47%)]\tLoss: 0.840199\n",
            "Train Epoch: 4 [1870/3978 (47%)]\tLoss: 0.445237\n",
            "Train Epoch: 4 [1871/3978 (47%)]\tLoss: 0.554613\n",
            "Train Epoch: 4 [1872/3978 (47%)]\tLoss: 0.001413\n",
            "Train Epoch: 4 [1873/3978 (47%)]\tLoss: 4.679485\n",
            "Train Epoch: 4 [1874/3978 (47%)]\tLoss: 0.126520\n",
            "Train Epoch: 4 [1875/3978 (47%)]\tLoss: 2.887335\n",
            "Train Epoch: 4 [1876/3978 (47%)]\tLoss: 3.425529\n",
            "Train Epoch: 4 [1877/3978 (47%)]\tLoss: 1.424833\n",
            "Train Epoch: 4 [1878/3978 (47%)]\tLoss: 3.671039\n",
            "Train Epoch: 4 [1879/3978 (47%)]\tLoss: 1.596256\n",
            "Train Epoch: 4 [1880/3978 (47%)]\tLoss: 2.517845\n",
            "Train Epoch: 4 [1881/3978 (47%)]\tLoss: 0.153850\n",
            "Train Epoch: 4 [1882/3978 (47%)]\tLoss: 0.233027\n",
            "Train Epoch: 4 [1883/3978 (47%)]\tLoss: 0.000622\n",
            "Train Epoch: 4 [1884/3978 (47%)]\tLoss: 1.960744\n",
            "Train Epoch: 4 [1885/3978 (47%)]\tLoss: 0.958839\n",
            "Train Epoch: 4 [1886/3978 (47%)]\tLoss: 0.996089\n",
            "Train Epoch: 4 [1887/3978 (47%)]\tLoss: 1.503929\n",
            "Train Epoch: 4 [1888/3978 (47%)]\tLoss: 0.953232\n",
            "Train Epoch: 4 [1889/3978 (47%)]\tLoss: 0.110525\n",
            "Train Epoch: 4 [1890/3978 (48%)]\tLoss: 1.756121\n",
            "Train Epoch: 4 [1891/3978 (48%)]\tLoss: 0.000120\n",
            "Train Epoch: 4 [1892/3978 (48%)]\tLoss: 0.014209\n",
            "Train Epoch: 4 [1893/3978 (48%)]\tLoss: 0.008928\n",
            "Train Epoch: 4 [1894/3978 (48%)]\tLoss: 0.000465\n",
            "Train Epoch: 4 [1895/3978 (48%)]\tLoss: 0.007182\n",
            "Train Epoch: 4 [1896/3978 (48%)]\tLoss: 0.457377\n",
            "Train Epoch: 4 [1897/3978 (48%)]\tLoss: 0.170873\n",
            "Train Epoch: 4 [1898/3978 (48%)]\tLoss: 0.146142\n",
            "Train Epoch: 4 [1899/3978 (48%)]\tLoss: 1.821044\n",
            "Train Epoch: 4 [1900/3978 (48%)]\tLoss: 2.454119\n",
            "Train Epoch: 4 [1901/3978 (48%)]\tLoss: 0.000287\n",
            "Train Epoch: 4 [1902/3978 (48%)]\tLoss: 0.000080\n",
            "Train Epoch: 4 [1903/3978 (48%)]\tLoss: 0.741342\n",
            "Train Epoch: 4 [1904/3978 (48%)]\tLoss: 0.000572\n",
            "Train Epoch: 4 [1905/3978 (48%)]\tLoss: 0.570340\n",
            "Train Epoch: 4 [1906/3978 (48%)]\tLoss: 0.155842\n",
            "Train Epoch: 4 [1907/3978 (48%)]\tLoss: 0.169712\n",
            "Train Epoch: 4 [1908/3978 (48%)]\tLoss: 0.671812\n",
            "Train Epoch: 4 [1909/3978 (48%)]\tLoss: 0.151678\n",
            "Train Epoch: 4 [1910/3978 (48%)]\tLoss: 0.000975\n",
            "Train Epoch: 4 [1911/3978 (48%)]\tLoss: 0.010482\n",
            "Train Epoch: 4 [1912/3978 (48%)]\tLoss: 0.067774\n",
            "Train Epoch: 4 [1913/3978 (48%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [1914/3978 (48%)]\tLoss: 4.322934\n",
            "Train Epoch: 4 [1915/3978 (48%)]\tLoss: 1.350429\n",
            "Train Epoch: 4 [1916/3978 (48%)]\tLoss: 0.001463\n",
            "Train Epoch: 4 [1917/3978 (48%)]\tLoss: 1.889782\n",
            "Train Epoch: 4 [1918/3978 (48%)]\tLoss: 1.861318\n",
            "Train Epoch: 4 [1919/3978 (48%)]\tLoss: 0.015792\n",
            "Train Epoch: 4 [1920/3978 (48%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1921/3978 (48%)]\tLoss: 2.341261\n",
            "Train Epoch: 4 [1922/3978 (48%)]\tLoss: 0.000523\n",
            "Train Epoch: 4 [1923/3978 (48%)]\tLoss: 0.143342\n",
            "Train Epoch: 4 [1924/3978 (48%)]\tLoss: 1.054123\n",
            "Train Epoch: 4 [1925/3978 (48%)]\tLoss: 1.014572\n",
            "Train Epoch: 4 [1926/3978 (48%)]\tLoss: 0.016183\n",
            "Train Epoch: 4 [1927/3978 (48%)]\tLoss: 0.326575\n",
            "Train Epoch: 4 [1928/3978 (48%)]\tLoss: 2.135559\n",
            "Train Epoch: 4 [1929/3978 (48%)]\tLoss: 1.585022\n",
            "Train Epoch: 4 [1930/3978 (49%)]\tLoss: 0.771050\n",
            "Train Epoch: 4 [1931/3978 (49%)]\tLoss: 0.013482\n",
            "Train Epoch: 4 [1932/3978 (49%)]\tLoss: 1.903314\n",
            "Train Epoch: 4 [1933/3978 (49%)]\tLoss: 2.575593\n",
            "Train Epoch: 4 [1934/3978 (49%)]\tLoss: 1.115439\n",
            "Train Epoch: 4 [1935/3978 (49%)]\tLoss: 0.768844\n",
            "Train Epoch: 4 [1936/3978 (49%)]\tLoss: 0.310623\n",
            "Train Epoch: 4 [1937/3978 (49%)]\tLoss: 2.134567\n",
            "Train Epoch: 4 [1938/3978 (49%)]\tLoss: 2.093475\n",
            "Train Epoch: 4 [1939/3978 (49%)]\tLoss: 0.263838\n",
            "Train Epoch: 4 [1940/3978 (49%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [1941/3978 (49%)]\tLoss: 0.043122\n",
            "Train Epoch: 4 [1942/3978 (49%)]\tLoss: 1.464526\n",
            "Train Epoch: 4 [1943/3978 (49%)]\tLoss: 2.019199\n",
            "Train Epoch: 4 [1944/3978 (49%)]\tLoss: 0.110159\n",
            "Train Epoch: 4 [1945/3978 (49%)]\tLoss: 0.486125\n",
            "Train Epoch: 4 [1946/3978 (49%)]\tLoss: 0.514413\n",
            "Train Epoch: 4 [1947/3978 (49%)]\tLoss: 0.603116\n",
            "Train Epoch: 4 [1948/3978 (49%)]\tLoss: 0.327676\n",
            "Train Epoch: 4 [1949/3978 (49%)]\tLoss: 0.091890\n",
            "Train Epoch: 4 [1950/3978 (49%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [1951/3978 (49%)]\tLoss: 6.274616\n",
            "Train Epoch: 4 [1952/3978 (49%)]\tLoss: 0.692947\n",
            "Train Epoch: 4 [1953/3978 (49%)]\tLoss: 0.464227\n",
            "Train Epoch: 4 [1954/3978 (49%)]\tLoss: 0.198927\n",
            "Train Epoch: 4 [1955/3978 (49%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1956/3978 (49%)]\tLoss: 3.302361\n",
            "Train Epoch: 4 [1957/3978 (49%)]\tLoss: 0.000092\n",
            "Train Epoch: 4 [1958/3978 (49%)]\tLoss: 1.976116\n",
            "Train Epoch: 4 [1959/3978 (49%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1960/3978 (49%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1961/3978 (49%)]\tLoss: 1.489063\n",
            "Train Epoch: 4 [1962/3978 (49%)]\tLoss: 0.000377\n",
            "Train Epoch: 4 [1963/3978 (49%)]\tLoss: 3.570370\n",
            "Train Epoch: 4 [1964/3978 (49%)]\tLoss: 0.143443\n",
            "Train Epoch: 4 [1965/3978 (49%)]\tLoss: 0.000340\n",
            "Train Epoch: 4 [1966/3978 (49%)]\tLoss: 0.115194\n",
            "Train Epoch: 4 [1967/3978 (49%)]\tLoss: 0.371605\n",
            "Train Epoch: 4 [1968/3978 (49%)]\tLoss: 1.714453\n",
            "Train Epoch: 4 [1969/3978 (49%)]\tLoss: 0.016840\n",
            "Train Epoch: 4 [1970/3978 (50%)]\tLoss: 0.230562\n",
            "Train Epoch: 4 [1971/3978 (50%)]\tLoss: 0.339015\n",
            "Train Epoch: 4 [1972/3978 (50%)]\tLoss: 0.124133\n",
            "Train Epoch: 4 [1973/3978 (50%)]\tLoss: 0.540568\n",
            "Train Epoch: 4 [1974/3978 (50%)]\tLoss: 2.104250\n",
            "Train Epoch: 4 [1975/3978 (50%)]\tLoss: 0.012183\n",
            "Train Epoch: 4 [1976/3978 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1977/3978 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1978/3978 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1979/3978 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1980/3978 (50%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1981/3978 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1982/3978 (50%)]\tLoss: 3.575950\n",
            "Train Epoch: 4 [1983/3978 (50%)]\tLoss: 1.995076\n",
            "Train Epoch: 4 [1984/3978 (50%)]\tLoss: 1.971939\n",
            "Train Epoch: 4 [1985/3978 (50%)]\tLoss: 6.018782\n",
            "Train Epoch: 4 [1986/3978 (50%)]\tLoss: 0.000466\n",
            "Train Epoch: 4 [1987/3978 (50%)]\tLoss: 1.533210\n",
            "Train Epoch: 4 [1988/3978 (50%)]\tLoss: 1.136346\n",
            "Train Epoch: 4 [1989/3978 (50%)]\tLoss: 1.282306\n",
            "Train Epoch: 4 [1990/3978 (50%)]\tLoss: 0.488699\n",
            "Train Epoch: 4 [1991/3978 (50%)]\tLoss: 0.081976\n",
            "Train Epoch: 4 [1992/3978 (50%)]\tLoss: 1.870102\n",
            "Train Epoch: 4 [1993/3978 (50%)]\tLoss: 1.288895\n",
            "Train Epoch: 4 [1994/3978 (50%)]\tLoss: 2.686346\n",
            "Train Epoch: 4 [1995/3978 (50%)]\tLoss: 0.214992\n",
            "Train Epoch: 4 [1996/3978 (50%)]\tLoss: 1.927111\n",
            "Train Epoch: 4 [1997/3978 (50%)]\tLoss: 3.437414\n",
            "Train Epoch: 4 [1998/3978 (50%)]\tLoss: 0.002244\n",
            "Train Epoch: 4 [1999/3978 (50%)]\tLoss: 0.153353\n",
            "Train Epoch: 4 [2000/3978 (50%)]\tLoss: 1.527571\n",
            "Train Epoch: 4 [2001/3978 (50%)]\tLoss: 1.583783\n",
            "Train Epoch: 4 [2002/3978 (50%)]\tLoss: 1.408050\n",
            "Train Epoch: 4 [2003/3978 (50%)]\tLoss: 0.868063\n",
            "Train Epoch: 4 [2004/3978 (50%)]\tLoss: 1.831439\n",
            "Train Epoch: 4 [2005/3978 (50%)]\tLoss: 1.280643\n",
            "Train Epoch: 4 [2006/3978 (50%)]\tLoss: 0.139051\n",
            "Train Epoch: 4 [2007/3978 (50%)]\tLoss: 0.178645\n",
            "Train Epoch: 4 [2008/3978 (50%)]\tLoss: 0.261461\n",
            "Train Epoch: 4 [2009/3978 (51%)]\tLoss: 2.711467\n",
            "Train Epoch: 4 [2010/3978 (51%)]\tLoss: 5.395019\n",
            "Train Epoch: 4 [2011/3978 (51%)]\tLoss: 3.450709\n",
            "Train Epoch: 4 [2012/3978 (51%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2013/3978 (51%)]\tLoss: 2.657732\n",
            "Train Epoch: 4 [2014/3978 (51%)]\tLoss: 0.000404\n",
            "Train Epoch: 4 [2015/3978 (51%)]\tLoss: 0.000706\n",
            "Train Epoch: 4 [2016/3978 (51%)]\tLoss: 0.000015\n",
            "Train Epoch: 4 [2017/3978 (51%)]\tLoss: 0.328998\n",
            "Train Epoch: 4 [2018/3978 (51%)]\tLoss: 0.312584\n",
            "Train Epoch: 4 [2019/3978 (51%)]\tLoss: 0.230845\n",
            "Train Epoch: 4 [2020/3978 (51%)]\tLoss: 2.727361\n",
            "Train Epoch: 4 [2021/3978 (51%)]\tLoss: 0.536467\n",
            "Train Epoch: 4 [2022/3978 (51%)]\tLoss: 2.291417\n",
            "Train Epoch: 4 [2023/3978 (51%)]\tLoss: 2.943648\n",
            "Train Epoch: 4 [2024/3978 (51%)]\tLoss: 1.597351\n",
            "Train Epoch: 4 [2025/3978 (51%)]\tLoss: 0.118846\n",
            "Train Epoch: 4 [2026/3978 (51%)]\tLoss: 0.001447\n",
            "Train Epoch: 4 [2027/3978 (51%)]\tLoss: 3.175777\n",
            "Train Epoch: 4 [2028/3978 (51%)]\tLoss: 0.000368\n",
            "Train Epoch: 4 [2029/3978 (51%)]\tLoss: 0.736796\n",
            "Train Epoch: 4 [2030/3978 (51%)]\tLoss: 1.583176\n",
            "Train Epoch: 4 [2031/3978 (51%)]\tLoss: 0.631058\n",
            "Train Epoch: 4 [2032/3978 (51%)]\tLoss: 0.004437\n",
            "Train Epoch: 4 [2033/3978 (51%)]\tLoss: 0.107115\n",
            "Train Epoch: 4 [2034/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2035/3978 (51%)]\tLoss: 1.898901\n",
            "Train Epoch: 4 [2036/3978 (51%)]\tLoss: 3.133550\n",
            "Train Epoch: 4 [2037/3978 (51%)]\tLoss: 2.559185\n",
            "Train Epoch: 4 [2038/3978 (51%)]\tLoss: 0.000038\n",
            "Train Epoch: 4 [2039/3978 (51%)]\tLoss: 1.628840\n",
            "Train Epoch: 4 [2040/3978 (51%)]\tLoss: 1.745634\n",
            "Train Epoch: 4 [2041/3978 (51%)]\tLoss: 0.579339\n",
            "Train Epoch: 4 [2042/3978 (51%)]\tLoss: 1.208797\n",
            "Train Epoch: 4 [2043/3978 (51%)]\tLoss: 0.015243\n",
            "Train Epoch: 4 [2044/3978 (51%)]\tLoss: 0.001894\n",
            "Train Epoch: 4 [2045/3978 (51%)]\tLoss: 0.000039\n",
            "Train Epoch: 4 [2046/3978 (51%)]\tLoss: 0.000092\n",
            "Train Epoch: 4 [2047/3978 (51%)]\tLoss: 3.770110\n",
            "Train Epoch: 4 [2048/3978 (51%)]\tLoss: 2.113661\n",
            "Train Epoch: 4 [2049/3978 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2050/3978 (52%)]\tLoss: 2.354880\n",
            "Train Epoch: 4 [2051/3978 (52%)]\tLoss: 2.141450\n",
            "Train Epoch: 4 [2052/3978 (52%)]\tLoss: 0.005269\n",
            "Train Epoch: 4 [2053/3978 (52%)]\tLoss: 0.000656\n",
            "Train Epoch: 4 [2054/3978 (52%)]\tLoss: 0.002234\n",
            "Train Epoch: 4 [2055/3978 (52%)]\tLoss: 1.069802\n",
            "Train Epoch: 4 [2056/3978 (52%)]\tLoss: 0.035408\n",
            "Train Epoch: 4 [2057/3978 (52%)]\tLoss: 0.025987\n",
            "Train Epoch: 4 [2058/3978 (52%)]\tLoss: 0.009940\n",
            "Train Epoch: 4 [2059/3978 (52%)]\tLoss: 1.356354\n",
            "Train Epoch: 4 [2060/3978 (52%)]\tLoss: 0.000332\n",
            "Train Epoch: 4 [2061/3978 (52%)]\tLoss: 0.001332\n",
            "Train Epoch: 4 [2062/3978 (52%)]\tLoss: 1.921521\n",
            "Train Epoch: 4 [2063/3978 (52%)]\tLoss: 0.000089\n",
            "Train Epoch: 4 [2064/3978 (52%)]\tLoss: 0.012741\n",
            "Train Epoch: 4 [2065/3978 (52%)]\tLoss: 0.023989\n",
            "Train Epoch: 4 [2066/3978 (52%)]\tLoss: 0.251713\n",
            "Train Epoch: 4 [2067/3978 (52%)]\tLoss: 0.464094\n",
            "Train Epoch: 4 [2068/3978 (52%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [2069/3978 (52%)]\tLoss: 1.892525\n",
            "Train Epoch: 4 [2070/3978 (52%)]\tLoss: 0.117739\n",
            "Train Epoch: 4 [2071/3978 (52%)]\tLoss: 0.858091\n",
            "Train Epoch: 4 [2072/3978 (52%)]\tLoss: 0.002886\n",
            "Train Epoch: 4 [2073/3978 (52%)]\tLoss: 0.009845\n",
            "Train Epoch: 4 [2074/3978 (52%)]\tLoss: 1.825294\n",
            "Train Epoch: 4 [2075/3978 (52%)]\tLoss: 1.403537\n",
            "Train Epoch: 4 [2076/3978 (52%)]\tLoss: 0.010339\n",
            "Train Epoch: 4 [2077/3978 (52%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2078/3978 (52%)]\tLoss: 0.000072\n",
            "Train Epoch: 4 [2079/3978 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2080/3978 (52%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [2081/3978 (52%)]\tLoss: 0.016818\n",
            "Train Epoch: 4 [2082/3978 (52%)]\tLoss: 0.003502\n",
            "Train Epoch: 4 [2083/3978 (52%)]\tLoss: 0.002046\n",
            "Train Epoch: 4 [2084/3978 (52%)]\tLoss: 1.008711\n",
            "Train Epoch: 4 [2085/3978 (52%)]\tLoss: 0.000198\n",
            "Train Epoch: 4 [2086/3978 (52%)]\tLoss: 0.000879\n",
            "Train Epoch: 4 [2087/3978 (52%)]\tLoss: 0.894488\n",
            "Train Epoch: 4 [2088/3978 (52%)]\tLoss: 0.009318\n",
            "Train Epoch: 4 [2089/3978 (53%)]\tLoss: 4.453270\n",
            "Train Epoch: 4 [2090/3978 (53%)]\tLoss: 0.000173\n",
            "Train Epoch: 4 [2091/3978 (53%)]\tLoss: 2.509819\n",
            "Train Epoch: 4 [2092/3978 (53%)]\tLoss: 0.024465\n",
            "Train Epoch: 4 [2093/3978 (53%)]\tLoss: 2.268096\n",
            "Train Epoch: 4 [2094/3978 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2095/3978 (53%)]\tLoss: 0.199122\n",
            "Train Epoch: 4 [2096/3978 (53%)]\tLoss: 0.176347\n",
            "Train Epoch: 4 [2097/3978 (53%)]\tLoss: 0.576137\n",
            "Train Epoch: 4 [2098/3978 (53%)]\tLoss: 0.039830\n",
            "Train Epoch: 4 [2099/3978 (53%)]\tLoss: 0.000173\n",
            "Train Epoch: 4 [2100/3978 (53%)]\tLoss: 1.410131\n",
            "Train Epoch: 4 [2101/3978 (53%)]\tLoss: 1.553819\n",
            "Train Epoch: 4 [2102/3978 (53%)]\tLoss: 0.283448\n",
            "Train Epoch: 4 [2103/3978 (53%)]\tLoss: 1.743827\n",
            "Train Epoch: 4 [2104/3978 (53%)]\tLoss: 1.930593\n",
            "Train Epoch: 4 [2105/3978 (53%)]\tLoss: 0.461120\n",
            "Train Epoch: 4 [2106/3978 (53%)]\tLoss: 1.998872\n",
            "Train Epoch: 4 [2107/3978 (53%)]\tLoss: 2.129148\n",
            "Train Epoch: 4 [2108/3978 (53%)]\tLoss: 0.000122\n",
            "Train Epoch: 4 [2109/3978 (53%)]\tLoss: 1.637100\n",
            "Train Epoch: 4 [2110/3978 (53%)]\tLoss: 0.799740\n",
            "Train Epoch: 4 [2111/3978 (53%)]\tLoss: 0.604473\n",
            "Train Epoch: 4 [2112/3978 (53%)]\tLoss: 0.059981\n",
            "Train Epoch: 4 [2113/3978 (53%)]\tLoss: 1.455533\n",
            "Train Epoch: 4 [2114/3978 (53%)]\tLoss: 0.001626\n",
            "Train Epoch: 4 [2115/3978 (53%)]\tLoss: 0.634440\n",
            "Train Epoch: 4 [2116/3978 (53%)]\tLoss: 1.078332\n",
            "Train Epoch: 4 [2117/3978 (53%)]\tLoss: 0.756417\n",
            "Train Epoch: 4 [2118/3978 (53%)]\tLoss: 1.079501\n",
            "Train Epoch: 4 [2119/3978 (53%)]\tLoss: 0.002562\n",
            "Train Epoch: 4 [2120/3978 (53%)]\tLoss: 0.056148\n",
            "Train Epoch: 4 [2121/3978 (53%)]\tLoss: 0.000137\n",
            "Train Epoch: 4 [2122/3978 (53%)]\tLoss: 0.914646\n",
            "Train Epoch: 4 [2123/3978 (53%)]\tLoss: 0.138266\n",
            "Train Epoch: 4 [2124/3978 (53%)]\tLoss: 0.295307\n",
            "Train Epoch: 4 [2125/3978 (53%)]\tLoss: 0.000259\n",
            "Train Epoch: 4 [2126/3978 (53%)]\tLoss: 0.188986\n",
            "Train Epoch: 4 [2127/3978 (53%)]\tLoss: 0.086115\n",
            "Train Epoch: 4 [2128/3978 (53%)]\tLoss: 0.001447\n",
            "Train Epoch: 4 [2129/3978 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2130/3978 (54%)]\tLoss: 2.867138\n",
            "Train Epoch: 4 [2131/3978 (54%)]\tLoss: 0.000112\n",
            "Train Epoch: 4 [2132/3978 (54%)]\tLoss: 2.375387\n",
            "Train Epoch: 4 [2133/3978 (54%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2134/3978 (54%)]\tLoss: 0.011871\n",
            "Train Epoch: 4 [2135/3978 (54%)]\tLoss: 0.171077\n",
            "Train Epoch: 4 [2136/3978 (54%)]\tLoss: 0.070448\n",
            "Train Epoch: 4 [2137/3978 (54%)]\tLoss: 0.332371\n",
            "Train Epoch: 4 [2138/3978 (54%)]\tLoss: 0.934389\n",
            "Train Epoch: 4 [2139/3978 (54%)]\tLoss: 0.403662\n",
            "Train Epoch: 4 [2140/3978 (54%)]\tLoss: 1.494488\n",
            "Train Epoch: 4 [2141/3978 (54%)]\tLoss: 0.595496\n",
            "Train Epoch: 4 [2142/3978 (54%)]\tLoss: 0.075253\n",
            "Train Epoch: 4 [2143/3978 (54%)]\tLoss: 0.583697\n",
            "Train Epoch: 4 [2144/3978 (54%)]\tLoss: 0.697216\n",
            "Train Epoch: 4 [2145/3978 (54%)]\tLoss: 0.035855\n",
            "Train Epoch: 4 [2146/3978 (54%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [2147/3978 (54%)]\tLoss: 1.119389\n",
            "Train Epoch: 4 [2148/3978 (54%)]\tLoss: 2.091744\n",
            "Train Epoch: 4 [2149/3978 (54%)]\tLoss: 4.848857\n",
            "Train Epoch: 4 [2150/3978 (54%)]\tLoss: 0.001165\n",
            "Train Epoch: 4 [2151/3978 (54%)]\tLoss: 0.002962\n",
            "Train Epoch: 4 [2152/3978 (54%)]\tLoss: 0.000410\n",
            "Train Epoch: 4 [2153/3978 (54%)]\tLoss: 1.214184\n",
            "Train Epoch: 4 [2154/3978 (54%)]\tLoss: 2.881606\n",
            "Train Epoch: 4 [2155/3978 (54%)]\tLoss: 0.348991\n",
            "Train Epoch: 4 [2156/3978 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2157/3978 (54%)]\tLoss: 0.114070\n",
            "Train Epoch: 4 [2158/3978 (54%)]\tLoss: 1.038042\n",
            "Train Epoch: 4 [2159/3978 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2160/3978 (54%)]\tLoss: 0.528973\n",
            "Train Epoch: 4 [2161/3978 (54%)]\tLoss: 0.632802\n",
            "Train Epoch: 4 [2162/3978 (54%)]\tLoss: 0.022632\n",
            "Train Epoch: 4 [2163/3978 (54%)]\tLoss: 0.007836\n",
            "Train Epoch: 4 [2164/3978 (54%)]\tLoss: 0.290227\n",
            "Train Epoch: 4 [2165/3978 (54%)]\tLoss: 3.754251\n",
            "Train Epoch: 4 [2166/3978 (54%)]\tLoss: 5.008336\n",
            "Train Epoch: 4 [2167/3978 (54%)]\tLoss: 2.080592\n",
            "Train Epoch: 4 [2168/3978 (54%)]\tLoss: 1.552997\n",
            "Train Epoch: 4 [2169/3978 (55%)]\tLoss: 0.173956\n",
            "Train Epoch: 4 [2170/3978 (55%)]\tLoss: 0.004339\n",
            "Train Epoch: 4 [2171/3978 (55%)]\tLoss: 0.084368\n",
            "Train Epoch: 4 [2172/3978 (55%)]\tLoss: 0.203008\n",
            "Train Epoch: 4 [2173/3978 (55%)]\tLoss: 0.353591\n",
            "Train Epoch: 4 [2174/3978 (55%)]\tLoss: 0.080639\n",
            "Train Epoch: 4 [2175/3978 (55%)]\tLoss: 1.697977\n",
            "Train Epoch: 4 [2176/3978 (55%)]\tLoss: 0.032833\n",
            "Train Epoch: 4 [2177/3978 (55%)]\tLoss: 0.000163\n",
            "Train Epoch: 4 [2178/3978 (55%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2179/3978 (55%)]\tLoss: 2.012068\n",
            "Train Epoch: 4 [2180/3978 (55%)]\tLoss: 0.534292\n",
            "Train Epoch: 4 [2181/3978 (55%)]\tLoss: 1.063589\n",
            "Train Epoch: 4 [2182/3978 (55%)]\tLoss: 4.644030\n",
            "Train Epoch: 4 [2183/3978 (55%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2184/3978 (55%)]\tLoss: 2.133494\n",
            "Train Epoch: 4 [2185/3978 (55%)]\tLoss: 3.067848\n",
            "Train Epoch: 4 [2186/3978 (55%)]\tLoss: 0.746150\n",
            "Train Epoch: 4 [2187/3978 (55%)]\tLoss: 0.055042\n",
            "Train Epoch: 4 [2188/3978 (55%)]\tLoss: 1.101328\n",
            "Train Epoch: 4 [2189/3978 (55%)]\tLoss: 0.064354\n",
            "Train Epoch: 4 [2190/3978 (55%)]\tLoss: 1.944888\n",
            "Train Epoch: 4 [2191/3978 (55%)]\tLoss: 0.501383\n",
            "Train Epoch: 4 [2192/3978 (55%)]\tLoss: 0.376025\n",
            "Train Epoch: 4 [2193/3978 (55%)]\tLoss: 1.627920\n",
            "Train Epoch: 4 [2194/3978 (55%)]\tLoss: 0.225724\n",
            "Train Epoch: 4 [2195/3978 (55%)]\tLoss: 0.000602\n",
            "Train Epoch: 4 [2196/3978 (55%)]\tLoss: 0.290532\n",
            "Train Epoch: 4 [2197/3978 (55%)]\tLoss: 0.544868\n",
            "Train Epoch: 4 [2198/3978 (55%)]\tLoss: 0.116254\n",
            "Train Epoch: 4 [2199/3978 (55%)]\tLoss: 0.006297\n",
            "Train Epoch: 4 [2200/3978 (55%)]\tLoss: 0.000958\n",
            "Train Epoch: 4 [2201/3978 (55%)]\tLoss: 0.777089\n",
            "Train Epoch: 4 [2202/3978 (55%)]\tLoss: 0.018755\n",
            "Train Epoch: 4 [2203/3978 (55%)]\tLoss: 0.340643\n",
            "Train Epoch: 4 [2204/3978 (55%)]\tLoss: 0.000786\n",
            "Train Epoch: 4 [2205/3978 (55%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [2206/3978 (55%)]\tLoss: 0.000066\n",
            "Train Epoch: 4 [2207/3978 (55%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2208/3978 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2209/3978 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2210/3978 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2211/3978 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2212/3978 (56%)]\tLoss: 6.473271\n",
            "Train Epoch: 4 [2213/3978 (56%)]\tLoss: 3.032786\n",
            "Train Epoch: 4 [2214/3978 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2215/3978 (56%)]\tLoss: 3.964573\n",
            "Train Epoch: 4 [2216/3978 (56%)]\tLoss: 1.307979\n",
            "Train Epoch: 4 [2217/3978 (56%)]\tLoss: 2.797490\n",
            "Train Epoch: 4 [2218/3978 (56%)]\tLoss: 1.579245\n",
            "Train Epoch: 4 [2219/3978 (56%)]\tLoss: 0.200951\n",
            "Train Epoch: 4 [2220/3978 (56%)]\tLoss: 1.232702\n",
            "Train Epoch: 4 [2221/3978 (56%)]\tLoss: 1.146160\n",
            "Train Epoch: 4 [2222/3978 (56%)]\tLoss: 0.768661\n",
            "Train Epoch: 4 [2223/3978 (56%)]\tLoss: 1.317120\n",
            "Train Epoch: 4 [2224/3978 (56%)]\tLoss: 7.324466\n",
            "Train Epoch: 4 [2225/3978 (56%)]\tLoss: 2.281028\n",
            "Train Epoch: 4 [2226/3978 (56%)]\tLoss: 0.393536\n",
            "Train Epoch: 4 [2227/3978 (56%)]\tLoss: 0.007030\n",
            "Train Epoch: 4 [2228/3978 (56%)]\tLoss: 0.000056\n",
            "Train Epoch: 4 [2229/3978 (56%)]\tLoss: 0.948104\n",
            "Train Epoch: 4 [2230/3978 (56%)]\tLoss: 6.007035\n",
            "Train Epoch: 4 [2231/3978 (56%)]\tLoss: 0.006614\n",
            "Train Epoch: 4 [2232/3978 (56%)]\tLoss: 1.166855\n",
            "Train Epoch: 4 [2233/3978 (56%)]\tLoss: 0.336276\n",
            "Train Epoch: 4 [2234/3978 (56%)]\tLoss: 0.779539\n",
            "Train Epoch: 4 [2235/3978 (56%)]\tLoss: 0.000064\n",
            "Train Epoch: 4 [2236/3978 (56%)]\tLoss: 0.245044\n",
            "Train Epoch: 4 [2237/3978 (56%)]\tLoss: 2.415521\n",
            "Train Epoch: 4 [2238/3978 (56%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [2239/3978 (56%)]\tLoss: 1.505896\n",
            "Train Epoch: 4 [2240/3978 (56%)]\tLoss: 0.830367\n",
            "Train Epoch: 4 [2241/3978 (56%)]\tLoss: 0.041851\n",
            "Train Epoch: 4 [2242/3978 (56%)]\tLoss: 1.345346\n",
            "Train Epoch: 4 [2243/3978 (56%)]\tLoss: 0.346133\n",
            "Train Epoch: 4 [2244/3978 (56%)]\tLoss: 0.577209\n",
            "Train Epoch: 4 [2245/3978 (56%)]\tLoss: 1.834560\n",
            "Train Epoch: 4 [2246/3978 (56%)]\tLoss: 0.051699\n",
            "Train Epoch: 4 [2247/3978 (56%)]\tLoss: 2.935167\n",
            "Train Epoch: 4 [2248/3978 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2249/3978 (57%)]\tLoss: 1.566393\n",
            "Train Epoch: 4 [2250/3978 (57%)]\tLoss: 0.136063\n",
            "Train Epoch: 4 [2251/3978 (57%)]\tLoss: 0.359512\n",
            "Train Epoch: 4 [2252/3978 (57%)]\tLoss: 0.264892\n",
            "Train Epoch: 4 [2253/3978 (57%)]\tLoss: 0.153693\n",
            "Train Epoch: 4 [2254/3978 (57%)]\tLoss: 0.193692\n",
            "Train Epoch: 4 [2255/3978 (57%)]\tLoss: 1.485306\n",
            "Train Epoch: 4 [2256/3978 (57%)]\tLoss: 0.000405\n",
            "Train Epoch: 4 [2257/3978 (57%)]\tLoss: 0.638185\n",
            "Train Epoch: 4 [2258/3978 (57%)]\tLoss: 0.874573\n",
            "Train Epoch: 4 [2259/3978 (57%)]\tLoss: 5.430698\n",
            "Train Epoch: 4 [2260/3978 (57%)]\tLoss: 2.302255\n",
            "Train Epoch: 4 [2261/3978 (57%)]\tLoss: 4.142539\n",
            "Train Epoch: 4 [2262/3978 (57%)]\tLoss: 0.154501\n",
            "Train Epoch: 4 [2263/3978 (57%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [2264/3978 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2265/3978 (57%)]\tLoss: 0.000039\n",
            "Train Epoch: 4 [2266/3978 (57%)]\tLoss: 3.402197\n",
            "Train Epoch: 4 [2267/3978 (57%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [2268/3978 (57%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [2269/3978 (57%)]\tLoss: 1.788646\n",
            "Train Epoch: 4 [2270/3978 (57%)]\tLoss: 1.060279\n",
            "Train Epoch: 4 [2271/3978 (57%)]\tLoss: 2.126089\n",
            "Train Epoch: 4 [2272/3978 (57%)]\tLoss: 1.993666\n",
            "Train Epoch: 4 [2273/3978 (57%)]\tLoss: 0.062269\n",
            "Train Epoch: 4 [2274/3978 (57%)]\tLoss: 0.000228\n",
            "Train Epoch: 4 [2275/3978 (57%)]\tLoss: 0.239954\n",
            "Train Epoch: 4 [2276/3978 (57%)]\tLoss: 0.068419\n",
            "Train Epoch: 4 [2277/3978 (57%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [2278/3978 (57%)]\tLoss: 1.773460\n",
            "Train Epoch: 4 [2279/3978 (57%)]\tLoss: 2.728588\n",
            "Train Epoch: 4 [2280/3978 (57%)]\tLoss: 3.107271\n",
            "Train Epoch: 4 [2281/3978 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2282/3978 (57%)]\tLoss: 10.780196\n",
            "Train Epoch: 4 [2283/3978 (57%)]\tLoss: 2.425889\n",
            "Train Epoch: 4 [2284/3978 (57%)]\tLoss: 2.131221\n",
            "Train Epoch: 4 [2285/3978 (57%)]\tLoss: 0.244762\n",
            "Train Epoch: 4 [2286/3978 (57%)]\tLoss: 0.214733\n",
            "Train Epoch: 4 [2287/3978 (57%)]\tLoss: 2.681843\n",
            "Train Epoch: 4 [2288/3978 (58%)]\tLoss: 0.393422\n",
            "Train Epoch: 4 [2289/3978 (58%)]\tLoss: 0.676406\n",
            "Train Epoch: 4 [2290/3978 (58%)]\tLoss: 1.084672\n",
            "Train Epoch: 4 [2291/3978 (58%)]\tLoss: 2.043824\n",
            "Train Epoch: 4 [2292/3978 (58%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [2293/3978 (58%)]\tLoss: 0.000137\n",
            "Train Epoch: 4 [2294/3978 (58%)]\tLoss: 0.000019\n",
            "Train Epoch: 4 [2295/3978 (58%)]\tLoss: 0.000022\n",
            "Train Epoch: 4 [2296/3978 (58%)]\tLoss: 2.335163\n",
            "Train Epoch: 4 [2297/3978 (58%)]\tLoss: 2.053435\n",
            "Train Epoch: 4 [2298/3978 (58%)]\tLoss: 2.796470\n",
            "Train Epoch: 4 [2299/3978 (58%)]\tLoss: 1.191824\n",
            "Train Epoch: 4 [2300/3978 (58%)]\tLoss: 1.106569\n",
            "Train Epoch: 4 [2301/3978 (58%)]\tLoss: 0.000602\n",
            "Train Epoch: 4 [2302/3978 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2303/3978 (58%)]\tLoss: 0.511029\n",
            "Train Epoch: 4 [2304/3978 (58%)]\tLoss: 0.000050\n",
            "Train Epoch: 4 [2305/3978 (58%)]\tLoss: 3.398335\n",
            "Train Epoch: 4 [2306/3978 (58%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2307/3978 (58%)]\tLoss: 2.595436\n",
            "Train Epoch: 4 [2308/3978 (58%)]\tLoss: 3.120455\n",
            "Train Epoch: 4 [2309/3978 (58%)]\tLoss: 0.006907\n",
            "Train Epoch: 4 [2310/3978 (58%)]\tLoss: 2.407392\n",
            "Train Epoch: 4 [2311/3978 (58%)]\tLoss: 0.069210\n",
            "Train Epoch: 4 [2312/3978 (58%)]\tLoss: 0.126535\n",
            "Train Epoch: 4 [2313/3978 (58%)]\tLoss: 3.582626\n",
            "Train Epoch: 4 [2314/3978 (58%)]\tLoss: 2.058477\n",
            "Train Epoch: 4 [2315/3978 (58%)]\tLoss: 0.098917\n",
            "Train Epoch: 4 [2316/3978 (58%)]\tLoss: 0.000542\n",
            "Train Epoch: 4 [2317/3978 (58%)]\tLoss: 0.509578\n",
            "Train Epoch: 4 [2318/3978 (58%)]\tLoss: 0.014223\n",
            "Train Epoch: 4 [2319/3978 (58%)]\tLoss: 0.001450\n",
            "Train Epoch: 4 [2320/3978 (58%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [2321/3978 (58%)]\tLoss: 1.257130\n",
            "Train Epoch: 4 [2322/3978 (58%)]\tLoss: 6.973306\n",
            "Train Epoch: 4 [2323/3978 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2324/3978 (58%)]\tLoss: 1.512913\n",
            "Train Epoch: 4 [2325/3978 (58%)]\tLoss: 1.011959\n",
            "Train Epoch: 4 [2326/3978 (58%)]\tLoss: 1.024835\n",
            "Train Epoch: 4 [2327/3978 (58%)]\tLoss: 0.524207\n",
            "Train Epoch: 4 [2328/3978 (59%)]\tLoss: 0.464743\n",
            "Train Epoch: 4 [2329/3978 (59%)]\tLoss: 6.362322\n",
            "Train Epoch: 4 [2330/3978 (59%)]\tLoss: 1.629930\n",
            "Train Epoch: 4 [2331/3978 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2332/3978 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2333/3978 (59%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [2334/3978 (59%)]\tLoss: 0.000689\n",
            "Train Epoch: 4 [2335/3978 (59%)]\tLoss: 3.658360\n",
            "Train Epoch: 4 [2336/3978 (59%)]\tLoss: 0.122659\n",
            "Train Epoch: 4 [2337/3978 (59%)]\tLoss: 0.001746\n",
            "Train Epoch: 4 [2338/3978 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2339/3978 (59%)]\tLoss: 0.776972\n",
            "Train Epoch: 4 [2340/3978 (59%)]\tLoss: 0.286215\n",
            "Train Epoch: 4 [2341/3978 (59%)]\tLoss: 0.028309\n",
            "Train Epoch: 4 [2342/3978 (59%)]\tLoss: 1.195835\n",
            "Train Epoch: 4 [2343/3978 (59%)]\tLoss: 0.269565\n",
            "Train Epoch: 4 [2344/3978 (59%)]\tLoss: 0.000015\n",
            "Train Epoch: 4 [2345/3978 (59%)]\tLoss: 0.001099\n",
            "Train Epoch: 4 [2346/3978 (59%)]\tLoss: 0.610357\n",
            "Train Epoch: 4 [2347/3978 (59%)]\tLoss: 3.413319\n",
            "Train Epoch: 4 [2348/3978 (59%)]\tLoss: 0.010771\n",
            "Train Epoch: 4 [2349/3978 (59%)]\tLoss: 0.129076\n",
            "Train Epoch: 4 [2350/3978 (59%)]\tLoss: 2.458434\n",
            "Train Epoch: 4 [2351/3978 (59%)]\tLoss: 0.065880\n",
            "Train Epoch: 4 [2352/3978 (59%)]\tLoss: 0.104782\n",
            "Train Epoch: 4 [2353/3978 (59%)]\tLoss: 1.446218\n",
            "Train Epoch: 4 [2354/3978 (59%)]\tLoss: 0.214603\n",
            "Train Epoch: 4 [2355/3978 (59%)]\tLoss: 0.660491\n",
            "Train Epoch: 4 [2356/3978 (59%)]\tLoss: 0.921263\n",
            "Train Epoch: 4 [2357/3978 (59%)]\tLoss: 0.797166\n",
            "Train Epoch: 4 [2358/3978 (59%)]\tLoss: 0.000366\n",
            "Train Epoch: 4 [2359/3978 (59%)]\tLoss: 0.537636\n",
            "Train Epoch: 4 [2360/3978 (59%)]\tLoss: 0.276347\n",
            "Train Epoch: 4 [2361/3978 (59%)]\tLoss: 2.117885\n",
            "Train Epoch: 4 [2362/3978 (59%)]\tLoss: 0.820161\n",
            "Train Epoch: 4 [2363/3978 (59%)]\tLoss: 0.000663\n",
            "Train Epoch: 4 [2364/3978 (59%)]\tLoss: 1.162196\n",
            "Train Epoch: 4 [2365/3978 (59%)]\tLoss: 2.512571\n",
            "Train Epoch: 4 [2366/3978 (59%)]\tLoss: 0.005793\n",
            "Train Epoch: 4 [2367/3978 (60%)]\tLoss: 0.086681\n",
            "Train Epoch: 4 [2368/3978 (60%)]\tLoss: 0.398569\n",
            "Train Epoch: 4 [2369/3978 (60%)]\tLoss: 0.161729\n",
            "Train Epoch: 4 [2370/3978 (60%)]\tLoss: 0.196607\n",
            "Train Epoch: 4 [2371/3978 (60%)]\tLoss: 0.719049\n",
            "Train Epoch: 4 [2372/3978 (60%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [2373/3978 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2374/3978 (60%)]\tLoss: 0.000034\n",
            "Train Epoch: 4 [2375/3978 (60%)]\tLoss: 0.105679\n",
            "Train Epoch: 4 [2376/3978 (60%)]\tLoss: 0.728363\n",
            "Train Epoch: 4 [2377/3978 (60%)]\tLoss: 0.010858\n",
            "Train Epoch: 4 [2378/3978 (60%)]\tLoss: 1.356082\n",
            "Train Epoch: 4 [2379/3978 (60%)]\tLoss: 0.959185\n",
            "Train Epoch: 4 [2380/3978 (60%)]\tLoss: 0.117149\n",
            "Train Epoch: 4 [2381/3978 (60%)]\tLoss: 0.108120\n",
            "Train Epoch: 4 [2382/3978 (60%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2383/3978 (60%)]\tLoss: 0.346948\n",
            "Train Epoch: 4 [2384/3978 (60%)]\tLoss: 3.577572\n",
            "Train Epoch: 4 [2385/3978 (60%)]\tLoss: 1.727229\n",
            "Train Epoch: 4 [2386/3978 (60%)]\tLoss: 1.997482\n",
            "Train Epoch: 4 [2387/3978 (60%)]\tLoss: 2.914401\n",
            "Train Epoch: 4 [2388/3978 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2389/3978 (60%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2390/3978 (60%)]\tLoss: 0.000084\n",
            "Train Epoch: 4 [2391/3978 (60%)]\tLoss: 0.000255\n",
            "Train Epoch: 4 [2392/3978 (60%)]\tLoss: 0.022207\n",
            "Train Epoch: 4 [2393/3978 (60%)]\tLoss: 0.072879\n",
            "Train Epoch: 4 [2394/3978 (60%)]\tLoss: 0.106260\n",
            "Train Epoch: 4 [2395/3978 (60%)]\tLoss: 0.006391\n",
            "Train Epoch: 4 [2396/3978 (60%)]\tLoss: 0.882919\n",
            "Train Epoch: 4 [2397/3978 (60%)]\tLoss: 0.234210\n",
            "Train Epoch: 4 [2398/3978 (60%)]\tLoss: 1.118801\n",
            "Train Epoch: 4 [2399/3978 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2400/3978 (60%)]\tLoss: 0.858399\n",
            "Train Epoch: 4 [2401/3978 (60%)]\tLoss: 0.709020\n",
            "Train Epoch: 4 [2402/3978 (60%)]\tLoss: 1.358066\n",
            "Train Epoch: 4 [2403/3978 (60%)]\tLoss: 0.000588\n",
            "Train Epoch: 4 [2404/3978 (60%)]\tLoss: 4.266201\n",
            "Train Epoch: 4 [2405/3978 (60%)]\tLoss: 0.780037\n",
            "Train Epoch: 4 [2406/3978 (60%)]\tLoss: 0.942351\n",
            "Train Epoch: 4 [2407/3978 (61%)]\tLoss: 0.335452\n",
            "Train Epoch: 4 [2408/3978 (61%)]\tLoss: 0.065699\n",
            "Train Epoch: 4 [2409/3978 (61%)]\tLoss: 1.414086\n",
            "Train Epoch: 4 [2410/3978 (61%)]\tLoss: 0.024849\n",
            "Train Epoch: 4 [2411/3978 (61%)]\tLoss: 0.001513\n",
            "Train Epoch: 4 [2412/3978 (61%)]\tLoss: 2.002611\n",
            "Train Epoch: 4 [2413/3978 (61%)]\tLoss: 2.504549\n",
            "Train Epoch: 4 [2414/3978 (61%)]\tLoss: 2.111254\n",
            "Train Epoch: 4 [2415/3978 (61%)]\tLoss: 0.895350\n",
            "Train Epoch: 4 [2416/3978 (61%)]\tLoss: 0.003345\n",
            "Train Epoch: 4 [2417/3978 (61%)]\tLoss: 2.891931\n",
            "Train Epoch: 4 [2418/3978 (61%)]\tLoss: 0.033636\n",
            "Train Epoch: 4 [2419/3978 (61%)]\tLoss: 2.004065\n",
            "Train Epoch: 4 [2420/3978 (61%)]\tLoss: 0.698943\n",
            "Train Epoch: 4 [2421/3978 (61%)]\tLoss: 1.921957\n",
            "Train Epoch: 4 [2422/3978 (61%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2423/3978 (61%)]\tLoss: 0.014748\n",
            "Train Epoch: 4 [2424/3978 (61%)]\tLoss: 0.005288\n",
            "Train Epoch: 4 [2425/3978 (61%)]\tLoss: 2.675318\n",
            "Train Epoch: 4 [2426/3978 (61%)]\tLoss: 2.659375\n",
            "Train Epoch: 4 [2427/3978 (61%)]\tLoss: 3.482421\n",
            "Train Epoch: 4 [2428/3978 (61%)]\tLoss: 1.541029\n",
            "Train Epoch: 4 [2429/3978 (61%)]\tLoss: 1.489043\n",
            "Train Epoch: 4 [2430/3978 (61%)]\tLoss: 0.667707\n",
            "Train Epoch: 4 [2431/3978 (61%)]\tLoss: 0.414968\n",
            "Train Epoch: 4 [2432/3978 (61%)]\tLoss: 0.078710\n",
            "Train Epoch: 4 [2433/3978 (61%)]\tLoss: 0.963403\n",
            "Train Epoch: 4 [2434/3978 (61%)]\tLoss: 0.001150\n",
            "Train Epoch: 4 [2435/3978 (61%)]\tLoss: 1.506502\n",
            "Train Epoch: 4 [2436/3978 (61%)]\tLoss: 0.014721\n",
            "Train Epoch: 4 [2437/3978 (61%)]\tLoss: 5.118304\n",
            "Train Epoch: 4 [2438/3978 (61%)]\tLoss: 1.011029\n",
            "Train Epoch: 4 [2439/3978 (61%)]\tLoss: 5.445444\n",
            "Train Epoch: 4 [2440/3978 (61%)]\tLoss: 1.272002\n",
            "Train Epoch: 4 [2441/3978 (61%)]\tLoss: 0.000182\n",
            "Train Epoch: 4 [2442/3978 (61%)]\tLoss: 1.060754\n",
            "Train Epoch: 4 [2443/3978 (61%)]\tLoss: 0.774092\n",
            "Train Epoch: 4 [2444/3978 (61%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2445/3978 (61%)]\tLoss: 0.001884\n",
            "Train Epoch: 4 [2446/3978 (61%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [2447/3978 (62%)]\tLoss: 1.617934\n",
            "Train Epoch: 4 [2448/3978 (62%)]\tLoss: 2.929764\n",
            "Train Epoch: 4 [2449/3978 (62%)]\tLoss: 3.351529\n",
            "Train Epoch: 4 [2450/3978 (62%)]\tLoss: 0.304166\n",
            "Train Epoch: 4 [2451/3978 (62%)]\tLoss: 0.234117\n",
            "Train Epoch: 4 [2452/3978 (62%)]\tLoss: 0.008636\n",
            "Train Epoch: 4 [2453/3978 (62%)]\tLoss: 1.093017\n",
            "Train Epoch: 4 [2454/3978 (62%)]\tLoss: 0.038032\n",
            "Train Epoch: 4 [2455/3978 (62%)]\tLoss: 2.367437\n",
            "Train Epoch: 4 [2456/3978 (62%)]\tLoss: 0.310188\n",
            "Train Epoch: 4 [2457/3978 (62%)]\tLoss: 0.215125\n",
            "Train Epoch: 4 [2458/3978 (62%)]\tLoss: 4.494922\n",
            "Train Epoch: 4 [2459/3978 (62%)]\tLoss: 2.528097\n",
            "Train Epoch: 4 [2460/3978 (62%)]\tLoss: 0.497721\n",
            "Train Epoch: 4 [2461/3978 (62%)]\tLoss: 0.000612\n",
            "Train Epoch: 4 [2462/3978 (62%)]\tLoss: 1.641021\n",
            "Train Epoch: 4 [2463/3978 (62%)]\tLoss: 2.318178\n",
            "Train Epoch: 4 [2464/3978 (62%)]\tLoss: 2.629079\n",
            "Train Epoch: 4 [2465/3978 (62%)]\tLoss: 1.225589\n",
            "Train Epoch: 4 [2466/3978 (62%)]\tLoss: 4.287173\n",
            "Train Epoch: 4 [2467/3978 (62%)]\tLoss: 3.973666\n",
            "Train Epoch: 4 [2468/3978 (62%)]\tLoss: 0.039815\n",
            "Train Epoch: 4 [2469/3978 (62%)]\tLoss: 0.208915\n",
            "Train Epoch: 4 [2470/3978 (62%)]\tLoss: 0.169396\n",
            "Train Epoch: 4 [2471/3978 (62%)]\tLoss: 0.000439\n",
            "Train Epoch: 4 [2472/3978 (62%)]\tLoss: 1.719844\n",
            "Train Epoch: 4 [2473/3978 (62%)]\tLoss: 0.000504\n",
            "Train Epoch: 4 [2474/3978 (62%)]\tLoss: 0.002229\n",
            "Train Epoch: 4 [2475/3978 (62%)]\tLoss: 0.495370\n",
            "Train Epoch: 4 [2476/3978 (62%)]\tLoss: 0.003544\n",
            "Train Epoch: 4 [2477/3978 (62%)]\tLoss: 0.086534\n",
            "Train Epoch: 4 [2478/3978 (62%)]\tLoss: 0.543310\n",
            "Train Epoch: 4 [2479/3978 (62%)]\tLoss: 0.027298\n",
            "Train Epoch: 4 [2480/3978 (62%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [2481/3978 (62%)]\tLoss: 1.095840\n",
            "Train Epoch: 4 [2482/3978 (62%)]\tLoss: 0.034597\n",
            "Train Epoch: 4 [2483/3978 (62%)]\tLoss: 1.761200\n",
            "Train Epoch: 4 [2484/3978 (62%)]\tLoss: 0.000047\n",
            "Train Epoch: 4 [2485/3978 (62%)]\tLoss: 5.628758\n",
            "Train Epoch: 4 [2486/3978 (62%)]\tLoss: 0.000068\n",
            "Train Epoch: 4 [2487/3978 (63%)]\tLoss: 1.504208\n",
            "Train Epoch: 4 [2488/3978 (63%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2489/3978 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2490/3978 (63%)]\tLoss: 0.770655\n",
            "Train Epoch: 4 [2491/3978 (63%)]\tLoss: 1.052276\n",
            "Train Epoch: 4 [2492/3978 (63%)]\tLoss: 0.513446\n",
            "Train Epoch: 4 [2493/3978 (63%)]\tLoss: 3.096057\n",
            "Train Epoch: 4 [2494/3978 (63%)]\tLoss: 1.045144\n",
            "Train Epoch: 4 [2495/3978 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2496/3978 (63%)]\tLoss: 2.810750\n",
            "Train Epoch: 4 [2497/3978 (63%)]\tLoss: 2.620533\n",
            "Train Epoch: 4 [2498/3978 (63%)]\tLoss: 5.262615\n",
            "Train Epoch: 4 [2499/3978 (63%)]\tLoss: 1.359467\n",
            "Train Epoch: 4 [2500/3978 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2501/3978 (63%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [2502/3978 (63%)]\tLoss: 0.932026\n",
            "Train Epoch: 4 [2503/3978 (63%)]\tLoss: 0.093030\n",
            "Train Epoch: 4 [2504/3978 (63%)]\tLoss: 0.000488\n",
            "Train Epoch: 4 [2505/3978 (63%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2506/3978 (63%)]\tLoss: 1.606488\n",
            "Train Epoch: 4 [2507/3978 (63%)]\tLoss: 0.026612\n",
            "Train Epoch: 4 [2508/3978 (63%)]\tLoss: 1.776257\n",
            "Train Epoch: 4 [2509/3978 (63%)]\tLoss: 0.031141\n",
            "Train Epoch: 4 [2510/3978 (63%)]\tLoss: 0.101302\n",
            "Train Epoch: 4 [2511/3978 (63%)]\tLoss: 0.129240\n",
            "Train Epoch: 4 [2512/3978 (63%)]\tLoss: 0.301103\n",
            "Train Epoch: 4 [2513/3978 (63%)]\tLoss: 0.000085\n",
            "Train Epoch: 4 [2514/3978 (63%)]\tLoss: 0.564273\n",
            "Train Epoch: 4 [2515/3978 (63%)]\tLoss: 2.001045\n",
            "Train Epoch: 4 [2516/3978 (63%)]\tLoss: 0.858995\n",
            "Train Epoch: 4 [2517/3978 (63%)]\tLoss: 5.528398\n",
            "Train Epoch: 4 [2518/3978 (63%)]\tLoss: 0.076100\n",
            "Train Epoch: 4 [2519/3978 (63%)]\tLoss: 1.002866\n",
            "Train Epoch: 4 [2520/3978 (63%)]\tLoss: 0.581023\n",
            "Train Epoch: 4 [2521/3978 (63%)]\tLoss: 0.037329\n",
            "Train Epoch: 4 [2522/3978 (63%)]\tLoss: 0.000126\n",
            "Train Epoch: 4 [2523/3978 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2524/3978 (63%)]\tLoss: 1.834516\n",
            "Train Epoch: 4 [2525/3978 (63%)]\tLoss: 2.185089\n",
            "Train Epoch: 4 [2526/3978 (63%)]\tLoss: 9.212820\n",
            "Train Epoch: 4 [2527/3978 (64%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2528/3978 (64%)]\tLoss: 4.782166\n",
            "Train Epoch: 4 [2529/3978 (64%)]\tLoss: 0.002863\n",
            "Train Epoch: 4 [2530/3978 (64%)]\tLoss: 0.000018\n",
            "Train Epoch: 4 [2531/3978 (64%)]\tLoss: 0.656300\n",
            "Train Epoch: 4 [2532/3978 (64%)]\tLoss: 2.842141\n",
            "Train Epoch: 4 [2533/3978 (64%)]\tLoss: 0.860208\n",
            "Train Epoch: 4 [2534/3978 (64%)]\tLoss: 1.287766\n",
            "Train Epoch: 4 [2535/3978 (64%)]\tLoss: 1.607649\n",
            "Train Epoch: 4 [2536/3978 (64%)]\tLoss: 0.001388\n",
            "Train Epoch: 4 [2537/3978 (64%)]\tLoss: 0.334075\n",
            "Train Epoch: 4 [2538/3978 (64%)]\tLoss: 0.000324\n",
            "Train Epoch: 4 [2539/3978 (64%)]\tLoss: 0.379674\n",
            "Train Epoch: 4 [2540/3978 (64%)]\tLoss: 1.359421\n",
            "Train Epoch: 4 [2541/3978 (64%)]\tLoss: 0.001245\n",
            "Train Epoch: 4 [2542/3978 (64%)]\tLoss: 0.893517\n",
            "Train Epoch: 4 [2543/3978 (64%)]\tLoss: 2.061904\n",
            "Train Epoch: 4 [2544/3978 (64%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2545/3978 (64%)]\tLoss: 0.895559\n",
            "Train Epoch: 4 [2546/3978 (64%)]\tLoss: 0.996381\n",
            "Train Epoch: 4 [2547/3978 (64%)]\tLoss: 0.034827\n",
            "Train Epoch: 4 [2548/3978 (64%)]\tLoss: 1.127947\n",
            "Train Epoch: 4 [2549/3978 (64%)]\tLoss: 0.236024\n",
            "Train Epoch: 4 [2550/3978 (64%)]\tLoss: 0.242286\n",
            "Train Epoch: 4 [2551/3978 (64%)]\tLoss: 0.001090\n",
            "Train Epoch: 4 [2552/3978 (64%)]\tLoss: 1.206798\n",
            "Train Epoch: 4 [2553/3978 (64%)]\tLoss: 0.589243\n",
            "Train Epoch: 4 [2554/3978 (64%)]\tLoss: 0.756302\n",
            "Train Epoch: 4 [2555/3978 (64%)]\tLoss: 1.750674\n",
            "Train Epoch: 4 [2556/3978 (64%)]\tLoss: 0.079399\n",
            "Train Epoch: 4 [2557/3978 (64%)]\tLoss: 1.015507\n",
            "Train Epoch: 4 [2558/3978 (64%)]\tLoss: 0.051434\n",
            "Train Epoch: 4 [2559/3978 (64%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [2560/3978 (64%)]\tLoss: 0.000635\n",
            "Train Epoch: 4 [2561/3978 (64%)]\tLoss: 0.548759\n",
            "Train Epoch: 4 [2562/3978 (64%)]\tLoss: 0.114445\n",
            "Train Epoch: 4 [2563/3978 (64%)]\tLoss: 0.032207\n",
            "Train Epoch: 4 [2564/3978 (64%)]\tLoss: 0.025675\n",
            "Train Epoch: 4 [2565/3978 (64%)]\tLoss: 0.290362\n",
            "Train Epoch: 4 [2566/3978 (65%)]\tLoss: 0.151860\n",
            "Train Epoch: 4 [2567/3978 (65%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2568/3978 (65%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2569/3978 (65%)]\tLoss: 1.665427\n",
            "Train Epoch: 4 [2570/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2571/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2572/3978 (65%)]\tLoss: 1.684594\n",
            "Train Epoch: 4 [2573/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2574/3978 (65%)]\tLoss: 1.298232\n",
            "Train Epoch: 4 [2575/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2576/3978 (65%)]\tLoss: 0.409369\n",
            "Train Epoch: 4 [2577/3978 (65%)]\tLoss: 0.045061\n",
            "Train Epoch: 4 [2578/3978 (65%)]\tLoss: 2.344954\n",
            "Train Epoch: 4 [2579/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2580/3978 (65%)]\tLoss: 0.788606\n",
            "Train Epoch: 4 [2581/3978 (65%)]\tLoss: 0.001225\n",
            "Train Epoch: 4 [2582/3978 (65%)]\tLoss: 0.008806\n",
            "Train Epoch: 4 [2583/3978 (65%)]\tLoss: 1.248883\n",
            "Train Epoch: 4 [2584/3978 (65%)]\tLoss: 1.062007\n",
            "Train Epoch: 4 [2585/3978 (65%)]\tLoss: 0.308769\n",
            "Train Epoch: 4 [2586/3978 (65%)]\tLoss: 1.446922\n",
            "Train Epoch: 4 [2587/3978 (65%)]\tLoss: 0.000387\n",
            "Train Epoch: 4 [2588/3978 (65%)]\tLoss: 0.080407\n",
            "Train Epoch: 4 [2589/3978 (65%)]\tLoss: 0.814051\n",
            "Train Epoch: 4 [2590/3978 (65%)]\tLoss: 1.168969\n",
            "Train Epoch: 4 [2591/3978 (65%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2592/3978 (65%)]\tLoss: 0.102775\n",
            "Train Epoch: 4 [2593/3978 (65%)]\tLoss: 0.003004\n",
            "Train Epoch: 4 [2594/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2595/3978 (65%)]\tLoss: 2.280304\n",
            "Train Epoch: 4 [2596/3978 (65%)]\tLoss: 0.457584\n",
            "Train Epoch: 4 [2597/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2598/3978 (65%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [2599/3978 (65%)]\tLoss: 0.090842\n",
            "Train Epoch: 4 [2600/3978 (65%)]\tLoss: 2.663965\n",
            "Train Epoch: 4 [2601/3978 (65%)]\tLoss: 2.575201\n",
            "Train Epoch: 4 [2602/3978 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2603/3978 (65%)]\tLoss: 0.000079\n",
            "Train Epoch: 4 [2604/3978 (65%)]\tLoss: 1.747770\n",
            "Train Epoch: 4 [2605/3978 (65%)]\tLoss: 3.541801\n",
            "Train Epoch: 4 [2606/3978 (66%)]\tLoss: 0.198894\n",
            "Train Epoch: 4 [2607/3978 (66%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2608/3978 (66%)]\tLoss: 0.191484\n",
            "Train Epoch: 4 [2609/3978 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2610/3978 (66%)]\tLoss: 2.426144\n",
            "Train Epoch: 4 [2611/3978 (66%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2612/3978 (66%)]\tLoss: 1.933874\n",
            "Train Epoch: 4 [2613/3978 (66%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [2614/3978 (66%)]\tLoss: 0.000065\n",
            "Train Epoch: 4 [2615/3978 (66%)]\tLoss: 4.250031\n",
            "Train Epoch: 4 [2616/3978 (66%)]\tLoss: 0.739404\n",
            "Train Epoch: 4 [2617/3978 (66%)]\tLoss: 0.252121\n",
            "Train Epoch: 4 [2618/3978 (66%)]\tLoss: 1.002632\n",
            "Train Epoch: 4 [2619/3978 (66%)]\tLoss: 0.081479\n",
            "Train Epoch: 4 [2620/3978 (66%)]\tLoss: 2.391117\n",
            "Train Epoch: 4 [2621/3978 (66%)]\tLoss: 2.743832\n",
            "Train Epoch: 4 [2622/3978 (66%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [2623/3978 (66%)]\tLoss: 0.470718\n",
            "Train Epoch: 4 [2624/3978 (66%)]\tLoss: 1.168693\n",
            "Train Epoch: 4 [2625/3978 (66%)]\tLoss: 3.563602\n",
            "Train Epoch: 4 [2626/3978 (66%)]\tLoss: 0.589179\n",
            "Train Epoch: 4 [2627/3978 (66%)]\tLoss: 2.360944\n",
            "Train Epoch: 4 [2628/3978 (66%)]\tLoss: 0.401755\n",
            "Train Epoch: 4 [2629/3978 (66%)]\tLoss: 0.761139\n",
            "Train Epoch: 4 [2630/3978 (66%)]\tLoss: 1.296836\n",
            "Train Epoch: 4 [2631/3978 (66%)]\tLoss: 0.545015\n",
            "Train Epoch: 4 [2632/3978 (66%)]\tLoss: 3.782712\n",
            "Train Epoch: 4 [2633/3978 (66%)]\tLoss: 0.050861\n",
            "Train Epoch: 4 [2634/3978 (66%)]\tLoss: 0.401995\n",
            "Train Epoch: 4 [2635/3978 (66%)]\tLoss: 0.836214\n",
            "Train Epoch: 4 [2636/3978 (66%)]\tLoss: 0.002344\n",
            "Train Epoch: 4 [2637/3978 (66%)]\tLoss: 0.208447\n",
            "Train Epoch: 4 [2638/3978 (66%)]\tLoss: 0.007025\n",
            "Train Epoch: 4 [2639/3978 (66%)]\tLoss: 0.211505\n",
            "Train Epoch: 4 [2640/3978 (66%)]\tLoss: 0.512310\n",
            "Train Epoch: 4 [2641/3978 (66%)]\tLoss: 0.075230\n",
            "Train Epoch: 4 [2642/3978 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2643/3978 (66%)]\tLoss: 0.040106\n",
            "Train Epoch: 4 [2644/3978 (66%)]\tLoss: 2.251046\n",
            "Train Epoch: 4 [2645/3978 (66%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [2646/3978 (67%)]\tLoss: 2.981977\n",
            "Train Epoch: 4 [2647/3978 (67%)]\tLoss: 0.276905\n",
            "Train Epoch: 4 [2648/3978 (67%)]\tLoss: 6.326113\n",
            "Train Epoch: 4 [2649/3978 (67%)]\tLoss: 5.438550\n",
            "Train Epoch: 4 [2650/3978 (67%)]\tLoss: 1.057291\n",
            "Train Epoch: 4 [2651/3978 (67%)]\tLoss: 0.019703\n",
            "Train Epoch: 4 [2652/3978 (67%)]\tLoss: 0.056840\n",
            "Train Epoch: 4 [2653/3978 (67%)]\tLoss: 2.053471\n",
            "Train Epoch: 4 [2654/3978 (67%)]\tLoss: 0.573449\n",
            "Train Epoch: 4 [2655/3978 (67%)]\tLoss: 0.519642\n",
            "Train Epoch: 4 [2656/3978 (67%)]\tLoss: 0.256465\n",
            "Train Epoch: 4 [2657/3978 (67%)]\tLoss: 0.175617\n",
            "Train Epoch: 4 [2658/3978 (67%)]\tLoss: 0.016357\n",
            "Train Epoch: 4 [2659/3978 (67%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [2660/3978 (67%)]\tLoss: 0.213030\n",
            "Train Epoch: 4 [2661/3978 (67%)]\tLoss: 3.176606\n",
            "Train Epoch: 4 [2662/3978 (67%)]\tLoss: 1.435502\n",
            "Train Epoch: 4 [2663/3978 (67%)]\tLoss: 0.011630\n",
            "Train Epoch: 4 [2664/3978 (67%)]\tLoss: 0.000054\n",
            "Train Epoch: 4 [2665/3978 (67%)]\tLoss: 0.003987\n",
            "Train Epoch: 4 [2666/3978 (67%)]\tLoss: 0.031955\n",
            "Train Epoch: 4 [2667/3978 (67%)]\tLoss: 6.169117\n",
            "Train Epoch: 4 [2668/3978 (67%)]\tLoss: 0.000247\n",
            "Train Epoch: 4 [2669/3978 (67%)]\tLoss: 0.001443\n",
            "Train Epoch: 4 [2670/3978 (67%)]\tLoss: 0.067685\n",
            "Train Epoch: 4 [2671/3978 (67%)]\tLoss: 0.340303\n",
            "Train Epoch: 4 [2672/3978 (67%)]\tLoss: 0.000220\n",
            "Train Epoch: 4 [2673/3978 (67%)]\tLoss: 1.392063\n",
            "Train Epoch: 4 [2674/3978 (67%)]\tLoss: 0.587934\n",
            "Train Epoch: 4 [2675/3978 (67%)]\tLoss: 0.220461\n",
            "Train Epoch: 4 [2676/3978 (67%)]\tLoss: 0.000094\n",
            "Train Epoch: 4 [2677/3978 (67%)]\tLoss: 0.076438\n",
            "Train Epoch: 4 [2678/3978 (67%)]\tLoss: 3.046930\n",
            "Train Epoch: 4 [2679/3978 (67%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2680/3978 (67%)]\tLoss: 0.963994\n",
            "Train Epoch: 4 [2681/3978 (67%)]\tLoss: 4.374193\n",
            "Train Epoch: 4 [2682/3978 (67%)]\tLoss: 1.806796\n",
            "Train Epoch: 4 [2683/3978 (67%)]\tLoss: 0.186949\n",
            "Train Epoch: 4 [2684/3978 (67%)]\tLoss: 0.120732\n",
            "Train Epoch: 4 [2685/3978 (67%)]\tLoss: 1.050636\n",
            "Train Epoch: 4 [2686/3978 (68%)]\tLoss: 1.145635\n",
            "Train Epoch: 4 [2687/3978 (68%)]\tLoss: 0.024086\n",
            "Train Epoch: 4 [2688/3978 (68%)]\tLoss: 4.368314\n",
            "Train Epoch: 4 [2689/3978 (68%)]\tLoss: 0.423287\n",
            "Train Epoch: 4 [2690/3978 (68%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2691/3978 (68%)]\tLoss: 1.297390\n",
            "Train Epoch: 4 [2692/3978 (68%)]\tLoss: 2.058838\n",
            "Train Epoch: 4 [2693/3978 (68%)]\tLoss: 1.532436\n",
            "Train Epoch: 4 [2694/3978 (68%)]\tLoss: 1.667274\n",
            "Train Epoch: 4 [2695/3978 (68%)]\tLoss: 0.001383\n",
            "Train Epoch: 4 [2696/3978 (68%)]\tLoss: 1.047518\n",
            "Train Epoch: 4 [2697/3978 (68%)]\tLoss: 0.000112\n",
            "Train Epoch: 4 [2698/3978 (68%)]\tLoss: 1.607180\n",
            "Train Epoch: 4 [2699/3978 (68%)]\tLoss: 1.670839\n",
            "Train Epoch: 4 [2700/3978 (68%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [2701/3978 (68%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [2702/3978 (68%)]\tLoss: 2.486184\n",
            "Train Epoch: 4 [2703/3978 (68%)]\tLoss: 2.730746\n",
            "Train Epoch: 4 [2704/3978 (68%)]\tLoss: 1.840284\n",
            "Train Epoch: 4 [2705/3978 (68%)]\tLoss: 1.492555\n",
            "Train Epoch: 4 [2706/3978 (68%)]\tLoss: 1.407114\n",
            "Train Epoch: 4 [2707/3978 (68%)]\tLoss: 5.751992\n",
            "Train Epoch: 4 [2708/3978 (68%)]\tLoss: 0.116026\n",
            "Train Epoch: 4 [2709/3978 (68%)]\tLoss: 1.298960\n",
            "Train Epoch: 4 [2710/3978 (68%)]\tLoss: 1.305952\n",
            "Train Epoch: 4 [2711/3978 (68%)]\tLoss: 2.069158\n",
            "Train Epoch: 4 [2712/3978 (68%)]\tLoss: 2.190523\n",
            "Train Epoch: 4 [2713/3978 (68%)]\tLoss: 0.679891\n",
            "Train Epoch: 4 [2714/3978 (68%)]\tLoss: 0.001408\n",
            "Train Epoch: 4 [2715/3978 (68%)]\tLoss: 0.981264\n",
            "Train Epoch: 4 [2716/3978 (68%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2717/3978 (68%)]\tLoss: 4.237865\n",
            "Train Epoch: 4 [2718/3978 (68%)]\tLoss: 3.184444\n",
            "Train Epoch: 4 [2719/3978 (68%)]\tLoss: 1.306193\n",
            "Train Epoch: 4 [2720/3978 (68%)]\tLoss: 1.102622\n",
            "Train Epoch: 4 [2721/3978 (68%)]\tLoss: 2.462671\n",
            "Train Epoch: 4 [2722/3978 (68%)]\tLoss: 1.603543\n",
            "Train Epoch: 4 [2723/3978 (68%)]\tLoss: 0.364395\n",
            "Train Epoch: 4 [2724/3978 (68%)]\tLoss: 0.189430\n",
            "Train Epoch: 4 [2725/3978 (69%)]\tLoss: 0.639886\n",
            "Train Epoch: 4 [2726/3978 (69%)]\tLoss: 0.446011\n",
            "Train Epoch: 4 [2727/3978 (69%)]\tLoss: 1.521994\n",
            "Train Epoch: 4 [2728/3978 (69%)]\tLoss: 1.768808\n",
            "Train Epoch: 4 [2729/3978 (69%)]\tLoss: 3.568224\n",
            "Train Epoch: 4 [2730/3978 (69%)]\tLoss: 0.068507\n",
            "Train Epoch: 4 [2731/3978 (69%)]\tLoss: 0.507582\n",
            "Train Epoch: 4 [2732/3978 (69%)]\tLoss: 0.762740\n",
            "Train Epoch: 4 [2733/3978 (69%)]\tLoss: 0.923013\n",
            "Train Epoch: 4 [2734/3978 (69%)]\tLoss: 0.012196\n",
            "Train Epoch: 4 [2735/3978 (69%)]\tLoss: 0.052246\n",
            "Train Epoch: 4 [2736/3978 (69%)]\tLoss: 0.266198\n",
            "Train Epoch: 4 [2737/3978 (69%)]\tLoss: 2.787147\n",
            "Train Epoch: 4 [2738/3978 (69%)]\tLoss: 0.008777\n",
            "Train Epoch: 4 [2739/3978 (69%)]\tLoss: 0.002175\n",
            "Train Epoch: 4 [2740/3978 (69%)]\tLoss: 1.344073\n",
            "Train Epoch: 4 [2741/3978 (69%)]\tLoss: 0.218397\n",
            "Train Epoch: 4 [2742/3978 (69%)]\tLoss: 0.000172\n",
            "Train Epoch: 4 [2743/3978 (69%)]\tLoss: 0.906820\n",
            "Train Epoch: 4 [2744/3978 (69%)]\tLoss: 0.021626\n",
            "Train Epoch: 4 [2745/3978 (69%)]\tLoss: 0.060012\n",
            "Train Epoch: 4 [2746/3978 (69%)]\tLoss: 5.101213\n",
            "Train Epoch: 4 [2747/3978 (69%)]\tLoss: 0.606494\n",
            "Train Epoch: 4 [2748/3978 (69%)]\tLoss: 0.000664\n",
            "Train Epoch: 4 [2749/3978 (69%)]\tLoss: 0.004728\n",
            "Train Epoch: 4 [2750/3978 (69%)]\tLoss: 1.502638\n",
            "Train Epoch: 4 [2751/3978 (69%)]\tLoss: 7.223019\n",
            "Train Epoch: 4 [2752/3978 (69%)]\tLoss: 0.111364\n",
            "Train Epoch: 4 [2753/3978 (69%)]\tLoss: 0.029263\n",
            "Train Epoch: 4 [2754/3978 (69%)]\tLoss: 1.078146\n",
            "Train Epoch: 4 [2755/3978 (69%)]\tLoss: 2.179639\n",
            "Train Epoch: 4 [2756/3978 (69%)]\tLoss: 0.341766\n",
            "Train Epoch: 4 [2757/3978 (69%)]\tLoss: 0.046301\n",
            "Train Epoch: 4 [2758/3978 (69%)]\tLoss: 0.027767\n",
            "Train Epoch: 4 [2759/3978 (69%)]\tLoss: 0.113207\n",
            "Train Epoch: 4 [2760/3978 (69%)]\tLoss: 0.589126\n",
            "Train Epoch: 4 [2761/3978 (69%)]\tLoss: 0.000753\n",
            "Train Epoch: 4 [2762/3978 (69%)]\tLoss: 1.056573\n",
            "Train Epoch: 4 [2763/3978 (69%)]\tLoss: 1.341116\n",
            "Train Epoch: 4 [2764/3978 (69%)]\tLoss: 0.001628\n",
            "Train Epoch: 4 [2765/3978 (70%)]\tLoss: 0.000117\n",
            "Train Epoch: 4 [2766/3978 (70%)]\tLoss: 2.597663\n",
            "Train Epoch: 4 [2767/3978 (70%)]\tLoss: 1.234347\n",
            "Train Epoch: 4 [2768/3978 (70%)]\tLoss: 0.766480\n",
            "Train Epoch: 4 [2769/3978 (70%)]\tLoss: 1.373313\n",
            "Train Epoch: 4 [2770/3978 (70%)]\tLoss: 0.250120\n",
            "Train Epoch: 4 [2771/3978 (70%)]\tLoss: 1.149063\n",
            "Train Epoch: 4 [2772/3978 (70%)]\tLoss: 0.180724\n",
            "Train Epoch: 4 [2773/3978 (70%)]\tLoss: 4.786124\n",
            "Train Epoch: 4 [2774/3978 (70%)]\tLoss: 1.930855\n",
            "Train Epoch: 4 [2775/3978 (70%)]\tLoss: 0.002866\n",
            "Train Epoch: 4 [2776/3978 (70%)]\tLoss: 0.030456\n",
            "Train Epoch: 4 [2777/3978 (70%)]\tLoss: 4.651453\n",
            "Train Epoch: 4 [2778/3978 (70%)]\tLoss: 0.000084\n",
            "Train Epoch: 4 [2779/3978 (70%)]\tLoss: 1.265869\n",
            "Train Epoch: 4 [2780/3978 (70%)]\tLoss: 3.303942\n",
            "Train Epoch: 4 [2781/3978 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2782/3978 (70%)]\tLoss: 0.000227\n",
            "Train Epoch: 4 [2783/3978 (70%)]\tLoss: 2.153177\n",
            "Train Epoch: 4 [2784/3978 (70%)]\tLoss: 2.229127\n",
            "Train Epoch: 4 [2785/3978 (70%)]\tLoss: 0.889474\n",
            "Train Epoch: 4 [2786/3978 (70%)]\tLoss: 0.417454\n",
            "Train Epoch: 4 [2787/3978 (70%)]\tLoss: 1.770454\n",
            "Train Epoch: 4 [2788/3978 (70%)]\tLoss: 0.235612\n",
            "Train Epoch: 4 [2789/3978 (70%)]\tLoss: 3.264364\n",
            "Train Epoch: 4 [2790/3978 (70%)]\tLoss: 0.000193\n",
            "Train Epoch: 4 [2791/3978 (70%)]\tLoss: 0.000072\n",
            "Train Epoch: 4 [2792/3978 (70%)]\tLoss: 2.611921\n",
            "Train Epoch: 4 [2793/3978 (70%)]\tLoss: 2.232247\n",
            "Train Epoch: 4 [2794/3978 (70%)]\tLoss: 2.451221\n",
            "Train Epoch: 4 [2795/3978 (70%)]\tLoss: 2.898883\n",
            "Train Epoch: 4 [2796/3978 (70%)]\tLoss: 0.323910\n",
            "Train Epoch: 4 [2797/3978 (70%)]\tLoss: 0.121393\n",
            "Train Epoch: 4 [2798/3978 (70%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [2799/3978 (70%)]\tLoss: 0.014927\n",
            "Train Epoch: 4 [2800/3978 (70%)]\tLoss: 0.188765\n",
            "Train Epoch: 4 [2801/3978 (70%)]\tLoss: 0.060451\n",
            "Train Epoch: 4 [2802/3978 (70%)]\tLoss: 1.147475\n",
            "Train Epoch: 4 [2803/3978 (70%)]\tLoss: 1.094905\n",
            "Train Epoch: 4 [2804/3978 (70%)]\tLoss: 6.079274\n",
            "Train Epoch: 4 [2805/3978 (71%)]\tLoss: 0.626627\n",
            "Train Epoch: 4 [2806/3978 (71%)]\tLoss: 0.390566\n",
            "Train Epoch: 4 [2807/3978 (71%)]\tLoss: 0.000413\n",
            "Train Epoch: 4 [2808/3978 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2809/3978 (71%)]\tLoss: 0.000050\n",
            "Train Epoch: 4 [2810/3978 (71%)]\tLoss: 2.824126\n",
            "Train Epoch: 4 [2811/3978 (71%)]\tLoss: 3.605145\n",
            "Train Epoch: 4 [2812/3978 (71%)]\tLoss: 0.536404\n",
            "Train Epoch: 4 [2813/3978 (71%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2814/3978 (71%)]\tLoss: 0.006385\n",
            "Train Epoch: 4 [2815/3978 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2816/3978 (71%)]\tLoss: 0.222727\n",
            "Train Epoch: 4 [2817/3978 (71%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2818/3978 (71%)]\tLoss: 0.000115\n",
            "Train Epoch: 4 [2819/3978 (71%)]\tLoss: 0.507018\n",
            "Train Epoch: 4 [2820/3978 (71%)]\tLoss: 1.121218\n",
            "Train Epoch: 4 [2821/3978 (71%)]\tLoss: 0.317126\n",
            "Train Epoch: 4 [2822/3978 (71%)]\tLoss: 0.302016\n",
            "Train Epoch: 4 [2823/3978 (71%)]\tLoss: 0.352709\n",
            "Train Epoch: 4 [2824/3978 (71%)]\tLoss: 0.215443\n",
            "Train Epoch: 4 [2825/3978 (71%)]\tLoss: 0.119322\n",
            "Train Epoch: 4 [2826/3978 (71%)]\tLoss: 1.539409\n",
            "Train Epoch: 4 [2827/3978 (71%)]\tLoss: 0.008364\n",
            "Train Epoch: 4 [2828/3978 (71%)]\tLoss: 3.281162\n",
            "Train Epoch: 4 [2829/3978 (71%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [2830/3978 (71%)]\tLoss: 1.906960\n",
            "Train Epoch: 4 [2831/3978 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2832/3978 (71%)]\tLoss: 2.600301\n",
            "Train Epoch: 4 [2833/3978 (71%)]\tLoss: 0.013233\n",
            "Train Epoch: 4 [2834/3978 (71%)]\tLoss: 0.431517\n",
            "Train Epoch: 4 [2835/3978 (71%)]\tLoss: 2.851797\n",
            "Train Epoch: 4 [2836/3978 (71%)]\tLoss: 0.075540\n",
            "Train Epoch: 4 [2837/3978 (71%)]\tLoss: 1.290048\n",
            "Train Epoch: 4 [2838/3978 (71%)]\tLoss: 0.167122\n",
            "Train Epoch: 4 [2839/3978 (71%)]\tLoss: 1.329545\n",
            "Train Epoch: 4 [2840/3978 (71%)]\tLoss: 0.852430\n",
            "Train Epoch: 4 [2841/3978 (71%)]\tLoss: 0.000505\n",
            "Train Epoch: 4 [2842/3978 (71%)]\tLoss: 1.168133\n",
            "Train Epoch: 4 [2843/3978 (71%)]\tLoss: 0.000062\n",
            "Train Epoch: 4 [2844/3978 (71%)]\tLoss: 1.204449\n",
            "Train Epoch: 4 [2845/3978 (72%)]\tLoss: 0.737957\n",
            "Train Epoch: 4 [2846/3978 (72%)]\tLoss: 0.398675\n",
            "Train Epoch: 4 [2847/3978 (72%)]\tLoss: 0.419153\n",
            "Train Epoch: 4 [2848/3978 (72%)]\tLoss: 0.221086\n",
            "Train Epoch: 4 [2849/3978 (72%)]\tLoss: 0.000924\n",
            "Train Epoch: 4 [2850/3978 (72%)]\tLoss: 1.045646\n",
            "Train Epoch: 4 [2851/3978 (72%)]\tLoss: 6.531792\n",
            "Train Epoch: 4 [2852/3978 (72%)]\tLoss: 0.106555\n",
            "Train Epoch: 4 [2853/3978 (72%)]\tLoss: 0.132445\n",
            "Train Epoch: 4 [2854/3978 (72%)]\tLoss: 0.000824\n",
            "Train Epoch: 4 [2855/3978 (72%)]\tLoss: 0.008978\n",
            "Train Epoch: 4 [2856/3978 (72%)]\tLoss: 1.066388\n",
            "Train Epoch: 4 [2857/3978 (72%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [2858/3978 (72%)]\tLoss: 0.980987\n",
            "Train Epoch: 4 [2859/3978 (72%)]\tLoss: 0.158520\n",
            "Train Epoch: 4 [2860/3978 (72%)]\tLoss: 1.810815\n",
            "Train Epoch: 4 [2861/3978 (72%)]\tLoss: 5.156747\n",
            "Train Epoch: 4 [2862/3978 (72%)]\tLoss: 0.087177\n",
            "Train Epoch: 4 [2863/3978 (72%)]\tLoss: 0.003362\n",
            "Train Epoch: 4 [2864/3978 (72%)]\tLoss: 2.977864\n",
            "Train Epoch: 4 [2865/3978 (72%)]\tLoss: 0.000172\n",
            "Train Epoch: 4 [2866/3978 (72%)]\tLoss: 0.003985\n",
            "Train Epoch: 4 [2867/3978 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2868/3978 (72%)]\tLoss: 1.166565\n",
            "Train Epoch: 4 [2869/3978 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2870/3978 (72%)]\tLoss: 0.747323\n",
            "Train Epoch: 4 [2871/3978 (72%)]\tLoss: 1.769246\n",
            "Train Epoch: 4 [2872/3978 (72%)]\tLoss: 3.058805\n",
            "Train Epoch: 4 [2873/3978 (72%)]\tLoss: 2.452096\n",
            "Train Epoch: 4 [2874/3978 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2875/3978 (72%)]\tLoss: 0.095995\n",
            "Train Epoch: 4 [2876/3978 (72%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [2877/3978 (72%)]\tLoss: 0.000395\n",
            "Train Epoch: 4 [2878/3978 (72%)]\tLoss: 1.810728\n",
            "Train Epoch: 4 [2879/3978 (72%)]\tLoss: 0.000103\n",
            "Train Epoch: 4 [2880/3978 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2881/3978 (72%)]\tLoss: 1.602885\n",
            "Train Epoch: 4 [2882/3978 (72%)]\tLoss: 0.041305\n",
            "Train Epoch: 4 [2883/3978 (72%)]\tLoss: 2.808722\n",
            "Train Epoch: 4 [2884/3978 (72%)]\tLoss: 0.947560\n",
            "Train Epoch: 4 [2885/3978 (73%)]\tLoss: 0.400165\n",
            "Train Epoch: 4 [2886/3978 (73%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [2887/3978 (73%)]\tLoss: 0.614154\n",
            "Train Epoch: 4 [2888/3978 (73%)]\tLoss: 1.004180\n",
            "Train Epoch: 4 [2889/3978 (73%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [2890/3978 (73%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [2891/3978 (73%)]\tLoss: 0.655812\n",
            "Train Epoch: 4 [2892/3978 (73%)]\tLoss: 0.256014\n",
            "Train Epoch: 4 [2893/3978 (73%)]\tLoss: 0.371120\n",
            "Train Epoch: 4 [2894/3978 (73%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [2895/3978 (73%)]\tLoss: 0.572663\n",
            "Train Epoch: 4 [2896/3978 (73%)]\tLoss: 0.737717\n",
            "Train Epoch: 4 [2897/3978 (73%)]\tLoss: 0.066221\n",
            "Train Epoch: 4 [2898/3978 (73%)]\tLoss: 0.434399\n",
            "Train Epoch: 4 [2899/3978 (73%)]\tLoss: 0.944673\n",
            "Train Epoch: 4 [2900/3978 (73%)]\tLoss: 0.004356\n",
            "Train Epoch: 4 [2901/3978 (73%)]\tLoss: 0.327934\n",
            "Train Epoch: 4 [2902/3978 (73%)]\tLoss: 5.362653\n",
            "Train Epoch: 4 [2903/3978 (73%)]\tLoss: 1.720206\n",
            "Train Epoch: 4 [2904/3978 (73%)]\tLoss: 1.379515\n",
            "Train Epoch: 4 [2905/3978 (73%)]\tLoss: 0.014217\n",
            "Train Epoch: 4 [2906/3978 (73%)]\tLoss: 3.079014\n",
            "Train Epoch: 4 [2907/3978 (73%)]\tLoss: 0.858714\n",
            "Train Epoch: 4 [2908/3978 (73%)]\tLoss: 4.570788\n",
            "Train Epoch: 4 [2909/3978 (73%)]\tLoss: 0.092526\n",
            "Train Epoch: 4 [2910/3978 (73%)]\tLoss: 0.413365\n",
            "Train Epoch: 4 [2911/3978 (73%)]\tLoss: 0.599806\n",
            "Train Epoch: 4 [2912/3978 (73%)]\tLoss: 0.448067\n",
            "Train Epoch: 4 [2913/3978 (73%)]\tLoss: 0.029875\n",
            "Train Epoch: 4 [2914/3978 (73%)]\tLoss: 0.068269\n",
            "Train Epoch: 4 [2915/3978 (73%)]\tLoss: 3.651951\n",
            "Train Epoch: 4 [2916/3978 (73%)]\tLoss: 0.463775\n",
            "Train Epoch: 4 [2917/3978 (73%)]\tLoss: 0.476241\n",
            "Train Epoch: 4 [2918/3978 (73%)]\tLoss: 0.132235\n",
            "Train Epoch: 4 [2919/3978 (73%)]\tLoss: 1.499430\n",
            "Train Epoch: 4 [2920/3978 (73%)]\tLoss: 1.965526\n",
            "Train Epoch: 4 [2921/3978 (73%)]\tLoss: 0.051005\n",
            "Train Epoch: 4 [2922/3978 (73%)]\tLoss: 2.576125\n",
            "Train Epoch: 4 [2923/3978 (73%)]\tLoss: 0.092916\n",
            "Train Epoch: 4 [2924/3978 (74%)]\tLoss: 1.864925\n",
            "Train Epoch: 4 [2925/3978 (74%)]\tLoss: 0.873917\n",
            "Train Epoch: 4 [2926/3978 (74%)]\tLoss: 0.104688\n",
            "Train Epoch: 4 [2927/3978 (74%)]\tLoss: 0.929240\n",
            "Train Epoch: 4 [2928/3978 (74%)]\tLoss: 0.468054\n",
            "Train Epoch: 4 [2929/3978 (74%)]\tLoss: 2.632357\n",
            "Train Epoch: 4 [2930/3978 (74%)]\tLoss: 0.538799\n",
            "Train Epoch: 4 [2931/3978 (74%)]\tLoss: 0.002654\n",
            "Train Epoch: 4 [2932/3978 (74%)]\tLoss: 0.046459\n",
            "Train Epoch: 4 [2933/3978 (74%)]\tLoss: 0.068840\n",
            "Train Epoch: 4 [2934/3978 (74%)]\tLoss: 0.249638\n",
            "Train Epoch: 4 [2935/3978 (74%)]\tLoss: 2.917803\n",
            "Train Epoch: 4 [2936/3978 (74%)]\tLoss: 0.000052\n",
            "Train Epoch: 4 [2937/3978 (74%)]\tLoss: 7.683506\n",
            "Train Epoch: 4 [2938/3978 (74%)]\tLoss: 1.425874\n",
            "Train Epoch: 4 [2939/3978 (74%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2940/3978 (74%)]\tLoss: 0.359641\n",
            "Train Epoch: 4 [2941/3978 (74%)]\tLoss: 0.001839\n",
            "Train Epoch: 4 [2942/3978 (74%)]\tLoss: 0.000332\n",
            "Train Epoch: 4 [2943/3978 (74%)]\tLoss: 0.229975\n",
            "Train Epoch: 4 [2944/3978 (74%)]\tLoss: 0.178545\n",
            "Train Epoch: 4 [2945/3978 (74%)]\tLoss: 0.005303\n",
            "Train Epoch: 4 [2946/3978 (74%)]\tLoss: 1.280702\n",
            "Train Epoch: 4 [2947/3978 (74%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [2948/3978 (74%)]\tLoss: 0.008844\n",
            "Train Epoch: 4 [2949/3978 (74%)]\tLoss: 0.349198\n",
            "Train Epoch: 4 [2950/3978 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2951/3978 (74%)]\tLoss: 0.038653\n",
            "Train Epoch: 4 [2952/3978 (74%)]\tLoss: 0.014153\n",
            "Train Epoch: 4 [2953/3978 (74%)]\tLoss: 5.294901\n",
            "Train Epoch: 4 [2954/3978 (74%)]\tLoss: 0.001226\n",
            "Train Epoch: 4 [2955/3978 (74%)]\tLoss: 0.041527\n",
            "Train Epoch: 4 [2956/3978 (74%)]\tLoss: 0.005276\n",
            "Train Epoch: 4 [2957/3978 (74%)]\tLoss: 0.001014\n",
            "Train Epoch: 4 [2958/3978 (74%)]\tLoss: 0.011248\n",
            "Train Epoch: 4 [2959/3978 (74%)]\tLoss: 1.650198\n",
            "Train Epoch: 4 [2960/3978 (74%)]\tLoss: 0.088627\n",
            "Train Epoch: 4 [2961/3978 (74%)]\tLoss: 0.398324\n",
            "Train Epoch: 4 [2962/3978 (74%)]\tLoss: 0.009286\n",
            "Train Epoch: 4 [2963/3978 (74%)]\tLoss: 0.797958\n",
            "Train Epoch: 4 [2964/3978 (75%)]\tLoss: 1.377940\n",
            "Train Epoch: 4 [2965/3978 (75%)]\tLoss: 1.086102\n",
            "Train Epoch: 4 [2966/3978 (75%)]\tLoss: 0.000137\n",
            "Train Epoch: 4 [2967/3978 (75%)]\tLoss: 0.881538\n",
            "Train Epoch: 4 [2968/3978 (75%)]\tLoss: 0.109444\n",
            "Train Epoch: 4 [2969/3978 (75%)]\tLoss: 0.041823\n",
            "Train Epoch: 4 [2970/3978 (75%)]\tLoss: 0.001645\n",
            "Train Epoch: 4 [2971/3978 (75%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [2972/3978 (75%)]\tLoss: 1.199740\n",
            "Train Epoch: 4 [2973/3978 (75%)]\tLoss: 0.000255\n",
            "Train Epoch: 4 [2974/3978 (75%)]\tLoss: 0.001849\n",
            "Train Epoch: 4 [2975/3978 (75%)]\tLoss: 1.643217\n",
            "Train Epoch: 4 [2976/3978 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2977/3978 (75%)]\tLoss: 1.335442\n",
            "Train Epoch: 4 [2978/3978 (75%)]\tLoss: 0.119930\n",
            "Train Epoch: 4 [2979/3978 (75%)]\tLoss: 0.006777\n",
            "Train Epoch: 4 [2980/3978 (75%)]\tLoss: 0.638452\n",
            "Train Epoch: 4 [2981/3978 (75%)]\tLoss: 0.003901\n",
            "Train Epoch: 4 [2982/3978 (75%)]\tLoss: 1.939486\n",
            "Train Epoch: 4 [2983/3978 (75%)]\tLoss: 2.033156\n",
            "Train Epoch: 4 [2984/3978 (75%)]\tLoss: 1.443249\n",
            "Train Epoch: 4 [2985/3978 (75%)]\tLoss: 1.911987\n",
            "Train Epoch: 4 [2986/3978 (75%)]\tLoss: 0.055835\n",
            "Train Epoch: 4 [2987/3978 (75%)]\tLoss: 1.162786\n",
            "Train Epoch: 4 [2988/3978 (75%)]\tLoss: 1.040810\n",
            "Train Epoch: 4 [2989/3978 (75%)]\tLoss: 0.751446\n",
            "Train Epoch: 4 [2990/3978 (75%)]\tLoss: 1.348696\n",
            "Train Epoch: 4 [2991/3978 (75%)]\tLoss: 1.607141\n",
            "Train Epoch: 4 [2992/3978 (75%)]\tLoss: 1.176650\n",
            "Train Epoch: 4 [2993/3978 (75%)]\tLoss: 2.411321\n",
            "Train Epoch: 4 [2994/3978 (75%)]\tLoss: 0.847205\n",
            "Train Epoch: 4 [2995/3978 (75%)]\tLoss: 0.005398\n",
            "Train Epoch: 4 [2996/3978 (75%)]\tLoss: 0.098322\n",
            "Train Epoch: 4 [2997/3978 (75%)]\tLoss: 1.371262\n",
            "Train Epoch: 4 [2998/3978 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2999/3978 (75%)]\tLoss: 1.265167\n",
            "Train Epoch: 4 [3000/3978 (75%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [3001/3978 (75%)]\tLoss: 0.004041\n",
            "Train Epoch: 4 [3002/3978 (75%)]\tLoss: 0.939854\n",
            "Train Epoch: 4 [3003/3978 (75%)]\tLoss: 0.255425\n",
            "Train Epoch: 4 [3004/3978 (76%)]\tLoss: 0.034708\n",
            "Train Epoch: 4 [3005/3978 (76%)]\tLoss: 0.351774\n",
            "Train Epoch: 4 [3006/3978 (76%)]\tLoss: 2.069351\n",
            "Train Epoch: 4 [3007/3978 (76%)]\tLoss: 1.691847\n",
            "Train Epoch: 4 [3008/3978 (76%)]\tLoss: 0.003070\n",
            "Train Epoch: 4 [3009/3978 (76%)]\tLoss: 0.910376\n",
            "Train Epoch: 4 [3010/3978 (76%)]\tLoss: 0.006639\n",
            "Train Epoch: 4 [3011/3978 (76%)]\tLoss: 0.495497\n",
            "Train Epoch: 4 [3012/3978 (76%)]\tLoss: 1.414201\n",
            "Train Epoch: 4 [3013/3978 (76%)]\tLoss: 0.010417\n",
            "Train Epoch: 4 [3014/3978 (76%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3015/3978 (76%)]\tLoss: 2.515054\n",
            "Train Epoch: 4 [3016/3978 (76%)]\tLoss: 2.973924\n",
            "Train Epoch: 4 [3017/3978 (76%)]\tLoss: 2.777697\n",
            "Train Epoch: 4 [3018/3978 (76%)]\tLoss: 2.847155\n",
            "Train Epoch: 4 [3019/3978 (76%)]\tLoss: 0.001921\n",
            "Train Epoch: 4 [3020/3978 (76%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [3021/3978 (76%)]\tLoss: 0.567884\n",
            "Train Epoch: 4 [3022/3978 (76%)]\tLoss: 0.005455\n",
            "Train Epoch: 4 [3023/3978 (76%)]\tLoss: 0.440815\n",
            "Train Epoch: 4 [3024/3978 (76%)]\tLoss: 1.040336\n",
            "Train Epoch: 4 [3025/3978 (76%)]\tLoss: 4.850976\n",
            "Train Epoch: 4 [3026/3978 (76%)]\tLoss: 0.231173\n",
            "Train Epoch: 4 [3027/3978 (76%)]\tLoss: 2.431977\n",
            "Train Epoch: 4 [3028/3978 (76%)]\tLoss: 0.016570\n",
            "Train Epoch: 4 [3029/3978 (76%)]\tLoss: 0.532675\n",
            "Train Epoch: 4 [3030/3978 (76%)]\tLoss: 0.001236\n",
            "Train Epoch: 4 [3031/3978 (76%)]\tLoss: 0.094410\n",
            "Train Epoch: 4 [3032/3978 (76%)]\tLoss: 2.862387\n",
            "Train Epoch: 4 [3033/3978 (76%)]\tLoss: 3.464887\n",
            "Train Epoch: 4 [3034/3978 (76%)]\tLoss: 0.010808\n",
            "Train Epoch: 4 [3035/3978 (76%)]\tLoss: 0.425857\n",
            "Train Epoch: 4 [3036/3978 (76%)]\tLoss: 0.000331\n",
            "Train Epoch: 4 [3037/3978 (76%)]\tLoss: 0.878730\n",
            "Train Epoch: 4 [3038/3978 (76%)]\tLoss: 0.032063\n",
            "Train Epoch: 4 [3039/3978 (76%)]\tLoss: 0.689594\n",
            "Train Epoch: 4 [3040/3978 (76%)]\tLoss: 0.836722\n",
            "Train Epoch: 4 [3041/3978 (76%)]\tLoss: 0.276509\n",
            "Train Epoch: 4 [3042/3978 (76%)]\tLoss: 1.774631\n",
            "Train Epoch: 4 [3043/3978 (76%)]\tLoss: 1.553490\n",
            "Train Epoch: 4 [3044/3978 (77%)]\tLoss: 0.176844\n",
            "Train Epoch: 4 [3045/3978 (77%)]\tLoss: 0.400710\n",
            "Train Epoch: 4 [3046/3978 (77%)]\tLoss: 0.690752\n",
            "Train Epoch: 4 [3047/3978 (77%)]\tLoss: 0.526941\n",
            "Train Epoch: 4 [3048/3978 (77%)]\tLoss: 0.933329\n",
            "Train Epoch: 4 [3049/3978 (77%)]\tLoss: 4.887809\n",
            "Train Epoch: 4 [3050/3978 (77%)]\tLoss: 0.000191\n",
            "Train Epoch: 4 [3051/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3052/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3053/3978 (77%)]\tLoss: 1.203441\n",
            "Train Epoch: 4 [3054/3978 (77%)]\tLoss: 1.132544\n",
            "Train Epoch: 4 [3055/3978 (77%)]\tLoss: 0.427843\n",
            "Train Epoch: 4 [3056/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3057/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3058/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3059/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3060/3978 (77%)]\tLoss: 2.679741\n",
            "Train Epoch: 4 [3061/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3062/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3063/3978 (77%)]\tLoss: 5.219407\n",
            "Train Epoch: 4 [3064/3978 (77%)]\tLoss: 3.793024\n",
            "Train Epoch: 4 [3065/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3066/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3067/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3068/3978 (77%)]\tLoss: 3.252136\n",
            "Train Epoch: 4 [3069/3978 (77%)]\tLoss: 8.973203\n",
            "Train Epoch: 4 [3070/3978 (77%)]\tLoss: 0.201511\n",
            "Train Epoch: 4 [3071/3978 (77%)]\tLoss: 0.001753\n",
            "Train Epoch: 4 [3072/3978 (77%)]\tLoss: 2.176588\n",
            "Train Epoch: 4 [3073/3978 (77%)]\tLoss: 2.541828\n",
            "Train Epoch: 4 [3074/3978 (77%)]\tLoss: 4.769730\n",
            "Train Epoch: 4 [3075/3978 (77%)]\tLoss: 0.389647\n",
            "Train Epoch: 4 [3076/3978 (77%)]\tLoss: 0.378326\n",
            "Train Epoch: 4 [3077/3978 (77%)]\tLoss: 1.128893\n",
            "Train Epoch: 4 [3078/3978 (77%)]\tLoss: 0.297419\n",
            "Train Epoch: 4 [3079/3978 (77%)]\tLoss: 1.343850\n",
            "Train Epoch: 4 [3080/3978 (77%)]\tLoss: 1.819931\n",
            "Train Epoch: 4 [3081/3978 (77%)]\tLoss: 0.494992\n",
            "Train Epoch: 4 [3082/3978 (77%)]\tLoss: 0.019960\n",
            "Train Epoch: 4 [3083/3978 (78%)]\tLoss: 0.561176\n",
            "Train Epoch: 4 [3084/3978 (78%)]\tLoss: 0.305232\n",
            "Train Epoch: 4 [3085/3978 (78%)]\tLoss: 3.186266\n",
            "Train Epoch: 4 [3086/3978 (78%)]\tLoss: 0.003154\n",
            "Train Epoch: 4 [3087/3978 (78%)]\tLoss: 0.208468\n",
            "Train Epoch: 4 [3088/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3089/3978 (78%)]\tLoss: 0.000085\n",
            "Train Epoch: 4 [3090/3978 (78%)]\tLoss: 2.254912\n",
            "Train Epoch: 4 [3091/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3092/3978 (78%)]\tLoss: 1.108495\n",
            "Train Epoch: 4 [3093/3978 (78%)]\tLoss: 1.206943\n",
            "Train Epoch: 4 [3094/3978 (78%)]\tLoss: 0.002472\n",
            "Train Epoch: 4 [3095/3978 (78%)]\tLoss: 0.000178\n",
            "Train Epoch: 4 [3096/3978 (78%)]\tLoss: 0.008174\n",
            "Train Epoch: 4 [3097/3978 (78%)]\tLoss: 0.000072\n",
            "Train Epoch: 4 [3098/3978 (78%)]\tLoss: 0.942079\n",
            "Train Epoch: 4 [3099/3978 (78%)]\tLoss: 0.491265\n",
            "Train Epoch: 4 [3100/3978 (78%)]\tLoss: 0.428692\n",
            "Train Epoch: 4 [3101/3978 (78%)]\tLoss: 3.756682\n",
            "Train Epoch: 4 [3102/3978 (78%)]\tLoss: 0.956889\n",
            "Train Epoch: 4 [3103/3978 (78%)]\tLoss: 0.006132\n",
            "Train Epoch: 4 [3104/3978 (78%)]\tLoss: 3.184517\n",
            "Train Epoch: 4 [3105/3978 (78%)]\tLoss: 2.313284\n",
            "Train Epoch: 4 [3106/3978 (78%)]\tLoss: 0.505162\n",
            "Train Epoch: 4 [3107/3978 (78%)]\tLoss: 1.676226\n",
            "Train Epoch: 4 [3108/3978 (78%)]\tLoss: 0.003404\n",
            "Train Epoch: 4 [3109/3978 (78%)]\tLoss: 1.181314\n",
            "Train Epoch: 4 [3110/3978 (78%)]\tLoss: 0.573324\n",
            "Train Epoch: 4 [3111/3978 (78%)]\tLoss: 0.006360\n",
            "Train Epoch: 4 [3112/3978 (78%)]\tLoss: 0.007984\n",
            "Train Epoch: 4 [3113/3978 (78%)]\tLoss: 2.191011\n",
            "Train Epoch: 4 [3114/3978 (78%)]\tLoss: 1.510977\n",
            "Train Epoch: 4 [3115/3978 (78%)]\tLoss: 0.000083\n",
            "Train Epoch: 4 [3116/3978 (78%)]\tLoss: 0.563752\n",
            "Train Epoch: 4 [3117/3978 (78%)]\tLoss: 0.628088\n",
            "Train Epoch: 4 [3118/3978 (78%)]\tLoss: 1.333690\n",
            "Train Epoch: 4 [3119/3978 (78%)]\tLoss: 0.565212\n",
            "Train Epoch: 4 [3120/3978 (78%)]\tLoss: 0.486357\n",
            "Train Epoch: 4 [3121/3978 (78%)]\tLoss: 1.254444\n",
            "Train Epoch: 4 [3122/3978 (78%)]\tLoss: 2.548707\n",
            "Train Epoch: 4 [3123/3978 (79%)]\tLoss: 4.512054\n",
            "Train Epoch: 4 [3124/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3125/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3126/3978 (79%)]\tLoss: 1.209432\n",
            "Train Epoch: 4 [3127/3978 (79%)]\tLoss: 0.231200\n",
            "Train Epoch: 4 [3128/3978 (79%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [3129/3978 (79%)]\tLoss: 0.000075\n",
            "Train Epoch: 4 [3130/3978 (79%)]\tLoss: 1.644143\n",
            "Train Epoch: 4 [3131/3978 (79%)]\tLoss: 1.706398\n",
            "Train Epoch: 4 [3132/3978 (79%)]\tLoss: 1.270993\n",
            "Train Epoch: 4 [3133/3978 (79%)]\tLoss: 0.919673\n",
            "Train Epoch: 4 [3134/3978 (79%)]\tLoss: 0.051925\n",
            "Train Epoch: 4 [3135/3978 (79%)]\tLoss: 3.638524\n",
            "Train Epoch: 4 [3136/3978 (79%)]\tLoss: 0.000095\n",
            "Train Epoch: 4 [3137/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3138/3978 (79%)]\tLoss: 8.495818\n",
            "Train Epoch: 4 [3139/3978 (79%)]\tLoss: 1.295280\n",
            "Train Epoch: 4 [3140/3978 (79%)]\tLoss: 1.576917\n",
            "Train Epoch: 4 [3141/3978 (79%)]\tLoss: 1.106421\n",
            "Train Epoch: 4 [3142/3978 (79%)]\tLoss: 1.294033\n",
            "Train Epoch: 4 [3143/3978 (79%)]\tLoss: 1.456449\n",
            "Train Epoch: 4 [3144/3978 (79%)]\tLoss: 1.344463\n",
            "Train Epoch: 4 [3145/3978 (79%)]\tLoss: 1.132873\n",
            "Train Epoch: 4 [3146/3978 (79%)]\tLoss: 0.009639\n",
            "Train Epoch: 4 [3147/3978 (79%)]\tLoss: 0.450454\n",
            "Train Epoch: 4 [3148/3978 (79%)]\tLoss: 1.595456\n",
            "Train Epoch: 4 [3149/3978 (79%)]\tLoss: 2.492288\n",
            "Train Epoch: 4 [3150/3978 (79%)]\tLoss: 1.115973\n",
            "Train Epoch: 4 [3151/3978 (79%)]\tLoss: 0.539747\n",
            "Train Epoch: 4 [3152/3978 (79%)]\tLoss: 0.260688\n",
            "Train Epoch: 4 [3153/3978 (79%)]\tLoss: 2.041370\n",
            "Train Epoch: 4 [3154/3978 (79%)]\tLoss: 0.493236\n",
            "Train Epoch: 4 [3155/3978 (79%)]\tLoss: 0.065630\n",
            "Train Epoch: 4 [3156/3978 (79%)]\tLoss: 0.006715\n",
            "Train Epoch: 4 [3157/3978 (79%)]\tLoss: 0.000103\n",
            "Train Epoch: 4 [3158/3978 (79%)]\tLoss: 0.044156\n",
            "Train Epoch: 4 [3159/3978 (79%)]\tLoss: 0.209677\n",
            "Train Epoch: 4 [3160/3978 (79%)]\tLoss: 0.994298\n",
            "Train Epoch: 4 [3161/3978 (79%)]\tLoss: 0.019114\n",
            "Train Epoch: 4 [3162/3978 (79%)]\tLoss: 0.003607\n",
            "Train Epoch: 4 [3163/3978 (80%)]\tLoss: 0.714348\n",
            "Train Epoch: 4 [3164/3978 (80%)]\tLoss: 0.009039\n",
            "Train Epoch: 4 [3165/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3166/3978 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3167/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3168/3978 (80%)]\tLoss: 1.817523\n",
            "Train Epoch: 4 [3169/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3170/3978 (80%)]\tLoss: 1.496711\n",
            "Train Epoch: 4 [3171/3978 (80%)]\tLoss: 6.390017\n",
            "Train Epoch: 4 [3172/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3173/3978 (80%)]\tLoss: 0.252727\n",
            "Train Epoch: 4 [3174/3978 (80%)]\tLoss: 0.045333\n",
            "Train Epoch: 4 [3175/3978 (80%)]\tLoss: 0.000105\n",
            "Train Epoch: 4 [3176/3978 (80%)]\tLoss: 0.158079\n",
            "Train Epoch: 4 [3177/3978 (80%)]\tLoss: 0.000296\n",
            "Train Epoch: 4 [3178/3978 (80%)]\tLoss: 0.730140\n",
            "Train Epoch: 4 [3179/3978 (80%)]\tLoss: 3.809233\n",
            "Train Epoch: 4 [3180/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3181/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3182/3978 (80%)]\tLoss: 0.024679\n",
            "Train Epoch: 4 [3183/3978 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3184/3978 (80%)]\tLoss: 0.721892\n",
            "Train Epoch: 4 [3185/3978 (80%)]\tLoss: 5.274469\n",
            "Train Epoch: 4 [3186/3978 (80%)]\tLoss: 4.770109\n",
            "Train Epoch: 4 [3187/3978 (80%)]\tLoss: 1.411080\n",
            "Train Epoch: 4 [3188/3978 (80%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [3189/3978 (80%)]\tLoss: 1.067270\n",
            "Train Epoch: 4 [3190/3978 (80%)]\tLoss: 0.081517\n",
            "Train Epoch: 4 [3191/3978 (80%)]\tLoss: 1.350990\n",
            "Train Epoch: 4 [3192/3978 (80%)]\tLoss: 0.044664\n",
            "Train Epoch: 4 [3193/3978 (80%)]\tLoss: 0.161778\n",
            "Train Epoch: 4 [3194/3978 (80%)]\tLoss: 0.038179\n",
            "Train Epoch: 4 [3195/3978 (80%)]\tLoss: 3.149365\n",
            "Train Epoch: 4 [3196/3978 (80%)]\tLoss: 0.000152\n",
            "Train Epoch: 4 [3197/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3198/3978 (80%)]\tLoss: 2.528493\n",
            "Train Epoch: 4 [3199/3978 (80%)]\tLoss: 1.482285\n",
            "Train Epoch: 4 [3200/3978 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3201/3978 (80%)]\tLoss: 3.425808\n",
            "Train Epoch: 4 [3202/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3203/3978 (81%)]\tLoss: 4.766825\n",
            "Train Epoch: 4 [3204/3978 (81%)]\tLoss: 1.821815\n",
            "Train Epoch: 4 [3205/3978 (81%)]\tLoss: 0.487402\n",
            "Train Epoch: 4 [3206/3978 (81%)]\tLoss: 0.001380\n",
            "Train Epoch: 4 [3207/3978 (81%)]\tLoss: 1.664630\n",
            "Train Epoch: 4 [3208/3978 (81%)]\tLoss: 2.318595\n",
            "Train Epoch: 4 [3209/3978 (81%)]\tLoss: 1.985539\n",
            "Train Epoch: 4 [3210/3978 (81%)]\tLoss: 0.992660\n",
            "Train Epoch: 4 [3211/3978 (81%)]\tLoss: 0.474053\n",
            "Train Epoch: 4 [3212/3978 (81%)]\tLoss: 0.299931\n",
            "Train Epoch: 4 [3213/3978 (81%)]\tLoss: 0.419992\n",
            "Train Epoch: 4 [3214/3978 (81%)]\tLoss: 0.462033\n",
            "Train Epoch: 4 [3215/3978 (81%)]\tLoss: 3.495750\n",
            "Train Epoch: 4 [3216/3978 (81%)]\tLoss: 0.040151\n",
            "Train Epoch: 4 [3217/3978 (81%)]\tLoss: 0.310298\n",
            "Train Epoch: 4 [3218/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3219/3978 (81%)]\tLoss: 0.202066\n",
            "Train Epoch: 4 [3220/3978 (81%)]\tLoss: 0.434899\n",
            "Train Epoch: 4 [3221/3978 (81%)]\tLoss: 0.000051\n",
            "Train Epoch: 4 [3222/3978 (81%)]\tLoss: 1.796184\n",
            "Train Epoch: 4 [3223/3978 (81%)]\tLoss: 0.763672\n",
            "Train Epoch: 4 [3224/3978 (81%)]\tLoss: 5.920032\n",
            "Train Epoch: 4 [3225/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3226/3978 (81%)]\tLoss: 1.452627\n",
            "Train Epoch: 4 [3227/3978 (81%)]\tLoss: 0.056732\n",
            "Train Epoch: 4 [3228/3978 (81%)]\tLoss: 1.187259\n",
            "Train Epoch: 4 [3229/3978 (81%)]\tLoss: 1.217806\n",
            "Train Epoch: 4 [3230/3978 (81%)]\tLoss: 6.552796\n",
            "Train Epoch: 4 [3231/3978 (81%)]\tLoss: 1.622552\n",
            "Train Epoch: 4 [3232/3978 (81%)]\tLoss: 1.868918\n",
            "Train Epoch: 4 [3233/3978 (81%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3234/3978 (81%)]\tLoss: 0.217142\n",
            "Train Epoch: 4 [3235/3978 (81%)]\tLoss: 1.178829\n",
            "Train Epoch: 4 [3236/3978 (81%)]\tLoss: 0.833487\n",
            "Train Epoch: 4 [3237/3978 (81%)]\tLoss: 2.906562\n",
            "Train Epoch: 4 [3238/3978 (81%)]\tLoss: 0.331159\n",
            "Train Epoch: 4 [3239/3978 (81%)]\tLoss: 1.236435\n",
            "Train Epoch: 4 [3240/3978 (81%)]\tLoss: 0.526570\n",
            "Train Epoch: 4 [3241/3978 (81%)]\tLoss: 0.031447\n",
            "Train Epoch: 4 [3242/3978 (81%)]\tLoss: 0.467944\n",
            "Train Epoch: 4 [3243/3978 (82%)]\tLoss: 0.009795\n",
            "Train Epoch: 4 [3244/3978 (82%)]\tLoss: 1.017072\n",
            "Train Epoch: 4 [3245/3978 (82%)]\tLoss: 0.459592\n",
            "Train Epoch: 4 [3246/3978 (82%)]\tLoss: 0.000039\n",
            "Train Epoch: 4 [3247/3978 (82%)]\tLoss: 0.008454\n",
            "Train Epoch: 4 [3248/3978 (82%)]\tLoss: 0.065572\n",
            "Train Epoch: 4 [3249/3978 (82%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [3250/3978 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3251/3978 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3252/3978 (82%)]\tLoss: 9.640914\n",
            "Train Epoch: 4 [3253/3978 (82%)]\tLoss: 7.133399\n",
            "Train Epoch: 4 [3254/3978 (82%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [3255/3978 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3256/3978 (82%)]\tLoss: 1.001889\n",
            "Train Epoch: 4 [3257/3978 (82%)]\tLoss: 6.289812\n",
            "Train Epoch: 4 [3258/3978 (82%)]\tLoss: 0.004581\n",
            "Train Epoch: 4 [3259/3978 (82%)]\tLoss: 1.597286\n",
            "Train Epoch: 4 [3260/3978 (82%)]\tLoss: 2.067877\n",
            "Train Epoch: 4 [3261/3978 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3262/3978 (82%)]\tLoss: 0.513158\n",
            "Train Epoch: 4 [3263/3978 (82%)]\tLoss: 4.336480\n",
            "Train Epoch: 4 [3264/3978 (82%)]\tLoss: 0.044209\n",
            "Train Epoch: 4 [3265/3978 (82%)]\tLoss: 1.934962\n",
            "Train Epoch: 4 [3266/3978 (82%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [3267/3978 (82%)]\tLoss: 0.000371\n",
            "Train Epoch: 4 [3268/3978 (82%)]\tLoss: 0.012737\n",
            "Train Epoch: 4 [3269/3978 (82%)]\tLoss: 1.949945\n",
            "Train Epoch: 4 [3270/3978 (82%)]\tLoss: 0.000255\n",
            "Train Epoch: 4 [3271/3978 (82%)]\tLoss: 1.044529\n",
            "Train Epoch: 4 [3272/3978 (82%)]\tLoss: 3.635608\n",
            "Train Epoch: 4 [3273/3978 (82%)]\tLoss: 1.188808\n",
            "Train Epoch: 4 [3274/3978 (82%)]\tLoss: 0.000715\n",
            "Train Epoch: 4 [3275/3978 (82%)]\tLoss: 0.044090\n",
            "Train Epoch: 4 [3276/3978 (82%)]\tLoss: 0.436622\n",
            "Train Epoch: 4 [3277/3978 (82%)]\tLoss: 0.012606\n",
            "Train Epoch: 4 [3278/3978 (82%)]\tLoss: 0.005436\n",
            "Train Epoch: 4 [3279/3978 (82%)]\tLoss: 3.634724\n",
            "Train Epoch: 4 [3280/3978 (82%)]\tLoss: 1.887758\n",
            "Train Epoch: 4 [3281/3978 (82%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [3282/3978 (83%)]\tLoss: 2.601117\n",
            "Train Epoch: 4 [3283/3978 (83%)]\tLoss: 1.208488\n",
            "Train Epoch: 4 [3284/3978 (83%)]\tLoss: 0.002705\n",
            "Train Epoch: 4 [3285/3978 (83%)]\tLoss: 1.116796\n",
            "Train Epoch: 4 [3286/3978 (83%)]\tLoss: 0.980962\n",
            "Train Epoch: 4 [3287/3978 (83%)]\tLoss: 4.501904\n",
            "Train Epoch: 4 [3288/3978 (83%)]\tLoss: 0.482149\n",
            "Train Epoch: 4 [3289/3978 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3290/3978 (83%)]\tLoss: 4.112287\n",
            "Train Epoch: 4 [3291/3978 (83%)]\tLoss: 1.481659\n",
            "Train Epoch: 4 [3292/3978 (83%)]\tLoss: 0.667800\n",
            "Train Epoch: 4 [3293/3978 (83%)]\tLoss: 0.008682\n",
            "Train Epoch: 4 [3294/3978 (83%)]\tLoss: 0.480313\n",
            "Train Epoch: 4 [3295/3978 (83%)]\tLoss: 0.156305\n",
            "Train Epoch: 4 [3296/3978 (83%)]\tLoss: 0.672788\n",
            "Train Epoch: 4 [3297/3978 (83%)]\tLoss: 0.005774\n",
            "Train Epoch: 4 [3298/3978 (83%)]\tLoss: 0.153434\n",
            "Train Epoch: 4 [3299/3978 (83%)]\tLoss: 0.001497\n",
            "Train Epoch: 4 [3300/3978 (83%)]\tLoss: 0.437470\n",
            "Train Epoch: 4 [3301/3978 (83%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [3302/3978 (83%)]\tLoss: 1.755386\n",
            "Train Epoch: 4 [3303/3978 (83%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [3304/3978 (83%)]\tLoss: 0.006695\n",
            "Train Epoch: 4 [3305/3978 (83%)]\tLoss: 1.458575\n",
            "Train Epoch: 4 [3306/3978 (83%)]\tLoss: 1.418613\n",
            "Train Epoch: 4 [3307/3978 (83%)]\tLoss: 0.587645\n",
            "Train Epoch: 4 [3308/3978 (83%)]\tLoss: 0.472332\n",
            "Train Epoch: 4 [3309/3978 (83%)]\tLoss: 0.740364\n",
            "Train Epoch: 4 [3310/3978 (83%)]\tLoss: 0.810335\n",
            "Train Epoch: 4 [3311/3978 (83%)]\tLoss: 1.748158\n",
            "Train Epoch: 4 [3312/3978 (83%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3313/3978 (83%)]\tLoss: 0.993461\n",
            "Train Epoch: 4 [3314/3978 (83%)]\tLoss: 0.131437\n",
            "Train Epoch: 4 [3315/3978 (83%)]\tLoss: 0.399552\n",
            "Train Epoch: 4 [3316/3978 (83%)]\tLoss: 0.000100\n",
            "Train Epoch: 4 [3317/3978 (83%)]\tLoss: 0.129918\n",
            "Train Epoch: 4 [3318/3978 (83%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3319/3978 (83%)]\tLoss: 0.000204\n",
            "Train Epoch: 4 [3320/3978 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3321/3978 (83%)]\tLoss: 2.343482\n",
            "Train Epoch: 4 [3322/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3323/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3324/3978 (84%)]\tLoss: 3.780331\n",
            "Train Epoch: 4 [3325/3978 (84%)]\tLoss: 5.498360\n",
            "Train Epoch: 4 [3326/3978 (84%)]\tLoss: 1.845155\n",
            "Train Epoch: 4 [3327/3978 (84%)]\tLoss: 0.000222\n",
            "Train Epoch: 4 [3328/3978 (84%)]\tLoss: 0.552245\n",
            "Train Epoch: 4 [3329/3978 (84%)]\tLoss: 4.034787\n",
            "Train Epoch: 4 [3330/3978 (84%)]\tLoss: 3.870666\n",
            "Train Epoch: 4 [3331/3978 (84%)]\tLoss: 1.825334\n",
            "Train Epoch: 4 [3332/3978 (84%)]\tLoss: 2.223975\n",
            "Train Epoch: 4 [3333/3978 (84%)]\tLoss: 1.845147\n",
            "Train Epoch: 4 [3334/3978 (84%)]\tLoss: 1.687845\n",
            "Train Epoch: 4 [3335/3978 (84%)]\tLoss: 1.766856\n",
            "Train Epoch: 4 [3336/3978 (84%)]\tLoss: 0.952935\n",
            "Train Epoch: 4 [3337/3978 (84%)]\tLoss: 0.820114\n",
            "Train Epoch: 4 [3338/3978 (84%)]\tLoss: 0.423918\n",
            "Train Epoch: 4 [3339/3978 (84%)]\tLoss: 1.584487\n",
            "Train Epoch: 4 [3340/3978 (84%)]\tLoss: 0.783227\n",
            "Train Epoch: 4 [3341/3978 (84%)]\tLoss: 0.011305\n",
            "Train Epoch: 4 [3342/3978 (84%)]\tLoss: 0.437977\n",
            "Train Epoch: 4 [3343/3978 (84%)]\tLoss: 2.206589\n",
            "Train Epoch: 4 [3344/3978 (84%)]\tLoss: 2.774502\n",
            "Train Epoch: 4 [3345/3978 (84%)]\tLoss: 1.606661\n",
            "Train Epoch: 4 [3346/3978 (84%)]\tLoss: 1.041221\n",
            "Train Epoch: 4 [3347/3978 (84%)]\tLoss: 0.060732\n",
            "Train Epoch: 4 [3348/3978 (84%)]\tLoss: 1.520363\n",
            "Train Epoch: 4 [3349/3978 (84%)]\tLoss: 0.155880\n",
            "Train Epoch: 4 [3350/3978 (84%)]\tLoss: 1.252797\n",
            "Train Epoch: 4 [3351/3978 (84%)]\tLoss: 2.604711\n",
            "Train Epoch: 4 [3352/3978 (84%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3353/3978 (84%)]\tLoss: 2.107803\n",
            "Train Epoch: 4 [3354/3978 (84%)]\tLoss: 1.433258\n",
            "Train Epoch: 4 [3355/3978 (84%)]\tLoss: 0.000762\n",
            "Train Epoch: 4 [3356/3978 (84%)]\tLoss: 0.000060\n",
            "Train Epoch: 4 [3357/3978 (84%)]\tLoss: 0.003658\n",
            "Train Epoch: 4 [3358/3978 (84%)]\tLoss: 2.411980\n",
            "Train Epoch: 4 [3359/3978 (84%)]\tLoss: 1.345182\n",
            "Train Epoch: 4 [3360/3978 (84%)]\tLoss: 0.097398\n",
            "Train Epoch: 4 [3361/3978 (84%)]\tLoss: 1.328068\n",
            "Train Epoch: 4 [3362/3978 (85%)]\tLoss: 2.754648\n",
            "Train Epoch: 4 [3363/3978 (85%)]\tLoss: 0.210417\n",
            "Train Epoch: 4 [3364/3978 (85%)]\tLoss: 1.422934\n",
            "Train Epoch: 4 [3365/3978 (85%)]\tLoss: 0.360706\n",
            "Train Epoch: 4 [3366/3978 (85%)]\tLoss: 2.368304\n",
            "Train Epoch: 4 [3367/3978 (85%)]\tLoss: 1.805745\n",
            "Train Epoch: 4 [3368/3978 (85%)]\tLoss: 1.211269\n",
            "Train Epoch: 4 [3369/3978 (85%)]\tLoss: 0.005264\n",
            "Train Epoch: 4 [3370/3978 (85%)]\tLoss: 0.000080\n",
            "Train Epoch: 4 [3371/3978 (85%)]\tLoss: 0.018451\n",
            "Train Epoch: 4 [3372/3978 (85%)]\tLoss: 0.146930\n",
            "Train Epoch: 4 [3373/3978 (85%)]\tLoss: 1.107339\n",
            "Train Epoch: 4 [3374/3978 (85%)]\tLoss: 0.383229\n",
            "Train Epoch: 4 [3375/3978 (85%)]\tLoss: 0.404819\n",
            "Train Epoch: 4 [3376/3978 (85%)]\tLoss: 0.136432\n",
            "Train Epoch: 4 [3377/3978 (85%)]\tLoss: 0.012348\n",
            "Train Epoch: 4 [3378/3978 (85%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [3379/3978 (85%)]\tLoss: 0.000120\n",
            "Train Epoch: 4 [3380/3978 (85%)]\tLoss: 1.699353\n",
            "Train Epoch: 4 [3381/3978 (85%)]\tLoss: 1.016715\n",
            "Train Epoch: 4 [3382/3978 (85%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3383/3978 (85%)]\tLoss: 0.017345\n",
            "Train Epoch: 4 [3384/3978 (85%)]\tLoss: 4.242164\n",
            "Train Epoch: 4 [3385/3978 (85%)]\tLoss: 0.555415\n",
            "Train Epoch: 4 [3386/3978 (85%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [3387/3978 (85%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3388/3978 (85%)]\tLoss: 0.183746\n",
            "Train Epoch: 4 [3389/3978 (85%)]\tLoss: 0.005164\n",
            "Train Epoch: 4 [3390/3978 (85%)]\tLoss: 0.000280\n",
            "Train Epoch: 4 [3391/3978 (85%)]\tLoss: 1.384427\n",
            "Train Epoch: 4 [3392/3978 (85%)]\tLoss: 0.211085\n",
            "Train Epoch: 4 [3393/3978 (85%)]\tLoss: 0.031886\n",
            "Train Epoch: 4 [3394/3978 (85%)]\tLoss: 4.023523\n",
            "Train Epoch: 4 [3395/3978 (85%)]\tLoss: 0.296730\n",
            "Train Epoch: 4 [3396/3978 (85%)]\tLoss: 0.008337\n",
            "Train Epoch: 4 [3397/3978 (85%)]\tLoss: 0.069145\n",
            "Train Epoch: 4 [3398/3978 (85%)]\tLoss: 0.013709\n",
            "Train Epoch: 4 [3399/3978 (85%)]\tLoss: 0.174103\n",
            "Train Epoch: 4 [3400/3978 (85%)]\tLoss: 6.160063\n",
            "Train Epoch: 4 [3401/3978 (85%)]\tLoss: 0.094314\n",
            "Train Epoch: 4 [3402/3978 (86%)]\tLoss: 0.781582\n",
            "Train Epoch: 4 [3403/3978 (86%)]\tLoss: 4.267585\n",
            "Train Epoch: 4 [3404/3978 (86%)]\tLoss: 2.300792\n",
            "Train Epoch: 4 [3405/3978 (86%)]\tLoss: 0.288631\n",
            "Train Epoch: 4 [3406/3978 (86%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [3407/3978 (86%)]\tLoss: 0.730825\n",
            "Train Epoch: 4 [3408/3978 (86%)]\tLoss: 3.018317\n",
            "Train Epoch: 4 [3409/3978 (86%)]\tLoss: 0.266794\n",
            "Train Epoch: 4 [3410/3978 (86%)]\tLoss: 0.588783\n",
            "Train Epoch: 4 [3411/3978 (86%)]\tLoss: 0.696171\n",
            "Train Epoch: 4 [3412/3978 (86%)]\tLoss: 0.091855\n",
            "Train Epoch: 4 [3413/3978 (86%)]\tLoss: 0.138252\n",
            "Train Epoch: 4 [3414/3978 (86%)]\tLoss: 0.303720\n",
            "Train Epoch: 4 [3415/3978 (86%)]\tLoss: 0.008847\n",
            "Train Epoch: 4 [3416/3978 (86%)]\tLoss: 2.805529\n",
            "Train Epoch: 4 [3417/3978 (86%)]\tLoss: 3.869476\n",
            "Train Epoch: 4 [3418/3978 (86%)]\tLoss: 0.000267\n",
            "Train Epoch: 4 [3419/3978 (86%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [3420/3978 (86%)]\tLoss: 0.000129\n",
            "Train Epoch: 4 [3421/3978 (86%)]\tLoss: 3.268996\n",
            "Train Epoch: 4 [3422/3978 (86%)]\tLoss: 2.316739\n",
            "Train Epoch: 4 [3423/3978 (86%)]\tLoss: 0.551872\n",
            "Train Epoch: 4 [3424/3978 (86%)]\tLoss: 1.867727\n",
            "Train Epoch: 4 [3425/3978 (86%)]\tLoss: 0.366853\n",
            "Train Epoch: 4 [3426/3978 (86%)]\tLoss: 0.004335\n",
            "Train Epoch: 4 [3427/3978 (86%)]\tLoss: 0.035248\n",
            "Train Epoch: 4 [3428/3978 (86%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [3429/3978 (86%)]\tLoss: 0.862159\n",
            "Train Epoch: 4 [3430/3978 (86%)]\tLoss: 0.000142\n",
            "Train Epoch: 4 [3431/3978 (86%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3432/3978 (86%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [3433/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3434/3978 (86%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3435/3978 (86%)]\tLoss: 1.662461\n",
            "Train Epoch: 4 [3436/3978 (86%)]\tLoss: 2.446727\n",
            "Train Epoch: 4 [3437/3978 (86%)]\tLoss: 0.465375\n",
            "Train Epoch: 4 [3438/3978 (86%)]\tLoss: 0.298961\n",
            "Train Epoch: 4 [3439/3978 (86%)]\tLoss: 1.069044\n",
            "Train Epoch: 4 [3440/3978 (86%)]\tLoss: 1.225657\n",
            "Train Epoch: 4 [3441/3978 (87%)]\tLoss: 1.216684\n",
            "Train Epoch: 4 [3442/3978 (87%)]\tLoss: 0.919783\n",
            "Train Epoch: 4 [3443/3978 (87%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [3444/3978 (87%)]\tLoss: 1.123093\n",
            "Train Epoch: 4 [3445/3978 (87%)]\tLoss: 0.700094\n",
            "Train Epoch: 4 [3446/3978 (87%)]\tLoss: 0.110388\n",
            "Train Epoch: 4 [3447/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3448/3978 (87%)]\tLoss: 2.873677\n",
            "Train Epoch: 4 [3449/3978 (87%)]\tLoss: 2.085238\n",
            "Train Epoch: 4 [3450/3978 (87%)]\tLoss: 0.127702\n",
            "Train Epoch: 4 [3451/3978 (87%)]\tLoss: 1.573946\n",
            "Train Epoch: 4 [3452/3978 (87%)]\tLoss: 0.002500\n",
            "Train Epoch: 4 [3453/3978 (87%)]\tLoss: 3.169229\n",
            "Train Epoch: 4 [3454/3978 (87%)]\tLoss: 0.706663\n",
            "Train Epoch: 4 [3455/3978 (87%)]\tLoss: 2.631562\n",
            "Train Epoch: 4 [3456/3978 (87%)]\tLoss: 0.030259\n",
            "Train Epoch: 4 [3457/3978 (87%)]\tLoss: 1.267620\n",
            "Train Epoch: 4 [3458/3978 (87%)]\tLoss: 2.155567\n",
            "Train Epoch: 4 [3459/3978 (87%)]\tLoss: 1.400559\n",
            "Train Epoch: 4 [3460/3978 (87%)]\tLoss: 1.219813\n",
            "Train Epoch: 4 [3461/3978 (87%)]\tLoss: 0.471213\n",
            "Train Epoch: 4 [3462/3978 (87%)]\tLoss: 0.004926\n",
            "Train Epoch: 4 [3463/3978 (87%)]\tLoss: 0.000104\n",
            "Train Epoch: 4 [3464/3978 (87%)]\tLoss: 1.007813\n",
            "Train Epoch: 4 [3465/3978 (87%)]\tLoss: 0.965608\n",
            "Train Epoch: 4 [3466/3978 (87%)]\tLoss: 1.143192\n",
            "Train Epoch: 4 [3467/3978 (87%)]\tLoss: 0.000596\n",
            "Train Epoch: 4 [3468/3978 (87%)]\tLoss: 0.520792\n",
            "Train Epoch: 4 [3469/3978 (87%)]\tLoss: 0.191630\n",
            "Train Epoch: 4 [3470/3978 (87%)]\tLoss: 0.077658\n",
            "Train Epoch: 4 [3471/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3472/3978 (87%)]\tLoss: 0.000151\n",
            "Train Epoch: 4 [3473/3978 (87%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [3474/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3475/3978 (87%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [3476/3978 (87%)]\tLoss: 5.216004\n",
            "Train Epoch: 4 [3477/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3478/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3479/3978 (87%)]\tLoss: 4.206047\n",
            "Train Epoch: 4 [3480/3978 (87%)]\tLoss: 8.770885\n",
            "Train Epoch: 4 [3481/3978 (88%)]\tLoss: 4.496686\n",
            "Train Epoch: 4 [3482/3978 (88%)]\tLoss: 0.069075\n",
            "Train Epoch: 4 [3483/3978 (88%)]\tLoss: 0.003502\n",
            "Train Epoch: 4 [3484/3978 (88%)]\tLoss: 1.902070\n",
            "Train Epoch: 4 [3485/3978 (88%)]\tLoss: 0.210291\n",
            "Train Epoch: 4 [3486/3978 (88%)]\tLoss: 2.752862\n",
            "Train Epoch: 4 [3487/3978 (88%)]\tLoss: 5.805881\n",
            "Train Epoch: 4 [3488/3978 (88%)]\tLoss: 0.740782\n",
            "Train Epoch: 4 [3489/3978 (88%)]\tLoss: 1.467966\n",
            "Train Epoch: 4 [3490/3978 (88%)]\tLoss: 0.002297\n",
            "Train Epoch: 4 [3491/3978 (88%)]\tLoss: 0.410832\n",
            "Train Epoch: 4 [3492/3978 (88%)]\tLoss: 1.220365\n",
            "Train Epoch: 4 [3493/3978 (88%)]\tLoss: 0.093342\n",
            "Train Epoch: 4 [3494/3978 (88%)]\tLoss: 1.171899\n",
            "Train Epoch: 4 [3495/3978 (88%)]\tLoss: 0.961232\n",
            "Train Epoch: 4 [3496/3978 (88%)]\tLoss: 1.941601\n",
            "Train Epoch: 4 [3497/3978 (88%)]\tLoss: 1.412491\n",
            "Train Epoch: 4 [3498/3978 (88%)]\tLoss: 0.239458\n",
            "Train Epoch: 4 [3499/3978 (88%)]\tLoss: 0.751047\n",
            "Train Epoch: 4 [3500/3978 (88%)]\tLoss: 1.492948\n",
            "Train Epoch: 4 [3501/3978 (88%)]\tLoss: 0.001579\n",
            "Train Epoch: 4 [3502/3978 (88%)]\tLoss: 0.506638\n",
            "Train Epoch: 4 [3503/3978 (88%)]\tLoss: 0.010377\n",
            "Train Epoch: 4 [3504/3978 (88%)]\tLoss: 2.932796\n",
            "Train Epoch: 4 [3505/3978 (88%)]\tLoss: 0.011627\n",
            "Train Epoch: 4 [3506/3978 (88%)]\tLoss: 0.850709\n",
            "Train Epoch: 4 [3507/3978 (88%)]\tLoss: 0.059602\n",
            "Train Epoch: 4 [3508/3978 (88%)]\tLoss: 0.461953\n",
            "Train Epoch: 4 [3509/3978 (88%)]\tLoss: 0.002317\n",
            "Train Epoch: 4 [3510/3978 (88%)]\tLoss: 0.787545\n",
            "Train Epoch: 4 [3511/3978 (88%)]\tLoss: 1.246802\n",
            "Train Epoch: 4 [3512/3978 (88%)]\tLoss: 1.958602\n",
            "Train Epoch: 4 [3513/3978 (88%)]\tLoss: 0.184723\n",
            "Train Epoch: 4 [3514/3978 (88%)]\tLoss: 0.010163\n",
            "Train Epoch: 4 [3515/3978 (88%)]\tLoss: 1.851347\n",
            "Train Epoch: 4 [3516/3978 (88%)]\tLoss: 0.000604\n",
            "Train Epoch: 4 [3517/3978 (88%)]\tLoss: 0.885996\n",
            "Train Epoch: 4 [3518/3978 (88%)]\tLoss: 1.412701\n",
            "Train Epoch: 4 [3519/3978 (88%)]\tLoss: 0.435482\n",
            "Train Epoch: 4 [3520/3978 (88%)]\tLoss: 2.062856\n",
            "Train Epoch: 4 [3521/3978 (89%)]\tLoss: 3.117322\n",
            "Train Epoch: 4 [3522/3978 (89%)]\tLoss: 2.270843\n",
            "Train Epoch: 4 [3523/3978 (89%)]\tLoss: 0.003688\n",
            "Train Epoch: 4 [3524/3978 (89%)]\tLoss: 0.350014\n",
            "Train Epoch: 4 [3525/3978 (89%)]\tLoss: 0.488052\n",
            "Train Epoch: 4 [3526/3978 (89%)]\tLoss: 0.118570\n",
            "Train Epoch: 4 [3527/3978 (89%)]\tLoss: 0.068436\n",
            "Train Epoch: 4 [3528/3978 (89%)]\tLoss: 0.793017\n",
            "Train Epoch: 4 [3529/3978 (89%)]\tLoss: 0.000170\n",
            "Train Epoch: 4 [3530/3978 (89%)]\tLoss: 0.009855\n",
            "Train Epoch: 4 [3531/3978 (89%)]\tLoss: 0.021147\n",
            "Train Epoch: 4 [3532/3978 (89%)]\tLoss: 0.795964\n",
            "Train Epoch: 4 [3533/3978 (89%)]\tLoss: 0.541881\n",
            "Train Epoch: 4 [3534/3978 (89%)]\tLoss: 2.066304\n",
            "Train Epoch: 4 [3535/3978 (89%)]\tLoss: 0.631887\n",
            "Train Epoch: 4 [3536/3978 (89%)]\tLoss: 0.490258\n",
            "Train Epoch: 4 [3537/3978 (89%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3538/3978 (89%)]\tLoss: 2.635286\n",
            "Train Epoch: 4 [3539/3978 (89%)]\tLoss: 1.919694\n",
            "Train Epoch: 4 [3540/3978 (89%)]\tLoss: 0.837316\n",
            "Train Epoch: 4 [3541/3978 (89%)]\tLoss: 0.163340\n",
            "Train Epoch: 4 [3542/3978 (89%)]\tLoss: 0.095299\n",
            "Train Epoch: 4 [3543/3978 (89%)]\tLoss: 1.180044\n",
            "Train Epoch: 4 [3544/3978 (89%)]\tLoss: 1.129834\n",
            "Train Epoch: 4 [3545/3978 (89%)]\tLoss: 0.016292\n",
            "Train Epoch: 4 [3546/3978 (89%)]\tLoss: 0.001828\n",
            "Train Epoch: 4 [3547/3978 (89%)]\tLoss: 0.914563\n",
            "Train Epoch: 4 [3548/3978 (89%)]\tLoss: 0.490655\n",
            "Train Epoch: 4 [3549/3978 (89%)]\tLoss: 0.384870\n",
            "Train Epoch: 4 [3550/3978 (89%)]\tLoss: 0.001707\n",
            "Train Epoch: 4 [3551/3978 (89%)]\tLoss: 0.218603\n",
            "Train Epoch: 4 [3552/3978 (89%)]\tLoss: 1.977155\n",
            "Train Epoch: 4 [3553/3978 (89%)]\tLoss: 0.006669\n",
            "Train Epoch: 4 [3554/3978 (89%)]\tLoss: 4.733290\n",
            "Train Epoch: 4 [3555/3978 (89%)]\tLoss: 4.001426\n",
            "Train Epoch: 4 [3556/3978 (89%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [3557/3978 (89%)]\tLoss: 0.054235\n",
            "Train Epoch: 4 [3558/3978 (89%)]\tLoss: 2.553859\n",
            "Train Epoch: 4 [3559/3978 (89%)]\tLoss: 0.894403\n",
            "Train Epoch: 4 [3560/3978 (89%)]\tLoss: 0.283347\n",
            "Train Epoch: 4 [3561/3978 (90%)]\tLoss: 1.065552\n",
            "Train Epoch: 4 [3562/3978 (90%)]\tLoss: 4.071129\n",
            "Train Epoch: 4 [3563/3978 (90%)]\tLoss: 1.344181\n",
            "Train Epoch: 4 [3564/3978 (90%)]\tLoss: 1.563766\n",
            "Train Epoch: 4 [3565/3978 (90%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [3566/3978 (90%)]\tLoss: 0.000786\n",
            "Train Epoch: 4 [3567/3978 (90%)]\tLoss: 1.093593\n",
            "Train Epoch: 4 [3568/3978 (90%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3569/3978 (90%)]\tLoss: 0.260065\n",
            "Train Epoch: 4 [3570/3978 (90%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [3571/3978 (90%)]\tLoss: 3.067028\n",
            "Train Epoch: 4 [3572/3978 (90%)]\tLoss: 1.717270\n",
            "Train Epoch: 4 [3573/3978 (90%)]\tLoss: 1.394936\n",
            "Train Epoch: 4 [3574/3978 (90%)]\tLoss: 0.009790\n",
            "Train Epoch: 4 [3575/3978 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3576/3978 (90%)]\tLoss: 0.001004\n",
            "Train Epoch: 4 [3577/3978 (90%)]\tLoss: 1.505280\n",
            "Train Epoch: 4 [3578/3978 (90%)]\tLoss: 1.102244\n",
            "Train Epoch: 4 [3579/3978 (90%)]\tLoss: 0.335475\n",
            "Train Epoch: 4 [3580/3978 (90%)]\tLoss: 0.002036\n",
            "Train Epoch: 4 [3581/3978 (90%)]\tLoss: 0.004161\n",
            "Train Epoch: 4 [3582/3978 (90%)]\tLoss: 0.000162\n",
            "Train Epoch: 4 [3583/3978 (90%)]\tLoss: 0.000051\n",
            "Train Epoch: 4 [3584/3978 (90%)]\tLoss: 2.603674\n",
            "Train Epoch: 4 [3585/3978 (90%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [3586/3978 (90%)]\tLoss: 0.829778\n",
            "Train Epoch: 4 [3587/3978 (90%)]\tLoss: 0.186268\n",
            "Train Epoch: 4 [3588/3978 (90%)]\tLoss: 0.055373\n",
            "Train Epoch: 4 [3589/3978 (90%)]\tLoss: 0.124434\n",
            "Train Epoch: 4 [3590/3978 (90%)]\tLoss: 3.807531\n",
            "Train Epoch: 4 [3591/3978 (90%)]\tLoss: 0.703585\n",
            "Train Epoch: 4 [3592/3978 (90%)]\tLoss: 0.004174\n",
            "Train Epoch: 4 [3593/3978 (90%)]\tLoss: 0.010942\n",
            "Train Epoch: 4 [3594/3978 (90%)]\tLoss: 1.879965\n",
            "Train Epoch: 4 [3595/3978 (90%)]\tLoss: 1.222385\n",
            "Train Epoch: 4 [3596/3978 (90%)]\tLoss: 1.790773\n",
            "Train Epoch: 4 [3597/3978 (90%)]\tLoss: 0.002449\n",
            "Train Epoch: 4 [3598/3978 (90%)]\tLoss: 0.057718\n",
            "Train Epoch: 4 [3599/3978 (90%)]\tLoss: 1.339513\n",
            "Train Epoch: 4 [3600/3978 (90%)]\tLoss: 0.081903\n",
            "Train Epoch: 4 [3601/3978 (91%)]\tLoss: 0.301878\n",
            "Train Epoch: 4 [3602/3978 (91%)]\tLoss: 0.386346\n",
            "Train Epoch: 4 [3603/3978 (91%)]\tLoss: 0.372489\n",
            "Train Epoch: 4 [3604/3978 (91%)]\tLoss: 0.000452\n",
            "Train Epoch: 4 [3605/3978 (91%)]\tLoss: 1.399961\n",
            "Train Epoch: 4 [3606/3978 (91%)]\tLoss: 1.959204\n",
            "Train Epoch: 4 [3607/3978 (91%)]\tLoss: 1.714043\n",
            "Train Epoch: 4 [3608/3978 (91%)]\tLoss: 0.115041\n",
            "Train Epoch: 4 [3609/3978 (91%)]\tLoss: 0.931119\n",
            "Train Epoch: 4 [3610/3978 (91%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [3611/3978 (91%)]\tLoss: 1.357809\n",
            "Train Epoch: 4 [3612/3978 (91%)]\tLoss: 1.560682\n",
            "Train Epoch: 4 [3613/3978 (91%)]\tLoss: 1.661147\n",
            "Train Epoch: 4 [3614/3978 (91%)]\tLoss: 3.494667\n",
            "Train Epoch: 4 [3615/3978 (91%)]\tLoss: 1.267864\n",
            "Train Epoch: 4 [3616/3978 (91%)]\tLoss: 0.008217\n",
            "Train Epoch: 4 [3617/3978 (91%)]\tLoss: 1.298493\n",
            "Train Epoch: 4 [3618/3978 (91%)]\tLoss: 1.194257\n",
            "Train Epoch: 4 [3619/3978 (91%)]\tLoss: 3.326984\n",
            "Train Epoch: 4 [3620/3978 (91%)]\tLoss: 0.176616\n",
            "Train Epoch: 4 [3621/3978 (91%)]\tLoss: 2.374520\n",
            "Train Epoch: 4 [3622/3978 (91%)]\tLoss: 1.723326\n",
            "Train Epoch: 4 [3623/3978 (91%)]\tLoss: 0.088326\n",
            "Train Epoch: 4 [3624/3978 (91%)]\tLoss: 5.840219\n",
            "Train Epoch: 4 [3625/3978 (91%)]\tLoss: 1.415169\n",
            "Train Epoch: 4 [3626/3978 (91%)]\tLoss: 0.893860\n",
            "Train Epoch: 4 [3627/3978 (91%)]\tLoss: 3.808597\n",
            "Train Epoch: 4 [3628/3978 (91%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3629/3978 (91%)]\tLoss: 2.581389\n",
            "Train Epoch: 4 [3630/3978 (91%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3631/3978 (91%)]\tLoss: 3.072785\n",
            "Train Epoch: 4 [3632/3978 (91%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3633/3978 (91%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [3634/3978 (91%)]\tLoss: 0.001097\n",
            "Train Epoch: 4 [3635/3978 (91%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [3636/3978 (91%)]\tLoss: 0.000283\n",
            "Train Epoch: 4 [3637/3978 (91%)]\tLoss: 0.000145\n",
            "Train Epoch: 4 [3638/3978 (91%)]\tLoss: 2.853518\n",
            "Train Epoch: 4 [3639/3978 (91%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [3640/3978 (92%)]\tLoss: 0.179672\n",
            "Train Epoch: 4 [3641/3978 (92%)]\tLoss: 1.828938\n",
            "Train Epoch: 4 [3642/3978 (92%)]\tLoss: 2.021938\n",
            "Train Epoch: 4 [3643/3978 (92%)]\tLoss: 1.108120\n",
            "Train Epoch: 4 [3644/3978 (92%)]\tLoss: 1.254633\n",
            "Train Epoch: 4 [3645/3978 (92%)]\tLoss: 1.262166\n",
            "Train Epoch: 4 [3646/3978 (92%)]\tLoss: 1.375285\n",
            "Train Epoch: 4 [3647/3978 (92%)]\tLoss: 0.781314\n",
            "Train Epoch: 4 [3648/3978 (92%)]\tLoss: 0.006661\n",
            "Train Epoch: 4 [3649/3978 (92%)]\tLoss: 0.641235\n",
            "Train Epoch: 4 [3650/3978 (92%)]\tLoss: 0.328977\n",
            "Train Epoch: 4 [3651/3978 (92%)]\tLoss: 0.052675\n",
            "Train Epoch: 4 [3652/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3653/3978 (92%)]\tLoss: 1.901394\n",
            "Train Epoch: 4 [3654/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3655/3978 (92%)]\tLoss: 1.248398\n",
            "Train Epoch: 4 [3656/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3657/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3658/3978 (92%)]\tLoss: 3.668961\n",
            "Train Epoch: 4 [3659/3978 (92%)]\tLoss: 0.003034\n",
            "Train Epoch: 4 [3660/3978 (92%)]\tLoss: 0.003714\n",
            "Train Epoch: 4 [3661/3978 (92%)]\tLoss: 0.011697\n",
            "Train Epoch: 4 [3662/3978 (92%)]\tLoss: 0.019602\n",
            "Train Epoch: 4 [3663/3978 (92%)]\tLoss: 3.597470\n",
            "Train Epoch: 4 [3664/3978 (92%)]\tLoss: 0.000152\n",
            "Train Epoch: 4 [3665/3978 (92%)]\tLoss: 0.000365\n",
            "Train Epoch: 4 [3666/3978 (92%)]\tLoss: 0.665027\n",
            "Train Epoch: 4 [3667/3978 (92%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3668/3978 (92%)]\tLoss: 3.639374\n",
            "Train Epoch: 4 [3669/3978 (92%)]\tLoss: 2.706898\n",
            "Train Epoch: 4 [3670/3978 (92%)]\tLoss: 0.313574\n",
            "Train Epoch: 4 [3671/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3672/3978 (92%)]\tLoss: 0.017154\n",
            "Train Epoch: 4 [3673/3978 (92%)]\tLoss: 2.239112\n",
            "Train Epoch: 4 [3674/3978 (92%)]\tLoss: 1.036191\n",
            "Train Epoch: 4 [3675/3978 (92%)]\tLoss: 1.629677\n",
            "Train Epoch: 4 [3676/3978 (92%)]\tLoss: 0.714573\n",
            "Train Epoch: 4 [3677/3978 (92%)]\tLoss: 0.491025\n",
            "Train Epoch: 4 [3678/3978 (92%)]\tLoss: 3.174445\n",
            "Train Epoch: 4 [3679/3978 (92%)]\tLoss: 1.254186\n",
            "Train Epoch: 4 [3680/3978 (93%)]\tLoss: 1.739960\n",
            "Train Epoch: 4 [3681/3978 (93%)]\tLoss: 1.261361\n",
            "Train Epoch: 4 [3682/3978 (93%)]\tLoss: 0.838153\n",
            "Train Epoch: 4 [3683/3978 (93%)]\tLoss: 1.154062\n",
            "Train Epoch: 4 [3684/3978 (93%)]\tLoss: 0.690704\n",
            "Train Epoch: 4 [3685/3978 (93%)]\tLoss: 0.264723\n",
            "Train Epoch: 4 [3686/3978 (93%)]\tLoss: 1.286637\n",
            "Train Epoch: 4 [3687/3978 (93%)]\tLoss: 1.675448\n",
            "Train Epoch: 4 [3688/3978 (93%)]\tLoss: 0.968199\n",
            "Train Epoch: 4 [3689/3978 (93%)]\tLoss: 0.487623\n",
            "Train Epoch: 4 [3690/3978 (93%)]\tLoss: 1.141252\n",
            "Train Epoch: 4 [3691/3978 (93%)]\tLoss: 0.873408\n",
            "Train Epoch: 4 [3692/3978 (93%)]\tLoss: 0.013213\n",
            "Train Epoch: 4 [3693/3978 (93%)]\tLoss: 1.084452\n",
            "Train Epoch: 4 [3694/3978 (93%)]\tLoss: 0.221209\n",
            "Train Epoch: 4 [3695/3978 (93%)]\tLoss: 0.802414\n",
            "Train Epoch: 4 [3696/3978 (93%)]\tLoss: 3.378724\n",
            "Train Epoch: 4 [3697/3978 (93%)]\tLoss: 0.117610\n",
            "Train Epoch: 4 [3698/3978 (93%)]\tLoss: 0.125001\n",
            "Train Epoch: 4 [3699/3978 (93%)]\tLoss: 0.009988\n",
            "Train Epoch: 4 [3700/3978 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3701/3978 (93%)]\tLoss: 1.842498\n",
            "Train Epoch: 4 [3702/3978 (93%)]\tLoss: 1.144384\n",
            "Train Epoch: 4 [3703/3978 (93%)]\tLoss: 0.688225\n",
            "Train Epoch: 4 [3704/3978 (93%)]\tLoss: 5.406017\n",
            "Train Epoch: 4 [3705/3978 (93%)]\tLoss: 1.794109\n",
            "Train Epoch: 4 [3706/3978 (93%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [3707/3978 (93%)]\tLoss: 0.547271\n",
            "Train Epoch: 4 [3708/3978 (93%)]\tLoss: 1.058292\n",
            "Train Epoch: 4 [3709/3978 (93%)]\tLoss: 0.927179\n",
            "Train Epoch: 4 [3710/3978 (93%)]\tLoss: 0.001360\n",
            "Train Epoch: 4 [3711/3978 (93%)]\tLoss: 1.034622\n",
            "Train Epoch: 4 [3712/3978 (93%)]\tLoss: 3.442439\n",
            "Train Epoch: 4 [3713/3978 (93%)]\tLoss: 3.065411\n",
            "Train Epoch: 4 [3714/3978 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3715/3978 (93%)]\tLoss: 0.580353\n",
            "Train Epoch: 4 [3716/3978 (93%)]\tLoss: 1.249544\n",
            "Train Epoch: 4 [3717/3978 (93%)]\tLoss: 5.534966\n",
            "Train Epoch: 4 [3718/3978 (93%)]\tLoss: 0.339827\n",
            "Train Epoch: 4 [3719/3978 (93%)]\tLoss: 0.005107\n",
            "Train Epoch: 4 [3720/3978 (94%)]\tLoss: 1.538201\n",
            "Train Epoch: 4 [3721/3978 (94%)]\tLoss: 0.808888\n",
            "Train Epoch: 4 [3722/3978 (94%)]\tLoss: 0.966777\n",
            "Train Epoch: 4 [3723/3978 (94%)]\tLoss: 0.681854\n",
            "Train Epoch: 4 [3724/3978 (94%)]\tLoss: 0.000753\n",
            "Train Epoch: 4 [3725/3978 (94%)]\tLoss: 0.144544\n",
            "Train Epoch: 4 [3726/3978 (94%)]\tLoss: 0.388773\n",
            "Train Epoch: 4 [3727/3978 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3728/3978 (94%)]\tLoss: 2.046293\n",
            "Train Epoch: 4 [3729/3978 (94%)]\tLoss: 0.913155\n",
            "Train Epoch: 4 [3730/3978 (94%)]\tLoss: 0.000067\n",
            "Train Epoch: 4 [3731/3978 (94%)]\tLoss: 1.540733\n",
            "Train Epoch: 4 [3732/3978 (94%)]\tLoss: 1.352442\n",
            "Train Epoch: 4 [3733/3978 (94%)]\tLoss: 1.149321\n",
            "Train Epoch: 4 [3734/3978 (94%)]\tLoss: 0.676483\n",
            "Train Epoch: 4 [3735/3978 (94%)]\tLoss: 5.866040\n",
            "Train Epoch: 4 [3736/3978 (94%)]\tLoss: 0.000069\n",
            "Train Epoch: 4 [3737/3978 (94%)]\tLoss: 0.182229\n",
            "Train Epoch: 4 [3738/3978 (94%)]\tLoss: 0.028004\n",
            "Train Epoch: 4 [3739/3978 (94%)]\tLoss: 0.177571\n",
            "Train Epoch: 4 [3740/3978 (94%)]\tLoss: 3.433623\n",
            "Train Epoch: 4 [3741/3978 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3742/3978 (94%)]\tLoss: 0.454998\n",
            "Train Epoch: 4 [3743/3978 (94%)]\tLoss: 1.560466\n",
            "Train Epoch: 4 [3744/3978 (94%)]\tLoss: 0.509265\n",
            "Train Epoch: 4 [3745/3978 (94%)]\tLoss: 0.654868\n",
            "Train Epoch: 4 [3746/3978 (94%)]\tLoss: 6.957277\n",
            "Train Epoch: 4 [3747/3978 (94%)]\tLoss: 1.080195\n",
            "Train Epoch: 4 [3748/3978 (94%)]\tLoss: 2.845380\n",
            "Train Epoch: 4 [3749/3978 (94%)]\tLoss: 1.146243\n",
            "Train Epoch: 4 [3750/3978 (94%)]\tLoss: 1.512527\n",
            "Train Epoch: 4 [3751/3978 (94%)]\tLoss: 0.001034\n",
            "Train Epoch: 4 [3752/3978 (94%)]\tLoss: 1.318591\n",
            "Train Epoch: 4 [3753/3978 (94%)]\tLoss: 0.326661\n",
            "Train Epoch: 4 [3754/3978 (94%)]\tLoss: 0.342474\n",
            "Train Epoch: 4 [3755/3978 (94%)]\tLoss: 0.000258\n",
            "Train Epoch: 4 [3756/3978 (94%)]\tLoss: 0.040020\n",
            "Train Epoch: 4 [3757/3978 (94%)]\tLoss: 6.042207\n",
            "Train Epoch: 4 [3758/3978 (94%)]\tLoss: 1.528994\n",
            "Train Epoch: 4 [3759/3978 (94%)]\tLoss: 1.428346\n",
            "Train Epoch: 4 [3760/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3761/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3762/3978 (95%)]\tLoss: 1.101078\n",
            "Train Epoch: 4 [3763/3978 (95%)]\tLoss: 0.029056\n",
            "Train Epoch: 4 [3764/3978 (95%)]\tLoss: 5.878092\n",
            "Train Epoch: 4 [3765/3978 (95%)]\tLoss: 0.000019\n",
            "Train Epoch: 4 [3766/3978 (95%)]\tLoss: 0.003840\n",
            "Train Epoch: 4 [3767/3978 (95%)]\tLoss: 0.023988\n",
            "Train Epoch: 4 [3768/3978 (95%)]\tLoss: 3.039455\n",
            "Train Epoch: 4 [3769/3978 (95%)]\tLoss: 0.003548\n",
            "Train Epoch: 4 [3770/3978 (95%)]\tLoss: 1.844414\n",
            "Train Epoch: 4 [3771/3978 (95%)]\tLoss: 1.292583\n",
            "Train Epoch: 4 [3772/3978 (95%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3773/3978 (95%)]\tLoss: 1.114311\n",
            "Train Epoch: 4 [3774/3978 (95%)]\tLoss: 0.849833\n",
            "Train Epoch: 4 [3775/3978 (95%)]\tLoss: 0.256210\n",
            "Train Epoch: 4 [3776/3978 (95%)]\tLoss: 0.142165\n",
            "Train Epoch: 4 [3777/3978 (95%)]\tLoss: 0.019985\n",
            "Train Epoch: 4 [3778/3978 (95%)]\tLoss: 0.033231\n",
            "Train Epoch: 4 [3779/3978 (95%)]\tLoss: 2.297668\n",
            "Train Epoch: 4 [3780/3978 (95%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [3781/3978 (95%)]\tLoss: 1.082354\n",
            "Train Epoch: 4 [3782/3978 (95%)]\tLoss: 4.650416\n",
            "Train Epoch: 4 [3783/3978 (95%)]\tLoss: 1.709500\n",
            "Train Epoch: 4 [3784/3978 (95%)]\tLoss: 0.026323\n",
            "Train Epoch: 4 [3785/3978 (95%)]\tLoss: 0.864054\n",
            "Train Epoch: 4 [3786/3978 (95%)]\tLoss: 0.286306\n",
            "Train Epoch: 4 [3787/3978 (95%)]\tLoss: 0.760717\n",
            "Train Epoch: 4 [3788/3978 (95%)]\tLoss: 1.127232\n",
            "Train Epoch: 4 [3789/3978 (95%)]\tLoss: 0.127285\n",
            "Train Epoch: 4 [3790/3978 (95%)]\tLoss: 1.091148\n",
            "Train Epoch: 4 [3791/3978 (95%)]\tLoss: 0.005539\n",
            "Train Epoch: 4 [3792/3978 (95%)]\tLoss: 1.609504\n",
            "Train Epoch: 4 [3793/3978 (95%)]\tLoss: 0.588414\n",
            "Train Epoch: 4 [3794/3978 (95%)]\tLoss: 1.267613\n",
            "Train Epoch: 4 [3795/3978 (95%)]\tLoss: 1.499530\n",
            "Train Epoch: 4 [3796/3978 (95%)]\tLoss: 0.882746\n",
            "Train Epoch: 4 [3797/3978 (95%)]\tLoss: 2.131995\n",
            "Train Epoch: 4 [3798/3978 (95%)]\tLoss: 1.018051\n",
            "Train Epoch: 4 [3799/3978 (96%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [3800/3978 (96%)]\tLoss: 1.836658\n",
            "Train Epoch: 4 [3801/3978 (96%)]\tLoss: 0.302084\n",
            "Train Epoch: 4 [3802/3978 (96%)]\tLoss: 0.512697\n",
            "Train Epoch: 4 [3803/3978 (96%)]\tLoss: 2.514674\n",
            "Train Epoch: 4 [3804/3978 (96%)]\tLoss: 3.321867\n",
            "Train Epoch: 4 [3805/3978 (96%)]\tLoss: 0.039639\n",
            "Train Epoch: 4 [3806/3978 (96%)]\tLoss: 1.209527\n",
            "Train Epoch: 4 [3807/3978 (96%)]\tLoss: 2.623242\n",
            "Train Epoch: 4 [3808/3978 (96%)]\tLoss: 4.600595\n",
            "Train Epoch: 4 [3809/3978 (96%)]\tLoss: 0.390834\n",
            "Train Epoch: 4 [3810/3978 (96%)]\tLoss: 0.614340\n",
            "Train Epoch: 4 [3811/3978 (96%)]\tLoss: 0.212692\n",
            "Train Epoch: 4 [3812/3978 (96%)]\tLoss: 0.000147\n",
            "Train Epoch: 4 [3813/3978 (96%)]\tLoss: 0.208922\n",
            "Train Epoch: 4 [3814/3978 (96%)]\tLoss: 0.002975\n",
            "Train Epoch: 4 [3815/3978 (96%)]\tLoss: 0.050753\n",
            "Train Epoch: 4 [3816/3978 (96%)]\tLoss: 0.673899\n",
            "Train Epoch: 4 [3817/3978 (96%)]\tLoss: 0.381168\n",
            "Train Epoch: 4 [3818/3978 (96%)]\tLoss: 0.033078\n",
            "Train Epoch: 4 [3819/3978 (96%)]\tLoss: 3.799630\n",
            "Train Epoch: 4 [3820/3978 (96%)]\tLoss: 0.032589\n",
            "Train Epoch: 4 [3821/3978 (96%)]\tLoss: 2.411549\n",
            "Train Epoch: 4 [3822/3978 (96%)]\tLoss: 0.000158\n",
            "Train Epoch: 4 [3823/3978 (96%)]\tLoss: 0.000183\n",
            "Train Epoch: 4 [3824/3978 (96%)]\tLoss: 1.600238\n",
            "Train Epoch: 4 [3825/3978 (96%)]\tLoss: 0.486559\n",
            "Train Epoch: 4 [3826/3978 (96%)]\tLoss: 1.273610\n",
            "Train Epoch: 4 [3827/3978 (96%)]\tLoss: 0.976292\n",
            "Train Epoch: 4 [3828/3978 (96%)]\tLoss: 0.811969\n",
            "Train Epoch: 4 [3829/3978 (96%)]\tLoss: 3.487776\n",
            "Train Epoch: 4 [3830/3978 (96%)]\tLoss: 0.269410\n",
            "Train Epoch: 4 [3831/3978 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3832/3978 (96%)]\tLoss: 0.145253\n",
            "Train Epoch: 4 [3833/3978 (96%)]\tLoss: 1.256900\n",
            "Train Epoch: 4 [3834/3978 (96%)]\tLoss: 0.591310\n",
            "Train Epoch: 4 [3835/3978 (96%)]\tLoss: 0.312250\n",
            "Train Epoch: 4 [3836/3978 (96%)]\tLoss: 0.976376\n",
            "Train Epoch: 4 [3837/3978 (96%)]\tLoss: 1.348017\n",
            "Train Epoch: 4 [3838/3978 (96%)]\tLoss: 2.311687\n",
            "Train Epoch: 4 [3839/3978 (97%)]\tLoss: 3.604289\n",
            "Train Epoch: 4 [3840/3978 (97%)]\tLoss: 1.064609\n",
            "Train Epoch: 4 [3841/3978 (97%)]\tLoss: 0.224423\n",
            "Train Epoch: 4 [3842/3978 (97%)]\tLoss: 0.002164\n",
            "Train Epoch: 4 [3843/3978 (97%)]\tLoss: 3.257122\n",
            "Train Epoch: 4 [3844/3978 (97%)]\tLoss: 0.112798\n",
            "Train Epoch: 4 [3845/3978 (97%)]\tLoss: 0.000071\n",
            "Train Epoch: 4 [3846/3978 (97%)]\tLoss: 0.020059\n",
            "Train Epoch: 4 [3847/3978 (97%)]\tLoss: 0.000158\n",
            "Train Epoch: 4 [3848/3978 (97%)]\tLoss: 2.516522\n",
            "Train Epoch: 4 [3849/3978 (97%)]\tLoss: 0.860151\n",
            "Train Epoch: 4 [3850/3978 (97%)]\tLoss: 1.314666\n",
            "Train Epoch: 4 [3851/3978 (97%)]\tLoss: 0.745856\n",
            "Train Epoch: 4 [3852/3978 (97%)]\tLoss: 7.160614\n",
            "Train Epoch: 4 [3853/3978 (97%)]\tLoss: 0.021679\n",
            "Train Epoch: 4 [3854/3978 (97%)]\tLoss: 0.000041\n",
            "Train Epoch: 4 [3855/3978 (97%)]\tLoss: 3.234818\n",
            "Train Epoch: 4 [3856/3978 (97%)]\tLoss: 2.723603\n",
            "Train Epoch: 4 [3857/3978 (97%)]\tLoss: 7.327923\n",
            "Train Epoch: 4 [3858/3978 (97%)]\tLoss: 2.146671\n",
            "Train Epoch: 4 [3859/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3860/3978 (97%)]\tLoss: 2.617001\n",
            "Train Epoch: 4 [3861/3978 (97%)]\tLoss: 1.769403\n",
            "Train Epoch: 4 [3862/3978 (97%)]\tLoss: 0.120928\n",
            "Train Epoch: 4 [3863/3978 (97%)]\tLoss: 0.530826\n",
            "Train Epoch: 4 [3864/3978 (97%)]\tLoss: 0.112156\n",
            "Train Epoch: 4 [3865/3978 (97%)]\tLoss: 0.002936\n",
            "Train Epoch: 4 [3866/3978 (97%)]\tLoss: 1.015854\n",
            "Train Epoch: 4 [3867/3978 (97%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [3868/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3869/3978 (97%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [3870/3978 (97%)]\tLoss: 4.205918\n",
            "Train Epoch: 4 [3871/3978 (97%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [3872/3978 (97%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [3873/3978 (97%)]\tLoss: 0.000314\n",
            "Train Epoch: 4 [3874/3978 (97%)]\tLoss: 5.025018\n",
            "Train Epoch: 4 [3875/3978 (97%)]\tLoss: 4.938807\n",
            "Train Epoch: 4 [3876/3978 (97%)]\tLoss: 0.517701\n",
            "Train Epoch: 4 [3877/3978 (97%)]\tLoss: 0.003245\n",
            "Train Epoch: 4 [3878/3978 (97%)]\tLoss: 0.007211\n",
            "Train Epoch: 4 [3879/3978 (98%)]\tLoss: 2.986904\n",
            "Train Epoch: 4 [3880/3978 (98%)]\tLoss: 3.523638\n",
            "Train Epoch: 4 [3881/3978 (98%)]\tLoss: 2.103344\n",
            "Train Epoch: 4 [3882/3978 (98%)]\tLoss: 0.801920\n",
            "Train Epoch: 4 [3883/3978 (98%)]\tLoss: 0.401714\n",
            "Train Epoch: 4 [3884/3978 (98%)]\tLoss: 0.772457\n",
            "Train Epoch: 4 [3885/3978 (98%)]\tLoss: 0.005323\n",
            "Train Epoch: 4 [3886/3978 (98%)]\tLoss: 0.475751\n",
            "Train Epoch: 4 [3887/3978 (98%)]\tLoss: 2.728168\n",
            "Train Epoch: 4 [3888/3978 (98%)]\tLoss: 0.003813\n",
            "Train Epoch: 4 [3889/3978 (98%)]\tLoss: 0.710139\n",
            "Train Epoch: 4 [3890/3978 (98%)]\tLoss: 0.002815\n",
            "Train Epoch: 4 [3891/3978 (98%)]\tLoss: 0.038325\n",
            "Train Epoch: 4 [3892/3978 (98%)]\tLoss: 1.080931\n",
            "Train Epoch: 4 [3893/3978 (98%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3894/3978 (98%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [3895/3978 (98%)]\tLoss: 1.473464\n",
            "Train Epoch: 4 [3896/3978 (98%)]\tLoss: 1.195838\n",
            "Train Epoch: 4 [3897/3978 (98%)]\tLoss: 0.051301\n",
            "Train Epoch: 4 [3898/3978 (98%)]\tLoss: 0.304182\n",
            "Train Epoch: 4 [3899/3978 (98%)]\tLoss: 0.049376\n",
            "Train Epoch: 4 [3900/3978 (98%)]\tLoss: 0.005058\n",
            "Train Epoch: 4 [3901/3978 (98%)]\tLoss: 0.189434\n",
            "Train Epoch: 4 [3902/3978 (98%)]\tLoss: 1.531259\n",
            "Train Epoch: 4 [3903/3978 (98%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [3904/3978 (98%)]\tLoss: 0.413595\n",
            "Train Epoch: 4 [3905/3978 (98%)]\tLoss: 0.000106\n",
            "Train Epoch: 4 [3906/3978 (98%)]\tLoss: 0.700085\n",
            "Train Epoch: 4 [3907/3978 (98%)]\tLoss: 0.049412\n",
            "Train Epoch: 4 [3908/3978 (98%)]\tLoss: 7.311072\n",
            "Train Epoch: 4 [3909/3978 (98%)]\tLoss: 0.000158\n",
            "Train Epoch: 4 [3910/3978 (98%)]\tLoss: 1.356601\n",
            "Train Epoch: 4 [3911/3978 (98%)]\tLoss: 6.146060\n",
            "Train Epoch: 4 [3912/3978 (98%)]\tLoss: 1.338564\n",
            "Train Epoch: 4 [3913/3978 (98%)]\tLoss: 5.146322\n",
            "Train Epoch: 4 [3914/3978 (98%)]\tLoss: 0.024510\n",
            "Train Epoch: 4 [3915/3978 (98%)]\tLoss: 0.000880\n",
            "Train Epoch: 4 [3916/3978 (98%)]\tLoss: 2.006409\n",
            "Train Epoch: 4 [3917/3978 (98%)]\tLoss: 1.814081\n",
            "Train Epoch: 4 [3918/3978 (98%)]\tLoss: 2.168103\n",
            "Train Epoch: 4 [3919/3978 (99%)]\tLoss: 1.567639\n",
            "Train Epoch: 4 [3920/3978 (99%)]\tLoss: 0.038205\n",
            "Train Epoch: 4 [3921/3978 (99%)]\tLoss: 8.006025\n",
            "Train Epoch: 4 [3922/3978 (99%)]\tLoss: 0.371801\n",
            "Train Epoch: 4 [3923/3978 (99%)]\tLoss: 0.047774\n",
            "Train Epoch: 4 [3924/3978 (99%)]\tLoss: 0.467554\n",
            "Train Epoch: 4 [3925/3978 (99%)]\tLoss: 0.001478\n",
            "Train Epoch: 4 [3926/3978 (99%)]\tLoss: 5.034208\n",
            "Train Epoch: 4 [3927/3978 (99%)]\tLoss: 7.008108\n",
            "Train Epoch: 4 [3928/3978 (99%)]\tLoss: 0.000216\n",
            "Train Epoch: 4 [3929/3978 (99%)]\tLoss: 0.076588\n",
            "Train Epoch: 4 [3930/3978 (99%)]\tLoss: 5.725986\n",
            "Train Epoch: 4 [3931/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3932/3978 (99%)]\tLoss: 0.158922\n",
            "Train Epoch: 4 [3933/3978 (99%)]\tLoss: 0.393664\n",
            "Train Epoch: 4 [3934/3978 (99%)]\tLoss: 0.364534\n",
            "Train Epoch: 4 [3935/3978 (99%)]\tLoss: 0.006979\n",
            "Train Epoch: 4 [3936/3978 (99%)]\tLoss: 2.078659\n",
            "Train Epoch: 4 [3937/3978 (99%)]\tLoss: 0.518101\n",
            "Train Epoch: 4 [3938/3978 (99%)]\tLoss: 1.341229\n",
            "Train Epoch: 4 [3939/3978 (99%)]\tLoss: 0.665817\n",
            "Train Epoch: 4 [3940/3978 (99%)]\tLoss: 0.479616\n",
            "Train Epoch: 4 [3941/3978 (99%)]\tLoss: 1.378100\n",
            "Train Epoch: 4 [3942/3978 (99%)]\tLoss: 1.519234\n",
            "Train Epoch: 4 [3943/3978 (99%)]\tLoss: 2.113199\n",
            "Train Epoch: 4 [3944/3978 (99%)]\tLoss: 0.052694\n",
            "Train Epoch: 4 [3945/3978 (99%)]\tLoss: 2.550459\n",
            "Train Epoch: 4 [3946/3978 (99%)]\tLoss: 0.233778\n",
            "Train Epoch: 4 [3947/3978 (99%)]\tLoss: 0.754632\n",
            "Train Epoch: 4 [3948/3978 (99%)]\tLoss: 0.116734\n",
            "Train Epoch: 4 [3949/3978 (99%)]\tLoss: 2.433781\n",
            "Train Epoch: 4 [3950/3978 (99%)]\tLoss: 0.194307\n",
            "Train Epoch: 4 [3951/3978 (99%)]\tLoss: 0.000461\n",
            "Train Epoch: 4 [3952/3978 (99%)]\tLoss: 0.028404\n",
            "Train Epoch: 4 [3953/3978 (99%)]\tLoss: 0.005746\n",
            "Train Epoch: 4 [3954/3978 (99%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [3955/3978 (99%)]\tLoss: 1.065552\n",
            "Train Epoch: 4 [3956/3978 (99%)]\tLoss: 0.060754\n",
            "Train Epoch: 4 [3957/3978 (99%)]\tLoss: 1.298056\n",
            "Train Epoch: 4 [3958/3978 (99%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [3959/3978 (100%)]\tLoss: 4.676147\n",
            "Train Epoch: 4 [3960/3978 (100%)]\tLoss: 2.607384\n",
            "Train Epoch: 4 [3961/3978 (100%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3962/3978 (100%)]\tLoss: 1.570793\n",
            "Train Epoch: 4 [3963/3978 (100%)]\tLoss: 2.295841\n",
            "Train Epoch: 4 [3964/3978 (100%)]\tLoss: 0.568497\n",
            "Train Epoch: 4 [3965/3978 (100%)]\tLoss: 0.457283\n",
            "Train Epoch: 4 [3966/3978 (100%)]\tLoss: 1.494237\n",
            "Train Epoch: 4 [3967/3978 (100%)]\tLoss: 0.001390\n",
            "Train Epoch: 4 [3968/3978 (100%)]\tLoss: 2.091583\n",
            "Train Epoch: 4 [3969/3978 (100%)]\tLoss: 0.000036\n",
            "Train Epoch: 4 [3970/3978 (100%)]\tLoss: 0.232772\n",
            "Train Epoch: 4 [3971/3978 (100%)]\tLoss: 2.132958\n",
            "Train Epoch: 4 [3972/3978 (100%)]\tLoss: 2.371170\n",
            "Train Epoch: 4 [3973/3978 (100%)]\tLoss: 1.371194\n",
            "Train Epoch: 4 [3974/3978 (100%)]\tLoss: 1.232555\n",
            "Train Epoch: 4 [3975/3978 (100%)]\tLoss: 1.424149\n",
            "Train Epoch: 4 [3976/3978 (100%)]\tLoss: 1.223921\n",
            "Train Epoch: 4 [3977/3978 (100%)]\tLoss: 0.266111\n",
            "Epoch\n",
            "train/train_loss: 0.26611143350601196\n",
            "\n",
            "Train Loss: 0.266, Valid Loss: 0.725256, Accuracy: 0.02\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='541.284 MB of 541.284 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c75fc2d1f064f2b86a071b6d4228231"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train/loss</td><td>▃▁▁▁▅▁▁▄▁▁▂▁▄▁▂▃▁▄▄▁▃▂▃▁▁▅▁▁▁▁▅▃▁▁▄▄▁▁█▁</td></tr><tr><td>validation/accuracy</td><td>███▂▁</td></tr><tr><td>validation/loss</td><td>▃▄█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/loss</td><td>0.26611</td></tr><tr><td>validation/accuracy</td><td>0.0156</td></tr><tr><td>validation/loss</td><td>0.72526</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fearless-sweep-2</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/12gc5nz4' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/12gc5nz4</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240829_173727-12gc5nz4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tywfuxmo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240829_181728-tywfuxmo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/tywfuxmo' target=\"_blank\">likely-sweep-3</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/tywfuxmo' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/tywfuxmo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train Epoch: 3 [2964/3978 (75%)]\tLoss: 0.075957\n",
            "Train Epoch: 3 [2965/3978 (75%)]\tLoss: 0.079918\n",
            "Train Epoch: 3 [2966/3978 (75%)]\tLoss: 0.573944\n",
            "Train Epoch: 3 [2967/3978 (75%)]\tLoss: 0.604337\n",
            "Train Epoch: 3 [2968/3978 (75%)]\tLoss: 0.000195\n",
            "Train Epoch: 3 [2969/3978 (75%)]\tLoss: 0.903405\n",
            "Train Epoch: 3 [2970/3978 (75%)]\tLoss: 1.912510\n",
            "Train Epoch: 3 [2971/3978 (75%)]\tLoss: 0.974621\n",
            "Train Epoch: 3 [2972/3978 (75%)]\tLoss: 0.084963\n",
            "Train Epoch: 3 [2973/3978 (75%)]\tLoss: 0.151538\n",
            "Train Epoch: 3 [2974/3978 (75%)]\tLoss: 0.011699\n",
            "Train Epoch: 3 [2975/3978 (75%)]\tLoss: 2.014434\n",
            "Train Epoch: 3 [2976/3978 (75%)]\tLoss: 0.377082\n",
            "Train Epoch: 3 [2977/3978 (75%)]\tLoss: 3.542736\n",
            "Train Epoch: 3 [2978/3978 (75%)]\tLoss: 0.002793\n",
            "Train Epoch: 3 [2979/3978 (75%)]\tLoss: 1.302199\n",
            "Train Epoch: 3 [2980/3978 (75%)]\tLoss: 1.011046\n",
            "Train Epoch: 3 [2981/3978 (75%)]\tLoss: 0.239446\n",
            "Train Epoch: 3 [2982/3978 (75%)]\tLoss: 0.811546\n",
            "Train Epoch: 3 [2983/3978 (75%)]\tLoss: 0.338311\n",
            "Train Epoch: 3 [2984/3978 (75%)]\tLoss: 0.765092\n",
            "Train Epoch: 3 [2985/3978 (75%)]\tLoss: 0.444641\n",
            "Train Epoch: 3 [2986/3978 (75%)]\tLoss: 0.660409\n",
            "Train Epoch: 3 [2987/3978 (75%)]\tLoss: 0.020336\n",
            "Train Epoch: 3 [2988/3978 (75%)]\tLoss: 0.082262\n",
            "Train Epoch: 3 [2989/3978 (75%)]\tLoss: 1.399891\n",
            "Train Epoch: 3 [2990/3978 (75%)]\tLoss: 1.215737\n",
            "Train Epoch: 3 [2991/3978 (75%)]\tLoss: 0.051114\n",
            "Train Epoch: 3 [2992/3978 (75%)]\tLoss: 0.344435\n",
            "Train Epoch: 3 [2993/3978 (75%)]\tLoss: 0.281407\n",
            "Train Epoch: 3 [2994/3978 (75%)]\tLoss: 0.899284\n",
            "Train Epoch: 3 [2995/3978 (75%)]\tLoss: 0.043127\n",
            "Train Epoch: 3 [2996/3978 (75%)]\tLoss: 0.688241\n",
            "Train Epoch: 3 [2997/3978 (75%)]\tLoss: 0.032472\n",
            "Train Epoch: 3 [2998/3978 (75%)]\tLoss: 0.228351\n",
            "Train Epoch: 3 [2999/3978 (75%)]\tLoss: 0.529781\n",
            "Train Epoch: 3 [3000/3978 (75%)]\tLoss: 0.861825\n",
            "Train Epoch: 3 [3001/3978 (75%)]\tLoss: 3.011858\n",
            "Train Epoch: 3 [3002/3978 (75%)]\tLoss: 0.177868\n",
            "Train Epoch: 3 [3003/3978 (75%)]\tLoss: 1.261165\n",
            "Train Epoch: 3 [3004/3978 (76%)]\tLoss: 1.852491\n",
            "Train Epoch: 3 [3005/3978 (76%)]\tLoss: 0.183161\n",
            "Train Epoch: 3 [3006/3978 (76%)]\tLoss: 0.712060\n",
            "Train Epoch: 3 [3007/3978 (76%)]\tLoss: 1.308512\n",
            "Train Epoch: 3 [3008/3978 (76%)]\tLoss: 0.154510\n",
            "Train Epoch: 3 [3009/3978 (76%)]\tLoss: 0.016593\n",
            "Train Epoch: 3 [3010/3978 (76%)]\tLoss: 0.424416\n",
            "Train Epoch: 3 [3011/3978 (76%)]\tLoss: 2.388558\n",
            "Train Epoch: 3 [3012/3978 (76%)]\tLoss: 0.053030\n",
            "Train Epoch: 3 [3013/3978 (76%)]\tLoss: 0.000019\n",
            "Train Epoch: 3 [3014/3978 (76%)]\tLoss: 0.001647\n",
            "Train Epoch: 3 [3015/3978 (76%)]\tLoss: 0.034196\n",
            "Train Epoch: 3 [3016/3978 (76%)]\tLoss: 0.013515\n",
            "Train Epoch: 3 [3017/3978 (76%)]\tLoss: 0.000416\n",
            "Train Epoch: 3 [3018/3978 (76%)]\tLoss: 2.861615\n",
            "Train Epoch: 3 [3019/3978 (76%)]\tLoss: 0.000618\n",
            "Train Epoch: 3 [3020/3978 (76%)]\tLoss: 1.558056\n",
            "Train Epoch: 3 [3021/3978 (76%)]\tLoss: 0.003382\n",
            "Train Epoch: 3 [3022/3978 (76%)]\tLoss: 0.000021\n",
            "Train Epoch: 3 [3023/3978 (76%)]\tLoss: 0.000537\n",
            "Train Epoch: 3 [3024/3978 (76%)]\tLoss: 0.283172\n",
            "Train Epoch: 3 [3025/3978 (76%)]\tLoss: 0.000006\n",
            "Train Epoch: 3 [3026/3978 (76%)]\tLoss: 0.082522\n",
            "Train Epoch: 3 [3027/3978 (76%)]\tLoss: 0.000100\n",
            "Train Epoch: 3 [3028/3978 (76%)]\tLoss: 0.617972\n",
            "Train Epoch: 3 [3029/3978 (76%)]\tLoss: 0.084660\n",
            "Train Epoch: 3 [3030/3978 (76%)]\tLoss: 1.482526\n",
            "Train Epoch: 3 [3031/3978 (76%)]\tLoss: 0.587796\n",
            "Train Epoch: 3 [3032/3978 (76%)]\tLoss: 0.059729\n",
            "Train Epoch: 3 [3033/3978 (76%)]\tLoss: 1.133348\n",
            "Train Epoch: 3 [3034/3978 (76%)]\tLoss: 0.394012\n",
            "Train Epoch: 3 [3035/3978 (76%)]\tLoss: 0.331480\n",
            "Train Epoch: 3 [3036/3978 (76%)]\tLoss: 0.188024\n",
            "Train Epoch: 3 [3037/3978 (76%)]\tLoss: 0.750668\n",
            "Train Epoch: 3 [3038/3978 (76%)]\tLoss: 0.273031\n",
            "Train Epoch: 3 [3039/3978 (76%)]\tLoss: 0.017401\n",
            "Train Epoch: 3 [3040/3978 (76%)]\tLoss: 3.074790\n",
            "Train Epoch: 3 [3041/3978 (76%)]\tLoss: 0.243482\n",
            "Train Epoch: 3 [3042/3978 (76%)]\tLoss: 0.000773\n",
            "Train Epoch: 3 [3043/3978 (76%)]\tLoss: 0.938690\n",
            "Train Epoch: 3 [3044/3978 (77%)]\tLoss: 2.689956\n",
            "Train Epoch: 3 [3045/3978 (77%)]\tLoss: 0.062681\n",
            "Train Epoch: 3 [3046/3978 (77%)]\tLoss: 0.340997\n",
            "Train Epoch: 3 [3047/3978 (77%)]\tLoss: 0.003513\n",
            "Train Epoch: 3 [3048/3978 (77%)]\tLoss: 1.411681\n",
            "Train Epoch: 3 [3049/3978 (77%)]\tLoss: 0.832907\n",
            "Train Epoch: 3 [3050/3978 (77%)]\tLoss: 0.000026\n",
            "Train Epoch: 3 [3051/3978 (77%)]\tLoss: 4.236028\n",
            "Train Epoch: 3 [3052/3978 (77%)]\tLoss: 0.196645\n",
            "Train Epoch: 3 [3053/3978 (77%)]\tLoss: 0.151398\n",
            "Train Epoch: 3 [3054/3978 (77%)]\tLoss: 0.113784\n",
            "Train Epoch: 3 [3055/3978 (77%)]\tLoss: 0.421240\n",
            "Train Epoch: 3 [3056/3978 (77%)]\tLoss: 2.175506\n",
            "Train Epoch: 3 [3057/3978 (77%)]\tLoss: 0.096534\n",
            "Train Epoch: 3 [3058/3978 (77%)]\tLoss: 0.398536\n",
            "Train Epoch: 3 [3059/3978 (77%)]\tLoss: 0.003342\n",
            "Train Epoch: 3 [3060/3978 (77%)]\tLoss: 0.952648\n",
            "Train Epoch: 3 [3061/3978 (77%)]\tLoss: 0.846365\n",
            "Train Epoch: 3 [3062/3978 (77%)]\tLoss: 1.720769\n",
            "Train Epoch: 3 [3063/3978 (77%)]\tLoss: 0.002348\n",
            "Train Epoch: 3 [3064/3978 (77%)]\tLoss: 0.868176\n",
            "Train Epoch: 3 [3065/3978 (77%)]\tLoss: 1.054027\n",
            "Train Epoch: 3 [3066/3978 (77%)]\tLoss: 0.972630\n",
            "Train Epoch: 3 [3067/3978 (77%)]\tLoss: 0.449892\n",
            "Train Epoch: 3 [3068/3978 (77%)]\tLoss: 0.093797\n",
            "Train Epoch: 3 [3069/3978 (77%)]\tLoss: 5.156015\n",
            "Train Epoch: 3 [3070/3978 (77%)]\tLoss: 1.173539\n",
            "Train Epoch: 3 [3071/3978 (77%)]\tLoss: 0.000017\n",
            "Train Epoch: 3 [3072/3978 (77%)]\tLoss: 0.000017\n",
            "Train Epoch: 3 [3073/3978 (77%)]\tLoss: 4.754031\n",
            "Train Epoch: 3 [3074/3978 (77%)]\tLoss: 0.815885\n",
            "Train Epoch: 3 [3075/3978 (77%)]\tLoss: 0.002143\n",
            "Train Epoch: 3 [3076/3978 (77%)]\tLoss: 0.000783\n",
            "Train Epoch: 3 [3077/3978 (77%)]\tLoss: 0.010065\n",
            "Train Epoch: 3 [3078/3978 (77%)]\tLoss: 1.149758\n",
            "Train Epoch: 3 [3079/3978 (77%)]\tLoss: 0.402019\n",
            "Train Epoch: 3 [3080/3978 (77%)]\tLoss: 0.392292\n",
            "Train Epoch: 3 [3081/3978 (77%)]\tLoss: 1.832278\n",
            "Train Epoch: 3 [3082/3978 (77%)]\tLoss: 0.110624\n",
            "Train Epoch: 3 [3083/3978 (78%)]\tLoss: 0.075125\n",
            "Train Epoch: 3 [3084/3978 (78%)]\tLoss: 1.670280\n",
            "Train Epoch: 3 [3085/3978 (78%)]\tLoss: 0.611956\n",
            "Train Epoch: 3 [3086/3978 (78%)]\tLoss: 1.336684\n",
            "Train Epoch: 3 [3087/3978 (78%)]\tLoss: 0.002557\n",
            "Train Epoch: 3 [3088/3978 (78%)]\tLoss: 0.837063\n",
            "Train Epoch: 3 [3089/3978 (78%)]\tLoss: 0.501198\n",
            "Train Epoch: 3 [3090/3978 (78%)]\tLoss: 0.088500\n",
            "Train Epoch: 3 [3091/3978 (78%)]\tLoss: 0.000304\n",
            "Train Epoch: 3 [3092/3978 (78%)]\tLoss: 0.000093\n",
            "Train Epoch: 3 [3093/3978 (78%)]\tLoss: 0.000321\n",
            "Train Epoch: 3 [3094/3978 (78%)]\tLoss: 0.701307\n",
            "Train Epoch: 3 [3095/3978 (78%)]\tLoss: 0.065878\n",
            "Train Epoch: 3 [3096/3978 (78%)]\tLoss: 0.492569\n",
            "Train Epoch: 3 [3097/3978 (78%)]\tLoss: 3.598075\n",
            "Train Epoch: 3 [3098/3978 (78%)]\tLoss: 0.000076\n",
            "Train Epoch: 3 [3099/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3100/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3101/3978 (78%)]\tLoss: 4.151431\n",
            "Train Epoch: 3 [3102/3978 (78%)]\tLoss: 1.359490\n",
            "Train Epoch: 3 [3103/3978 (78%)]\tLoss: 1.982627\n",
            "Train Epoch: 3 [3104/3978 (78%)]\tLoss: 3.540042\n",
            "Train Epoch: 3 [3105/3978 (78%)]\tLoss: 0.728006\n",
            "Train Epoch: 3 [3106/3978 (78%)]\tLoss: 0.759036\n",
            "Train Epoch: 3 [3107/3978 (78%)]\tLoss: 2.728286\n",
            "Train Epoch: 3 [3108/3978 (78%)]\tLoss: 6.681786\n",
            "Train Epoch: 3 [3109/3978 (78%)]\tLoss: 4.133600\n",
            "Train Epoch: 3 [3110/3978 (78%)]\tLoss: 0.000163\n",
            "Train Epoch: 3 [3111/3978 (78%)]\tLoss: 2.453186\n",
            "Train Epoch: 3 [3112/3978 (78%)]\tLoss: 2.505285\n",
            "Train Epoch: 3 [3113/3978 (78%)]\tLoss: 2.097302\n",
            "Train Epoch: 3 [3114/3978 (78%)]\tLoss: 1.139681\n",
            "Train Epoch: 3 [3115/3978 (78%)]\tLoss: 0.582160\n",
            "Train Epoch: 3 [3116/3978 (78%)]\tLoss: 1.895255\n",
            "Train Epoch: 3 [3117/3978 (78%)]\tLoss: 1.489930\n",
            "Train Epoch: 3 [3118/3978 (78%)]\tLoss: 1.068561\n",
            "Train Epoch: 3 [3119/3978 (78%)]\tLoss: 0.657367\n",
            "Train Epoch: 3 [3120/3978 (78%)]\tLoss: 0.375142\n",
            "Train Epoch: 3 [3121/3978 (78%)]\tLoss: 0.103358\n",
            "Train Epoch: 3 [3122/3978 (78%)]\tLoss: 0.065717\n",
            "Train Epoch: 3 [3123/3978 (79%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3124/3978 (79%)]\tLoss: 0.000126\n",
            "Train Epoch: 3 [3125/3978 (79%)]\tLoss: 0.000033\n",
            "Train Epoch: 3 [3126/3978 (79%)]\tLoss: 1.594390\n",
            "Train Epoch: 3 [3127/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3128/3978 (79%)]\tLoss: 3.501688\n",
            "Train Epoch: 3 [3129/3978 (79%)]\tLoss: 1.170839\n",
            "Train Epoch: 3 [3130/3978 (79%)]\tLoss: 0.001278\n",
            "Train Epoch: 3 [3131/3978 (79%)]\tLoss: 0.225005\n",
            "Train Epoch: 3 [3132/3978 (79%)]\tLoss: 0.189814\n",
            "Train Epoch: 3 [3133/3978 (79%)]\tLoss: 4.236306\n",
            "Train Epoch: 3 [3134/3978 (79%)]\tLoss: 3.455188\n",
            "Train Epoch: 3 [3135/3978 (79%)]\tLoss: 0.000041\n",
            "Train Epoch: 3 [3136/3978 (79%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3137/3978 (79%)]\tLoss: 1.283010\n",
            "Train Epoch: 3 [3138/3978 (79%)]\tLoss: 2.652569\n",
            "Train Epoch: 3 [3139/3978 (79%)]\tLoss: 3.242629\n",
            "Train Epoch: 3 [3140/3978 (79%)]\tLoss: 0.591061\n",
            "Train Epoch: 3 [3141/3978 (79%)]\tLoss: 1.810733\n",
            "Train Epoch: 3 [3142/3978 (79%)]\tLoss: 0.476331\n",
            "Train Epoch: 3 [3143/3978 (79%)]\tLoss: 0.574326\n",
            "Train Epoch: 3 [3144/3978 (79%)]\tLoss: 1.791690\n",
            "Train Epoch: 3 [3145/3978 (79%)]\tLoss: 0.400054\n",
            "Train Epoch: 3 [3146/3978 (79%)]\tLoss: 1.997416\n",
            "Train Epoch: 3 [3147/3978 (79%)]\tLoss: 0.039390\n",
            "Train Epoch: 3 [3148/3978 (79%)]\tLoss: 2.536344\n",
            "Train Epoch: 3 [3149/3978 (79%)]\tLoss: 1.946101\n",
            "Train Epoch: 3 [3150/3978 (79%)]\tLoss: 1.429407\n",
            "Train Epoch: 3 [3151/3978 (79%)]\tLoss: 2.074624\n",
            "Train Epoch: 3 [3152/3978 (79%)]\tLoss: 0.830390\n",
            "Train Epoch: 3 [3153/3978 (79%)]\tLoss: 0.166267\n",
            "Train Epoch: 3 [3154/3978 (79%)]\tLoss: 0.336283\n",
            "Train Epoch: 3 [3155/3978 (79%)]\tLoss: 0.203049\n",
            "Train Epoch: 3 [3156/3978 (79%)]\tLoss: 1.149892\n",
            "Train Epoch: 3 [3157/3978 (79%)]\tLoss: 0.003705\n",
            "Train Epoch: 3 [3158/3978 (79%)]\tLoss: 0.721199\n",
            "Train Epoch: 3 [3159/3978 (79%)]\tLoss: 0.307193\n",
            "Train Epoch: 3 [3160/3978 (79%)]\tLoss: 0.181263\n",
            "Train Epoch: 3 [3161/3978 (79%)]\tLoss: 0.015211\n",
            "Train Epoch: 3 [3162/3978 (79%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3163/3978 (80%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3164/3978 (80%)]\tLoss: 5.924172\n",
            "Train Epoch: 3 [3165/3978 (80%)]\tLoss: 6.703637\n",
            "Train Epoch: 3 [3166/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3167/3978 (80%)]\tLoss: 2.342076\n",
            "Train Epoch: 3 [3168/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3169/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3170/3978 (80%)]\tLoss: 4.476776\n",
            "Train Epoch: 3 [3171/3978 (80%)]\tLoss: 2.568023\n",
            "Train Epoch: 3 [3172/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3173/3978 (80%)]\tLoss: 0.000724\n",
            "Train Epoch: 3 [3174/3978 (80%)]\tLoss: 4.056095\n",
            "Train Epoch: 3 [3175/3978 (80%)]\tLoss: 0.023507\n",
            "Train Epoch: 3 [3176/3978 (80%)]\tLoss: 0.255226\n",
            "Train Epoch: 3 [3177/3978 (80%)]\tLoss: 0.244964\n",
            "Train Epoch: 3 [3178/3978 (80%)]\tLoss: 0.056064\n",
            "Train Epoch: 3 [3179/3978 (80%)]\tLoss: 0.228453\n",
            "Train Epoch: 3 [3180/3978 (80%)]\tLoss: 1.219474\n",
            "Train Epoch: 3 [3181/3978 (80%)]\tLoss: 0.007743\n",
            "Train Epoch: 3 [3182/3978 (80%)]\tLoss: 0.611224\n",
            "Train Epoch: 3 [3183/3978 (80%)]\tLoss: 1.614945\n",
            "Train Epoch: 3 [3184/3978 (80%)]\tLoss: 0.322983\n",
            "Train Epoch: 3 [3185/3978 (80%)]\tLoss: 0.475038\n",
            "Train Epoch: 3 [3186/3978 (80%)]\tLoss: 1.974210\n",
            "Train Epoch: 3 [3187/3978 (80%)]\tLoss: 0.446749\n",
            "Train Epoch: 3 [3188/3978 (80%)]\tLoss: 0.105090\n",
            "Train Epoch: 3 [3189/3978 (80%)]\tLoss: 2.268828\n",
            "Train Epoch: 3 [3190/3978 (80%)]\tLoss: 0.036117\n",
            "Train Epoch: 3 [3191/3978 (80%)]\tLoss: 0.000579\n",
            "Train Epoch: 3 [3192/3978 (80%)]\tLoss: 1.146230\n",
            "Train Epoch: 3 [3193/3978 (80%)]\tLoss: 5.150266\n",
            "Train Epoch: 3 [3194/3978 (80%)]\tLoss: 2.634285\n",
            "Train Epoch: 3 [3195/3978 (80%)]\tLoss: 0.000328\n",
            "Train Epoch: 3 [3196/3978 (80%)]\tLoss: 0.034726\n",
            "Train Epoch: 3 [3197/3978 (80%)]\tLoss: 0.003009\n",
            "Train Epoch: 3 [3198/3978 (80%)]\tLoss: 0.211860\n",
            "Train Epoch: 3 [3199/3978 (80%)]\tLoss: 0.000215\n",
            "Train Epoch: 3 [3200/3978 (80%)]\tLoss: 0.407563\n",
            "Train Epoch: 3 [3201/3978 (80%)]\tLoss: 1.133488\n",
            "Train Epoch: 3 [3202/3978 (80%)]\tLoss: 0.260621\n",
            "Train Epoch: 3 [3203/3978 (81%)]\tLoss: 0.000203\n",
            "Train Epoch: 3 [3204/3978 (81%)]\tLoss: 0.027683\n",
            "Train Epoch: 3 [3205/3978 (81%)]\tLoss: 0.012306\n",
            "Train Epoch: 3 [3206/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3207/3978 (81%)]\tLoss: 0.000009\n",
            "Train Epoch: 3 [3208/3978 (81%)]\tLoss: 2.555660\n",
            "Train Epoch: 3 [3209/3978 (81%)]\tLoss: 0.000370\n",
            "Train Epoch: 3 [3210/3978 (81%)]\tLoss: 2.517823\n",
            "Train Epoch: 3 [3211/3978 (81%)]\tLoss: 0.000084\n",
            "Train Epoch: 3 [3212/3978 (81%)]\tLoss: 0.000172\n",
            "Train Epoch: 3 [3213/3978 (81%)]\tLoss: 0.003123\n",
            "Train Epoch: 3 [3214/3978 (81%)]\tLoss: 1.090368\n",
            "Train Epoch: 3 [3215/3978 (81%)]\tLoss: 0.072754\n",
            "Train Epoch: 3 [3216/3978 (81%)]\tLoss: 0.002726\n",
            "Train Epoch: 3 [3217/3978 (81%)]\tLoss: 0.831103\n",
            "Train Epoch: 3 [3218/3978 (81%)]\tLoss: 0.477759\n",
            "Train Epoch: 3 [3219/3978 (81%)]\tLoss: 0.089980\n",
            "Train Epoch: 3 [3220/3978 (81%)]\tLoss: 1.048352\n",
            "Train Epoch: 3 [3221/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3222/3978 (81%)]\tLoss: 0.000024\n",
            "Train Epoch: 3 [3223/3978 (81%)]\tLoss: 2.009733\n",
            "Train Epoch: 3 [3224/3978 (81%)]\tLoss: 0.002951\n",
            "Train Epoch: 3 [3225/3978 (81%)]\tLoss: 0.000096\n",
            "Train Epoch: 3 [3226/3978 (81%)]\tLoss: 0.796046\n",
            "Train Epoch: 3 [3227/3978 (81%)]\tLoss: 1.056960\n",
            "Train Epoch: 3 [3228/3978 (81%)]\tLoss: 0.000204\n",
            "Train Epoch: 3 [3229/3978 (81%)]\tLoss: 1.099602\n",
            "Train Epoch: 3 [3230/3978 (81%)]\tLoss: 1.605078\n",
            "Train Epoch: 3 [3231/3978 (81%)]\tLoss: 0.000144\n",
            "Train Epoch: 3 [3232/3978 (81%)]\tLoss: 0.960708\n",
            "Train Epoch: 3 [3233/3978 (81%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3234/3978 (81%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3235/3978 (81%)]\tLoss: 0.004202\n",
            "Train Epoch: 3 [3236/3978 (81%)]\tLoss: 0.000364\n",
            "Train Epoch: 3 [3237/3978 (81%)]\tLoss: 0.011339\n",
            "Train Epoch: 3 [3238/3978 (81%)]\tLoss: 0.001805\n",
            "Train Epoch: 3 [3239/3978 (81%)]\tLoss: 0.008565\n",
            "Train Epoch: 3 [3240/3978 (81%)]\tLoss: 5.672973\n",
            "Train Epoch: 3 [3241/3978 (81%)]\tLoss: 0.029145\n",
            "Train Epoch: 3 [3242/3978 (81%)]\tLoss: 0.274945\n",
            "Train Epoch: 3 [3243/3978 (82%)]\tLoss: 0.350381\n",
            "Train Epoch: 3 [3244/3978 (82%)]\tLoss: 0.043683\n",
            "Train Epoch: 3 [3245/3978 (82%)]\tLoss: 1.775542\n",
            "Train Epoch: 3 [3246/3978 (82%)]\tLoss: 2.805988\n",
            "Train Epoch: 3 [3247/3978 (82%)]\tLoss: 0.049495\n",
            "Train Epoch: 3 [3248/3978 (82%)]\tLoss: 3.957353\n",
            "Train Epoch: 3 [3249/3978 (82%)]\tLoss: 0.040843\n",
            "Train Epoch: 3 [3250/3978 (82%)]\tLoss: 1.323359\n",
            "Train Epoch: 3 [3251/3978 (82%)]\tLoss: 0.020524\n",
            "Train Epoch: 3 [3252/3978 (82%)]\tLoss: 0.401414\n",
            "Train Epoch: 3 [3253/3978 (82%)]\tLoss: 0.401195\n",
            "Train Epoch: 3 [3254/3978 (82%)]\tLoss: 0.306744\n",
            "Train Epoch: 3 [3255/3978 (82%)]\tLoss: 0.017262\n",
            "Train Epoch: 3 [3256/3978 (82%)]\tLoss: 0.408458\n",
            "Train Epoch: 3 [3257/3978 (82%)]\tLoss: 0.000660\n",
            "Train Epoch: 3 [3258/3978 (82%)]\tLoss: 0.907185\n",
            "Train Epoch: 3 [3259/3978 (82%)]\tLoss: 0.000172\n",
            "Train Epoch: 3 [3260/3978 (82%)]\tLoss: 0.017267\n",
            "Train Epoch: 3 [3261/3978 (82%)]\tLoss: 2.208584\n",
            "Train Epoch: 3 [3262/3978 (82%)]\tLoss: 0.159213\n",
            "Train Epoch: 3 [3263/3978 (82%)]\tLoss: 1.238143\n",
            "Train Epoch: 3 [3264/3978 (82%)]\tLoss: 0.003408\n",
            "Train Epoch: 3 [3265/3978 (82%)]\tLoss: 0.000800\n",
            "Train Epoch: 3 [3266/3978 (82%)]\tLoss: 0.000032\n",
            "Train Epoch: 3 [3267/3978 (82%)]\tLoss: 0.000266\n",
            "Train Epoch: 3 [3268/3978 (82%)]\tLoss: 3.275073\n",
            "Train Epoch: 3 [3269/3978 (82%)]\tLoss: 1.306540\n",
            "Train Epoch: 3 [3270/3978 (82%)]\tLoss: 0.534776\n",
            "Train Epoch: 3 [3271/3978 (82%)]\tLoss: 1.045676\n",
            "Train Epoch: 3 [3272/3978 (82%)]\tLoss: 0.226502\n",
            "Train Epoch: 3 [3273/3978 (82%)]\tLoss: 0.552221\n",
            "Train Epoch: 3 [3274/3978 (82%)]\tLoss: 0.925692\n",
            "Train Epoch: 3 [3275/3978 (82%)]\tLoss: 1.008037\n",
            "Train Epoch: 3 [3276/3978 (82%)]\tLoss: 3.729247\n",
            "Train Epoch: 3 [3277/3978 (82%)]\tLoss: 0.000647\n",
            "Train Epoch: 3 [3278/3978 (82%)]\tLoss: 1.062274\n",
            "Train Epoch: 3 [3279/3978 (82%)]\tLoss: 0.021305\n",
            "Train Epoch: 3 [3280/3978 (82%)]\tLoss: 0.023453\n",
            "Train Epoch: 3 [3281/3978 (82%)]\tLoss: 2.474124\n",
            "Train Epoch: 3 [3282/3978 (83%)]\tLoss: 0.000020\n",
            "Train Epoch: 3 [3283/3978 (83%)]\tLoss: 3.745107\n",
            "Train Epoch: 3 [3284/3978 (83%)]\tLoss: 0.000537\n",
            "Train Epoch: 3 [3285/3978 (83%)]\tLoss: 1.869105\n",
            "Train Epoch: 3 [3286/3978 (83%)]\tLoss: 1.624332\n",
            "Train Epoch: 3 [3287/3978 (83%)]\tLoss: 1.429303\n",
            "Train Epoch: 3 [3288/3978 (83%)]\tLoss: 0.000591\n",
            "Train Epoch: 3 [3289/3978 (83%)]\tLoss: 0.469280\n",
            "Train Epoch: 3 [3290/3978 (83%)]\tLoss: 0.481441\n",
            "Train Epoch: 3 [3291/3978 (83%)]\tLoss: 1.112611\n",
            "Train Epoch: 3 [3292/3978 (83%)]\tLoss: 0.719121\n",
            "Train Epoch: 3 [3293/3978 (83%)]\tLoss: 0.765965\n",
            "Train Epoch: 3 [3294/3978 (83%)]\tLoss: 0.320093\n",
            "Train Epoch: 3 [3295/3978 (83%)]\tLoss: 0.000197\n",
            "Train Epoch: 3 [3296/3978 (83%)]\tLoss: 1.452120\n",
            "Train Epoch: 3 [3297/3978 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3298/3978 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3299/3978 (83%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3300/3978 (83%)]\tLoss: 1.465774\n",
            "Train Epoch: 3 [3301/3978 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3302/3978 (83%)]\tLoss: 4.322764\n",
            "Train Epoch: 3 [3303/3978 (83%)]\tLoss: 1.591385\n",
            "Train Epoch: 3 [3304/3978 (83%)]\tLoss: 0.856077\n",
            "Train Epoch: 3 [3305/3978 (83%)]\tLoss: 2.859404\n",
            "Train Epoch: 3 [3306/3978 (83%)]\tLoss: 0.058597\n",
            "Train Epoch: 3 [3307/3978 (83%)]\tLoss: 0.494088\n",
            "Train Epoch: 3 [3308/3978 (83%)]\tLoss: 0.187776\n",
            "Train Epoch: 3 [3309/3978 (83%)]\tLoss: 0.001796\n",
            "Train Epoch: 3 [3310/3978 (83%)]\tLoss: 0.000604\n",
            "Train Epoch: 3 [3311/3978 (83%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3312/3978 (83%)]\tLoss: 0.000146\n",
            "Train Epoch: 3 [3313/3978 (83%)]\tLoss: 0.001317\n",
            "Train Epoch: 3 [3314/3978 (83%)]\tLoss: 0.448834\n",
            "Train Epoch: 3 [3315/3978 (83%)]\tLoss: 0.409241\n",
            "Train Epoch: 3 [3316/3978 (83%)]\tLoss: 0.151661\n",
            "Train Epoch: 3 [3317/3978 (83%)]\tLoss: 0.516978\n",
            "Train Epoch: 3 [3318/3978 (83%)]\tLoss: 0.036802\n",
            "Train Epoch: 3 [3319/3978 (83%)]\tLoss: 0.628006\n",
            "Train Epoch: 3 [3320/3978 (83%)]\tLoss: 0.529429\n",
            "Train Epoch: 3 [3321/3978 (83%)]\tLoss: 2.305323\n",
            "Train Epoch: 3 [3322/3978 (84%)]\tLoss: 0.505808\n",
            "Train Epoch: 3 [3323/3978 (84%)]\tLoss: 0.971630\n",
            "Train Epoch: 3 [3324/3978 (84%)]\tLoss: 2.555660\n",
            "Train Epoch: 3 [3325/3978 (84%)]\tLoss: 0.939495\n",
            "Train Epoch: 3 [3326/3978 (84%)]\tLoss: 0.502279\n",
            "Train Epoch: 3 [3327/3978 (84%)]\tLoss: 1.435959\n",
            "Train Epoch: 3 [3328/3978 (84%)]\tLoss: 1.068335\n",
            "Train Epoch: 3 [3329/3978 (84%)]\tLoss: 1.918620\n",
            "Train Epoch: 3 [3330/3978 (84%)]\tLoss: 1.209982\n",
            "Train Epoch: 3 [3331/3978 (84%)]\tLoss: 0.000559\n",
            "Train Epoch: 3 [3332/3978 (84%)]\tLoss: 0.800626\n",
            "Train Epoch: 3 [3333/3978 (84%)]\tLoss: 0.758495\n",
            "Train Epoch: 3 [3334/3978 (84%)]\tLoss: 0.386828\n",
            "Train Epoch: 3 [3335/3978 (84%)]\tLoss: 0.028084\n",
            "Train Epoch: 3 [3336/3978 (84%)]\tLoss: 0.001071\n",
            "Train Epoch: 3 [3337/3978 (84%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3338/3978 (84%)]\tLoss: 1.360275\n",
            "Train Epoch: 3 [3339/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3340/3978 (84%)]\tLoss: 1.559352\n",
            "Train Epoch: 3 [3341/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3342/3978 (84%)]\tLoss: 3.408047\n",
            "Train Epoch: 3 [3343/3978 (84%)]\tLoss: 0.001866\n",
            "Train Epoch: 3 [3344/3978 (84%)]\tLoss: 0.000593\n",
            "Train Epoch: 3 [3345/3978 (84%)]\tLoss: 0.233531\n",
            "Train Epoch: 3 [3346/3978 (84%)]\tLoss: 2.923926\n",
            "Train Epoch: 3 [3347/3978 (84%)]\tLoss: 3.897173\n",
            "Train Epoch: 3 [3348/3978 (84%)]\tLoss: 0.042402\n",
            "Train Epoch: 3 [3349/3978 (84%)]\tLoss: 2.910074\n",
            "Train Epoch: 3 [3350/3978 (84%)]\tLoss: 0.000027\n",
            "Train Epoch: 3 [3351/3978 (84%)]\tLoss: 0.000486\n",
            "Train Epoch: 3 [3352/3978 (84%)]\tLoss: 1.842263\n",
            "Train Epoch: 3 [3353/3978 (84%)]\tLoss: 0.319960\n",
            "Train Epoch: 3 [3354/3978 (84%)]\tLoss: 0.000573\n",
            "Train Epoch: 3 [3355/3978 (84%)]\tLoss: 0.001901\n",
            "Train Epoch: 3 [3356/3978 (84%)]\tLoss: 0.341920\n",
            "Train Epoch: 3 [3357/3978 (84%)]\tLoss: 0.084764\n",
            "Train Epoch: 3 [3358/3978 (84%)]\tLoss: 0.389759\n",
            "Train Epoch: 3 [3359/3978 (84%)]\tLoss: 0.133118\n",
            "Train Epoch: 3 [3360/3978 (84%)]\tLoss: 1.041254\n",
            "Train Epoch: 3 [3361/3978 (84%)]\tLoss: 3.593238\n",
            "Train Epoch: 3 [3362/3978 (85%)]\tLoss: 2.643464\n",
            "Train Epoch: 3 [3363/3978 (85%)]\tLoss: 0.757007\n",
            "Train Epoch: 3 [3364/3978 (85%)]\tLoss: 0.012291\n",
            "Train Epoch: 3 [3365/3978 (85%)]\tLoss: 0.247577\n",
            "Train Epoch: 3 [3366/3978 (85%)]\tLoss: 0.124575\n",
            "Train Epoch: 3 [3367/3978 (85%)]\tLoss: 1.650813\n",
            "Train Epoch: 3 [3368/3978 (85%)]\tLoss: 0.498234\n",
            "Train Epoch: 3 [3369/3978 (85%)]\tLoss: 0.086883\n",
            "Train Epoch: 3 [3370/3978 (85%)]\tLoss: 0.020190\n",
            "Train Epoch: 3 [3371/3978 (85%)]\tLoss: 0.044588\n",
            "Train Epoch: 3 [3372/3978 (85%)]\tLoss: 0.590030\n",
            "Train Epoch: 3 [3373/3978 (85%)]\tLoss: 1.683458\n",
            "Train Epoch: 3 [3374/3978 (85%)]\tLoss: 0.054651\n",
            "Train Epoch: 3 [3375/3978 (85%)]\tLoss: 2.127605\n",
            "Train Epoch: 3 [3376/3978 (85%)]\tLoss: 3.278486\n",
            "Train Epoch: 3 [3377/3978 (85%)]\tLoss: 1.638951\n",
            "Train Epoch: 3 [3378/3978 (85%)]\tLoss: 0.413829\n",
            "Train Epoch: 3 [3379/3978 (85%)]\tLoss: 0.192064\n",
            "Train Epoch: 3 [3380/3978 (85%)]\tLoss: 0.046967\n",
            "Train Epoch: 3 [3381/3978 (85%)]\tLoss: 0.317915\n",
            "Train Epoch: 3 [3382/3978 (85%)]\tLoss: 0.166476\n",
            "Train Epoch: 3 [3383/3978 (85%)]\tLoss: 1.154830\n",
            "Train Epoch: 3 [3384/3978 (85%)]\tLoss: 0.000043\n",
            "Train Epoch: 3 [3385/3978 (85%)]\tLoss: 0.613926\n",
            "Train Epoch: 3 [3386/3978 (85%)]\tLoss: 0.000018\n",
            "Train Epoch: 3 [3387/3978 (85%)]\tLoss: 0.000020\n",
            "Train Epoch: 3 [3388/3978 (85%)]\tLoss: 0.000115\n",
            "Train Epoch: 3 [3389/3978 (85%)]\tLoss: 0.338500\n",
            "Train Epoch: 3 [3390/3978 (85%)]\tLoss: 4.277815\n",
            "Train Epoch: 3 [3391/3978 (85%)]\tLoss: 0.001982\n",
            "Train Epoch: 3 [3392/3978 (85%)]\tLoss: 0.000142\n",
            "Train Epoch: 3 [3393/3978 (85%)]\tLoss: 0.137619\n",
            "Train Epoch: 3 [3394/3978 (85%)]\tLoss: 3.683283\n",
            "Train Epoch: 3 [3395/3978 (85%)]\tLoss: 0.698072\n",
            "Train Epoch: 3 [3396/3978 (85%)]\tLoss: 0.004765\n",
            "Train Epoch: 3 [3397/3978 (85%)]\tLoss: 0.073193\n",
            "Train Epoch: 3 [3398/3978 (85%)]\tLoss: 0.123769\n",
            "Train Epoch: 3 [3399/3978 (85%)]\tLoss: 0.062798\n",
            "Train Epoch: 3 [3400/3978 (85%)]\tLoss: 2.111204\n",
            "Train Epoch: 3 [3401/3978 (85%)]\tLoss: 0.309065\n",
            "Train Epoch: 3 [3402/3978 (86%)]\tLoss: 1.093900\n",
            "Train Epoch: 3 [3403/3978 (86%)]\tLoss: 3.062685\n",
            "Train Epoch: 3 [3404/3978 (86%)]\tLoss: 4.864793\n",
            "Train Epoch: 3 [3405/3978 (86%)]\tLoss: 2.882104\n",
            "Train Epoch: 3 [3406/3978 (86%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3407/3978 (86%)]\tLoss: 1.929329\n",
            "Train Epoch: 3 [3408/3978 (86%)]\tLoss: 0.007843\n",
            "Train Epoch: 3 [3409/3978 (86%)]\tLoss: 3.460744\n",
            "Train Epoch: 3 [3410/3978 (86%)]\tLoss: 0.373685\n",
            "Train Epoch: 3 [3411/3978 (86%)]\tLoss: 0.151378\n",
            "Train Epoch: 3 [3412/3978 (86%)]\tLoss: 0.442508\n",
            "Train Epoch: 3 [3413/3978 (86%)]\tLoss: 0.931898\n",
            "Train Epoch: 3 [3414/3978 (86%)]\tLoss: 0.051824\n",
            "Train Epoch: 3 [3415/3978 (86%)]\tLoss: 0.023440\n",
            "Train Epoch: 3 [3416/3978 (86%)]\tLoss: 0.290096\n",
            "Train Epoch: 3 [3417/3978 (86%)]\tLoss: 0.603706\n",
            "Train Epoch: 3 [3418/3978 (86%)]\tLoss: 1.454737\n",
            "Train Epoch: 3 [3419/3978 (86%)]\tLoss: 0.021197\n",
            "Train Epoch: 3 [3420/3978 (86%)]\tLoss: 1.297970\n",
            "Train Epoch: 3 [3421/3978 (86%)]\tLoss: 0.037724\n",
            "Train Epoch: 3 [3422/3978 (86%)]\tLoss: 0.718250\n",
            "Train Epoch: 3 [3423/3978 (86%)]\tLoss: 0.178780\n",
            "Train Epoch: 3 [3424/3978 (86%)]\tLoss: 1.301946\n",
            "Train Epoch: 3 [3425/3978 (86%)]\tLoss: 0.528514\n",
            "Train Epoch: 3 [3426/3978 (86%)]\tLoss: 1.922044\n",
            "Train Epoch: 3 [3427/3978 (86%)]\tLoss: 1.921225\n",
            "Train Epoch: 3 [3428/3978 (86%)]\tLoss: 0.936186\n",
            "Train Epoch: 3 [3429/3978 (86%)]\tLoss: 0.363130\n",
            "Train Epoch: 3 [3430/3978 (86%)]\tLoss: 0.261045\n",
            "Train Epoch: 3 [3431/3978 (86%)]\tLoss: 0.188811\n",
            "Train Epoch: 3 [3432/3978 (86%)]\tLoss: 1.609404\n",
            "Train Epoch: 3 [3433/3978 (86%)]\tLoss: 0.000016\n",
            "Train Epoch: 3 [3434/3978 (86%)]\tLoss: 1.678823\n",
            "Train Epoch: 3 [3435/3978 (86%)]\tLoss: 2.377306\n",
            "Train Epoch: 3 [3436/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3437/3978 (86%)]\tLoss: 1.740436\n",
            "Train Epoch: 3 [3438/3978 (86%)]\tLoss: 0.000028\n",
            "Train Epoch: 3 [3439/3978 (86%)]\tLoss: 0.000016\n",
            "Train Epoch: 3 [3440/3978 (86%)]\tLoss: 0.002846\n",
            "Train Epoch: 3 [3441/3978 (87%)]\tLoss: 0.351659\n",
            "Train Epoch: 3 [3442/3978 (87%)]\tLoss: 2.559726\n",
            "Train Epoch: 3 [3443/3978 (87%)]\tLoss: 0.839103\n",
            "Train Epoch: 3 [3444/3978 (87%)]\tLoss: 0.765170\n",
            "Train Epoch: 3 [3445/3978 (87%)]\tLoss: 0.086009\n",
            "Train Epoch: 3 [3446/3978 (87%)]\tLoss: 2.148316\n",
            "Train Epoch: 3 [3447/3978 (87%)]\tLoss: 0.436311\n",
            "Train Epoch: 3 [3448/3978 (87%)]\tLoss: 0.000955\n",
            "Train Epoch: 3 [3449/3978 (87%)]\tLoss: 0.110227\n",
            "Train Epoch: 3 [3450/3978 (87%)]\tLoss: 1.638913\n",
            "Train Epoch: 3 [3451/3978 (87%)]\tLoss: 2.259170\n",
            "Train Epoch: 3 [3452/3978 (87%)]\tLoss: 0.000069\n",
            "Train Epoch: 3 [3453/3978 (87%)]\tLoss: 0.148695\n",
            "Train Epoch: 3 [3454/3978 (87%)]\tLoss: 0.615568\n",
            "Train Epoch: 3 [3455/3978 (87%)]\tLoss: 0.002231\n",
            "Train Epoch: 3 [3456/3978 (87%)]\tLoss: 0.334939\n",
            "Train Epoch: 3 [3457/3978 (87%)]\tLoss: 0.902950\n",
            "Train Epoch: 3 [3458/3978 (87%)]\tLoss: 2.062588\n",
            "Train Epoch: 3 [3459/3978 (87%)]\tLoss: 0.351856\n",
            "Train Epoch: 3 [3460/3978 (87%)]\tLoss: 0.088530\n",
            "Train Epoch: 3 [3461/3978 (87%)]\tLoss: 0.041821\n",
            "Train Epoch: 3 [3462/3978 (87%)]\tLoss: 1.537870\n",
            "Train Epoch: 3 [3463/3978 (87%)]\tLoss: 1.372231\n",
            "Train Epoch: 3 [3464/3978 (87%)]\tLoss: 0.000020\n",
            "Train Epoch: 3 [3465/3978 (87%)]\tLoss: 0.000145\n",
            "Train Epoch: 3 [3466/3978 (87%)]\tLoss: 0.708087\n",
            "Train Epoch: 3 [3467/3978 (87%)]\tLoss: 1.412606\n",
            "Train Epoch: 3 [3468/3978 (87%)]\tLoss: 0.299183\n",
            "Train Epoch: 3 [3469/3978 (87%)]\tLoss: 0.000060\n",
            "Train Epoch: 3 [3470/3978 (87%)]\tLoss: 0.884335\n",
            "Train Epoch: 3 [3471/3978 (87%)]\tLoss: 0.371702\n",
            "Train Epoch: 3 [3472/3978 (87%)]\tLoss: 1.068419\n",
            "Train Epoch: 3 [3473/3978 (87%)]\tLoss: 1.391369\n",
            "Train Epoch: 3 [3474/3978 (87%)]\tLoss: 1.348375\n",
            "Train Epoch: 3 [3475/3978 (87%)]\tLoss: 0.539013\n",
            "Train Epoch: 3 [3476/3978 (87%)]\tLoss: 0.000551\n",
            "Train Epoch: 3 [3477/3978 (87%)]\tLoss: 0.022977\n",
            "Train Epoch: 3 [3478/3978 (87%)]\tLoss: 1.710403\n",
            "Train Epoch: 3 [3479/3978 (87%)]\tLoss: 4.782865\n",
            "Train Epoch: 3 [3480/3978 (87%)]\tLoss: 1.274030\n",
            "Train Epoch: 3 [3481/3978 (88%)]\tLoss: 0.868269\n",
            "Train Epoch: 3 [3482/3978 (88%)]\tLoss: 0.482514\n",
            "Train Epoch: 3 [3483/3978 (88%)]\tLoss: 4.160645\n",
            "Train Epoch: 3 [3484/3978 (88%)]\tLoss: 3.501621\n",
            "Train Epoch: 3 [3485/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3486/3978 (88%)]\tLoss: 4.008676\n",
            "Train Epoch: 3 [3487/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3488/3978 (88%)]\tLoss: 1.472209\n",
            "Train Epoch: 3 [3489/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3490/3978 (88%)]\tLoss: 0.000191\n",
            "Train Epoch: 3 [3491/3978 (88%)]\tLoss: 0.002494\n",
            "Train Epoch: 3 [3492/3978 (88%)]\tLoss: 1.485662\n",
            "Train Epoch: 3 [3493/3978 (88%)]\tLoss: 1.686483\n",
            "Train Epoch: 3 [3494/3978 (88%)]\tLoss: 0.045285\n",
            "Train Epoch: 3 [3495/3978 (88%)]\tLoss: 0.022519\n",
            "Train Epoch: 3 [3496/3978 (88%)]\tLoss: 2.215734\n",
            "Train Epoch: 3 [3497/3978 (88%)]\tLoss: 0.011785\n",
            "Train Epoch: 3 [3498/3978 (88%)]\tLoss: 0.018072\n",
            "Train Epoch: 3 [3499/3978 (88%)]\tLoss: 0.637653\n",
            "Train Epoch: 3 [3500/3978 (88%)]\tLoss: 0.012566\n",
            "Train Epoch: 3 [3501/3978 (88%)]\tLoss: 0.522399\n",
            "Train Epoch: 3 [3502/3978 (88%)]\tLoss: 0.057079\n",
            "Train Epoch: 3 [3503/3978 (88%)]\tLoss: 0.393262\n",
            "Train Epoch: 3 [3504/3978 (88%)]\tLoss: 0.190415\n",
            "Train Epoch: 3 [3505/3978 (88%)]\tLoss: 0.456538\n",
            "Train Epoch: 3 [3506/3978 (88%)]\tLoss: 0.215211\n",
            "Train Epoch: 3 [3507/3978 (88%)]\tLoss: 0.059557\n",
            "Train Epoch: 3 [3508/3978 (88%)]\tLoss: 4.500705\n",
            "Train Epoch: 3 [3509/3978 (88%)]\tLoss: 0.871835\n",
            "Train Epoch: 3 [3510/3978 (88%)]\tLoss: 0.722065\n",
            "Train Epoch: 3 [3511/3978 (88%)]\tLoss: 0.021045\n",
            "Train Epoch: 3 [3512/3978 (88%)]\tLoss: 5.638744\n",
            "Train Epoch: 3 [3513/3978 (88%)]\tLoss: 0.000287\n",
            "Train Epoch: 3 [3514/3978 (88%)]\tLoss: 0.000158\n",
            "Train Epoch: 3 [3515/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3516/3978 (88%)]\tLoss: 2.762421\n",
            "Train Epoch: 3 [3517/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3518/3978 (88%)]\tLoss: 5.458087\n",
            "Train Epoch: 3 [3519/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3520/3978 (88%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3521/3978 (89%)]\tLoss: 2.578239\n",
            "Train Epoch: 3 [3522/3978 (89%)]\tLoss: 1.948562\n",
            "Train Epoch: 3 [3523/3978 (89%)]\tLoss: 1.493361\n",
            "Train Epoch: 3 [3524/3978 (89%)]\tLoss: 0.267014\n",
            "Train Epoch: 3 [3525/3978 (89%)]\tLoss: 0.139910\n",
            "Train Epoch: 3 [3526/3978 (89%)]\tLoss: 0.597947\n",
            "Train Epoch: 3 [3527/3978 (89%)]\tLoss: 0.367914\n",
            "Train Epoch: 3 [3528/3978 (89%)]\tLoss: 1.238524\n",
            "Train Epoch: 3 [3529/3978 (89%)]\tLoss: 0.446909\n",
            "Train Epoch: 3 [3530/3978 (89%)]\tLoss: 1.458896\n",
            "Train Epoch: 3 [3531/3978 (89%)]\tLoss: 0.087461\n",
            "Train Epoch: 3 [3532/3978 (89%)]\tLoss: 0.306268\n",
            "Train Epoch: 3 [3533/3978 (89%)]\tLoss: 0.516544\n",
            "Train Epoch: 3 [3534/3978 (89%)]\tLoss: 0.011924\n",
            "Train Epoch: 3 [3535/3978 (89%)]\tLoss: 0.008897\n",
            "Train Epoch: 3 [3536/3978 (89%)]\tLoss: 1.989548\n",
            "Train Epoch: 3 [3537/3978 (89%)]\tLoss: 0.598093\n",
            "Train Epoch: 3 [3538/3978 (89%)]\tLoss: 2.426725\n",
            "Train Epoch: 3 [3539/3978 (89%)]\tLoss: 0.000501\n",
            "Train Epoch: 3 [3540/3978 (89%)]\tLoss: 1.621588\n",
            "Train Epoch: 3 [3541/3978 (89%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3542/3978 (89%)]\tLoss: 2.304595\n",
            "Train Epoch: 3 [3543/3978 (89%)]\tLoss: 0.000007\n",
            "Train Epoch: 3 [3544/3978 (89%)]\tLoss: 0.000004\n",
            "Train Epoch: 3 [3545/3978 (89%)]\tLoss: 6.714039\n",
            "Train Epoch: 3 [3546/3978 (89%)]\tLoss: 0.108904\n",
            "Train Epoch: 3 [3547/3978 (89%)]\tLoss: 6.522986\n",
            "Train Epoch: 3 [3548/3978 (89%)]\tLoss: 0.116030\n",
            "Train Epoch: 3 [3549/3978 (89%)]\tLoss: 0.251499\n",
            "Train Epoch: 3 [3550/3978 (89%)]\tLoss: 0.010579\n",
            "Train Epoch: 3 [3551/3978 (89%)]\tLoss: 0.797191\n",
            "Train Epoch: 3 [3552/3978 (89%)]\tLoss: 0.055144\n",
            "Train Epoch: 3 [3553/3978 (89%)]\tLoss: 0.775933\n",
            "Train Epoch: 3 [3554/3978 (89%)]\tLoss: 6.918749\n",
            "Train Epoch: 3 [3555/3978 (89%)]\tLoss: 0.007799\n",
            "Train Epoch: 3 [3556/3978 (89%)]\tLoss: 1.581975\n",
            "Train Epoch: 3 [3557/3978 (89%)]\tLoss: 0.202111\n",
            "Train Epoch: 3 [3558/3978 (89%)]\tLoss: 0.025046\n",
            "Train Epoch: 3 [3559/3978 (89%)]\tLoss: 2.193048\n",
            "Train Epoch: 3 [3560/3978 (89%)]\tLoss: 0.179247\n",
            "Train Epoch: 3 [3561/3978 (90%)]\tLoss: 0.001555\n",
            "Train Epoch: 3 [3562/3978 (90%)]\tLoss: 0.522302\n",
            "Train Epoch: 3 [3563/3978 (90%)]\tLoss: 1.921142\n",
            "Train Epoch: 3 [3564/3978 (90%)]\tLoss: 1.978645\n",
            "Train Epoch: 3 [3565/3978 (90%)]\tLoss: 1.942097\n",
            "Train Epoch: 3 [3566/3978 (90%)]\tLoss: 1.924416\n",
            "Train Epoch: 3 [3567/3978 (90%)]\tLoss: 4.539303\n",
            "Train Epoch: 3 [3568/3978 (90%)]\tLoss: 0.270212\n",
            "Train Epoch: 3 [3569/3978 (90%)]\tLoss: 0.387452\n",
            "Train Epoch: 3 [3570/3978 (90%)]\tLoss: 0.714644\n",
            "Train Epoch: 3 [3571/3978 (90%)]\tLoss: 0.695185\n",
            "Train Epoch: 3 [3572/3978 (90%)]\tLoss: 0.994657\n",
            "Train Epoch: 3 [3573/3978 (90%)]\tLoss: 0.000774\n",
            "Train Epoch: 3 [3574/3978 (90%)]\tLoss: 1.490057\n",
            "Train Epoch: 3 [3575/3978 (90%)]\tLoss: 0.139450\n",
            "Train Epoch: 3 [3576/3978 (90%)]\tLoss: 0.030630\n",
            "Train Epoch: 3 [3577/3978 (90%)]\tLoss: 0.490447\n",
            "Train Epoch: 3 [3578/3978 (90%)]\tLoss: 0.273065\n",
            "Train Epoch: 3 [3579/3978 (90%)]\tLoss: 2.634191\n",
            "Train Epoch: 3 [3580/3978 (90%)]\tLoss: 0.056770\n",
            "Train Epoch: 3 [3581/3978 (90%)]\tLoss: 0.351554\n",
            "Train Epoch: 3 [3582/3978 (90%)]\tLoss: 0.253783\n",
            "Train Epoch: 3 [3583/3978 (90%)]\tLoss: 0.002972\n",
            "Train Epoch: 3 [3584/3978 (90%)]\tLoss: 1.457356\n",
            "Train Epoch: 3 [3585/3978 (90%)]\tLoss: 0.893239\n",
            "Train Epoch: 3 [3586/3978 (90%)]\tLoss: 0.358262\n",
            "Train Epoch: 3 [3587/3978 (90%)]\tLoss: 3.690314\n",
            "Train Epoch: 3 [3588/3978 (90%)]\tLoss: 0.005720\n",
            "Train Epoch: 3 [3589/3978 (90%)]\tLoss: 0.431685\n",
            "Train Epoch: 3 [3590/3978 (90%)]\tLoss: 3.721538\n",
            "Train Epoch: 3 [3591/3978 (90%)]\tLoss: 0.874344\n",
            "Train Epoch: 3 [3592/3978 (90%)]\tLoss: 0.432752\n",
            "Train Epoch: 3 [3593/3978 (90%)]\tLoss: 0.271862\n",
            "Train Epoch: 3 [3594/3978 (90%)]\tLoss: 0.094645\n",
            "Train Epoch: 3 [3595/3978 (90%)]\tLoss: 2.395708\n",
            "Train Epoch: 3 [3596/3978 (90%)]\tLoss: 0.000339\n",
            "Train Epoch: 3 [3597/3978 (90%)]\tLoss: 0.769610\n",
            "Train Epoch: 3 [3598/3978 (90%)]\tLoss: 0.154758\n",
            "Train Epoch: 3 [3599/3978 (90%)]\tLoss: 0.000157\n",
            "Train Epoch: 3 [3600/3978 (90%)]\tLoss: 1.290667\n",
            "Train Epoch: 3 [3601/3978 (91%)]\tLoss: 0.000172\n",
            "Train Epoch: 3 [3602/3978 (91%)]\tLoss: 0.101747\n",
            "Train Epoch: 3 [3603/3978 (91%)]\tLoss: 0.073349\n",
            "Train Epoch: 3 [3604/3978 (91%)]\tLoss: 0.810227\n",
            "Train Epoch: 3 [3605/3978 (91%)]\tLoss: 0.012621\n",
            "Train Epoch: 3 [3606/3978 (91%)]\tLoss: 1.866917\n",
            "Train Epoch: 3 [3607/3978 (91%)]\tLoss: 1.237690\n",
            "Train Epoch: 3 [3608/3978 (91%)]\tLoss: 3.477620\n",
            "Train Epoch: 3 [3609/3978 (91%)]\tLoss: 0.038295\n",
            "Train Epoch: 3 [3610/3978 (91%)]\tLoss: 0.125486\n",
            "Train Epoch: 3 [3611/3978 (91%)]\tLoss: 0.051074\n",
            "Train Epoch: 3 [3612/3978 (91%)]\tLoss: 0.000529\n",
            "Train Epoch: 3 [3613/3978 (91%)]\tLoss: 0.092342\n",
            "Train Epoch: 3 [3614/3978 (91%)]\tLoss: 0.697869\n",
            "Train Epoch: 3 [3615/3978 (91%)]\tLoss: 1.781018\n",
            "Train Epoch: 3 [3616/3978 (91%)]\tLoss: 0.238251\n",
            "Train Epoch: 3 [3617/3978 (91%)]\tLoss: 0.133785\n",
            "Train Epoch: 3 [3618/3978 (91%)]\tLoss: 0.098691\n",
            "Train Epoch: 3 [3619/3978 (91%)]\tLoss: 0.914914\n",
            "Train Epoch: 3 [3620/3978 (91%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3621/3978 (91%)]\tLoss: 0.189484\n",
            "Train Epoch: 3 [3622/3978 (91%)]\tLoss: 2.914869\n",
            "Train Epoch: 3 [3623/3978 (91%)]\tLoss: 0.151957\n",
            "Train Epoch: 3 [3624/3978 (91%)]\tLoss: 0.000698\n",
            "Train Epoch: 3 [3625/3978 (91%)]\tLoss: 1.202693\n",
            "Train Epoch: 3 [3626/3978 (91%)]\tLoss: 7.342519\n",
            "Train Epoch: 3 [3627/3978 (91%)]\tLoss: 2.553430\n",
            "Train Epoch: 3 [3628/3978 (91%)]\tLoss: 6.904699\n",
            "Train Epoch: 3 [3629/3978 (91%)]\tLoss: 0.031149\n",
            "Train Epoch: 3 [3630/3978 (91%)]\tLoss: 0.100970\n",
            "Train Epoch: 3 [3631/3978 (91%)]\tLoss: 0.163571\n",
            "Train Epoch: 3 [3632/3978 (91%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3633/3978 (91%)]\tLoss: 1.197451\n",
            "Train Epoch: 3 [3634/3978 (91%)]\tLoss: 0.697718\n",
            "Train Epoch: 3 [3635/3978 (91%)]\tLoss: 0.909999\n",
            "Train Epoch: 3 [3636/3978 (91%)]\tLoss: 1.677993\n",
            "Train Epoch: 3 [3637/3978 (91%)]\tLoss: 0.177842\n",
            "Train Epoch: 3 [3638/3978 (91%)]\tLoss: 0.968019\n",
            "Train Epoch: 3 [3639/3978 (91%)]\tLoss: 0.684987\n",
            "Train Epoch: 3 [3640/3978 (92%)]\tLoss: 1.384384\n",
            "Train Epoch: 3 [3641/3978 (92%)]\tLoss: 0.000011\n",
            "Train Epoch: 3 [3642/3978 (92%)]\tLoss: 0.387080\n",
            "Train Epoch: 3 [3643/3978 (92%)]\tLoss: 0.240616\n",
            "Train Epoch: 3 [3644/3978 (92%)]\tLoss: 1.922086\n",
            "Train Epoch: 3 [3645/3978 (92%)]\tLoss: 2.703247\n",
            "Train Epoch: 3 [3646/3978 (92%)]\tLoss: 1.454731\n",
            "Train Epoch: 3 [3647/3978 (92%)]\tLoss: 1.946956\n",
            "Train Epoch: 3 [3648/3978 (92%)]\tLoss: 1.646080\n",
            "Train Epoch: 3 [3649/3978 (92%)]\tLoss: 1.444068\n",
            "Train Epoch: 3 [3650/3978 (92%)]\tLoss: 0.465559\n",
            "Train Epoch: 3 [3651/3978 (92%)]\tLoss: 0.340662\n",
            "Train Epoch: 3 [3652/3978 (92%)]\tLoss: 0.568369\n",
            "Train Epoch: 3 [3653/3978 (92%)]\tLoss: 0.011931\n",
            "Train Epoch: 3 [3654/3978 (92%)]\tLoss: 0.769167\n",
            "Train Epoch: 3 [3655/3978 (92%)]\tLoss: 0.781392\n",
            "Train Epoch: 3 [3656/3978 (92%)]\tLoss: 0.146780\n",
            "Train Epoch: 3 [3657/3978 (92%)]\tLoss: 0.150887\n",
            "Train Epoch: 3 [3658/3978 (92%)]\tLoss: 1.882417\n",
            "Train Epoch: 3 [3659/3978 (92%)]\tLoss: 0.626725\n",
            "Train Epoch: 3 [3660/3978 (92%)]\tLoss: 0.000024\n",
            "Train Epoch: 3 [3661/3978 (92%)]\tLoss: 0.145664\n",
            "Train Epoch: 3 [3662/3978 (92%)]\tLoss: 0.058069\n",
            "Train Epoch: 3 [3663/3978 (92%)]\tLoss: 1.202907\n",
            "Train Epoch: 3 [3664/3978 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3665/3978 (92%)]\tLoss: 0.544089\n",
            "Train Epoch: 3 [3666/3978 (92%)]\tLoss: 0.490338\n",
            "Train Epoch: 3 [3667/3978 (92%)]\tLoss: 2.516286\n",
            "Train Epoch: 3 [3668/3978 (92%)]\tLoss: 0.017082\n",
            "Train Epoch: 3 [3669/3978 (92%)]\tLoss: 2.208863\n",
            "Train Epoch: 3 [3670/3978 (92%)]\tLoss: 0.726732\n",
            "Train Epoch: 3 [3671/3978 (92%)]\tLoss: 0.510938\n",
            "Train Epoch: 3 [3672/3978 (92%)]\tLoss: 0.141774\n",
            "Train Epoch: 3 [3673/3978 (92%)]\tLoss: 0.136389\n",
            "Train Epoch: 3 [3674/3978 (92%)]\tLoss: 0.096367\n",
            "Train Epoch: 3 [3675/3978 (92%)]\tLoss: 0.019332\n",
            "Train Epoch: 3 [3676/3978 (92%)]\tLoss: 0.103087\n",
            "Train Epoch: 3 [3677/3978 (92%)]\tLoss: 0.491892\n",
            "Train Epoch: 3 [3678/3978 (92%)]\tLoss: 0.187083\n",
            "Train Epoch: 3 [3679/3978 (92%)]\tLoss: 0.215466\n",
            "Train Epoch: 3 [3680/3978 (93%)]\tLoss: 0.298465\n",
            "Train Epoch: 3 [3681/3978 (93%)]\tLoss: 0.000061\n",
            "Train Epoch: 3 [3682/3978 (93%)]\tLoss: 0.286274\n",
            "Train Epoch: 3 [3683/3978 (93%)]\tLoss: 0.236011\n",
            "Train Epoch: 3 [3684/3978 (93%)]\tLoss: 0.156864\n",
            "Train Epoch: 3 [3685/3978 (93%)]\tLoss: 3.870104\n",
            "Train Epoch: 3 [3686/3978 (93%)]\tLoss: 0.249456\n",
            "Train Epoch: 3 [3687/3978 (93%)]\tLoss: 0.078602\n",
            "Train Epoch: 3 [3688/3978 (93%)]\tLoss: 0.197140\n",
            "Train Epoch: 3 [3689/3978 (93%)]\tLoss: 0.109291\n",
            "Train Epoch: 3 [3690/3978 (93%)]\tLoss: 0.171777\n",
            "Train Epoch: 3 [3691/3978 (93%)]\tLoss: 0.266925\n",
            "Train Epoch: 3 [3692/3978 (93%)]\tLoss: 2.557605\n",
            "Train Epoch: 3 [3693/3978 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3694/3978 (93%)]\tLoss: 2.691509\n",
            "Train Epoch: 3 [3695/3978 (93%)]\tLoss: 0.750373\n",
            "Train Epoch: 3 [3696/3978 (93%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3697/3978 (93%)]\tLoss: 0.000026\n",
            "Train Epoch: 3 [3698/3978 (93%)]\tLoss: 0.000210\n",
            "Train Epoch: 3 [3699/3978 (93%)]\tLoss: 0.750439\n",
            "Train Epoch: 3 [3700/3978 (93%)]\tLoss: 0.951975\n",
            "Train Epoch: 3 [3701/3978 (93%)]\tLoss: 0.139385\n",
            "Train Epoch: 3 [3702/3978 (93%)]\tLoss: 0.000907\n",
            "Train Epoch: 3 [3703/3978 (93%)]\tLoss: 0.000102\n",
            "Train Epoch: 3 [3704/3978 (93%)]\tLoss: 1.839010\n",
            "Train Epoch: 3 [3705/3978 (93%)]\tLoss: 0.000135\n",
            "Train Epoch: 3 [3706/3978 (93%)]\tLoss: 0.000010\n",
            "Train Epoch: 3 [3707/3978 (93%)]\tLoss: 0.000005\n",
            "Train Epoch: 3 [3708/3978 (93%)]\tLoss: 0.000115\n",
            "Train Epoch: 3 [3709/3978 (93%)]\tLoss: 0.000087\n",
            "Train Epoch: 3 [3710/3978 (93%)]\tLoss: 2.538150\n",
            "Train Epoch: 3 [3711/3978 (93%)]\tLoss: 1.198023\n",
            "Train Epoch: 3 [3712/3978 (93%)]\tLoss: 2.089530\n",
            "Train Epoch: 3 [3713/3978 (93%)]\tLoss: 1.516752\n",
            "Train Epoch: 3 [3714/3978 (93%)]\tLoss: 1.583801\n",
            "Train Epoch: 3 [3715/3978 (93%)]\tLoss: 1.726416\n",
            "Train Epoch: 3 [3716/3978 (93%)]\tLoss: 0.461590\n",
            "Train Epoch: 3 [3717/3978 (93%)]\tLoss: 0.632325\n",
            "Train Epoch: 3 [3718/3978 (93%)]\tLoss: 1.052022\n",
            "Train Epoch: 3 [3719/3978 (93%)]\tLoss: 0.000006\n",
            "Train Epoch: 3 [3720/3978 (94%)]\tLoss: 1.725134\n",
            "Train Epoch: 3 [3721/3978 (94%)]\tLoss: 0.000003\n",
            "Train Epoch: 3 [3722/3978 (94%)]\tLoss: 1.539747\n",
            "Train Epoch: 3 [3723/3978 (94%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3724/3978 (94%)]\tLoss: 0.003496\n",
            "Train Epoch: 3 [3725/3978 (94%)]\tLoss: 0.000795\n",
            "Train Epoch: 3 [3726/3978 (94%)]\tLoss: 0.545647\n",
            "Train Epoch: 3 [3727/3978 (94%)]\tLoss: 0.053437\n",
            "Train Epoch: 3 [3728/3978 (94%)]\tLoss: 0.861305\n",
            "Train Epoch: 3 [3729/3978 (94%)]\tLoss: 2.780364\n",
            "Train Epoch: 3 [3730/3978 (94%)]\tLoss: 0.730366\n",
            "Train Epoch: 3 [3731/3978 (94%)]\tLoss: 0.000050\n",
            "Train Epoch: 3 [3732/3978 (94%)]\tLoss: 0.153204\n",
            "Train Epoch: 3 [3733/3978 (94%)]\tLoss: 0.291196\n",
            "Train Epoch: 3 [3734/3978 (94%)]\tLoss: 0.019186\n",
            "Train Epoch: 3 [3735/3978 (94%)]\tLoss: 0.001526\n",
            "Train Epoch: 3 [3736/3978 (94%)]\tLoss: 0.107640\n",
            "Train Epoch: 3 [3737/3978 (94%)]\tLoss: 0.722171\n",
            "Train Epoch: 3 [3738/3978 (94%)]\tLoss: 4.499473\n",
            "Train Epoch: 3 [3739/3978 (94%)]\tLoss: 0.000036\n",
            "Train Epoch: 3 [3740/3978 (94%)]\tLoss: 0.013690\n",
            "Train Epoch: 3 [3741/3978 (94%)]\tLoss: 2.144190\n",
            "Train Epoch: 3 [3742/3978 (94%)]\tLoss: 1.491280\n",
            "Train Epoch: 3 [3743/3978 (94%)]\tLoss: 0.090282\n",
            "Train Epoch: 3 [3744/3978 (94%)]\tLoss: 0.460291\n",
            "Train Epoch: 3 [3745/3978 (94%)]\tLoss: 1.796718\n",
            "Train Epoch: 3 [3746/3978 (94%)]\tLoss: 0.181001\n",
            "Train Epoch: 3 [3747/3978 (94%)]\tLoss: 1.834472\n",
            "Train Epoch: 3 [3748/3978 (94%)]\tLoss: 0.158197\n",
            "Train Epoch: 3 [3749/3978 (94%)]\tLoss: 0.668577\n",
            "Train Epoch: 3 [3750/3978 (94%)]\tLoss: 0.997977\n",
            "Train Epoch: 3 [3751/3978 (94%)]\tLoss: 2.573401\n",
            "Train Epoch: 3 [3752/3978 (94%)]\tLoss: 1.439362\n",
            "Train Epoch: 3 [3753/3978 (94%)]\tLoss: 1.281422\n",
            "Train Epoch: 3 [3754/3978 (94%)]\tLoss: 0.535414\n",
            "Train Epoch: 3 [3755/3978 (94%)]\tLoss: 1.427739\n",
            "Train Epoch: 3 [3756/3978 (94%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3757/3978 (94%)]\tLoss: 0.000105\n",
            "Train Epoch: 3 [3758/3978 (94%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3759/3978 (94%)]\tLoss: 0.000008\n",
            "Train Epoch: 3 [3760/3978 (95%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3761/3978 (95%)]\tLoss: 2.643525\n",
            "Train Epoch: 3 [3762/3978 (95%)]\tLoss: 3.162430\n",
            "Train Epoch: 3 [3763/3978 (95%)]\tLoss: 1.603827\n",
            "Train Epoch: 3 [3764/3978 (95%)]\tLoss: 0.000018\n",
            "Train Epoch: 3 [3765/3978 (95%)]\tLoss: 1.129723\n",
            "Train Epoch: 3 [3766/3978 (95%)]\tLoss: 3.369514\n",
            "Train Epoch: 3 [3767/3978 (95%)]\tLoss: 0.308393\n",
            "Train Epoch: 3 [3768/3978 (95%)]\tLoss: 0.009707\n",
            "Train Epoch: 3 [3769/3978 (95%)]\tLoss: 1.170862\n",
            "Train Epoch: 3 [3770/3978 (95%)]\tLoss: 1.561084\n",
            "Train Epoch: 3 [3771/3978 (95%)]\tLoss: 0.000006\n",
            "Train Epoch: 3 [3772/3978 (95%)]\tLoss: 0.886391\n",
            "Train Epoch: 3 [3773/3978 (95%)]\tLoss: 2.078432\n",
            "Train Epoch: 3 [3774/3978 (95%)]\tLoss: 1.973829\n",
            "Train Epoch: 3 [3775/3978 (95%)]\tLoss: 0.237988\n",
            "Train Epoch: 3 [3776/3978 (95%)]\tLoss: 1.540842\n",
            "Train Epoch: 3 [3777/3978 (95%)]\tLoss: 0.067527\n",
            "Train Epoch: 3 [3778/3978 (95%)]\tLoss: 0.883935\n",
            "Train Epoch: 3 [3779/3978 (95%)]\tLoss: 0.055081\n",
            "Train Epoch: 3 [3780/3978 (95%)]\tLoss: 0.144879\n",
            "Train Epoch: 3 [3781/3978 (95%)]\tLoss: 0.000906\n",
            "Train Epoch: 3 [3782/3978 (95%)]\tLoss: 0.091543\n",
            "Train Epoch: 3 [3783/3978 (95%)]\tLoss: 0.002980\n",
            "Train Epoch: 3 [3784/3978 (95%)]\tLoss: 4.234064\n",
            "Train Epoch: 3 [3785/3978 (95%)]\tLoss: 2.204718\n",
            "Train Epoch: 3 [3786/3978 (95%)]\tLoss: 0.515243\n",
            "Train Epoch: 3 [3787/3978 (95%)]\tLoss: 2.433160\n",
            "Train Epoch: 3 [3788/3978 (95%)]\tLoss: 0.179786\n",
            "Train Epoch: 3 [3789/3978 (95%)]\tLoss: 0.906364\n",
            "Train Epoch: 3 [3790/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3791/3978 (95%)]\tLoss: 0.728905\n",
            "Train Epoch: 3 [3792/3978 (95%)]\tLoss: 0.876568\n",
            "Train Epoch: 3 [3793/3978 (95%)]\tLoss: 0.022528\n",
            "Train Epoch: 3 [3794/3978 (95%)]\tLoss: 0.202442\n",
            "Train Epoch: 3 [3795/3978 (95%)]\tLoss: 0.968173\n",
            "Train Epoch: 3 [3796/3978 (95%)]\tLoss: 0.789485\n",
            "Train Epoch: 3 [3797/3978 (95%)]\tLoss: 0.404843\n",
            "Train Epoch: 3 [3798/3978 (95%)]\tLoss: 1.260029\n",
            "Train Epoch: 3 [3799/3978 (96%)]\tLoss: 0.041757\n",
            "Train Epoch: 3 [3800/3978 (96%)]\tLoss: 0.001059\n",
            "Train Epoch: 3 [3801/3978 (96%)]\tLoss: 0.541736\n",
            "Train Epoch: 3 [3802/3978 (96%)]\tLoss: 0.071145\n",
            "Train Epoch: 3 [3803/3978 (96%)]\tLoss: 0.004351\n",
            "Train Epoch: 3 [3804/3978 (96%)]\tLoss: 3.048030\n",
            "Train Epoch: 3 [3805/3978 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3806/3978 (96%)]\tLoss: 0.006676\n",
            "Train Epoch: 3 [3807/3978 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3808/3978 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3809/3978 (96%)]\tLoss: 2.251523\n",
            "Train Epoch: 3 [3810/3978 (96%)]\tLoss: 1.651952\n",
            "Train Epoch: 3 [3811/3978 (96%)]\tLoss: 4.732448\n",
            "Train Epoch: 3 [3812/3978 (96%)]\tLoss: 0.005019\n",
            "Train Epoch: 3 [3813/3978 (96%)]\tLoss: 1.784302\n",
            "Train Epoch: 3 [3814/3978 (96%)]\tLoss: 3.490511\n",
            "Train Epoch: 3 [3815/3978 (96%)]\tLoss: 1.355876\n",
            "Train Epoch: 3 [3816/3978 (96%)]\tLoss: 4.378734\n",
            "Train Epoch: 3 [3817/3978 (96%)]\tLoss: 0.206196\n",
            "Train Epoch: 3 [3818/3978 (96%)]\tLoss: 0.467246\n",
            "Train Epoch: 3 [3819/3978 (96%)]\tLoss: 0.006597\n",
            "Train Epoch: 3 [3820/3978 (96%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3821/3978 (96%)]\tLoss: 0.000331\n",
            "Train Epoch: 3 [3822/3978 (96%)]\tLoss: 0.729887\n",
            "Train Epoch: 3 [3823/3978 (96%)]\tLoss: 1.082870\n",
            "Train Epoch: 3 [3824/3978 (96%)]\tLoss: 0.362093\n",
            "Train Epoch: 3 [3825/3978 (96%)]\tLoss: 0.169604\n",
            "Train Epoch: 3 [3826/3978 (96%)]\tLoss: 0.008702\n",
            "Train Epoch: 3 [3827/3978 (96%)]\tLoss: 2.639588\n",
            "Train Epoch: 3 [3828/3978 (96%)]\tLoss: 1.136813\n",
            "Train Epoch: 3 [3829/3978 (96%)]\tLoss: 1.586884\n",
            "Train Epoch: 3 [3830/3978 (96%)]\tLoss: 0.112026\n",
            "Train Epoch: 3 [3831/3978 (96%)]\tLoss: 0.629155\n",
            "Train Epoch: 3 [3832/3978 (96%)]\tLoss: 0.116600\n",
            "Train Epoch: 3 [3833/3978 (96%)]\tLoss: 0.212815\n",
            "Train Epoch: 3 [3834/3978 (96%)]\tLoss: 4.675574\n",
            "Train Epoch: 3 [3835/3978 (96%)]\tLoss: 0.858563\n",
            "Train Epoch: 3 [3836/3978 (96%)]\tLoss: 0.004939\n",
            "Train Epoch: 3 [3837/3978 (96%)]\tLoss: 0.139451\n",
            "Train Epoch: 3 [3838/3978 (96%)]\tLoss: 0.386301\n",
            "Train Epoch: 3 [3839/3978 (97%)]\tLoss: 0.002265\n",
            "Train Epoch: 3 [3840/3978 (97%)]\tLoss: 0.377814\n",
            "Train Epoch: 3 [3841/3978 (97%)]\tLoss: 0.088272\n",
            "Train Epoch: 3 [3842/3978 (97%)]\tLoss: 0.286328\n",
            "Train Epoch: 3 [3843/3978 (97%)]\tLoss: 0.340984\n",
            "Train Epoch: 3 [3844/3978 (97%)]\tLoss: 0.000019\n",
            "Train Epoch: 3 [3845/3978 (97%)]\tLoss: 0.000672\n",
            "Train Epoch: 3 [3846/3978 (97%)]\tLoss: 2.815512\n",
            "Train Epoch: 3 [3847/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3848/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3849/3978 (97%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3850/3978 (97%)]\tLoss: 0.000039\n",
            "Train Epoch: 3 [3851/3978 (97%)]\tLoss: 0.716447\n",
            "Train Epoch: 3 [3852/3978 (97%)]\tLoss: 0.000014\n",
            "Train Epoch: 3 [3853/3978 (97%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3854/3978 (97%)]\tLoss: 8.643868\n",
            "Train Epoch: 3 [3855/3978 (97%)]\tLoss: 8.541296\n",
            "Train Epoch: 3 [3856/3978 (97%)]\tLoss: 0.175891\n",
            "Train Epoch: 3 [3857/3978 (97%)]\tLoss: 0.067779\n",
            "Train Epoch: 3 [3858/3978 (97%)]\tLoss: 0.000069\n",
            "Train Epoch: 3 [3859/3978 (97%)]\tLoss: 1.353095\n",
            "Train Epoch: 3 [3860/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3861/3978 (97%)]\tLoss: 1.523042\n",
            "Train Epoch: 3 [3862/3978 (97%)]\tLoss: 0.004292\n",
            "Train Epoch: 3 [3863/3978 (97%)]\tLoss: 0.061930\n",
            "Train Epoch: 3 [3864/3978 (97%)]\tLoss: 1.996404\n",
            "Train Epoch: 3 [3865/3978 (97%)]\tLoss: 0.021995\n",
            "Train Epoch: 3 [3866/3978 (97%)]\tLoss: 0.169463\n",
            "Train Epoch: 3 [3867/3978 (97%)]\tLoss: 0.033337\n",
            "Train Epoch: 3 [3868/3978 (97%)]\tLoss: 0.091952\n",
            "Train Epoch: 3 [3869/3978 (97%)]\tLoss: 0.037198\n",
            "Train Epoch: 3 [3870/3978 (97%)]\tLoss: 0.292979\n",
            "Train Epoch: 3 [3871/3978 (97%)]\tLoss: 0.019655\n",
            "Train Epoch: 3 [3872/3978 (97%)]\tLoss: 0.472441\n",
            "Train Epoch: 3 [3873/3978 (97%)]\tLoss: 0.405503\n",
            "Train Epoch: 3 [3874/3978 (97%)]\tLoss: 5.483905\n",
            "Train Epoch: 3 [3875/3978 (97%)]\tLoss: 0.461721\n",
            "Train Epoch: 3 [3876/3978 (97%)]\tLoss: 0.134854\n",
            "Train Epoch: 3 [3877/3978 (97%)]\tLoss: 0.870432\n",
            "Train Epoch: 3 [3878/3978 (97%)]\tLoss: 0.000025\n",
            "Train Epoch: 3 [3879/3978 (98%)]\tLoss: 0.984678\n",
            "Train Epoch: 3 [3880/3978 (98%)]\tLoss: 0.000044\n",
            "Train Epoch: 3 [3881/3978 (98%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3882/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3883/3978 (98%)]\tLoss: 2.505699\n",
            "Train Epoch: 3 [3884/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3885/3978 (98%)]\tLoss: 1.539196\n",
            "Train Epoch: 3 [3886/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3887/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3888/3978 (98%)]\tLoss: 0.904212\n",
            "Train Epoch: 3 [3889/3978 (98%)]\tLoss: 0.001888\n",
            "Train Epoch: 3 [3890/3978 (98%)]\tLoss: 0.099123\n",
            "Train Epoch: 3 [3891/3978 (98%)]\tLoss: 0.155325\n",
            "Train Epoch: 3 [3892/3978 (98%)]\tLoss: 0.033323\n",
            "Train Epoch: 3 [3893/3978 (98%)]\tLoss: 1.121902\n",
            "Train Epoch: 3 [3894/3978 (98%)]\tLoss: 0.631482\n",
            "Train Epoch: 3 [3895/3978 (98%)]\tLoss: 0.414073\n",
            "Train Epoch: 3 [3896/3978 (98%)]\tLoss: 0.735788\n",
            "Train Epoch: 3 [3897/3978 (98%)]\tLoss: 2.728940\n",
            "Train Epoch: 3 [3898/3978 (98%)]\tLoss: 0.374980\n",
            "Train Epoch: 3 [3899/3978 (98%)]\tLoss: 1.001469\n",
            "Train Epoch: 3 [3900/3978 (98%)]\tLoss: 0.794479\n",
            "Train Epoch: 3 [3901/3978 (98%)]\tLoss: 0.166119\n",
            "Train Epoch: 3 [3902/3978 (98%)]\tLoss: 0.468493\n",
            "Train Epoch: 3 [3903/3978 (98%)]\tLoss: 0.669936\n",
            "Train Epoch: 3 [3904/3978 (98%)]\tLoss: 0.160500\n",
            "Train Epoch: 3 [3905/3978 (98%)]\tLoss: 0.017191\n",
            "Train Epoch: 3 [3906/3978 (98%)]\tLoss: 0.000028\n",
            "Train Epoch: 3 [3907/3978 (98%)]\tLoss: 1.943654\n",
            "Train Epoch: 3 [3908/3978 (98%)]\tLoss: 1.619062\n",
            "Train Epoch: 3 [3909/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3910/3978 (98%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3911/3978 (98%)]\tLoss: 0.875768\n",
            "Train Epoch: 3 [3912/3978 (98%)]\tLoss: 0.183094\n",
            "Train Epoch: 3 [3913/3978 (98%)]\tLoss: 1.684927\n",
            "Train Epoch: 3 [3914/3978 (98%)]\tLoss: 0.044421\n",
            "Train Epoch: 3 [3915/3978 (98%)]\tLoss: 0.000261\n",
            "Train Epoch: 3 [3916/3978 (98%)]\tLoss: 1.828731\n",
            "Train Epoch: 3 [3917/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3918/3978 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3919/3978 (99%)]\tLoss: 2.384632\n",
            "Train Epoch: 3 [3920/3978 (99%)]\tLoss: 2.980722\n",
            "Train Epoch: 3 [3921/3978 (99%)]\tLoss: 0.001226\n",
            "Train Epoch: 3 [3922/3978 (99%)]\tLoss: 0.008904\n",
            "Train Epoch: 3 [3923/3978 (99%)]\tLoss: 0.626329\n",
            "Train Epoch: 3 [3924/3978 (99%)]\tLoss: 0.115737\n",
            "Train Epoch: 3 [3925/3978 (99%)]\tLoss: 2.308621\n",
            "Train Epoch: 3 [3926/3978 (99%)]\tLoss: 0.402142\n",
            "Train Epoch: 3 [3927/3978 (99%)]\tLoss: 0.187847\n",
            "Train Epoch: 3 [3928/3978 (99%)]\tLoss: 0.104683\n",
            "Train Epoch: 3 [3929/3978 (99%)]\tLoss: 0.038203\n",
            "Train Epoch: 3 [3930/3978 (99%)]\tLoss: 2.044315\n",
            "Train Epoch: 3 [3931/3978 (99%)]\tLoss: 0.000043\n",
            "Train Epoch: 3 [3932/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3933/3978 (99%)]\tLoss: 0.000002\n",
            "Train Epoch: 3 [3934/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3935/3978 (99%)]\tLoss: 2.316427\n",
            "Train Epoch: 3 [3936/3978 (99%)]\tLoss: 1.447783\n",
            "Train Epoch: 3 [3937/3978 (99%)]\tLoss: 1.388205\n",
            "Train Epoch: 3 [3938/3978 (99%)]\tLoss: 1.135849\n",
            "Train Epoch: 3 [3939/3978 (99%)]\tLoss: 1.163361\n",
            "Train Epoch: 3 [3940/3978 (99%)]\tLoss: 0.284633\n",
            "Train Epoch: 3 [3941/3978 (99%)]\tLoss: 0.468339\n",
            "Train Epoch: 3 [3942/3978 (99%)]\tLoss: 0.000015\n",
            "Train Epoch: 3 [3943/3978 (99%)]\tLoss: 0.804791\n",
            "Train Epoch: 3 [3944/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3945/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3946/3978 (99%)]\tLoss: 0.000193\n",
            "Train Epoch: 3 [3947/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [3948/3978 (99%)]\tLoss: 2.984341\n",
            "Train Epoch: 3 [3949/3978 (99%)]\tLoss: 2.299146\n",
            "Train Epoch: 3 [3950/3978 (99%)]\tLoss: 2.291573\n",
            "Train Epoch: 3 [3951/3978 (99%)]\tLoss: 0.000005\n",
            "Train Epoch: 3 [3952/3978 (99%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3953/3978 (99%)]\tLoss: 0.000129\n",
            "Train Epoch: 3 [3954/3978 (99%)]\tLoss: 0.898448\n",
            "Train Epoch: 3 [3955/3978 (99%)]\tLoss: 0.408059\n",
            "Train Epoch: 3 [3956/3978 (99%)]\tLoss: 1.183623\n",
            "Train Epoch: 3 [3957/3978 (99%)]\tLoss: 0.847965\n",
            "Train Epoch: 3 [3958/3978 (99%)]\tLoss: 1.041260\n",
            "Train Epoch: 3 [3959/3978 (100%)]\tLoss: 0.000067\n",
            "Train Epoch: 3 [3960/3978 (100%)]\tLoss: 1.288353\n",
            "Train Epoch: 3 [3961/3978 (100%)]\tLoss: 0.001919\n",
            "Train Epoch: 3 [3962/3978 (100%)]\tLoss: 0.352800\n",
            "Train Epoch: 3 [3963/3978 (100%)]\tLoss: 0.316761\n",
            "Train Epoch: 3 [3964/3978 (100%)]\tLoss: 4.062776\n",
            "Train Epoch: 3 [3965/3978 (100%)]\tLoss: 0.388497\n",
            "Train Epoch: 3 [3966/3978 (100%)]\tLoss: 1.376288\n",
            "Train Epoch: 3 [3967/3978 (100%)]\tLoss: 1.424370\n",
            "Train Epoch: 3 [3968/3978 (100%)]\tLoss: 1.924957\n",
            "Train Epoch: 3 [3969/3978 (100%)]\tLoss: 0.000001\n",
            "Train Epoch: 3 [3970/3978 (100%)]\tLoss: 1.501979\n",
            "Train Epoch: 3 [3971/3978 (100%)]\tLoss: 0.018276\n",
            "Train Epoch: 3 [3972/3978 (100%)]\tLoss: 0.042531\n",
            "Train Epoch: 3 [3973/3978 (100%)]\tLoss: 0.003634\n",
            "Train Epoch: 3 [3974/3978 (100%)]\tLoss: 0.405680\n",
            "Train Epoch: 3 [3975/3978 (100%)]\tLoss: 0.006199\n",
            "Train Epoch: 3 [3976/3978 (100%)]\tLoss: 0.010787\n",
            "Train Epoch: 3 [3977/3978 (100%)]\tLoss: 0.115791\n",
            "Epoch\n",
            "train/train_loss: 0.11579092592000961\n",
            "\n",
            "Train Loss: 0.116, Valid Loss: 0.658171, Accuracy: 0.36\n",
            "Train Epoch: 4 [0/3978 (0%)]\tLoss: 1.370546\n",
            "Train Epoch: 4 [1/3978 (0%)]\tLoss: 0.000119\n",
            "Train Epoch: 4 [2/3978 (0%)]\tLoss: 0.018953\n",
            "Train Epoch: 4 [3/3978 (0%)]\tLoss: 0.022582\n",
            "Train Epoch: 4 [4/3978 (0%)]\tLoss: 0.001186\n",
            "Train Epoch: 4 [5/3978 (0%)]\tLoss: 3.169249\n",
            "Train Epoch: 4 [6/3978 (0%)]\tLoss: 0.319457\n",
            "Train Epoch: 4 [7/3978 (0%)]\tLoss: 0.672646\n",
            "Train Epoch: 4 [8/3978 (0%)]\tLoss: 0.579997\n",
            "Train Epoch: 4 [9/3978 (0%)]\tLoss: 0.022855\n",
            "Train Epoch: 4 [10/3978 (0%)]\tLoss: 0.128488\n",
            "Train Epoch: 4 [11/3978 (0%)]\tLoss: 0.009406\n",
            "Train Epoch: 4 [12/3978 (0%)]\tLoss: 0.802696\n",
            "Train Epoch: 4 [13/3978 (0%)]\tLoss: 3.449658\n",
            "Train Epoch: 4 [14/3978 (0%)]\tLoss: 0.041498\n",
            "Train Epoch: 4 [15/3978 (0%)]\tLoss: 2.319977\n",
            "Train Epoch: 4 [16/3978 (0%)]\tLoss: 0.002487\n",
            "Train Epoch: 4 [17/3978 (0%)]\tLoss: 0.027312\n",
            "Train Epoch: 4 [18/3978 (0%)]\tLoss: 0.284198\n",
            "Train Epoch: 4 [19/3978 (0%)]\tLoss: 3.602283\n",
            "Train Epoch: 4 [20/3978 (1%)]\tLoss: 0.014400\n",
            "Train Epoch: 4 [21/3978 (1%)]\tLoss: 0.505402\n",
            "Train Epoch: 4 [22/3978 (1%)]\tLoss: 0.119477\n",
            "Train Epoch: 4 [23/3978 (1%)]\tLoss: 0.003967\n",
            "Train Epoch: 4 [24/3978 (1%)]\tLoss: 0.000248\n",
            "Train Epoch: 4 [25/3978 (1%)]\tLoss: 1.023572\n",
            "Train Epoch: 4 [26/3978 (1%)]\tLoss: 0.000024\n",
            "Train Epoch: 4 [27/3978 (1%)]\tLoss: 0.737092\n",
            "Train Epoch: 4 [28/3978 (1%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [29/3978 (1%)]\tLoss: 0.169552\n",
            "Train Epoch: 4 [30/3978 (1%)]\tLoss: 0.030745\n",
            "Train Epoch: 4 [31/3978 (1%)]\tLoss: 0.026131\n",
            "Train Epoch: 4 [32/3978 (1%)]\tLoss: 0.386101\n",
            "Train Epoch: 4 [33/3978 (1%)]\tLoss: 1.309097\n",
            "Train Epoch: 4 [34/3978 (1%)]\tLoss: 0.750167\n",
            "Train Epoch: 4 [35/3978 (1%)]\tLoss: 0.475837\n",
            "Train Epoch: 4 [36/3978 (1%)]\tLoss: 2.352399\n",
            "Train Epoch: 4 [37/3978 (1%)]\tLoss: 1.052587\n",
            "Train Epoch: 4 [38/3978 (1%)]\tLoss: 0.000120\n",
            "Train Epoch: 4 [39/3978 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [40/3978 (1%)]\tLoss: 2.120293\n",
            "Train Epoch: 4 [41/3978 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [42/3978 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [43/3978 (1%)]\tLoss: 1.204419\n",
            "Train Epoch: 4 [44/3978 (1%)]\tLoss: 0.414638\n",
            "Train Epoch: 4 [45/3978 (1%)]\tLoss: 1.053639\n",
            "Train Epoch: 4 [46/3978 (1%)]\tLoss: 0.067360\n",
            "Train Epoch: 4 [47/3978 (1%)]\tLoss: 0.186088\n",
            "Train Epoch: 4 [48/3978 (1%)]\tLoss: 0.717358\n",
            "Train Epoch: 4 [49/3978 (1%)]\tLoss: 1.368575\n",
            "Train Epoch: 4 [50/3978 (1%)]\tLoss: 0.552949\n",
            "Train Epoch: 4 [51/3978 (1%)]\tLoss: 0.487729\n",
            "Train Epoch: 4 [52/3978 (1%)]\tLoss: 0.006232\n",
            "Train Epoch: 4 [53/3978 (1%)]\tLoss: 1.334889\n",
            "Train Epoch: 4 [54/3978 (1%)]\tLoss: 0.962842\n",
            "Train Epoch: 4 [55/3978 (1%)]\tLoss: 0.000602\n",
            "Train Epoch: 4 [56/3978 (1%)]\tLoss: 0.000057\n",
            "Train Epoch: 4 [57/3978 (1%)]\tLoss: 0.712314\n",
            "Train Epoch: 4 [58/3978 (1%)]\tLoss: 0.143679\n",
            "Train Epoch: 4 [59/3978 (1%)]\tLoss: 1.839668\n",
            "Train Epoch: 4 [60/3978 (2%)]\tLoss: 0.238187\n",
            "Train Epoch: 4 [61/3978 (2%)]\tLoss: 0.066431\n",
            "Train Epoch: 4 [62/3978 (2%)]\tLoss: 4.208993\n",
            "Train Epoch: 4 [63/3978 (2%)]\tLoss: 1.000335\n",
            "Train Epoch: 4 [64/3978 (2%)]\tLoss: 0.072544\n",
            "Train Epoch: 4 [65/3978 (2%)]\tLoss: 0.239555\n",
            "Train Epoch: 4 [66/3978 (2%)]\tLoss: 0.177569\n",
            "Train Epoch: 4 [67/3978 (2%)]\tLoss: 0.452624\n",
            "Train Epoch: 4 [68/3978 (2%)]\tLoss: 0.395164\n",
            "Train Epoch: 4 [69/3978 (2%)]\tLoss: 0.003855\n",
            "Train Epoch: 4 [70/3978 (2%)]\tLoss: 0.323294\n",
            "Train Epoch: 4 [71/3978 (2%)]\tLoss: 2.308719\n",
            "Train Epoch: 4 [72/3978 (2%)]\tLoss: 0.006832\n",
            "Train Epoch: 4 [73/3978 (2%)]\tLoss: 0.002551\n",
            "Train Epoch: 4 [74/3978 (2%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [75/3978 (2%)]\tLoss: 0.624333\n",
            "Train Epoch: 4 [76/3978 (2%)]\tLoss: 0.000058\n",
            "Train Epoch: 4 [77/3978 (2%)]\tLoss: 0.049361\n",
            "Train Epoch: 4 [78/3978 (2%)]\tLoss: 3.252496\n",
            "Train Epoch: 4 [79/3978 (2%)]\tLoss: 0.064838\n",
            "Train Epoch: 4 [80/3978 (2%)]\tLoss: 0.003368\n",
            "Train Epoch: 4 [81/3978 (2%)]\tLoss: 0.550843\n",
            "Train Epoch: 4 [82/3978 (2%)]\tLoss: 0.130407\n",
            "Train Epoch: 4 [83/3978 (2%)]\tLoss: 0.085407\n",
            "Train Epoch: 4 [84/3978 (2%)]\tLoss: 0.191652\n",
            "Train Epoch: 4 [85/3978 (2%)]\tLoss: 0.058009\n",
            "Train Epoch: 4 [86/3978 (2%)]\tLoss: 0.057379\n",
            "Train Epoch: 4 [87/3978 (2%)]\tLoss: 0.977633\n",
            "Train Epoch: 4 [88/3978 (2%)]\tLoss: 2.844499\n",
            "Train Epoch: 4 [89/3978 (2%)]\tLoss: 0.026535\n",
            "Train Epoch: 4 [90/3978 (2%)]\tLoss: 0.005318\n",
            "Train Epoch: 4 [91/3978 (2%)]\tLoss: 0.948272\n",
            "Train Epoch: 4 [92/3978 (2%)]\tLoss: 0.069748\n",
            "Train Epoch: 4 [93/3978 (2%)]\tLoss: 3.088852\n",
            "Train Epoch: 4 [94/3978 (2%)]\tLoss: 0.186159\n",
            "Train Epoch: 4 [95/3978 (2%)]\tLoss: 1.671997\n",
            "Train Epoch: 4 [96/3978 (2%)]\tLoss: 0.008948\n",
            "Train Epoch: 4 [97/3978 (2%)]\tLoss: 0.242523\n",
            "Train Epoch: 4 [98/3978 (2%)]\tLoss: 4.670773\n",
            "Train Epoch: 4 [99/3978 (2%)]\tLoss: 0.273384\n",
            "Train Epoch: 4 [100/3978 (3%)]\tLoss: 0.127159\n",
            "Train Epoch: 4 [101/3978 (3%)]\tLoss: 0.012471\n",
            "Train Epoch: 4 [102/3978 (3%)]\tLoss: 0.007966\n",
            "Train Epoch: 4 [103/3978 (3%)]\tLoss: 1.729650\n",
            "Train Epoch: 4 [104/3978 (3%)]\tLoss: 1.937661\n",
            "Train Epoch: 4 [105/3978 (3%)]\tLoss: 2.120382\n",
            "Train Epoch: 4 [106/3978 (3%)]\tLoss: 0.002776\n",
            "Train Epoch: 4 [107/3978 (3%)]\tLoss: 0.000091\n",
            "Train Epoch: 4 [108/3978 (3%)]\tLoss: 0.001179\n",
            "Train Epoch: 4 [109/3978 (3%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [110/3978 (3%)]\tLoss: 0.007752\n",
            "Train Epoch: 4 [111/3978 (3%)]\tLoss: 0.068336\n",
            "Train Epoch: 4 [112/3978 (3%)]\tLoss: 0.222074\n",
            "Train Epoch: 4 [113/3978 (3%)]\tLoss: 1.570629\n",
            "Train Epoch: 4 [114/3978 (3%)]\tLoss: 1.004364\n",
            "Train Epoch: 4 [115/3978 (3%)]\tLoss: 0.110581\n",
            "Train Epoch: 4 [116/3978 (3%)]\tLoss: 0.028952\n",
            "Train Epoch: 4 [117/3978 (3%)]\tLoss: 0.390241\n",
            "Train Epoch: 4 [118/3978 (3%)]\tLoss: 1.739970\n",
            "Train Epoch: 4 [119/3978 (3%)]\tLoss: 0.004923\n",
            "Train Epoch: 4 [120/3978 (3%)]\tLoss: 0.021359\n",
            "Train Epoch: 4 [121/3978 (3%)]\tLoss: 0.417631\n",
            "Train Epoch: 4 [122/3978 (3%)]\tLoss: 0.001412\n",
            "Train Epoch: 4 [123/3978 (3%)]\tLoss: 0.502159\n",
            "Train Epoch: 4 [124/3978 (3%)]\tLoss: 0.090881\n",
            "Train Epoch: 4 [125/3978 (3%)]\tLoss: 0.385302\n",
            "Train Epoch: 4 [126/3978 (3%)]\tLoss: 0.671931\n",
            "Train Epoch: 4 [127/3978 (3%)]\tLoss: 0.462015\n",
            "Train Epoch: 4 [128/3978 (3%)]\tLoss: 0.695362\n",
            "Train Epoch: 4 [129/3978 (3%)]\tLoss: 0.019531\n",
            "Train Epoch: 4 [130/3978 (3%)]\tLoss: 0.046573\n",
            "Train Epoch: 4 [131/3978 (3%)]\tLoss: 0.000186\n",
            "Train Epoch: 4 [132/3978 (3%)]\tLoss: 0.395989\n",
            "Train Epoch: 4 [133/3978 (3%)]\tLoss: 0.584652\n",
            "Train Epoch: 4 [134/3978 (3%)]\tLoss: 0.241182\n",
            "Train Epoch: 4 [135/3978 (3%)]\tLoss: 0.543294\n",
            "Train Epoch: 4 [136/3978 (3%)]\tLoss: 0.870191\n",
            "Train Epoch: 4 [137/3978 (3%)]\tLoss: 1.428575\n",
            "Train Epoch: 4 [138/3978 (3%)]\tLoss: 4.023849\n",
            "Train Epoch: 4 [139/3978 (3%)]\tLoss: 1.541395\n",
            "Train Epoch: 4 [140/3978 (4%)]\tLoss: 1.454253\n",
            "Train Epoch: 4 [141/3978 (4%)]\tLoss: 0.718854\n",
            "Train Epoch: 4 [142/3978 (4%)]\tLoss: 0.000042\n",
            "Train Epoch: 4 [143/3978 (4%)]\tLoss: 0.075742\n",
            "Train Epoch: 4 [144/3978 (4%)]\tLoss: 1.599580\n",
            "Train Epoch: 4 [145/3978 (4%)]\tLoss: 1.635381\n",
            "Train Epoch: 4 [146/3978 (4%)]\tLoss: 1.740085\n",
            "Train Epoch: 4 [147/3978 (4%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [148/3978 (4%)]\tLoss: 3.681132\n",
            "Train Epoch: 4 [149/3978 (4%)]\tLoss: 1.051719\n",
            "Train Epoch: 4 [150/3978 (4%)]\tLoss: 0.004844\n",
            "Train Epoch: 4 [151/3978 (4%)]\tLoss: 0.461123\n",
            "Train Epoch: 4 [152/3978 (4%)]\tLoss: 2.033752\n",
            "Train Epoch: 4 [153/3978 (4%)]\tLoss: 0.003928\n",
            "Train Epoch: 4 [154/3978 (4%)]\tLoss: 0.495224\n",
            "Train Epoch: 4 [155/3978 (4%)]\tLoss: 0.856822\n",
            "Train Epoch: 4 [156/3978 (4%)]\tLoss: 0.010466\n",
            "Train Epoch: 4 [157/3978 (4%)]\tLoss: 0.204109\n",
            "Train Epoch: 4 [158/3978 (4%)]\tLoss: 1.826380\n",
            "Train Epoch: 4 [159/3978 (4%)]\tLoss: 0.087817\n",
            "Train Epoch: 4 [160/3978 (4%)]\tLoss: 0.752421\n",
            "Train Epoch: 4 [161/3978 (4%)]\tLoss: 0.340682\n",
            "Train Epoch: 4 [162/3978 (4%)]\tLoss: 0.013602\n",
            "Train Epoch: 4 [163/3978 (4%)]\tLoss: 0.004642\n",
            "Train Epoch: 4 [164/3978 (4%)]\tLoss: 0.000228\n",
            "Train Epoch: 4 [165/3978 (4%)]\tLoss: 1.512806\n",
            "Train Epoch: 4 [166/3978 (4%)]\tLoss: 0.000163\n",
            "Train Epoch: 4 [167/3978 (4%)]\tLoss: 0.000112\n",
            "Train Epoch: 4 [168/3978 (4%)]\tLoss: 1.399993\n",
            "Train Epoch: 4 [169/3978 (4%)]\tLoss: 0.000114\n",
            "Train Epoch: 4 [170/3978 (4%)]\tLoss: 0.494600\n",
            "Train Epoch: 4 [171/3978 (4%)]\tLoss: 0.353000\n",
            "Train Epoch: 4 [172/3978 (4%)]\tLoss: 0.926041\n",
            "Train Epoch: 4 [173/3978 (4%)]\tLoss: 0.298589\n",
            "Train Epoch: 4 [174/3978 (4%)]\tLoss: 0.249476\n",
            "Train Epoch: 4 [175/3978 (4%)]\tLoss: 0.232103\n",
            "Train Epoch: 4 [176/3978 (4%)]\tLoss: 0.012499\n",
            "Train Epoch: 4 [177/3978 (4%)]\tLoss: 0.016605\n",
            "Train Epoch: 4 [178/3978 (4%)]\tLoss: 2.166795\n",
            "Train Epoch: 4 [179/3978 (4%)]\tLoss: 0.044533\n",
            "Train Epoch: 4 [180/3978 (5%)]\tLoss: 0.008785\n",
            "Train Epoch: 4 [181/3978 (5%)]\tLoss: 6.101767\n",
            "Train Epoch: 4 [182/3978 (5%)]\tLoss: 0.005061\n",
            "Train Epoch: 4 [183/3978 (5%)]\tLoss: 3.506194\n",
            "Train Epoch: 4 [184/3978 (5%)]\tLoss: 0.032348\n",
            "Train Epoch: 4 [185/3978 (5%)]\tLoss: 0.122600\n",
            "Train Epoch: 4 [186/3978 (5%)]\tLoss: 0.034471\n",
            "Train Epoch: 4 [187/3978 (5%)]\tLoss: 0.071080\n",
            "Train Epoch: 4 [188/3978 (5%)]\tLoss: 0.908825\n",
            "Train Epoch: 4 [189/3978 (5%)]\tLoss: 0.000185\n",
            "Train Epoch: 4 [190/3978 (5%)]\tLoss: 0.543121\n",
            "Train Epoch: 4 [191/3978 (5%)]\tLoss: 0.004464\n",
            "Train Epoch: 4 [192/3978 (5%)]\tLoss: 0.548094\n",
            "Train Epoch: 4 [193/3978 (5%)]\tLoss: 2.561102\n",
            "Train Epoch: 4 [194/3978 (5%)]\tLoss: 1.237073\n",
            "Train Epoch: 4 [195/3978 (5%)]\tLoss: 5.718154\n",
            "Train Epoch: 4 [196/3978 (5%)]\tLoss: 0.006806\n",
            "Train Epoch: 4 [197/3978 (5%)]\tLoss: 0.250310\n",
            "Train Epoch: 4 [198/3978 (5%)]\tLoss: 0.208765\n",
            "Train Epoch: 4 [199/3978 (5%)]\tLoss: 0.839066\n",
            "Train Epoch: 4 [200/3978 (5%)]\tLoss: 4.847477\n",
            "Train Epoch: 4 [201/3978 (5%)]\tLoss: 2.014257\n",
            "Train Epoch: 4 [202/3978 (5%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [203/3978 (5%)]\tLoss: 0.857979\n",
            "Train Epoch: 4 [204/3978 (5%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [205/3978 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [206/3978 (5%)]\tLoss: 1.055695\n",
            "Train Epoch: 4 [207/3978 (5%)]\tLoss: 1.375630\n",
            "Train Epoch: 4 [208/3978 (5%)]\tLoss: 0.391398\n",
            "Train Epoch: 4 [209/3978 (5%)]\tLoss: 0.244477\n",
            "Train Epoch: 4 [210/3978 (5%)]\tLoss: 2.617730\n",
            "Train Epoch: 4 [211/3978 (5%)]\tLoss: 0.363996\n",
            "Train Epoch: 4 [212/3978 (5%)]\tLoss: 2.041520\n",
            "Train Epoch: 4 [213/3978 (5%)]\tLoss: 0.003712\n",
            "Train Epoch: 4 [214/3978 (5%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [215/3978 (5%)]\tLoss: 0.755272\n",
            "Train Epoch: 4 [216/3978 (5%)]\tLoss: 1.430823\n",
            "Train Epoch: 4 [217/3978 (5%)]\tLoss: 0.293469\n",
            "Train Epoch: 4 [218/3978 (5%)]\tLoss: 1.102901\n",
            "Train Epoch: 4 [219/3978 (6%)]\tLoss: 1.253752\n",
            "Train Epoch: 4 [220/3978 (6%)]\tLoss: 0.794588\n",
            "Train Epoch: 4 [221/3978 (6%)]\tLoss: 0.183261\n",
            "Train Epoch: 4 [222/3978 (6%)]\tLoss: 0.352150\n",
            "Train Epoch: 4 [223/3978 (6%)]\tLoss: 0.972618\n",
            "Train Epoch: 4 [224/3978 (6%)]\tLoss: 1.415452\n",
            "Train Epoch: 4 [225/3978 (6%)]\tLoss: 0.453912\n",
            "Train Epoch: 4 [226/3978 (6%)]\tLoss: 0.010025\n",
            "Train Epoch: 4 [227/3978 (6%)]\tLoss: 0.463582\n",
            "Train Epoch: 4 [228/3978 (6%)]\tLoss: 3.872611\n",
            "Train Epoch: 4 [229/3978 (6%)]\tLoss: 2.344058\n",
            "Train Epoch: 4 [230/3978 (6%)]\tLoss: 0.000130\n",
            "Train Epoch: 4 [231/3978 (6%)]\tLoss: 1.850124\n",
            "Train Epoch: 4 [232/3978 (6%)]\tLoss: 2.525408\n",
            "Train Epoch: 4 [233/3978 (6%)]\tLoss: 0.141085\n",
            "Train Epoch: 4 [234/3978 (6%)]\tLoss: 0.172238\n",
            "Train Epoch: 4 [235/3978 (6%)]\tLoss: 0.195230\n",
            "Train Epoch: 4 [236/3978 (6%)]\tLoss: 5.248675\n",
            "Train Epoch: 4 [237/3978 (6%)]\tLoss: 0.076066\n",
            "Train Epoch: 4 [238/3978 (6%)]\tLoss: 0.317721\n",
            "Train Epoch: 4 [239/3978 (6%)]\tLoss: 0.637607\n",
            "Train Epoch: 4 [240/3978 (6%)]\tLoss: 0.261947\n",
            "Train Epoch: 4 [241/3978 (6%)]\tLoss: 0.010031\n",
            "Train Epoch: 4 [242/3978 (6%)]\tLoss: 3.058482\n",
            "Train Epoch: 4 [243/3978 (6%)]\tLoss: 0.001330\n",
            "Train Epoch: 4 [244/3978 (6%)]\tLoss: 0.763968\n",
            "Train Epoch: 4 [245/3978 (6%)]\tLoss: 4.753793\n",
            "Train Epoch: 4 [246/3978 (6%)]\tLoss: 2.100771\n",
            "Train Epoch: 4 [247/3978 (6%)]\tLoss: 1.724126\n",
            "Train Epoch: 4 [248/3978 (6%)]\tLoss: 0.012049\n",
            "Train Epoch: 4 [249/3978 (6%)]\tLoss: 0.035036\n",
            "Train Epoch: 4 [250/3978 (6%)]\tLoss: 0.466103\n",
            "Train Epoch: 4 [251/3978 (6%)]\tLoss: 0.585373\n",
            "Train Epoch: 4 [252/3978 (6%)]\tLoss: 1.003167\n",
            "Train Epoch: 4 [253/3978 (6%)]\tLoss: 0.405114\n",
            "Train Epoch: 4 [254/3978 (6%)]\tLoss: 0.001188\n",
            "Train Epoch: 4 [255/3978 (6%)]\tLoss: 0.003941\n",
            "Train Epoch: 4 [256/3978 (6%)]\tLoss: 0.649554\n",
            "Train Epoch: 4 [257/3978 (6%)]\tLoss: 0.787810\n",
            "Train Epoch: 4 [258/3978 (6%)]\tLoss: 0.055037\n",
            "Train Epoch: 4 [259/3978 (7%)]\tLoss: 0.091452\n",
            "Train Epoch: 4 [260/3978 (7%)]\tLoss: 0.566850\n",
            "Train Epoch: 4 [261/3978 (7%)]\tLoss: 0.664068\n",
            "Train Epoch: 4 [262/3978 (7%)]\tLoss: 0.000508\n",
            "Train Epoch: 4 [263/3978 (7%)]\tLoss: 2.279673\n",
            "Train Epoch: 4 [264/3978 (7%)]\tLoss: 2.578530\n",
            "Train Epoch: 4 [265/3978 (7%)]\tLoss: 0.003239\n",
            "Train Epoch: 4 [266/3978 (7%)]\tLoss: 0.073964\n",
            "Train Epoch: 4 [267/3978 (7%)]\tLoss: 0.360258\n",
            "Train Epoch: 4 [268/3978 (7%)]\tLoss: 4.580060\n",
            "Train Epoch: 4 [269/3978 (7%)]\tLoss: 0.080689\n",
            "Train Epoch: 4 [270/3978 (7%)]\tLoss: 0.036524\n",
            "Train Epoch: 4 [271/3978 (7%)]\tLoss: 0.788571\n",
            "Train Epoch: 4 [272/3978 (7%)]\tLoss: 0.470675\n",
            "Train Epoch: 4 [273/3978 (7%)]\tLoss: 0.346423\n",
            "Train Epoch: 4 [274/3978 (7%)]\tLoss: 0.011328\n",
            "Train Epoch: 4 [275/3978 (7%)]\tLoss: 1.088942\n",
            "Train Epoch: 4 [276/3978 (7%)]\tLoss: 0.009781\n",
            "Train Epoch: 4 [277/3978 (7%)]\tLoss: 0.123607\n",
            "Train Epoch: 4 [278/3978 (7%)]\tLoss: 0.686864\n",
            "Train Epoch: 4 [279/3978 (7%)]\tLoss: 2.094063\n",
            "Train Epoch: 4 [280/3978 (7%)]\tLoss: 0.007454\n",
            "Train Epoch: 4 [281/3978 (7%)]\tLoss: 0.025746\n",
            "Train Epoch: 4 [282/3978 (7%)]\tLoss: 0.141112\n",
            "Train Epoch: 4 [283/3978 (7%)]\tLoss: 0.007925\n",
            "Train Epoch: 4 [284/3978 (7%)]\tLoss: 1.135208\n",
            "Train Epoch: 4 [285/3978 (7%)]\tLoss: 0.021990\n",
            "Train Epoch: 4 [286/3978 (7%)]\tLoss: 0.508762\n",
            "Train Epoch: 4 [287/3978 (7%)]\tLoss: 0.000249\n",
            "Train Epoch: 4 [288/3978 (7%)]\tLoss: 1.209093\n",
            "Train Epoch: 4 [289/3978 (7%)]\tLoss: 0.992663\n",
            "Train Epoch: 4 [290/3978 (7%)]\tLoss: 1.687474\n",
            "Train Epoch: 4 [291/3978 (7%)]\tLoss: 0.042730\n",
            "Train Epoch: 4 [292/3978 (7%)]\tLoss: 0.605443\n",
            "Train Epoch: 4 [293/3978 (7%)]\tLoss: 0.001517\n",
            "Train Epoch: 4 [294/3978 (7%)]\tLoss: 0.043031\n",
            "Train Epoch: 4 [295/3978 (7%)]\tLoss: 0.202009\n",
            "Train Epoch: 4 [296/3978 (7%)]\tLoss: 0.011598\n",
            "Train Epoch: 4 [297/3978 (7%)]\tLoss: 0.216589\n",
            "Train Epoch: 4 [298/3978 (7%)]\tLoss: 0.027805\n",
            "Train Epoch: 4 [299/3978 (8%)]\tLoss: 0.473174\n",
            "Train Epoch: 4 [300/3978 (8%)]\tLoss: 0.413880\n",
            "Train Epoch: 4 [301/3978 (8%)]\tLoss: 2.680551\n",
            "Train Epoch: 4 [302/3978 (8%)]\tLoss: 0.351485\n",
            "Train Epoch: 4 [303/3978 (8%)]\tLoss: 0.991477\n",
            "Train Epoch: 4 [304/3978 (8%)]\tLoss: 2.727557\n",
            "Train Epoch: 4 [305/3978 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [306/3978 (8%)]\tLoss: 0.209942\n",
            "Train Epoch: 4 [307/3978 (8%)]\tLoss: 0.025831\n",
            "Train Epoch: 4 [308/3978 (8%)]\tLoss: 0.549431\n",
            "Train Epoch: 4 [309/3978 (8%)]\tLoss: 0.418719\n",
            "Train Epoch: 4 [310/3978 (8%)]\tLoss: 0.124376\n",
            "Train Epoch: 4 [311/3978 (8%)]\tLoss: 0.899618\n",
            "Train Epoch: 4 [312/3978 (8%)]\tLoss: 1.111969\n",
            "Train Epoch: 4 [313/3978 (8%)]\tLoss: 0.000130\n",
            "Train Epoch: 4 [314/3978 (8%)]\tLoss: 1.281171\n",
            "Train Epoch: 4 [315/3978 (8%)]\tLoss: 0.797786\n",
            "Train Epoch: 4 [316/3978 (8%)]\tLoss: 1.116756\n",
            "Train Epoch: 4 [317/3978 (8%)]\tLoss: 0.293527\n",
            "Train Epoch: 4 [318/3978 (8%)]\tLoss: 0.044266\n",
            "Train Epoch: 4 [319/3978 (8%)]\tLoss: 0.494968\n",
            "Train Epoch: 4 [320/3978 (8%)]\tLoss: 0.000862\n",
            "Train Epoch: 4 [321/3978 (8%)]\tLoss: 1.601602\n",
            "Train Epoch: 4 [322/3978 (8%)]\tLoss: 1.558464\n",
            "Train Epoch: 4 [323/3978 (8%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [324/3978 (8%)]\tLoss: 1.295563\n",
            "Train Epoch: 4 [325/3978 (8%)]\tLoss: 0.181527\n",
            "Train Epoch: 4 [326/3978 (8%)]\tLoss: 0.278120\n",
            "Train Epoch: 4 [327/3978 (8%)]\tLoss: 2.008854\n",
            "Train Epoch: 4 [328/3978 (8%)]\tLoss: 1.148484\n",
            "Train Epoch: 4 [329/3978 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [330/3978 (8%)]\tLoss: 1.755349\n",
            "Train Epoch: 4 [331/3978 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [332/3978 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [333/3978 (8%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [334/3978 (8%)]\tLoss: 1.159664\n",
            "Train Epoch: 4 [335/3978 (8%)]\tLoss: 1.067508\n",
            "Train Epoch: 4 [336/3978 (8%)]\tLoss: 0.413251\n",
            "Train Epoch: 4 [337/3978 (8%)]\tLoss: 0.080814\n",
            "Train Epoch: 4 [338/3978 (8%)]\tLoss: 0.001827\n",
            "Train Epoch: 4 [339/3978 (9%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [340/3978 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [341/3978 (9%)]\tLoss: 3.222439\n",
            "Train Epoch: 4 [342/3978 (9%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [343/3978 (9%)]\tLoss: 3.747879\n",
            "Train Epoch: 4 [344/3978 (9%)]\tLoss: 2.793632\n",
            "Train Epoch: 4 [345/3978 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [346/3978 (9%)]\tLoss: 3.101408\n",
            "Train Epoch: 4 [347/3978 (9%)]\tLoss: 2.735133\n",
            "Train Epoch: 4 [348/3978 (9%)]\tLoss: 3.326429\n",
            "Train Epoch: 4 [349/3978 (9%)]\tLoss: 0.685860\n",
            "Train Epoch: 4 [350/3978 (9%)]\tLoss: 0.098196\n",
            "Train Epoch: 4 [351/3978 (9%)]\tLoss: 0.004637\n",
            "Train Epoch: 4 [352/3978 (9%)]\tLoss: 0.001915\n",
            "Train Epoch: 4 [353/3978 (9%)]\tLoss: 0.021722\n",
            "Train Epoch: 4 [354/3978 (9%)]\tLoss: 0.074633\n",
            "Train Epoch: 4 [355/3978 (9%)]\tLoss: 2.170990\n",
            "Train Epoch: 4 [356/3978 (9%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [357/3978 (9%)]\tLoss: 3.324415\n",
            "Train Epoch: 4 [358/3978 (9%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [359/3978 (9%)]\tLoss: 4.186528\n",
            "Train Epoch: 4 [360/3978 (9%)]\tLoss: 0.139111\n",
            "Train Epoch: 4 [361/3978 (9%)]\tLoss: 3.561209\n",
            "Train Epoch: 4 [362/3978 (9%)]\tLoss: 0.000781\n",
            "Train Epoch: 4 [363/3978 (9%)]\tLoss: 0.142758\n",
            "Train Epoch: 4 [364/3978 (9%)]\tLoss: 0.457965\n",
            "Train Epoch: 4 [365/3978 (9%)]\tLoss: 0.004112\n",
            "Train Epoch: 4 [366/3978 (9%)]\tLoss: 3.129701\n",
            "Train Epoch: 4 [367/3978 (9%)]\tLoss: 0.002979\n",
            "Train Epoch: 4 [368/3978 (9%)]\tLoss: 0.001015\n",
            "Train Epoch: 4 [369/3978 (9%)]\tLoss: 2.156382\n",
            "Train Epoch: 4 [370/3978 (9%)]\tLoss: 0.381427\n",
            "Train Epoch: 4 [371/3978 (9%)]\tLoss: 1.613931\n",
            "Train Epoch: 4 [372/3978 (9%)]\tLoss: 0.458786\n",
            "Train Epoch: 4 [373/3978 (9%)]\tLoss: 0.064861\n",
            "Train Epoch: 4 [374/3978 (9%)]\tLoss: 0.535552\n",
            "Train Epoch: 4 [375/3978 (9%)]\tLoss: 0.069807\n",
            "Train Epoch: 4 [376/3978 (9%)]\tLoss: 2.854183\n",
            "Train Epoch: 4 [377/3978 (9%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [378/3978 (10%)]\tLoss: 1.783899\n",
            "Train Epoch: 4 [379/3978 (10%)]\tLoss: 1.029104\n",
            "Train Epoch: 4 [380/3978 (10%)]\tLoss: 1.412827\n",
            "Train Epoch: 4 [381/3978 (10%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [382/3978 (10%)]\tLoss: 0.002185\n",
            "Train Epoch: 4 [383/3978 (10%)]\tLoss: 2.459207\n",
            "Train Epoch: 4 [384/3978 (10%)]\tLoss: 3.423147\n",
            "Train Epoch: 4 [385/3978 (10%)]\tLoss: 2.406091\n",
            "Train Epoch: 4 [386/3978 (10%)]\tLoss: 0.000408\n",
            "Train Epoch: 4 [387/3978 (10%)]\tLoss: 0.504790\n",
            "Train Epoch: 4 [388/3978 (10%)]\tLoss: 1.267563\n",
            "Train Epoch: 4 [389/3978 (10%)]\tLoss: 1.304957\n",
            "Train Epoch: 4 [390/3978 (10%)]\tLoss: 0.012199\n",
            "Train Epoch: 4 [391/3978 (10%)]\tLoss: 0.341073\n",
            "Train Epoch: 4 [392/3978 (10%)]\tLoss: 1.990330\n",
            "Train Epoch: 4 [393/3978 (10%)]\tLoss: 0.900725\n",
            "Train Epoch: 4 [394/3978 (10%)]\tLoss: 0.113215\n",
            "Train Epoch: 4 [395/3978 (10%)]\tLoss: 1.084702\n",
            "Train Epoch: 4 [396/3978 (10%)]\tLoss: 0.782513\n",
            "Train Epoch: 4 [397/3978 (10%)]\tLoss: 1.266989\n",
            "Train Epoch: 4 [398/3978 (10%)]\tLoss: 1.101297\n",
            "Train Epoch: 4 [399/3978 (10%)]\tLoss: 1.658429\n",
            "Train Epoch: 4 [400/3978 (10%)]\tLoss: 0.437460\n",
            "Train Epoch: 4 [401/3978 (10%)]\tLoss: 0.148218\n",
            "Train Epoch: 4 [402/3978 (10%)]\tLoss: 0.003017\n",
            "Train Epoch: 4 [403/3978 (10%)]\tLoss: 1.406203\n",
            "Train Epoch: 4 [404/3978 (10%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [405/3978 (10%)]\tLoss: 1.059910\n",
            "Train Epoch: 4 [406/3978 (10%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [407/3978 (10%)]\tLoss: 0.000132\n",
            "Train Epoch: 4 [408/3978 (10%)]\tLoss: 0.217780\n",
            "Train Epoch: 4 [409/3978 (10%)]\tLoss: 0.008356\n",
            "Train Epoch: 4 [410/3978 (10%)]\tLoss: 2.527778\n",
            "Train Epoch: 4 [411/3978 (10%)]\tLoss: 5.375809\n",
            "Train Epoch: 4 [412/3978 (10%)]\tLoss: 0.705171\n",
            "Train Epoch: 4 [413/3978 (10%)]\tLoss: 1.590317\n",
            "Train Epoch: 4 [414/3978 (10%)]\tLoss: 2.303774\n",
            "Train Epoch: 4 [415/3978 (10%)]\tLoss: 0.087093\n",
            "Train Epoch: 4 [416/3978 (10%)]\tLoss: 0.020328\n",
            "Train Epoch: 4 [417/3978 (10%)]\tLoss: 0.356914\n",
            "Train Epoch: 4 [418/3978 (11%)]\tLoss: 2.646883\n",
            "Train Epoch: 4 [419/3978 (11%)]\tLoss: 0.009668\n",
            "Train Epoch: 4 [420/3978 (11%)]\tLoss: 0.480481\n",
            "Train Epoch: 4 [421/3978 (11%)]\tLoss: 0.044883\n",
            "Train Epoch: 4 [422/3978 (11%)]\tLoss: 0.577082\n",
            "Train Epoch: 4 [423/3978 (11%)]\tLoss: 0.565401\n",
            "Train Epoch: 4 [424/3978 (11%)]\tLoss: 0.592544\n",
            "Train Epoch: 4 [425/3978 (11%)]\tLoss: 0.012723\n",
            "Train Epoch: 4 [426/3978 (11%)]\tLoss: 1.537832\n",
            "Train Epoch: 4 [427/3978 (11%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [428/3978 (11%)]\tLoss: 3.160454\n",
            "Train Epoch: 4 [429/3978 (11%)]\tLoss: 0.925651\n",
            "Train Epoch: 4 [430/3978 (11%)]\tLoss: 0.888257\n",
            "Train Epoch: 4 [431/3978 (11%)]\tLoss: 0.448284\n",
            "Train Epoch: 4 [432/3978 (11%)]\tLoss: 0.170703\n",
            "Train Epoch: 4 [433/3978 (11%)]\tLoss: 0.507227\n",
            "Train Epoch: 4 [434/3978 (11%)]\tLoss: 0.036000\n",
            "Train Epoch: 4 [435/3978 (11%)]\tLoss: 0.559346\n",
            "Train Epoch: 4 [436/3978 (11%)]\tLoss: 0.102006\n",
            "Train Epoch: 4 [437/3978 (11%)]\tLoss: 0.024389\n",
            "Train Epoch: 4 [438/3978 (11%)]\tLoss: 0.021576\n",
            "Train Epoch: 4 [439/3978 (11%)]\tLoss: 0.030365\n",
            "Train Epoch: 4 [440/3978 (11%)]\tLoss: 1.815092\n",
            "Train Epoch: 4 [441/3978 (11%)]\tLoss: 0.000135\n",
            "Train Epoch: 4 [442/3978 (11%)]\tLoss: 0.579355\n",
            "Train Epoch: 4 [443/3978 (11%)]\tLoss: 0.040485\n",
            "Train Epoch: 4 [444/3978 (11%)]\tLoss: 0.023489\n",
            "Train Epoch: 4 [445/3978 (11%)]\tLoss: 0.341204\n",
            "Train Epoch: 4 [446/3978 (11%)]\tLoss: 3.487792\n",
            "Train Epoch: 4 [447/3978 (11%)]\tLoss: 0.060288\n",
            "Train Epoch: 4 [448/3978 (11%)]\tLoss: 0.181100\n",
            "Train Epoch: 4 [449/3978 (11%)]\tLoss: 0.360641\n",
            "Train Epoch: 4 [450/3978 (11%)]\tLoss: 1.092523\n",
            "Train Epoch: 4 [451/3978 (11%)]\tLoss: 2.914005\n",
            "Train Epoch: 4 [452/3978 (11%)]\tLoss: 2.649398\n",
            "Train Epoch: 4 [453/3978 (11%)]\tLoss: 0.009697\n",
            "Train Epoch: 4 [454/3978 (11%)]\tLoss: 0.000047\n",
            "Train Epoch: 4 [455/3978 (11%)]\tLoss: 1.573396\n",
            "Train Epoch: 4 [456/3978 (11%)]\tLoss: 5.730342\n",
            "Train Epoch: 4 [457/3978 (11%)]\tLoss: 0.150786\n",
            "Train Epoch: 4 [458/3978 (12%)]\tLoss: 0.420748\n",
            "Train Epoch: 4 [459/3978 (12%)]\tLoss: 0.318203\n",
            "Train Epoch: 4 [460/3978 (12%)]\tLoss: 0.024230\n",
            "Train Epoch: 4 [461/3978 (12%)]\tLoss: 2.272887\n",
            "Train Epoch: 4 [462/3978 (12%)]\tLoss: 2.504329\n",
            "Train Epoch: 4 [463/3978 (12%)]\tLoss: 0.348702\n",
            "Train Epoch: 4 [464/3978 (12%)]\tLoss: 0.012280\n",
            "Train Epoch: 4 [465/3978 (12%)]\tLoss: 0.013575\n",
            "Train Epoch: 4 [466/3978 (12%)]\tLoss: 0.000108\n",
            "Train Epoch: 4 [467/3978 (12%)]\tLoss: 0.057234\n",
            "Train Epoch: 4 [468/3978 (12%)]\tLoss: 0.002203\n",
            "Train Epoch: 4 [469/3978 (12%)]\tLoss: 0.000245\n",
            "Train Epoch: 4 [470/3978 (12%)]\tLoss: 0.922507\n",
            "Train Epoch: 4 [471/3978 (12%)]\tLoss: 0.165490\n",
            "Train Epoch: 4 [472/3978 (12%)]\tLoss: 0.017025\n",
            "Train Epoch: 4 [473/3978 (12%)]\tLoss: 0.627748\n",
            "Train Epoch: 4 [474/3978 (12%)]\tLoss: 6.022664\n",
            "Train Epoch: 4 [475/3978 (12%)]\tLoss: 0.153864\n",
            "Train Epoch: 4 [476/3978 (12%)]\tLoss: 3.750195\n",
            "Train Epoch: 4 [477/3978 (12%)]\tLoss: 0.082638\n",
            "Train Epoch: 4 [478/3978 (12%)]\tLoss: 1.644866\n",
            "Train Epoch: 4 [479/3978 (12%)]\tLoss: 1.589513\n",
            "Train Epoch: 4 [480/3978 (12%)]\tLoss: 0.125061\n",
            "Train Epoch: 4 [481/3978 (12%)]\tLoss: 1.193291\n",
            "Train Epoch: 4 [482/3978 (12%)]\tLoss: 0.316867\n",
            "Train Epoch: 4 [483/3978 (12%)]\tLoss: 0.149379\n",
            "Train Epoch: 4 [484/3978 (12%)]\tLoss: 0.713991\n",
            "Train Epoch: 4 [485/3978 (12%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [486/3978 (12%)]\tLoss: 2.600861\n",
            "Train Epoch: 4 [487/3978 (12%)]\tLoss: 1.313083\n",
            "Train Epoch: 4 [488/3978 (12%)]\tLoss: 1.001013\n",
            "Train Epoch: 4 [489/3978 (12%)]\tLoss: 0.105851\n",
            "Train Epoch: 4 [490/3978 (12%)]\tLoss: 0.008892\n",
            "Train Epoch: 4 [491/3978 (12%)]\tLoss: 1.067167\n",
            "Train Epoch: 4 [492/3978 (12%)]\tLoss: 0.479010\n",
            "Train Epoch: 4 [493/3978 (12%)]\tLoss: 2.405585\n",
            "Train Epoch: 4 [494/3978 (12%)]\tLoss: 0.049546\n",
            "Train Epoch: 4 [495/3978 (12%)]\tLoss: 0.001446\n",
            "Train Epoch: 4 [496/3978 (12%)]\tLoss: 4.738629\n",
            "Train Epoch: 4 [497/3978 (12%)]\tLoss: 3.613094\n",
            "Train Epoch: 4 [498/3978 (13%)]\tLoss: 1.263371\n",
            "Train Epoch: 4 [499/3978 (13%)]\tLoss: 0.715308\n",
            "Train Epoch: 4 [500/3978 (13%)]\tLoss: 0.290410\n",
            "Train Epoch: 4 [501/3978 (13%)]\tLoss: 0.374894\n",
            "Train Epoch: 4 [502/3978 (13%)]\tLoss: 0.000271\n",
            "Train Epoch: 4 [503/3978 (13%)]\tLoss: 0.472404\n",
            "Train Epoch: 4 [504/3978 (13%)]\tLoss: 0.433360\n",
            "Train Epoch: 4 [505/3978 (13%)]\tLoss: 0.766708\n",
            "Train Epoch: 4 [506/3978 (13%)]\tLoss: 1.924627\n",
            "Train Epoch: 4 [507/3978 (13%)]\tLoss: 0.209381\n",
            "Train Epoch: 4 [508/3978 (13%)]\tLoss: 0.053655\n",
            "Train Epoch: 4 [509/3978 (13%)]\tLoss: 0.014242\n",
            "Train Epoch: 4 [510/3978 (13%)]\tLoss: 0.081404\n",
            "Train Epoch: 4 [511/3978 (13%)]\tLoss: 0.092139\n",
            "Train Epoch: 4 [512/3978 (13%)]\tLoss: 0.561278\n",
            "Train Epoch: 4 [513/3978 (13%)]\tLoss: 2.331856\n",
            "Train Epoch: 4 [514/3978 (13%)]\tLoss: 0.143102\n",
            "Train Epoch: 4 [515/3978 (13%)]\tLoss: 0.077019\n",
            "Train Epoch: 4 [516/3978 (13%)]\tLoss: 0.416202\n",
            "Train Epoch: 4 [517/3978 (13%)]\tLoss: 0.275879\n",
            "Train Epoch: 4 [518/3978 (13%)]\tLoss: 0.304308\n",
            "Train Epoch: 4 [519/3978 (13%)]\tLoss: 0.001851\n",
            "Train Epoch: 4 [520/3978 (13%)]\tLoss: 0.013576\n",
            "Train Epoch: 4 [521/3978 (13%)]\tLoss: 1.929361\n",
            "Train Epoch: 4 [522/3978 (13%)]\tLoss: 0.465403\n",
            "Train Epoch: 4 [523/3978 (13%)]\tLoss: 3.301699\n",
            "Train Epoch: 4 [524/3978 (13%)]\tLoss: 0.029474\n",
            "Train Epoch: 4 [525/3978 (13%)]\tLoss: 0.894132\n",
            "Train Epoch: 4 [526/3978 (13%)]\tLoss: 0.816968\n",
            "Train Epoch: 4 [527/3978 (13%)]\tLoss: 1.119842\n",
            "Train Epoch: 4 [528/3978 (13%)]\tLoss: 0.611382\n",
            "Train Epoch: 4 [529/3978 (13%)]\tLoss: 0.693927\n",
            "Train Epoch: 4 [530/3978 (13%)]\tLoss: 0.047518\n",
            "Train Epoch: 4 [531/3978 (13%)]\tLoss: 3.564950\n",
            "Train Epoch: 4 [532/3978 (13%)]\tLoss: 0.535349\n",
            "Train Epoch: 4 [533/3978 (13%)]\tLoss: 0.000092\n",
            "Train Epoch: 4 [534/3978 (13%)]\tLoss: 0.000203\n",
            "Train Epoch: 4 [535/3978 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [536/3978 (13%)]\tLoss: 0.002111\n",
            "Train Epoch: 4 [537/3978 (13%)]\tLoss: 0.002062\n",
            "Train Epoch: 4 [538/3978 (14%)]\tLoss: 0.329808\n",
            "Train Epoch: 4 [539/3978 (14%)]\tLoss: 0.103666\n",
            "Train Epoch: 4 [540/3978 (14%)]\tLoss: 1.096482\n",
            "Train Epoch: 4 [541/3978 (14%)]\tLoss: 0.000445\n",
            "Train Epoch: 4 [542/3978 (14%)]\tLoss: 0.000029\n",
            "Train Epoch: 4 [543/3978 (14%)]\tLoss: 1.966486\n",
            "Train Epoch: 4 [544/3978 (14%)]\tLoss: 0.054666\n",
            "Train Epoch: 4 [545/3978 (14%)]\tLoss: 2.652280\n",
            "Train Epoch: 4 [546/3978 (14%)]\tLoss: 0.037452\n",
            "Train Epoch: 4 [547/3978 (14%)]\tLoss: 0.006927\n",
            "Train Epoch: 4 [548/3978 (14%)]\tLoss: 1.973840\n",
            "Train Epoch: 4 [549/3978 (14%)]\tLoss: 1.658407\n",
            "Train Epoch: 4 [550/3978 (14%)]\tLoss: 0.004149\n",
            "Train Epoch: 4 [551/3978 (14%)]\tLoss: 1.513161\n",
            "Train Epoch: 4 [552/3978 (14%)]\tLoss: 0.057771\n",
            "Train Epoch: 4 [553/3978 (14%)]\tLoss: 0.213999\n",
            "Train Epoch: 4 [554/3978 (14%)]\tLoss: 0.251209\n",
            "Train Epoch: 4 [555/3978 (14%)]\tLoss: 0.787862\n",
            "Train Epoch: 4 [556/3978 (14%)]\tLoss: 0.071808\n",
            "Train Epoch: 4 [557/3978 (14%)]\tLoss: 0.000653\n",
            "Train Epoch: 4 [558/3978 (14%)]\tLoss: 1.845919\n",
            "Train Epoch: 4 [559/3978 (14%)]\tLoss: 0.309054\n",
            "Train Epoch: 4 [560/3978 (14%)]\tLoss: 0.015979\n",
            "Train Epoch: 4 [561/3978 (14%)]\tLoss: 0.006849\n",
            "Train Epoch: 4 [562/3978 (14%)]\tLoss: 0.603172\n",
            "Train Epoch: 4 [563/3978 (14%)]\tLoss: 0.002851\n",
            "Train Epoch: 4 [564/3978 (14%)]\tLoss: 0.117245\n",
            "Train Epoch: 4 [565/3978 (14%)]\tLoss: 0.234407\n",
            "Train Epoch: 4 [566/3978 (14%)]\tLoss: 0.038445\n",
            "Train Epoch: 4 [567/3978 (14%)]\tLoss: 0.241759\n",
            "Train Epoch: 4 [568/3978 (14%)]\tLoss: 0.113519\n",
            "Train Epoch: 4 [569/3978 (14%)]\tLoss: 1.437269\n",
            "Train Epoch: 4 [570/3978 (14%)]\tLoss: 0.007454\n",
            "Train Epoch: 4 [571/3978 (14%)]\tLoss: 0.018455\n",
            "Train Epoch: 4 [572/3978 (14%)]\tLoss: 0.573923\n",
            "Train Epoch: 4 [573/3978 (14%)]\tLoss: 0.332584\n",
            "Train Epoch: 4 [574/3978 (14%)]\tLoss: 1.956621\n",
            "Train Epoch: 4 [575/3978 (14%)]\tLoss: 0.174800\n",
            "Train Epoch: 4 [576/3978 (14%)]\tLoss: 0.006693\n",
            "Train Epoch: 4 [577/3978 (15%)]\tLoss: 0.015602\n",
            "Train Epoch: 4 [578/3978 (15%)]\tLoss: 0.059447\n",
            "Train Epoch: 4 [579/3978 (15%)]\tLoss: 0.520625\n",
            "Train Epoch: 4 [580/3978 (15%)]\tLoss: 0.012562\n",
            "Train Epoch: 4 [581/3978 (15%)]\tLoss: 2.118631\n",
            "Train Epoch: 4 [582/3978 (15%)]\tLoss: 0.010610\n",
            "Train Epoch: 4 [583/3978 (15%)]\tLoss: 0.269260\n",
            "Train Epoch: 4 [584/3978 (15%)]\tLoss: 0.058134\n",
            "Train Epoch: 4 [585/3978 (15%)]\tLoss: 3.727316\n",
            "Train Epoch: 4 [586/3978 (15%)]\tLoss: 0.033179\n",
            "Train Epoch: 4 [587/3978 (15%)]\tLoss: 0.006197\n",
            "Train Epoch: 4 [588/3978 (15%)]\tLoss: 2.898583\n",
            "Train Epoch: 4 [589/3978 (15%)]\tLoss: 0.000034\n",
            "Train Epoch: 4 [590/3978 (15%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [591/3978 (15%)]\tLoss: 1.218439\n",
            "Train Epoch: 4 [592/3978 (15%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [593/3978 (15%)]\tLoss: 0.086285\n",
            "Train Epoch: 4 [594/3978 (15%)]\tLoss: 0.011094\n",
            "Train Epoch: 4 [595/3978 (15%)]\tLoss: 0.100619\n",
            "Train Epoch: 4 [596/3978 (15%)]\tLoss: 0.088098\n",
            "Train Epoch: 4 [597/3978 (15%)]\tLoss: 0.278454\n",
            "Train Epoch: 4 [598/3978 (15%)]\tLoss: 1.192606\n",
            "Train Epoch: 4 [599/3978 (15%)]\tLoss: 0.020832\n",
            "Train Epoch: 4 [600/3978 (15%)]\tLoss: 0.539223\n",
            "Train Epoch: 4 [601/3978 (15%)]\tLoss: 0.266201\n",
            "Train Epoch: 4 [602/3978 (15%)]\tLoss: 0.092404\n",
            "Train Epoch: 4 [603/3978 (15%)]\tLoss: 0.177853\n",
            "Train Epoch: 4 [604/3978 (15%)]\tLoss: 5.927787\n",
            "Train Epoch: 4 [605/3978 (15%)]\tLoss: 2.304180\n",
            "Train Epoch: 4 [606/3978 (15%)]\tLoss: 0.797460\n",
            "Train Epoch: 4 [607/3978 (15%)]\tLoss: 0.041250\n",
            "Train Epoch: 4 [608/3978 (15%)]\tLoss: 3.427276\n",
            "Train Epoch: 4 [609/3978 (15%)]\tLoss: 0.076880\n",
            "Train Epoch: 4 [610/3978 (15%)]\tLoss: 0.657793\n",
            "Train Epoch: 4 [611/3978 (15%)]\tLoss: 1.065437\n",
            "Train Epoch: 4 [612/3978 (15%)]\tLoss: 0.000378\n",
            "Train Epoch: 4 [613/3978 (15%)]\tLoss: 0.981754\n",
            "Train Epoch: 4 [614/3978 (15%)]\tLoss: 1.889624\n",
            "Train Epoch: 4 [615/3978 (15%)]\tLoss: 1.193669\n",
            "Train Epoch: 4 [616/3978 (15%)]\tLoss: 0.892685\n",
            "Train Epoch: 4 [617/3978 (16%)]\tLoss: 1.482449\n",
            "Train Epoch: 4 [618/3978 (16%)]\tLoss: 0.101180\n",
            "Train Epoch: 4 [619/3978 (16%)]\tLoss: 0.026189\n",
            "Train Epoch: 4 [620/3978 (16%)]\tLoss: 0.078740\n",
            "Train Epoch: 4 [621/3978 (16%)]\tLoss: 2.865036\n",
            "Train Epoch: 4 [622/3978 (16%)]\tLoss: 2.960991\n",
            "Train Epoch: 4 [623/3978 (16%)]\tLoss: 0.111960\n",
            "Train Epoch: 4 [624/3978 (16%)]\tLoss: 0.033832\n",
            "Train Epoch: 4 [625/3978 (16%)]\tLoss: 0.237441\n",
            "Train Epoch: 4 [626/3978 (16%)]\tLoss: 0.074357\n",
            "Train Epoch: 4 [627/3978 (16%)]\tLoss: 0.688298\n",
            "Train Epoch: 4 [628/3978 (16%)]\tLoss: 0.000195\n",
            "Train Epoch: 4 [629/3978 (16%)]\tLoss: 4.385598\n",
            "Train Epoch: 4 [630/3978 (16%)]\tLoss: 4.354442\n",
            "Train Epoch: 4 [631/3978 (16%)]\tLoss: 0.001611\n",
            "Train Epoch: 4 [632/3978 (16%)]\tLoss: 0.520741\n",
            "Train Epoch: 4 [633/3978 (16%)]\tLoss: 0.396840\n",
            "Train Epoch: 4 [634/3978 (16%)]\tLoss: 0.000802\n",
            "Train Epoch: 4 [635/3978 (16%)]\tLoss: 0.604058\n",
            "Train Epoch: 4 [636/3978 (16%)]\tLoss: 1.154341\n",
            "Train Epoch: 4 [637/3978 (16%)]\tLoss: 0.005310\n",
            "Train Epoch: 4 [638/3978 (16%)]\tLoss: 1.051605\n",
            "Train Epoch: 4 [639/3978 (16%)]\tLoss: 0.986552\n",
            "Train Epoch: 4 [640/3978 (16%)]\tLoss: 0.394556\n",
            "Train Epoch: 4 [641/3978 (16%)]\tLoss: 2.802118\n",
            "Train Epoch: 4 [642/3978 (16%)]\tLoss: 1.429813\n",
            "Train Epoch: 4 [643/3978 (16%)]\tLoss: 0.114770\n",
            "Train Epoch: 4 [644/3978 (16%)]\tLoss: 0.607437\n",
            "Train Epoch: 4 [645/3978 (16%)]\tLoss: 0.017812\n",
            "Train Epoch: 4 [646/3978 (16%)]\tLoss: 1.609770\n",
            "Train Epoch: 4 [647/3978 (16%)]\tLoss: 0.009861\n",
            "Train Epoch: 4 [648/3978 (16%)]\tLoss: 0.000520\n",
            "Train Epoch: 4 [649/3978 (16%)]\tLoss: 1.956713\n",
            "Train Epoch: 4 [650/3978 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [651/3978 (16%)]\tLoss: 0.000136\n",
            "Train Epoch: 4 [652/3978 (16%)]\tLoss: 0.034955\n",
            "Train Epoch: 4 [653/3978 (16%)]\tLoss: 0.838297\n",
            "Train Epoch: 4 [654/3978 (16%)]\tLoss: 1.020526\n",
            "Train Epoch: 4 [655/3978 (16%)]\tLoss: 0.160881\n",
            "Train Epoch: 4 [656/3978 (16%)]\tLoss: 0.107792\n",
            "Train Epoch: 4 [657/3978 (17%)]\tLoss: 0.015211\n",
            "Train Epoch: 4 [658/3978 (17%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [659/3978 (17%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [660/3978 (17%)]\tLoss: 2.503946\n",
            "Train Epoch: 4 [661/3978 (17%)]\tLoss: 4.741405\n",
            "Train Epoch: 4 [662/3978 (17%)]\tLoss: 1.568686\n",
            "Train Epoch: 4 [663/3978 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [664/3978 (17%)]\tLoss: 1.176416\n",
            "Train Epoch: 4 [665/3978 (17%)]\tLoss: 0.002493\n",
            "Train Epoch: 4 [666/3978 (17%)]\tLoss: 0.374328\n",
            "Train Epoch: 4 [667/3978 (17%)]\tLoss: 0.275466\n",
            "Train Epoch: 4 [668/3978 (17%)]\tLoss: 0.009771\n",
            "Train Epoch: 4 [669/3978 (17%)]\tLoss: 1.305291\n",
            "Train Epoch: 4 [670/3978 (17%)]\tLoss: 1.998596\n",
            "Train Epoch: 4 [671/3978 (17%)]\tLoss: 2.103465\n",
            "Train Epoch: 4 [672/3978 (17%)]\tLoss: 1.990670\n",
            "Train Epoch: 4 [673/3978 (17%)]\tLoss: 1.230917\n",
            "Train Epoch: 4 [674/3978 (17%)]\tLoss: 0.391284\n",
            "Train Epoch: 4 [675/3978 (17%)]\tLoss: 0.093173\n",
            "Train Epoch: 4 [676/3978 (17%)]\tLoss: 0.000058\n",
            "Train Epoch: 4 [677/3978 (17%)]\tLoss: 0.949390\n",
            "Train Epoch: 4 [678/3978 (17%)]\tLoss: 1.220391\n",
            "Train Epoch: 4 [679/3978 (17%)]\tLoss: 2.641090\n",
            "Train Epoch: 4 [680/3978 (17%)]\tLoss: 0.294044\n",
            "Train Epoch: 4 [681/3978 (17%)]\tLoss: 0.044877\n",
            "Train Epoch: 4 [682/3978 (17%)]\tLoss: 0.041673\n",
            "Train Epoch: 4 [683/3978 (17%)]\tLoss: 0.708803\n",
            "Train Epoch: 4 [684/3978 (17%)]\tLoss: 0.001571\n",
            "Train Epoch: 4 [685/3978 (17%)]\tLoss: 0.000217\n",
            "Train Epoch: 4 [686/3978 (17%)]\tLoss: 2.597712\n",
            "Train Epoch: 4 [687/3978 (17%)]\tLoss: 0.659451\n",
            "Train Epoch: 4 [688/3978 (17%)]\tLoss: 0.000663\n",
            "Train Epoch: 4 [689/3978 (17%)]\tLoss: 0.043957\n",
            "Train Epoch: 4 [690/3978 (17%)]\tLoss: 3.299423\n",
            "Train Epoch: 4 [691/3978 (17%)]\tLoss: 0.006449\n",
            "Train Epoch: 4 [692/3978 (17%)]\tLoss: 0.136908\n",
            "Train Epoch: 4 [693/3978 (17%)]\tLoss: 0.016167\n",
            "Train Epoch: 4 [694/3978 (17%)]\tLoss: 0.224196\n",
            "Train Epoch: 4 [695/3978 (17%)]\tLoss: 0.072794\n",
            "Train Epoch: 4 [696/3978 (17%)]\tLoss: 0.712470\n",
            "Train Epoch: 4 [697/3978 (18%)]\tLoss: 0.463185\n",
            "Train Epoch: 4 [698/3978 (18%)]\tLoss: 0.076005\n",
            "Train Epoch: 4 [699/3978 (18%)]\tLoss: 0.163666\n",
            "Train Epoch: 4 [700/3978 (18%)]\tLoss: 0.801435\n",
            "Train Epoch: 4 [701/3978 (18%)]\tLoss: 0.779811\n",
            "Train Epoch: 4 [702/3978 (18%)]\tLoss: 5.057693\n",
            "Train Epoch: 4 [703/3978 (18%)]\tLoss: 0.096953\n",
            "Train Epoch: 4 [704/3978 (18%)]\tLoss: 0.390271\n",
            "Train Epoch: 4 [705/3978 (18%)]\tLoss: 3.817083\n",
            "Train Epoch: 4 [706/3978 (18%)]\tLoss: 5.261628\n",
            "Train Epoch: 4 [707/3978 (18%)]\tLoss: 1.850680\n",
            "Train Epoch: 4 [708/3978 (18%)]\tLoss: 0.009241\n",
            "Train Epoch: 4 [709/3978 (18%)]\tLoss: 0.580472\n",
            "Train Epoch: 4 [710/3978 (18%)]\tLoss: 0.386829\n",
            "Train Epoch: 4 [711/3978 (18%)]\tLoss: 4.112857\n",
            "Train Epoch: 4 [712/3978 (18%)]\tLoss: 0.061844\n",
            "Train Epoch: 4 [713/3978 (18%)]\tLoss: 0.877373\n",
            "Train Epoch: 4 [714/3978 (18%)]\tLoss: 0.377297\n",
            "Train Epoch: 4 [715/3978 (18%)]\tLoss: 0.687269\n",
            "Train Epoch: 4 [716/3978 (18%)]\tLoss: 0.801454\n",
            "Train Epoch: 4 [717/3978 (18%)]\tLoss: 0.009430\n",
            "Train Epoch: 4 [718/3978 (18%)]\tLoss: 0.035187\n",
            "Train Epoch: 4 [719/3978 (18%)]\tLoss: 0.748206\n",
            "Train Epoch: 4 [720/3978 (18%)]\tLoss: 0.006555\n",
            "Train Epoch: 4 [721/3978 (18%)]\tLoss: 0.165735\n",
            "Train Epoch: 4 [722/3978 (18%)]\tLoss: 0.274382\n",
            "Train Epoch: 4 [723/3978 (18%)]\tLoss: 0.470878\n",
            "Train Epoch: 4 [724/3978 (18%)]\tLoss: 1.849271\n",
            "Train Epoch: 4 [725/3978 (18%)]\tLoss: 2.586803\n",
            "Train Epoch: 4 [726/3978 (18%)]\tLoss: 0.152309\n",
            "Train Epoch: 4 [727/3978 (18%)]\tLoss: 1.010943\n",
            "Train Epoch: 4 [728/3978 (18%)]\tLoss: 1.315047\n",
            "Train Epoch: 4 [729/3978 (18%)]\tLoss: 0.001290\n",
            "Train Epoch: 4 [730/3978 (18%)]\tLoss: 0.358364\n",
            "Train Epoch: 4 [731/3978 (18%)]\tLoss: 0.210017\n",
            "Train Epoch: 4 [732/3978 (18%)]\tLoss: 0.282839\n",
            "Train Epoch: 4 [733/3978 (18%)]\tLoss: 0.311567\n",
            "Train Epoch: 4 [734/3978 (18%)]\tLoss: 0.045713\n",
            "Train Epoch: 4 [735/3978 (18%)]\tLoss: 0.060789\n",
            "Train Epoch: 4 [736/3978 (19%)]\tLoss: 0.048670\n",
            "Train Epoch: 4 [737/3978 (19%)]\tLoss: 0.919902\n",
            "Train Epoch: 4 [738/3978 (19%)]\tLoss: 0.770589\n",
            "Train Epoch: 4 [739/3978 (19%)]\tLoss: 0.000168\n",
            "Train Epoch: 4 [740/3978 (19%)]\tLoss: 0.200790\n",
            "Train Epoch: 4 [741/3978 (19%)]\tLoss: 0.000083\n",
            "Train Epoch: 4 [742/3978 (19%)]\tLoss: 1.465970\n",
            "Train Epoch: 4 [743/3978 (19%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [744/3978 (19%)]\tLoss: 0.249579\n",
            "Train Epoch: 4 [745/3978 (19%)]\tLoss: 0.000160\n",
            "Train Epoch: 4 [746/3978 (19%)]\tLoss: 1.093429\n",
            "Train Epoch: 4 [747/3978 (19%)]\tLoss: 0.001672\n",
            "Train Epoch: 4 [748/3978 (19%)]\tLoss: 0.410140\n",
            "Train Epoch: 4 [749/3978 (19%)]\tLoss: 1.150980\n",
            "Train Epoch: 4 [750/3978 (19%)]\tLoss: 0.041093\n",
            "Train Epoch: 4 [751/3978 (19%)]\tLoss: 0.631342\n",
            "Train Epoch: 4 [752/3978 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [753/3978 (19%)]\tLoss: 1.916107\n",
            "Train Epoch: 4 [754/3978 (19%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [755/3978 (19%)]\tLoss: 1.140451\n",
            "Train Epoch: 4 [756/3978 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [757/3978 (19%)]\tLoss: 1.283707\n",
            "Train Epoch: 4 [758/3978 (19%)]\tLoss: 1.491705\n",
            "Train Epoch: 4 [759/3978 (19%)]\tLoss: 3.917590\n",
            "Train Epoch: 4 [760/3978 (19%)]\tLoss: 0.250363\n",
            "Train Epoch: 4 [761/3978 (19%)]\tLoss: 0.609205\n",
            "Train Epoch: 4 [762/3978 (19%)]\tLoss: 0.138404\n",
            "Train Epoch: 4 [763/3978 (19%)]\tLoss: 0.068618\n",
            "Train Epoch: 4 [764/3978 (19%)]\tLoss: 0.003401\n",
            "Train Epoch: 4 [765/3978 (19%)]\tLoss: 0.000130\n",
            "Train Epoch: 4 [766/3978 (19%)]\tLoss: 0.251118\n",
            "Train Epoch: 4 [767/3978 (19%)]\tLoss: 1.216803\n",
            "Train Epoch: 4 [768/3978 (19%)]\tLoss: 2.421531\n",
            "Train Epoch: 4 [769/3978 (19%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [770/3978 (19%)]\tLoss: 0.402976\n",
            "Train Epoch: 4 [771/3978 (19%)]\tLoss: 0.001878\n",
            "Train Epoch: 4 [772/3978 (19%)]\tLoss: 3.568250\n",
            "Train Epoch: 4 [773/3978 (19%)]\tLoss: 1.476306\n",
            "Train Epoch: 4 [774/3978 (19%)]\tLoss: 1.528675\n",
            "Train Epoch: 4 [775/3978 (19%)]\tLoss: 0.008205\n",
            "Train Epoch: 4 [776/3978 (20%)]\tLoss: 1.518347\n",
            "Train Epoch: 4 [777/3978 (20%)]\tLoss: 0.004895\n",
            "Train Epoch: 4 [778/3978 (20%)]\tLoss: 1.422174\n",
            "Train Epoch: 4 [779/3978 (20%)]\tLoss: 1.144898\n",
            "Train Epoch: 4 [780/3978 (20%)]\tLoss: 0.170030\n",
            "Train Epoch: 4 [781/3978 (20%)]\tLoss: 0.021838\n",
            "Train Epoch: 4 [782/3978 (20%)]\tLoss: 2.388938\n",
            "Train Epoch: 4 [783/3978 (20%)]\tLoss: 1.306645\n",
            "Train Epoch: 4 [784/3978 (20%)]\tLoss: 0.000267\n",
            "Train Epoch: 4 [785/3978 (20%)]\tLoss: 0.000042\n",
            "Train Epoch: 4 [786/3978 (20%)]\tLoss: 1.282071\n",
            "Train Epoch: 4 [787/3978 (20%)]\tLoss: 0.895179\n",
            "Train Epoch: 4 [788/3978 (20%)]\tLoss: 0.782469\n",
            "Train Epoch: 4 [789/3978 (20%)]\tLoss: 1.206569\n",
            "Train Epoch: 4 [790/3978 (20%)]\tLoss: 0.916924\n",
            "Train Epoch: 4 [791/3978 (20%)]\tLoss: 1.332493\n",
            "Train Epoch: 4 [792/3978 (20%)]\tLoss: 1.550756\n",
            "Train Epoch: 4 [793/3978 (20%)]\tLoss: 1.005655\n",
            "Train Epoch: 4 [794/3978 (20%)]\tLoss: 1.256967\n",
            "Train Epoch: 4 [795/3978 (20%)]\tLoss: 1.134611\n",
            "Train Epoch: 4 [796/3978 (20%)]\tLoss: 3.636971\n",
            "Train Epoch: 4 [797/3978 (20%)]\tLoss: 0.400297\n",
            "Train Epoch: 4 [798/3978 (20%)]\tLoss: 0.038187\n",
            "Train Epoch: 4 [799/3978 (20%)]\tLoss: 0.582463\n",
            "Train Epoch: 4 [800/3978 (20%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [801/3978 (20%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [802/3978 (20%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [803/3978 (20%)]\tLoss: 3.400518\n",
            "Train Epoch: 4 [804/3978 (20%)]\tLoss: 0.135373\n",
            "Train Epoch: 4 [805/3978 (20%)]\tLoss: 0.000029\n",
            "Train Epoch: 4 [806/3978 (20%)]\tLoss: 3.357456\n",
            "Train Epoch: 4 [807/3978 (20%)]\tLoss: 0.006798\n",
            "Train Epoch: 4 [808/3978 (20%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [809/3978 (20%)]\tLoss: 2.133811\n",
            "Train Epoch: 4 [810/3978 (20%)]\tLoss: 2.613041\n",
            "Train Epoch: 4 [811/3978 (20%)]\tLoss: 3.547766\n",
            "Train Epoch: 4 [812/3978 (20%)]\tLoss: 0.571969\n",
            "Train Epoch: 4 [813/3978 (20%)]\tLoss: 0.000334\n",
            "Train Epoch: 4 [814/3978 (20%)]\tLoss: 0.904399\n",
            "Train Epoch: 4 [815/3978 (20%)]\tLoss: 0.667990\n",
            "Train Epoch: 4 [816/3978 (21%)]\tLoss: 0.001589\n",
            "Train Epoch: 4 [817/3978 (21%)]\tLoss: 0.895709\n",
            "Train Epoch: 4 [818/3978 (21%)]\tLoss: 1.122805\n",
            "Train Epoch: 4 [819/3978 (21%)]\tLoss: 0.199891\n",
            "Train Epoch: 4 [820/3978 (21%)]\tLoss: 1.304491\n",
            "Train Epoch: 4 [821/3978 (21%)]\tLoss: 0.060594\n",
            "Train Epoch: 4 [822/3978 (21%)]\tLoss: 0.026984\n",
            "Train Epoch: 4 [823/3978 (21%)]\tLoss: 0.442155\n",
            "Train Epoch: 4 [824/3978 (21%)]\tLoss: 0.772501\n",
            "Train Epoch: 4 [825/3978 (21%)]\tLoss: 0.001154\n",
            "Train Epoch: 4 [826/3978 (21%)]\tLoss: 1.215435\n",
            "Train Epoch: 4 [827/3978 (21%)]\tLoss: 0.003466\n",
            "Train Epoch: 4 [828/3978 (21%)]\tLoss: 0.065522\n",
            "Train Epoch: 4 [829/3978 (21%)]\tLoss: 0.798300\n",
            "Train Epoch: 4 [830/3978 (21%)]\tLoss: 0.054035\n",
            "Train Epoch: 4 [831/3978 (21%)]\tLoss: 0.060293\n",
            "Train Epoch: 4 [832/3978 (21%)]\tLoss: 0.060100\n",
            "Train Epoch: 4 [833/3978 (21%)]\tLoss: 0.016379\n",
            "Train Epoch: 4 [834/3978 (21%)]\tLoss: 3.788343\n",
            "Train Epoch: 4 [835/3978 (21%)]\tLoss: 2.345210\n",
            "Train Epoch: 4 [836/3978 (21%)]\tLoss: 0.002465\n",
            "Train Epoch: 4 [837/3978 (21%)]\tLoss: 1.449293\n",
            "Train Epoch: 4 [838/3978 (21%)]\tLoss: 0.162801\n",
            "Train Epoch: 4 [839/3978 (21%)]\tLoss: 0.441106\n",
            "Train Epoch: 4 [840/3978 (21%)]\tLoss: 0.264924\n",
            "Train Epoch: 4 [841/3978 (21%)]\tLoss: 0.817356\n",
            "Train Epoch: 4 [842/3978 (21%)]\tLoss: 1.481080\n",
            "Train Epoch: 4 [843/3978 (21%)]\tLoss: 0.815172\n",
            "Train Epoch: 4 [844/3978 (21%)]\tLoss: 0.065726\n",
            "Train Epoch: 4 [845/3978 (21%)]\tLoss: 0.501919\n",
            "Train Epoch: 4 [846/3978 (21%)]\tLoss: 5.650999\n",
            "Train Epoch: 4 [847/3978 (21%)]\tLoss: 0.192280\n",
            "Train Epoch: 4 [848/3978 (21%)]\tLoss: 0.930248\n",
            "Train Epoch: 4 [849/3978 (21%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [850/3978 (21%)]\tLoss: 0.066909\n",
            "Train Epoch: 4 [851/3978 (21%)]\tLoss: 0.035706\n",
            "Train Epoch: 4 [852/3978 (21%)]\tLoss: 0.046252\n",
            "Train Epoch: 4 [853/3978 (21%)]\tLoss: 0.006700\n",
            "Train Epoch: 4 [854/3978 (21%)]\tLoss: 1.482885\n",
            "Train Epoch: 4 [855/3978 (21%)]\tLoss: 4.222645\n",
            "Train Epoch: 4 [856/3978 (22%)]\tLoss: 1.168491\n",
            "Train Epoch: 4 [857/3978 (22%)]\tLoss: 0.222536\n",
            "Train Epoch: 4 [858/3978 (22%)]\tLoss: 0.080244\n",
            "Train Epoch: 4 [859/3978 (22%)]\tLoss: 0.390435\n",
            "Train Epoch: 4 [860/3978 (22%)]\tLoss: 1.551366\n",
            "Train Epoch: 4 [861/3978 (22%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [862/3978 (22%)]\tLoss: 0.000060\n",
            "Train Epoch: 4 [863/3978 (22%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [864/3978 (22%)]\tLoss: 1.131070\n",
            "Train Epoch: 4 [865/3978 (22%)]\tLoss: 0.546556\n",
            "Train Epoch: 4 [866/3978 (22%)]\tLoss: 0.001774\n",
            "Train Epoch: 4 [867/3978 (22%)]\tLoss: 0.016997\n",
            "Train Epoch: 4 [868/3978 (22%)]\tLoss: 0.632257\n",
            "Train Epoch: 4 [869/3978 (22%)]\tLoss: 0.476145\n",
            "Train Epoch: 4 [870/3978 (22%)]\tLoss: 0.732494\n",
            "Train Epoch: 4 [871/3978 (22%)]\tLoss: 0.050105\n",
            "Train Epoch: 4 [872/3978 (22%)]\tLoss: 1.217181\n",
            "Train Epoch: 4 [873/3978 (22%)]\tLoss: 1.806979\n",
            "Train Epoch: 4 [874/3978 (22%)]\tLoss: 4.833042\n",
            "Train Epoch: 4 [875/3978 (22%)]\tLoss: 1.195608\n",
            "Train Epoch: 4 [876/3978 (22%)]\tLoss: 0.881935\n",
            "Train Epoch: 4 [877/3978 (22%)]\tLoss: 0.519498\n",
            "Train Epoch: 4 [878/3978 (22%)]\tLoss: 0.564042\n",
            "Train Epoch: 4 [879/3978 (22%)]\tLoss: 0.913599\n",
            "Train Epoch: 4 [880/3978 (22%)]\tLoss: 0.459279\n",
            "Train Epoch: 4 [881/3978 (22%)]\tLoss: 0.147720\n",
            "Train Epoch: 4 [882/3978 (22%)]\tLoss: 0.866404\n",
            "Train Epoch: 4 [883/3978 (22%)]\tLoss: 0.845388\n",
            "Train Epoch: 4 [884/3978 (22%)]\tLoss: 0.000101\n",
            "Train Epoch: 4 [885/3978 (22%)]\tLoss: 0.088925\n",
            "Train Epoch: 4 [886/3978 (22%)]\tLoss: 0.001983\n",
            "Train Epoch: 4 [887/3978 (22%)]\tLoss: 0.083983\n",
            "Train Epoch: 4 [888/3978 (22%)]\tLoss: 2.056255\n",
            "Train Epoch: 4 [889/3978 (22%)]\tLoss: 0.004878\n",
            "Train Epoch: 4 [890/3978 (22%)]\tLoss: 0.047897\n",
            "Train Epoch: 4 [891/3978 (22%)]\tLoss: 0.075385\n",
            "Train Epoch: 4 [892/3978 (22%)]\tLoss: 0.000114\n",
            "Train Epoch: 4 [893/3978 (22%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [894/3978 (22%)]\tLoss: 0.000314\n",
            "Train Epoch: 4 [895/3978 (22%)]\tLoss: 1.027418\n",
            "Train Epoch: 4 [896/3978 (23%)]\tLoss: 1.699058\n",
            "Train Epoch: 4 [897/3978 (23%)]\tLoss: 2.133222\n",
            "Train Epoch: 4 [898/3978 (23%)]\tLoss: 2.387383\n",
            "Train Epoch: 4 [899/3978 (23%)]\tLoss: 0.202052\n",
            "Train Epoch: 4 [900/3978 (23%)]\tLoss: 0.050083\n",
            "Train Epoch: 4 [901/3978 (23%)]\tLoss: 0.013168\n",
            "Train Epoch: 4 [902/3978 (23%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [903/3978 (23%)]\tLoss: 7.530106\n",
            "Train Epoch: 4 [904/3978 (23%)]\tLoss: 1.238028\n",
            "Train Epoch: 4 [905/3978 (23%)]\tLoss: 2.968170\n",
            "Train Epoch: 4 [906/3978 (23%)]\tLoss: 2.369026\n",
            "Train Epoch: 4 [907/3978 (23%)]\tLoss: 0.280225\n",
            "Train Epoch: 4 [908/3978 (23%)]\tLoss: 0.001054\n",
            "Train Epoch: 4 [909/3978 (23%)]\tLoss: 0.934432\n",
            "Train Epoch: 4 [910/3978 (23%)]\tLoss: 2.022724\n",
            "Train Epoch: 4 [911/3978 (23%)]\tLoss: 1.751637\n",
            "Train Epoch: 4 [912/3978 (23%)]\tLoss: 0.582882\n",
            "Train Epoch: 4 [913/3978 (23%)]\tLoss: 1.391704\n",
            "Train Epoch: 4 [914/3978 (23%)]\tLoss: 1.081295\n",
            "Train Epoch: 4 [915/3978 (23%)]\tLoss: 0.050888\n",
            "Train Epoch: 4 [916/3978 (23%)]\tLoss: 5.095480\n",
            "Train Epoch: 4 [917/3978 (23%)]\tLoss: 0.917901\n",
            "Train Epoch: 4 [918/3978 (23%)]\tLoss: 1.550852\n",
            "Train Epoch: 4 [919/3978 (23%)]\tLoss: 0.004167\n",
            "Train Epoch: 4 [920/3978 (23%)]\tLoss: 0.562950\n",
            "Train Epoch: 4 [921/3978 (23%)]\tLoss: 0.053657\n",
            "Train Epoch: 4 [922/3978 (23%)]\tLoss: 0.077513\n",
            "Train Epoch: 4 [923/3978 (23%)]\tLoss: 0.056671\n",
            "Train Epoch: 4 [924/3978 (23%)]\tLoss: 0.963938\n",
            "Train Epoch: 4 [925/3978 (23%)]\tLoss: 0.001849\n",
            "Train Epoch: 4 [926/3978 (23%)]\tLoss: 1.939268\n",
            "Train Epoch: 4 [927/3978 (23%)]\tLoss: 0.770823\n",
            "Train Epoch: 4 [928/3978 (23%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [929/3978 (23%)]\tLoss: 0.823417\n",
            "Train Epoch: 4 [930/3978 (23%)]\tLoss: 0.224748\n",
            "Train Epoch: 4 [931/3978 (23%)]\tLoss: 0.687494\n",
            "Train Epoch: 4 [932/3978 (23%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [933/3978 (23%)]\tLoss: 1.346784\n",
            "Train Epoch: 4 [934/3978 (23%)]\tLoss: 5.609794\n",
            "Train Epoch: 4 [935/3978 (24%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [936/3978 (24%)]\tLoss: 1.664984\n",
            "Train Epoch: 4 [937/3978 (24%)]\tLoss: 3.992446\n",
            "Train Epoch: 4 [938/3978 (24%)]\tLoss: 1.003258\n",
            "Train Epoch: 4 [939/3978 (24%)]\tLoss: 3.451886\n",
            "Train Epoch: 4 [940/3978 (24%)]\tLoss: 2.263649\n",
            "Train Epoch: 4 [941/3978 (24%)]\tLoss: 1.912414\n",
            "Train Epoch: 4 [942/3978 (24%)]\tLoss: 1.053301\n",
            "Train Epoch: 4 [943/3978 (24%)]\tLoss: 0.000418\n",
            "Train Epoch: 4 [944/3978 (24%)]\tLoss: 0.352027\n",
            "Train Epoch: 4 [945/3978 (24%)]\tLoss: 1.301699\n",
            "Train Epoch: 4 [946/3978 (24%)]\tLoss: 0.957672\n",
            "Train Epoch: 4 [947/3978 (24%)]\tLoss: 2.067765\n",
            "Train Epoch: 4 [948/3978 (24%)]\tLoss: 1.224042\n",
            "Train Epoch: 4 [949/3978 (24%)]\tLoss: 0.412564\n",
            "Train Epoch: 4 [950/3978 (24%)]\tLoss: 0.027074\n",
            "Train Epoch: 4 [951/3978 (24%)]\tLoss: 0.000666\n",
            "Train Epoch: 4 [952/3978 (24%)]\tLoss: 1.665011\n",
            "Train Epoch: 4 [953/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [954/3978 (24%)]\tLoss: 1.560579\n",
            "Train Epoch: 4 [955/3978 (24%)]\tLoss: 0.562106\n",
            "Train Epoch: 4 [956/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [957/3978 (24%)]\tLoss: 0.215210\n",
            "Train Epoch: 4 [958/3978 (24%)]\tLoss: 0.537458\n",
            "Train Epoch: 4 [959/3978 (24%)]\tLoss: 0.388526\n",
            "Train Epoch: 4 [960/3978 (24%)]\tLoss: 0.000605\n",
            "Train Epoch: 4 [961/3978 (24%)]\tLoss: 4.951696\n",
            "Train Epoch: 4 [962/3978 (24%)]\tLoss: 0.003006\n",
            "Train Epoch: 4 [963/3978 (24%)]\tLoss: 0.970619\n",
            "Train Epoch: 4 [964/3978 (24%)]\tLoss: 0.137868\n",
            "Train Epoch: 4 [965/3978 (24%)]\tLoss: 0.702269\n",
            "Train Epoch: 4 [966/3978 (24%)]\tLoss: 0.141763\n",
            "Train Epoch: 4 [967/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [968/3978 (24%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [969/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [970/3978 (24%)]\tLoss: 2.320766\n",
            "Train Epoch: 4 [971/3978 (24%)]\tLoss: 3.683698\n",
            "Train Epoch: 4 [972/3978 (24%)]\tLoss: 2.652628\n",
            "Train Epoch: 4 [973/3978 (24%)]\tLoss: 4.714048\n",
            "Train Epoch: 4 [974/3978 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [975/3978 (25%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [976/3978 (25%)]\tLoss: 1.355961\n",
            "Train Epoch: 4 [977/3978 (25%)]\tLoss: 0.000033\n",
            "Train Epoch: 4 [978/3978 (25%)]\tLoss: 1.551423\n",
            "Train Epoch: 4 [979/3978 (25%)]\tLoss: 0.276959\n",
            "Train Epoch: 4 [980/3978 (25%)]\tLoss: 0.090197\n",
            "Train Epoch: 4 [981/3978 (25%)]\tLoss: 0.000847\n",
            "Train Epoch: 4 [982/3978 (25%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [983/3978 (25%)]\tLoss: 1.887092\n",
            "Train Epoch: 4 [984/3978 (25%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [985/3978 (25%)]\tLoss: 1.068304\n",
            "Train Epoch: 4 [986/3978 (25%)]\tLoss: 0.993939\n",
            "Train Epoch: 4 [987/3978 (25%)]\tLoss: 0.757045\n",
            "Train Epoch: 4 [988/3978 (25%)]\tLoss: 0.293596\n",
            "Train Epoch: 4 [989/3978 (25%)]\tLoss: 2.278600\n",
            "Train Epoch: 4 [990/3978 (25%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [991/3978 (25%)]\tLoss: 0.495102\n",
            "Train Epoch: 4 [992/3978 (25%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [993/3978 (25%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [994/3978 (25%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [995/3978 (25%)]\tLoss: 0.000015\n",
            "Train Epoch: 4 [996/3978 (25%)]\tLoss: 0.010834\n",
            "Train Epoch: 4 [997/3978 (25%)]\tLoss: 0.000325\n",
            "Train Epoch: 4 [998/3978 (25%)]\tLoss: 3.221480\n",
            "Train Epoch: 4 [999/3978 (25%)]\tLoss: 0.001784\n",
            "Train Epoch: 4 [1000/3978 (25%)]\tLoss: 4.071534\n",
            "Train Epoch: 4 [1001/3978 (25%)]\tLoss: 3.479464\n",
            "Train Epoch: 4 [1002/3978 (25%)]\tLoss: 1.763324\n",
            "Train Epoch: 4 [1003/3978 (25%)]\tLoss: 0.034004\n",
            "Train Epoch: 4 [1004/3978 (25%)]\tLoss: 1.952782\n",
            "Train Epoch: 4 [1005/3978 (25%)]\tLoss: 0.007235\n",
            "Train Epoch: 4 [1006/3978 (25%)]\tLoss: 0.737526\n",
            "Train Epoch: 4 [1007/3978 (25%)]\tLoss: 1.211334\n",
            "Train Epoch: 4 [1008/3978 (25%)]\tLoss: 0.292916\n",
            "Train Epoch: 4 [1009/3978 (25%)]\tLoss: 0.760913\n",
            "Train Epoch: 4 [1010/3978 (25%)]\tLoss: 1.243090\n",
            "Train Epoch: 4 [1011/3978 (25%)]\tLoss: 0.213006\n",
            "Train Epoch: 4 [1012/3978 (25%)]\tLoss: 0.061641\n",
            "Train Epoch: 4 [1013/3978 (25%)]\tLoss: 0.112612\n",
            "Train Epoch: 4 [1014/3978 (25%)]\tLoss: 0.642135\n",
            "Train Epoch: 4 [1015/3978 (26%)]\tLoss: 0.553356\n",
            "Train Epoch: 4 [1016/3978 (26%)]\tLoss: 0.000080\n",
            "Train Epoch: 4 [1017/3978 (26%)]\tLoss: 0.002057\n",
            "Train Epoch: 4 [1018/3978 (26%)]\tLoss: 0.879012\n",
            "Train Epoch: 4 [1019/3978 (26%)]\tLoss: 0.874053\n",
            "Train Epoch: 4 [1020/3978 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1021/3978 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1022/3978 (26%)]\tLoss: 0.000529\n",
            "Train Epoch: 4 [1023/3978 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1024/3978 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1025/3978 (26%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [1026/3978 (26%)]\tLoss: 0.045459\n",
            "Train Epoch: 4 [1027/3978 (26%)]\tLoss: 0.266557\n",
            "Train Epoch: 4 [1028/3978 (26%)]\tLoss: 0.059686\n",
            "Train Epoch: 4 [1029/3978 (26%)]\tLoss: 0.139503\n",
            "Train Epoch: 4 [1030/3978 (26%)]\tLoss: 6.189027\n",
            "Train Epoch: 4 [1031/3978 (26%)]\tLoss: 0.374219\n",
            "Train Epoch: 4 [1032/3978 (26%)]\tLoss: 0.006327\n",
            "Train Epoch: 4 [1033/3978 (26%)]\tLoss: 0.023280\n",
            "Train Epoch: 4 [1034/3978 (26%)]\tLoss: 0.708086\n",
            "Train Epoch: 4 [1035/3978 (26%)]\tLoss: 2.095911\n",
            "Train Epoch: 4 [1036/3978 (26%)]\tLoss: 0.054099\n",
            "Train Epoch: 4 [1037/3978 (26%)]\tLoss: 0.086813\n",
            "Train Epoch: 4 [1038/3978 (26%)]\tLoss: 0.665987\n",
            "Train Epoch: 4 [1039/3978 (26%)]\tLoss: 0.781737\n",
            "Train Epoch: 4 [1040/3978 (26%)]\tLoss: 0.209373\n",
            "Train Epoch: 4 [1041/3978 (26%)]\tLoss: 4.189262\n",
            "Train Epoch: 4 [1042/3978 (26%)]\tLoss: 0.187262\n",
            "Train Epoch: 4 [1043/3978 (26%)]\tLoss: 1.166035\n",
            "Train Epoch: 4 [1044/3978 (26%)]\tLoss: 0.003833\n",
            "Train Epoch: 4 [1045/3978 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1046/3978 (26%)]\tLoss: 0.820053\n",
            "Train Epoch: 4 [1047/3978 (26%)]\tLoss: 1.369493\n",
            "Train Epoch: 4 [1048/3978 (26%)]\tLoss: 0.002689\n",
            "Train Epoch: 4 [1049/3978 (26%)]\tLoss: 0.311150\n",
            "Train Epoch: 4 [1050/3978 (26%)]\tLoss: 1.441896\n",
            "Train Epoch: 4 [1051/3978 (26%)]\tLoss: 2.603754\n",
            "Train Epoch: 4 [1052/3978 (26%)]\tLoss: 1.612430\n",
            "Train Epoch: 4 [1053/3978 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1054/3978 (26%)]\tLoss: 1.685506\n",
            "Train Epoch: 4 [1055/3978 (27%)]\tLoss: 1.322670\n",
            "Train Epoch: 4 [1056/3978 (27%)]\tLoss: 0.023448\n",
            "Train Epoch: 4 [1057/3978 (27%)]\tLoss: 3.638690\n",
            "Train Epoch: 4 [1058/3978 (27%)]\tLoss: 0.637842\n",
            "Train Epoch: 4 [1059/3978 (27%)]\tLoss: 0.362118\n",
            "Train Epoch: 4 [1060/3978 (27%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [1061/3978 (27%)]\tLoss: 0.807350\n",
            "Train Epoch: 4 [1062/3978 (27%)]\tLoss: 1.768269\n",
            "Train Epoch: 4 [1063/3978 (27%)]\tLoss: 2.725869\n",
            "Train Epoch: 4 [1064/3978 (27%)]\tLoss: 1.948529\n",
            "Train Epoch: 4 [1065/3978 (27%)]\tLoss: 1.459656\n",
            "Train Epoch: 4 [1066/3978 (27%)]\tLoss: 0.001285\n",
            "Train Epoch: 4 [1067/3978 (27%)]\tLoss: 0.732932\n",
            "Train Epoch: 4 [1068/3978 (27%)]\tLoss: 0.089072\n",
            "Train Epoch: 4 [1069/3978 (27%)]\tLoss: 1.066450\n",
            "Train Epoch: 4 [1070/3978 (27%)]\tLoss: 1.137783\n",
            "Train Epoch: 4 [1071/3978 (27%)]\tLoss: 2.320453\n",
            "Train Epoch: 4 [1072/3978 (27%)]\tLoss: 0.027991\n",
            "Train Epoch: 4 [1073/3978 (27%)]\tLoss: 0.010068\n",
            "Train Epoch: 4 [1074/3978 (27%)]\tLoss: 1.102430\n",
            "Train Epoch: 4 [1075/3978 (27%)]\tLoss: 0.428901\n",
            "Train Epoch: 4 [1076/3978 (27%)]\tLoss: 1.403521\n",
            "Train Epoch: 4 [1077/3978 (27%)]\tLoss: 0.039557\n",
            "Train Epoch: 4 [1078/3978 (27%)]\tLoss: 0.299448\n",
            "Train Epoch: 4 [1079/3978 (27%)]\tLoss: 0.714435\n",
            "Train Epoch: 4 [1080/3978 (27%)]\tLoss: 0.975793\n",
            "Train Epoch: 4 [1081/3978 (27%)]\tLoss: 0.712939\n",
            "Train Epoch: 4 [1082/3978 (27%)]\tLoss: 0.223978\n",
            "Train Epoch: 4 [1083/3978 (27%)]\tLoss: 0.371855\n",
            "Train Epoch: 4 [1084/3978 (27%)]\tLoss: 1.856447\n",
            "Train Epoch: 4 [1085/3978 (27%)]\tLoss: 0.122471\n",
            "Train Epoch: 4 [1086/3978 (27%)]\tLoss: 0.003483\n",
            "Train Epoch: 4 [1087/3978 (27%)]\tLoss: 0.000621\n",
            "Train Epoch: 4 [1088/3978 (27%)]\tLoss: 2.508030\n",
            "Train Epoch: 4 [1089/3978 (27%)]\tLoss: 2.004827\n",
            "Train Epoch: 4 [1090/3978 (27%)]\tLoss: 0.000944\n",
            "Train Epoch: 4 [1091/3978 (27%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1092/3978 (27%)]\tLoss: 1.046520\n",
            "Train Epoch: 4 [1093/3978 (27%)]\tLoss: 0.033800\n",
            "Train Epoch: 4 [1094/3978 (28%)]\tLoss: 0.525877\n",
            "Train Epoch: 4 [1095/3978 (28%)]\tLoss: 0.172888\n",
            "Train Epoch: 4 [1096/3978 (28%)]\tLoss: 0.467129\n",
            "Train Epoch: 4 [1097/3978 (28%)]\tLoss: 0.008748\n",
            "Train Epoch: 4 [1098/3978 (28%)]\tLoss: 0.156127\n",
            "Train Epoch: 4 [1099/3978 (28%)]\tLoss: 0.597075\n",
            "Train Epoch: 4 [1100/3978 (28%)]\tLoss: 0.053305\n",
            "Train Epoch: 4 [1101/3978 (28%)]\tLoss: 0.345402\n",
            "Train Epoch: 4 [1102/3978 (28%)]\tLoss: 0.047225\n",
            "Train Epoch: 4 [1103/3978 (28%)]\tLoss: 0.939202\n",
            "Train Epoch: 4 [1104/3978 (28%)]\tLoss: 2.038736\n",
            "Train Epoch: 4 [1105/3978 (28%)]\tLoss: 0.009299\n",
            "Train Epoch: 4 [1106/3978 (28%)]\tLoss: 0.003861\n",
            "Train Epoch: 4 [1107/3978 (28%)]\tLoss: 0.187841\n",
            "Train Epoch: 4 [1108/3978 (28%)]\tLoss: 2.224972\n",
            "Train Epoch: 4 [1109/3978 (28%)]\tLoss: 0.002499\n",
            "Train Epoch: 4 [1110/3978 (28%)]\tLoss: 0.011970\n",
            "Train Epoch: 4 [1111/3978 (28%)]\tLoss: 1.878209\n",
            "Train Epoch: 4 [1112/3978 (28%)]\tLoss: 0.857325\n",
            "Train Epoch: 4 [1113/3978 (28%)]\tLoss: 0.692500\n",
            "Train Epoch: 4 [1114/3978 (28%)]\tLoss: 0.834822\n",
            "Train Epoch: 4 [1115/3978 (28%)]\tLoss: 0.154072\n",
            "Train Epoch: 4 [1116/3978 (28%)]\tLoss: 0.761237\n",
            "Train Epoch: 4 [1117/3978 (28%)]\tLoss: 0.040371\n",
            "Train Epoch: 4 [1118/3978 (28%)]\tLoss: 0.175186\n",
            "Train Epoch: 4 [1119/3978 (28%)]\tLoss: 1.041970\n",
            "Train Epoch: 4 [1120/3978 (28%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1121/3978 (28%)]\tLoss: 0.823265\n",
            "Train Epoch: 4 [1122/3978 (28%)]\tLoss: 1.739078\n",
            "Train Epoch: 4 [1123/3978 (28%)]\tLoss: 0.923043\n",
            "Train Epoch: 4 [1124/3978 (28%)]\tLoss: 0.022821\n",
            "Train Epoch: 4 [1125/3978 (28%)]\tLoss: 3.472635\n",
            "Train Epoch: 4 [1126/3978 (28%)]\tLoss: 0.000018\n",
            "Train Epoch: 4 [1127/3978 (28%)]\tLoss: 3.464146\n",
            "Train Epoch: 4 [1128/3978 (28%)]\tLoss: 1.027935\n",
            "Train Epoch: 4 [1129/3978 (28%)]\tLoss: 2.337502\n",
            "Train Epoch: 4 [1130/3978 (28%)]\tLoss: 1.295351\n",
            "Train Epoch: 4 [1131/3978 (28%)]\tLoss: 0.003427\n",
            "Train Epoch: 4 [1132/3978 (28%)]\tLoss: 0.393269\n",
            "Train Epoch: 4 [1133/3978 (28%)]\tLoss: 0.480720\n",
            "Train Epoch: 4 [1134/3978 (29%)]\tLoss: 0.383517\n",
            "Train Epoch: 4 [1135/3978 (29%)]\tLoss: 0.717038\n",
            "Train Epoch: 4 [1136/3978 (29%)]\tLoss: 0.137007\n",
            "Train Epoch: 4 [1137/3978 (29%)]\tLoss: 2.554810\n",
            "Train Epoch: 4 [1138/3978 (29%)]\tLoss: 0.001295\n",
            "Train Epoch: 4 [1139/3978 (29%)]\tLoss: 0.011267\n",
            "Train Epoch: 4 [1140/3978 (29%)]\tLoss: 1.350945\n",
            "Train Epoch: 4 [1141/3978 (29%)]\tLoss: 0.858462\n",
            "Train Epoch: 4 [1142/3978 (29%)]\tLoss: 0.798399\n",
            "Train Epoch: 4 [1143/3978 (29%)]\tLoss: 0.028565\n",
            "Train Epoch: 4 [1144/3978 (29%)]\tLoss: 1.785802\n",
            "Train Epoch: 4 [1145/3978 (29%)]\tLoss: 1.363595\n",
            "Train Epoch: 4 [1146/3978 (29%)]\tLoss: 1.792548\n",
            "Train Epoch: 4 [1147/3978 (29%)]\tLoss: 0.400196\n",
            "Train Epoch: 4 [1148/3978 (29%)]\tLoss: 1.732573\n",
            "Train Epoch: 4 [1149/3978 (29%)]\tLoss: 0.299530\n",
            "Train Epoch: 4 [1150/3978 (29%)]\tLoss: 0.005168\n",
            "Train Epoch: 4 [1151/3978 (29%)]\tLoss: 0.426598\n",
            "Train Epoch: 4 [1152/3978 (29%)]\tLoss: 0.002767\n",
            "Train Epoch: 4 [1153/3978 (29%)]\tLoss: 0.020575\n",
            "Train Epoch: 4 [1154/3978 (29%)]\tLoss: 1.011209\n",
            "Train Epoch: 4 [1155/3978 (29%)]\tLoss: 1.823463\n",
            "Train Epoch: 4 [1156/3978 (29%)]\tLoss: 0.006046\n",
            "Train Epoch: 4 [1157/3978 (29%)]\tLoss: 0.536677\n",
            "Train Epoch: 4 [1158/3978 (29%)]\tLoss: 2.829633\n",
            "Train Epoch: 4 [1159/3978 (29%)]\tLoss: 0.444381\n",
            "Train Epoch: 4 [1160/3978 (29%)]\tLoss: 0.458861\n",
            "Train Epoch: 4 [1161/3978 (29%)]\tLoss: 0.040819\n",
            "Train Epoch: 4 [1162/3978 (29%)]\tLoss: 0.188565\n",
            "Train Epoch: 4 [1163/3978 (29%)]\tLoss: 0.003465\n",
            "Train Epoch: 4 [1164/3978 (29%)]\tLoss: 0.963922\n",
            "Train Epoch: 4 [1165/3978 (29%)]\tLoss: 0.000028\n",
            "Train Epoch: 4 [1166/3978 (29%)]\tLoss: 1.490539\n",
            "Train Epoch: 4 [1167/3978 (29%)]\tLoss: 0.030815\n",
            "Train Epoch: 4 [1168/3978 (29%)]\tLoss: 0.004786\n",
            "Train Epoch: 4 [1169/3978 (29%)]\tLoss: 0.709098\n",
            "Train Epoch: 4 [1170/3978 (29%)]\tLoss: 4.457676\n",
            "Train Epoch: 4 [1171/3978 (29%)]\tLoss: 0.051901\n",
            "Train Epoch: 4 [1172/3978 (29%)]\tLoss: 0.001000\n",
            "Train Epoch: 4 [1173/3978 (29%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [1174/3978 (30%)]\tLoss: 0.610588\n",
            "Train Epoch: 4 [1175/3978 (30%)]\tLoss: 8.511129\n",
            "Train Epoch: 4 [1176/3978 (30%)]\tLoss: 0.013101\n",
            "Train Epoch: 4 [1177/3978 (30%)]\tLoss: 1.721232\n",
            "Train Epoch: 4 [1178/3978 (30%)]\tLoss: 2.071037\n",
            "Train Epoch: 4 [1179/3978 (30%)]\tLoss: 2.008764\n",
            "Train Epoch: 4 [1180/3978 (30%)]\tLoss: 2.382283\n",
            "Train Epoch: 4 [1181/3978 (30%)]\tLoss: 0.974501\n",
            "Train Epoch: 4 [1182/3978 (30%)]\tLoss: 0.815843\n",
            "Train Epoch: 4 [1183/3978 (30%)]\tLoss: 0.811701\n",
            "Train Epoch: 4 [1184/3978 (30%)]\tLoss: 0.591840\n",
            "Train Epoch: 4 [1185/3978 (30%)]\tLoss: 0.209643\n",
            "Train Epoch: 4 [1186/3978 (30%)]\tLoss: 1.651458\n",
            "Train Epoch: 4 [1187/3978 (30%)]\tLoss: 0.001023\n",
            "Train Epoch: 4 [1188/3978 (30%)]\tLoss: 0.000417\n",
            "Train Epoch: 4 [1189/3978 (30%)]\tLoss: 2.779490\n",
            "Train Epoch: 4 [1190/3978 (30%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [1191/3978 (30%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [1192/3978 (30%)]\tLoss: 0.000024\n",
            "Train Epoch: 4 [1193/3978 (30%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [1194/3978 (30%)]\tLoss: 2.491847\n",
            "Train Epoch: 4 [1195/3978 (30%)]\tLoss: 2.515235\n",
            "Train Epoch: 4 [1196/3978 (30%)]\tLoss: 2.295485\n",
            "Train Epoch: 4 [1197/3978 (30%)]\tLoss: 4.177170\n",
            "Train Epoch: 4 [1198/3978 (30%)]\tLoss: 0.012491\n",
            "Train Epoch: 4 [1199/3978 (30%)]\tLoss: 0.092203\n",
            "Train Epoch: 4 [1200/3978 (30%)]\tLoss: 0.472191\n",
            "Train Epoch: 4 [1201/3978 (30%)]\tLoss: 1.309916\n",
            "Train Epoch: 4 [1202/3978 (30%)]\tLoss: 0.078132\n",
            "Train Epoch: 4 [1203/3978 (30%)]\tLoss: 1.620201\n",
            "Train Epoch: 4 [1204/3978 (30%)]\tLoss: 2.053632\n",
            "Train Epoch: 4 [1205/3978 (30%)]\tLoss: 2.042222\n",
            "Train Epoch: 4 [1206/3978 (30%)]\tLoss: 1.469614\n",
            "Train Epoch: 4 [1207/3978 (30%)]\tLoss: 1.249432\n",
            "Train Epoch: 4 [1208/3978 (30%)]\tLoss: 0.641579\n",
            "Train Epoch: 4 [1209/3978 (30%)]\tLoss: 0.305921\n",
            "Train Epoch: 4 [1210/3978 (30%)]\tLoss: 0.148634\n",
            "Train Epoch: 4 [1211/3978 (30%)]\tLoss: 1.696499\n",
            "Train Epoch: 4 [1212/3978 (30%)]\tLoss: 5.070216\n",
            "Train Epoch: 4 [1213/3978 (30%)]\tLoss: 1.449966\n",
            "Train Epoch: 4 [1214/3978 (31%)]\tLoss: 0.001715\n",
            "Train Epoch: 4 [1215/3978 (31%)]\tLoss: 0.000302\n",
            "Train Epoch: 4 [1216/3978 (31%)]\tLoss: 0.353342\n",
            "Train Epoch: 4 [1217/3978 (31%)]\tLoss: 0.000656\n",
            "Train Epoch: 4 [1218/3978 (31%)]\tLoss: 3.135947\n",
            "Train Epoch: 4 [1219/3978 (31%)]\tLoss: 0.000808\n",
            "Train Epoch: 4 [1220/3978 (31%)]\tLoss: 0.000233\n",
            "Train Epoch: 4 [1221/3978 (31%)]\tLoss: 3.015842\n",
            "Train Epoch: 4 [1222/3978 (31%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1223/3978 (31%)]\tLoss: 0.037414\n",
            "Train Epoch: 4 [1224/3978 (31%)]\tLoss: 3.585097\n",
            "Train Epoch: 4 [1225/3978 (31%)]\tLoss: 0.903815\n",
            "Train Epoch: 4 [1226/3978 (31%)]\tLoss: 2.714607\n",
            "Train Epoch: 4 [1227/3978 (31%)]\tLoss: 0.263367\n",
            "Train Epoch: 4 [1228/3978 (31%)]\tLoss: 1.872530\n",
            "Train Epoch: 4 [1229/3978 (31%)]\tLoss: 0.529697\n",
            "Train Epoch: 4 [1230/3978 (31%)]\tLoss: 0.856324\n",
            "Train Epoch: 4 [1231/3978 (31%)]\tLoss: 0.895345\n",
            "Train Epoch: 4 [1232/3978 (31%)]\tLoss: 0.071813\n",
            "Train Epoch: 4 [1233/3978 (31%)]\tLoss: 0.006995\n",
            "Train Epoch: 4 [1234/3978 (31%)]\tLoss: 0.525148\n",
            "Train Epoch: 4 [1235/3978 (31%)]\tLoss: 1.002250\n",
            "Train Epoch: 4 [1236/3978 (31%)]\tLoss: 0.094457\n",
            "Train Epoch: 4 [1237/3978 (31%)]\tLoss: 1.145387\n",
            "Train Epoch: 4 [1238/3978 (31%)]\tLoss: 0.010833\n",
            "Train Epoch: 4 [1239/3978 (31%)]\tLoss: 0.000051\n",
            "Train Epoch: 4 [1240/3978 (31%)]\tLoss: 0.004352\n",
            "Train Epoch: 4 [1241/3978 (31%)]\tLoss: 0.000508\n",
            "Train Epoch: 4 [1242/3978 (31%)]\tLoss: 0.068253\n",
            "Train Epoch: 4 [1243/3978 (31%)]\tLoss: 0.232965\n",
            "Train Epoch: 4 [1244/3978 (31%)]\tLoss: 0.113550\n",
            "Train Epoch: 4 [1245/3978 (31%)]\tLoss: 2.378815\n",
            "Train Epoch: 4 [1246/3978 (31%)]\tLoss: 0.754197\n",
            "Train Epoch: 4 [1247/3978 (31%)]\tLoss: 0.003886\n",
            "Train Epoch: 4 [1248/3978 (31%)]\tLoss: 3.429040\n",
            "Train Epoch: 4 [1249/3978 (31%)]\tLoss: 0.001205\n",
            "Train Epoch: 4 [1250/3978 (31%)]\tLoss: 0.001576\n",
            "Train Epoch: 4 [1251/3978 (31%)]\tLoss: 0.068954\n",
            "Train Epoch: 4 [1252/3978 (31%)]\tLoss: 0.037052\n",
            "Train Epoch: 4 [1253/3978 (31%)]\tLoss: 0.305641\n",
            "Train Epoch: 4 [1254/3978 (32%)]\tLoss: 0.383064\n",
            "Train Epoch: 4 [1255/3978 (32%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1256/3978 (32%)]\tLoss: 0.405184\n",
            "Train Epoch: 4 [1257/3978 (32%)]\tLoss: 0.945128\n",
            "Train Epoch: 4 [1258/3978 (32%)]\tLoss: 0.000094\n",
            "Train Epoch: 4 [1259/3978 (32%)]\tLoss: 0.032937\n",
            "Train Epoch: 4 [1260/3978 (32%)]\tLoss: 0.759148\n",
            "Train Epoch: 4 [1261/3978 (32%)]\tLoss: 5.103638\n",
            "Train Epoch: 4 [1262/3978 (32%)]\tLoss: 7.014588\n",
            "Train Epoch: 4 [1263/3978 (32%)]\tLoss: 0.028245\n",
            "Train Epoch: 4 [1264/3978 (32%)]\tLoss: 0.127287\n",
            "Train Epoch: 4 [1265/3978 (32%)]\tLoss: 0.183135\n",
            "Train Epoch: 4 [1266/3978 (32%)]\tLoss: 0.001344\n",
            "Train Epoch: 4 [1267/3978 (32%)]\tLoss: 0.022841\n",
            "Train Epoch: 4 [1268/3978 (32%)]\tLoss: 0.252375\n",
            "Train Epoch: 4 [1269/3978 (32%)]\tLoss: 0.696228\n",
            "Train Epoch: 4 [1270/3978 (32%)]\tLoss: 0.235684\n",
            "Train Epoch: 4 [1271/3978 (32%)]\tLoss: 0.000903\n",
            "Train Epoch: 4 [1272/3978 (32%)]\tLoss: 4.457772\n",
            "Train Epoch: 4 [1273/3978 (32%)]\tLoss: 0.000125\n",
            "Train Epoch: 4 [1274/3978 (32%)]\tLoss: 0.337371\n",
            "Train Epoch: 4 [1275/3978 (32%)]\tLoss: 0.329808\n",
            "Train Epoch: 4 [1276/3978 (32%)]\tLoss: 0.000941\n",
            "Train Epoch: 4 [1277/3978 (32%)]\tLoss: 0.240269\n",
            "Train Epoch: 4 [1278/3978 (32%)]\tLoss: 0.000458\n",
            "Train Epoch: 4 [1279/3978 (32%)]\tLoss: 0.521793\n",
            "Train Epoch: 4 [1280/3978 (32%)]\tLoss: 0.605995\n",
            "Train Epoch: 4 [1281/3978 (32%)]\tLoss: 0.000204\n",
            "Train Epoch: 4 [1282/3978 (32%)]\tLoss: 0.698268\n",
            "Train Epoch: 4 [1283/3978 (32%)]\tLoss: 0.001341\n",
            "Train Epoch: 4 [1284/3978 (32%)]\tLoss: 0.002267\n",
            "Train Epoch: 4 [1285/3978 (32%)]\tLoss: 0.005916\n",
            "Train Epoch: 4 [1286/3978 (32%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1287/3978 (32%)]\tLoss: 0.000505\n",
            "Train Epoch: 4 [1288/3978 (32%)]\tLoss: 1.293119\n",
            "Train Epoch: 4 [1289/3978 (32%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [1290/3978 (32%)]\tLoss: 1.634802\n",
            "Train Epoch: 4 [1291/3978 (32%)]\tLoss: 0.506318\n",
            "Train Epoch: 4 [1292/3978 (32%)]\tLoss: 5.961200\n",
            "Train Epoch: 4 [1293/3978 (33%)]\tLoss: 2.036129\n",
            "Train Epoch: 4 [1294/3978 (33%)]\tLoss: 0.316294\n",
            "Train Epoch: 4 [1295/3978 (33%)]\tLoss: 0.895909\n",
            "Train Epoch: 4 [1296/3978 (33%)]\tLoss: 0.004517\n",
            "Train Epoch: 4 [1297/3978 (33%)]\tLoss: 0.933002\n",
            "Train Epoch: 4 [1298/3978 (33%)]\tLoss: 0.048604\n",
            "Train Epoch: 4 [1299/3978 (33%)]\tLoss: 0.292929\n",
            "Train Epoch: 4 [1300/3978 (33%)]\tLoss: 3.905508\n",
            "Train Epoch: 4 [1301/3978 (33%)]\tLoss: 0.006604\n",
            "Train Epoch: 4 [1302/3978 (33%)]\tLoss: 0.029591\n",
            "Train Epoch: 4 [1303/3978 (33%)]\tLoss: 0.116476\n",
            "Train Epoch: 4 [1304/3978 (33%)]\tLoss: 0.211452\n",
            "Train Epoch: 4 [1305/3978 (33%)]\tLoss: 0.128908\n",
            "Train Epoch: 4 [1306/3978 (33%)]\tLoss: 0.564175\n",
            "Train Epoch: 4 [1307/3978 (33%)]\tLoss: 0.000936\n",
            "Train Epoch: 4 [1308/3978 (33%)]\tLoss: 0.159635\n",
            "Train Epoch: 4 [1309/3978 (33%)]\tLoss: 0.000426\n",
            "Train Epoch: 4 [1310/3978 (33%)]\tLoss: 0.001719\n",
            "Train Epoch: 4 [1311/3978 (33%)]\tLoss: 0.625185\n",
            "Train Epoch: 4 [1312/3978 (33%)]\tLoss: 0.077885\n",
            "Train Epoch: 4 [1313/3978 (33%)]\tLoss: 0.603543\n",
            "Train Epoch: 4 [1314/3978 (33%)]\tLoss: 0.199053\n",
            "Train Epoch: 4 [1315/3978 (33%)]\tLoss: 0.000123\n",
            "Train Epoch: 4 [1316/3978 (33%)]\tLoss: 0.000054\n",
            "Train Epoch: 4 [1317/3978 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1318/3978 (33%)]\tLoss: 0.000064\n",
            "Train Epoch: 4 [1319/3978 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1320/3978 (33%)]\tLoss: 1.556890\n",
            "Train Epoch: 4 [1321/3978 (33%)]\tLoss: 1.495551\n",
            "Train Epoch: 4 [1322/3978 (33%)]\tLoss: 2.132188\n",
            "Train Epoch: 4 [1323/3978 (33%)]\tLoss: 3.005583\n",
            "Train Epoch: 4 [1324/3978 (33%)]\tLoss: 0.742556\n",
            "Train Epoch: 4 [1325/3978 (33%)]\tLoss: 0.544190\n",
            "Train Epoch: 4 [1326/3978 (33%)]\tLoss: 0.049830\n",
            "Train Epoch: 4 [1327/3978 (33%)]\tLoss: 0.293890\n",
            "Train Epoch: 4 [1328/3978 (33%)]\tLoss: 1.070298\n",
            "Train Epoch: 4 [1329/3978 (33%)]\tLoss: 1.000803\n",
            "Train Epoch: 4 [1330/3978 (33%)]\tLoss: 0.982119\n",
            "Train Epoch: 4 [1331/3978 (33%)]\tLoss: 1.338374\n",
            "Train Epoch: 4 [1332/3978 (33%)]\tLoss: 1.103855\n",
            "Train Epoch: 4 [1333/3978 (34%)]\tLoss: 0.614578\n",
            "Train Epoch: 4 [1334/3978 (34%)]\tLoss: 0.025614\n",
            "Train Epoch: 4 [1335/3978 (34%)]\tLoss: 0.841018\n",
            "Train Epoch: 4 [1336/3978 (34%)]\tLoss: 1.302302\n",
            "Train Epoch: 4 [1337/3978 (34%)]\tLoss: 1.311394\n",
            "Train Epoch: 4 [1338/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1339/3978 (34%)]\tLoss: 0.000015\n",
            "Train Epoch: 4 [1340/3978 (34%)]\tLoss: 0.756269\n",
            "Train Epoch: 4 [1341/3978 (34%)]\tLoss: 0.299419\n",
            "Train Epoch: 4 [1342/3978 (34%)]\tLoss: 0.000594\n",
            "Train Epoch: 4 [1343/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1344/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1345/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1346/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1347/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1348/3978 (34%)]\tLoss: 3.724675\n",
            "Train Epoch: 4 [1349/3978 (34%)]\tLoss: 4.067765\n",
            "Train Epoch: 4 [1350/3978 (34%)]\tLoss: 3.330659\n",
            "Train Epoch: 4 [1351/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1352/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1353/3978 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1354/3978 (34%)]\tLoss: 1.972914\n",
            "Train Epoch: 4 [1355/3978 (34%)]\tLoss: 1.919798\n",
            "Train Epoch: 4 [1356/3978 (34%)]\tLoss: 2.856796\n",
            "Train Epoch: 4 [1357/3978 (34%)]\tLoss: 2.013579\n",
            "Train Epoch: 4 [1358/3978 (34%)]\tLoss: 0.096847\n",
            "Train Epoch: 4 [1359/3978 (34%)]\tLoss: 1.001344\n",
            "Train Epoch: 4 [1360/3978 (34%)]\tLoss: 2.226044\n",
            "Train Epoch: 4 [1361/3978 (34%)]\tLoss: 0.275099\n",
            "Train Epoch: 4 [1362/3978 (34%)]\tLoss: 1.164110\n",
            "Train Epoch: 4 [1363/3978 (34%)]\tLoss: 3.512094\n",
            "Train Epoch: 4 [1364/3978 (34%)]\tLoss: 2.518420\n",
            "Train Epoch: 4 [1365/3978 (34%)]\tLoss: 2.406047\n",
            "Train Epoch: 4 [1366/3978 (34%)]\tLoss: 0.072188\n",
            "Train Epoch: 4 [1367/3978 (34%)]\tLoss: 2.002441\n",
            "Train Epoch: 4 [1368/3978 (34%)]\tLoss: 1.878543\n",
            "Train Epoch: 4 [1369/3978 (34%)]\tLoss: 0.601396\n",
            "Train Epoch: 4 [1370/3978 (34%)]\tLoss: 0.706494\n",
            "Train Epoch: 4 [1371/3978 (34%)]\tLoss: 1.319764\n",
            "Train Epoch: 4 [1372/3978 (34%)]\tLoss: 1.747172\n",
            "Train Epoch: 4 [1373/3978 (35%)]\tLoss: 0.217166\n",
            "Train Epoch: 4 [1374/3978 (35%)]\tLoss: 0.581158\n",
            "Train Epoch: 4 [1375/3978 (35%)]\tLoss: 0.144546\n",
            "Train Epoch: 4 [1376/3978 (35%)]\tLoss: 4.084937\n",
            "Train Epoch: 4 [1377/3978 (35%)]\tLoss: 0.000680\n",
            "Train Epoch: 4 [1378/3978 (35%)]\tLoss: 0.297098\n",
            "Train Epoch: 4 [1379/3978 (35%)]\tLoss: 0.058804\n",
            "Train Epoch: 4 [1380/3978 (35%)]\tLoss: 0.027484\n",
            "Train Epoch: 4 [1381/3978 (35%)]\tLoss: 0.677810\n",
            "Train Epoch: 4 [1382/3978 (35%)]\tLoss: 0.004428\n",
            "Train Epoch: 4 [1383/3978 (35%)]\tLoss: 0.008389\n",
            "Train Epoch: 4 [1384/3978 (35%)]\tLoss: 0.028996\n",
            "Train Epoch: 4 [1385/3978 (35%)]\tLoss: 0.126669\n",
            "Train Epoch: 4 [1386/3978 (35%)]\tLoss: 0.046891\n",
            "Train Epoch: 4 [1387/3978 (35%)]\tLoss: 0.009283\n",
            "Train Epoch: 4 [1388/3978 (35%)]\tLoss: 0.024646\n",
            "Train Epoch: 4 [1389/3978 (35%)]\tLoss: 0.192447\n",
            "Train Epoch: 4 [1390/3978 (35%)]\tLoss: 2.974481\n",
            "Train Epoch: 4 [1391/3978 (35%)]\tLoss: 0.000476\n",
            "Train Epoch: 4 [1392/3978 (35%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1393/3978 (35%)]\tLoss: 0.871289\n",
            "Train Epoch: 4 [1394/3978 (35%)]\tLoss: 0.000820\n",
            "Train Epoch: 4 [1395/3978 (35%)]\tLoss: 1.949625\n",
            "Train Epoch: 4 [1396/3978 (35%)]\tLoss: 0.202925\n",
            "Train Epoch: 4 [1397/3978 (35%)]\tLoss: 0.058125\n",
            "Train Epoch: 4 [1398/3978 (35%)]\tLoss: 0.317989\n",
            "Train Epoch: 4 [1399/3978 (35%)]\tLoss: 0.001224\n",
            "Train Epoch: 4 [1400/3978 (35%)]\tLoss: 0.094188\n",
            "Train Epoch: 4 [1401/3978 (35%)]\tLoss: 0.489498\n",
            "Train Epoch: 4 [1402/3978 (35%)]\tLoss: 0.544598\n",
            "Train Epoch: 4 [1403/3978 (35%)]\tLoss: 0.794400\n",
            "Train Epoch: 4 [1404/3978 (35%)]\tLoss: 4.013566\n",
            "Train Epoch: 4 [1405/3978 (35%)]\tLoss: 0.038784\n",
            "Train Epoch: 4 [1406/3978 (35%)]\tLoss: 0.282853\n",
            "Train Epoch: 4 [1407/3978 (35%)]\tLoss: 0.344755\n",
            "Train Epoch: 4 [1408/3978 (35%)]\tLoss: 1.493023\n",
            "Train Epoch: 4 [1409/3978 (35%)]\tLoss: 0.914355\n",
            "Train Epoch: 4 [1410/3978 (35%)]\tLoss: 0.002379\n",
            "Train Epoch: 4 [1411/3978 (35%)]\tLoss: 0.000024\n",
            "Train Epoch: 4 [1412/3978 (35%)]\tLoss: 4.524536\n",
            "Train Epoch: 4 [1413/3978 (36%)]\tLoss: 2.701066\n",
            "Train Epoch: 4 [1414/3978 (36%)]\tLoss: 0.828397\n",
            "Train Epoch: 4 [1415/3978 (36%)]\tLoss: 1.359721\n",
            "Train Epoch: 4 [1416/3978 (36%)]\tLoss: 0.171548\n",
            "Train Epoch: 4 [1417/3978 (36%)]\tLoss: 3.120829\n",
            "Train Epoch: 4 [1418/3978 (36%)]\tLoss: 0.140302\n",
            "Train Epoch: 4 [1419/3978 (36%)]\tLoss: 4.391095\n",
            "Train Epoch: 4 [1420/3978 (36%)]\tLoss: 1.563047\n",
            "Train Epoch: 4 [1421/3978 (36%)]\tLoss: 3.443320\n",
            "Train Epoch: 4 [1422/3978 (36%)]\tLoss: 0.005161\n",
            "Train Epoch: 4 [1423/3978 (36%)]\tLoss: 0.001401\n",
            "Train Epoch: 4 [1424/3978 (36%)]\tLoss: 1.575598\n",
            "Train Epoch: 4 [1425/3978 (36%)]\tLoss: 2.421259\n",
            "Train Epoch: 4 [1426/3978 (36%)]\tLoss: 0.591830\n",
            "Train Epoch: 4 [1427/3978 (36%)]\tLoss: 0.581038\n",
            "Train Epoch: 4 [1428/3978 (36%)]\tLoss: 0.473616\n",
            "Train Epoch: 4 [1429/3978 (36%)]\tLoss: 1.679405\n",
            "Train Epoch: 4 [1430/3978 (36%)]\tLoss: 1.099877\n",
            "Train Epoch: 4 [1431/3978 (36%)]\tLoss: 1.388976\n",
            "Train Epoch: 4 [1432/3978 (36%)]\tLoss: 0.529009\n",
            "Train Epoch: 4 [1433/3978 (36%)]\tLoss: 0.372255\n",
            "Train Epoch: 4 [1434/3978 (36%)]\tLoss: 0.000104\n",
            "Train Epoch: 4 [1435/3978 (36%)]\tLoss: 1.060467\n",
            "Train Epoch: 4 [1436/3978 (36%)]\tLoss: 1.724834\n",
            "Train Epoch: 4 [1437/3978 (36%)]\tLoss: 1.252392\n",
            "Train Epoch: 4 [1438/3978 (36%)]\tLoss: 1.799246\n",
            "Train Epoch: 4 [1439/3978 (36%)]\tLoss: 1.222373\n",
            "Train Epoch: 4 [1440/3978 (36%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1441/3978 (36%)]\tLoss: 2.831695\n",
            "Train Epoch: 4 [1442/3978 (36%)]\tLoss: 0.000244\n",
            "Train Epoch: 4 [1443/3978 (36%)]\tLoss: 1.177703\n",
            "Train Epoch: 4 [1444/3978 (36%)]\tLoss: 1.151783\n",
            "Train Epoch: 4 [1445/3978 (36%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [1446/3978 (36%)]\tLoss: 0.078404\n",
            "Train Epoch: 4 [1447/3978 (36%)]\tLoss: 0.006404\n",
            "Train Epoch: 4 [1448/3978 (36%)]\tLoss: 0.256194\n",
            "Train Epoch: 4 [1449/3978 (36%)]\tLoss: 0.441119\n",
            "Train Epoch: 4 [1450/3978 (36%)]\tLoss: 0.256093\n",
            "Train Epoch: 4 [1451/3978 (36%)]\tLoss: 0.559593\n",
            "Train Epoch: 4 [1452/3978 (37%)]\tLoss: 0.056952\n",
            "Train Epoch: 4 [1453/3978 (37%)]\tLoss: 1.122109\n",
            "Train Epoch: 4 [1454/3978 (37%)]\tLoss: 0.810493\n",
            "Train Epoch: 4 [1455/3978 (37%)]\tLoss: 3.830568\n",
            "Train Epoch: 4 [1456/3978 (37%)]\tLoss: 4.436043\n",
            "Train Epoch: 4 [1457/3978 (37%)]\tLoss: 0.007298\n",
            "Train Epoch: 4 [1458/3978 (37%)]\tLoss: 0.419375\n",
            "Train Epoch: 4 [1459/3978 (37%)]\tLoss: 0.001330\n",
            "Train Epoch: 4 [1460/3978 (37%)]\tLoss: 3.554621\n",
            "Train Epoch: 4 [1461/3978 (37%)]\tLoss: 0.763843\n",
            "Train Epoch: 4 [1462/3978 (37%)]\tLoss: 0.047072\n",
            "Train Epoch: 4 [1463/3978 (37%)]\tLoss: 1.128588\n",
            "Train Epoch: 4 [1464/3978 (37%)]\tLoss: 0.014119\n",
            "Train Epoch: 4 [1465/3978 (37%)]\tLoss: 0.262506\n",
            "Train Epoch: 4 [1466/3978 (37%)]\tLoss: 1.510427\n",
            "Train Epoch: 4 [1467/3978 (37%)]\tLoss: 1.607380\n",
            "Train Epoch: 4 [1468/3978 (37%)]\tLoss: 0.106770\n",
            "Train Epoch: 4 [1469/3978 (37%)]\tLoss: 0.367474\n",
            "Train Epoch: 4 [1470/3978 (37%)]\tLoss: 1.078125\n",
            "Train Epoch: 4 [1471/3978 (37%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1472/3978 (37%)]\tLoss: 0.002406\n",
            "Train Epoch: 4 [1473/3978 (37%)]\tLoss: 0.006850\n",
            "Train Epoch: 4 [1474/3978 (37%)]\tLoss: 2.284245\n",
            "Train Epoch: 4 [1475/3978 (37%)]\tLoss: 5.620466\n",
            "Train Epoch: 4 [1476/3978 (37%)]\tLoss: 0.017026\n",
            "Train Epoch: 4 [1477/3978 (37%)]\tLoss: 1.466430\n",
            "Train Epoch: 4 [1478/3978 (37%)]\tLoss: 1.494346\n",
            "Train Epoch: 4 [1479/3978 (37%)]\tLoss: 0.272029\n",
            "Train Epoch: 4 [1480/3978 (37%)]\tLoss: 0.353339\n",
            "Train Epoch: 4 [1481/3978 (37%)]\tLoss: 0.057192\n",
            "Train Epoch: 4 [1482/3978 (37%)]\tLoss: 0.003727\n",
            "Train Epoch: 4 [1483/3978 (37%)]\tLoss: 0.239551\n",
            "Train Epoch: 4 [1484/3978 (37%)]\tLoss: 0.014467\n",
            "Train Epoch: 4 [1485/3978 (37%)]\tLoss: 6.544659\n",
            "Train Epoch: 4 [1486/3978 (37%)]\tLoss: 2.104362\n",
            "Train Epoch: 4 [1487/3978 (37%)]\tLoss: 0.188855\n",
            "Train Epoch: 4 [1488/3978 (37%)]\tLoss: 1.005216\n",
            "Train Epoch: 4 [1489/3978 (37%)]\tLoss: 1.581223\n",
            "Train Epoch: 4 [1490/3978 (37%)]\tLoss: 0.753793\n",
            "Train Epoch: 4 [1491/3978 (37%)]\tLoss: 1.664790\n",
            "Train Epoch: 4 [1492/3978 (38%)]\tLoss: 0.012020\n",
            "Train Epoch: 4 [1493/3978 (38%)]\tLoss: 0.138837\n",
            "Train Epoch: 4 [1494/3978 (38%)]\tLoss: 0.315350\n",
            "Train Epoch: 4 [1495/3978 (38%)]\tLoss: 0.967349\n",
            "Train Epoch: 4 [1496/3978 (38%)]\tLoss: 0.302833\n",
            "Train Epoch: 4 [1497/3978 (38%)]\tLoss: 0.132582\n",
            "Train Epoch: 4 [1498/3978 (38%)]\tLoss: 0.375030\n",
            "Train Epoch: 4 [1499/3978 (38%)]\tLoss: 0.388330\n",
            "Train Epoch: 4 [1500/3978 (38%)]\tLoss: 0.831994\n",
            "Train Epoch: 4 [1501/3978 (38%)]\tLoss: 0.032389\n",
            "Train Epoch: 4 [1502/3978 (38%)]\tLoss: 1.093797\n",
            "Train Epoch: 4 [1503/3978 (38%)]\tLoss: 1.043805\n",
            "Train Epoch: 4 [1504/3978 (38%)]\tLoss: 0.000077\n",
            "Train Epoch: 4 [1505/3978 (38%)]\tLoss: 0.169501\n",
            "Train Epoch: 4 [1506/3978 (38%)]\tLoss: 0.006221\n",
            "Train Epoch: 4 [1507/3978 (38%)]\tLoss: 0.050177\n",
            "Train Epoch: 4 [1508/3978 (38%)]\tLoss: 0.001800\n",
            "Train Epoch: 4 [1509/3978 (38%)]\tLoss: 0.122802\n",
            "Train Epoch: 4 [1510/3978 (38%)]\tLoss: 0.000664\n",
            "Train Epoch: 4 [1511/3978 (38%)]\tLoss: 0.066200\n",
            "Train Epoch: 4 [1512/3978 (38%)]\tLoss: 0.001286\n",
            "Train Epoch: 4 [1513/3978 (38%)]\tLoss: 0.557727\n",
            "Train Epoch: 4 [1514/3978 (38%)]\tLoss: 0.036312\n",
            "Train Epoch: 4 [1515/3978 (38%)]\tLoss: 0.168209\n",
            "Train Epoch: 4 [1516/3978 (38%)]\tLoss: 0.485637\n",
            "Train Epoch: 4 [1517/3978 (38%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1518/3978 (38%)]\tLoss: 0.000074\n",
            "Train Epoch: 4 [1519/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1520/3978 (38%)]\tLoss: 0.709349\n",
            "Train Epoch: 4 [1521/3978 (38%)]\tLoss: 0.617106\n",
            "Train Epoch: 4 [1522/3978 (38%)]\tLoss: 0.785051\n",
            "Train Epoch: 4 [1523/3978 (38%)]\tLoss: 0.052132\n",
            "Train Epoch: 4 [1524/3978 (38%)]\tLoss: 0.000224\n",
            "Train Epoch: 4 [1525/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1526/3978 (38%)]\tLoss: 1.999053\n",
            "Train Epoch: 4 [1527/3978 (38%)]\tLoss: 1.869999\n",
            "Train Epoch: 4 [1528/3978 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1529/3978 (38%)]\tLoss: 1.697495\n",
            "Train Epoch: 4 [1530/3978 (38%)]\tLoss: 1.245163\n",
            "Train Epoch: 4 [1531/3978 (38%)]\tLoss: 2.122555\n",
            "Train Epoch: 4 [1532/3978 (39%)]\tLoss: 3.449047\n",
            "Train Epoch: 4 [1533/3978 (39%)]\tLoss: 0.135697\n",
            "Train Epoch: 4 [1534/3978 (39%)]\tLoss: 4.117430\n",
            "Train Epoch: 4 [1535/3978 (39%)]\tLoss: 0.755268\n",
            "Train Epoch: 4 [1536/3978 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1537/3978 (39%)]\tLoss: 1.983628\n",
            "Train Epoch: 4 [1538/3978 (39%)]\tLoss: 0.844034\n",
            "Train Epoch: 4 [1539/3978 (39%)]\tLoss: 0.000189\n",
            "Train Epoch: 4 [1540/3978 (39%)]\tLoss: 0.359047\n",
            "Train Epoch: 4 [1541/3978 (39%)]\tLoss: 0.011936\n",
            "Train Epoch: 4 [1542/3978 (39%)]\tLoss: 0.058847\n",
            "Train Epoch: 4 [1543/3978 (39%)]\tLoss: 0.554024\n",
            "Train Epoch: 4 [1544/3978 (39%)]\tLoss: 0.042072\n",
            "Train Epoch: 4 [1545/3978 (39%)]\tLoss: 0.056890\n",
            "Train Epoch: 4 [1546/3978 (39%)]\tLoss: 0.432382\n",
            "Train Epoch: 4 [1547/3978 (39%)]\tLoss: 0.179315\n",
            "Train Epoch: 4 [1548/3978 (39%)]\tLoss: 0.199359\n",
            "Train Epoch: 4 [1549/3978 (39%)]\tLoss: 0.002688\n",
            "Train Epoch: 4 [1550/3978 (39%)]\tLoss: 0.075564\n",
            "Train Epoch: 4 [1551/3978 (39%)]\tLoss: 0.002841\n",
            "Train Epoch: 4 [1552/3978 (39%)]\tLoss: 0.000111\n",
            "Train Epoch: 4 [1553/3978 (39%)]\tLoss: 5.690608\n",
            "Train Epoch: 4 [1554/3978 (39%)]\tLoss: 0.015557\n",
            "Train Epoch: 4 [1555/3978 (39%)]\tLoss: 4.856390\n",
            "Train Epoch: 4 [1556/3978 (39%)]\tLoss: 0.463511\n",
            "Train Epoch: 4 [1557/3978 (39%)]\tLoss: 0.026917\n",
            "Train Epoch: 4 [1558/3978 (39%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [1559/3978 (39%)]\tLoss: 0.776523\n",
            "Train Epoch: 4 [1560/3978 (39%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [1561/3978 (39%)]\tLoss: 0.005962\n",
            "Train Epoch: 4 [1562/3978 (39%)]\tLoss: 0.821248\n",
            "Train Epoch: 4 [1563/3978 (39%)]\tLoss: 0.018554\n",
            "Train Epoch: 4 [1564/3978 (39%)]\tLoss: 0.698825\n",
            "Train Epoch: 4 [1565/3978 (39%)]\tLoss: 1.197333\n",
            "Train Epoch: 4 [1566/3978 (39%)]\tLoss: 0.245035\n",
            "Train Epoch: 4 [1567/3978 (39%)]\tLoss: 4.486070\n",
            "Train Epoch: 4 [1568/3978 (39%)]\tLoss: 0.143300\n",
            "Train Epoch: 4 [1569/3978 (39%)]\tLoss: 1.431022\n",
            "Train Epoch: 4 [1570/3978 (39%)]\tLoss: 0.886500\n",
            "Train Epoch: 4 [1571/3978 (39%)]\tLoss: 1.731848\n",
            "Train Epoch: 4 [1572/3978 (40%)]\tLoss: 2.327614\n",
            "Train Epoch: 4 [1573/3978 (40%)]\tLoss: 0.249536\n",
            "Train Epoch: 4 [1574/3978 (40%)]\tLoss: 0.899120\n",
            "Train Epoch: 4 [1575/3978 (40%)]\tLoss: 0.008639\n",
            "Train Epoch: 4 [1576/3978 (40%)]\tLoss: 0.012929\n",
            "Train Epoch: 4 [1577/3978 (40%)]\tLoss: 0.000242\n",
            "Train Epoch: 4 [1578/3978 (40%)]\tLoss: 1.685261\n",
            "Train Epoch: 4 [1579/3978 (40%)]\tLoss: 1.203655\n",
            "Train Epoch: 4 [1580/3978 (40%)]\tLoss: 0.000257\n",
            "Train Epoch: 4 [1581/3978 (40%)]\tLoss: 1.527864\n",
            "Train Epoch: 4 [1582/3978 (40%)]\tLoss: 2.055406\n",
            "Train Epoch: 4 [1583/3978 (40%)]\tLoss: 5.089980\n",
            "Train Epoch: 4 [1584/3978 (40%)]\tLoss: 0.179376\n",
            "Train Epoch: 4 [1585/3978 (40%)]\tLoss: 6.004081\n",
            "Train Epoch: 4 [1586/3978 (40%)]\tLoss: 0.477359\n",
            "Train Epoch: 4 [1587/3978 (40%)]\tLoss: 0.320629\n",
            "Train Epoch: 4 [1588/3978 (40%)]\tLoss: 0.168102\n",
            "Train Epoch: 4 [1589/3978 (40%)]\tLoss: 0.001334\n",
            "Train Epoch: 4 [1590/3978 (40%)]\tLoss: 0.012378\n",
            "Train Epoch: 4 [1591/3978 (40%)]\tLoss: 1.535887\n",
            "Train Epoch: 4 [1592/3978 (40%)]\tLoss: 0.013480\n",
            "Train Epoch: 4 [1593/3978 (40%)]\tLoss: 0.208912\n",
            "Train Epoch: 4 [1594/3978 (40%)]\tLoss: 0.084400\n",
            "Train Epoch: 4 [1595/3978 (40%)]\tLoss: 2.962370\n",
            "Train Epoch: 4 [1596/3978 (40%)]\tLoss: 0.345144\n",
            "Train Epoch: 4 [1597/3978 (40%)]\tLoss: 0.614116\n",
            "Train Epoch: 4 [1598/3978 (40%)]\tLoss: 0.018006\n",
            "Train Epoch: 4 [1599/3978 (40%)]\tLoss: 2.166817\n",
            "Train Epoch: 4 [1600/3978 (40%)]\tLoss: 1.970257\n",
            "Train Epoch: 4 [1601/3978 (40%)]\tLoss: 0.096397\n",
            "Train Epoch: 4 [1602/3978 (40%)]\tLoss: 1.972335\n",
            "Train Epoch: 4 [1603/3978 (40%)]\tLoss: 0.352620\n",
            "Train Epoch: 4 [1604/3978 (40%)]\tLoss: 0.958879\n",
            "Train Epoch: 4 [1605/3978 (40%)]\tLoss: 0.826221\n",
            "Train Epoch: 4 [1606/3978 (40%)]\tLoss: 1.039734\n",
            "Train Epoch: 4 [1607/3978 (40%)]\tLoss: 0.343684\n",
            "Train Epoch: 4 [1608/3978 (40%)]\tLoss: 1.255020\n",
            "Train Epoch: 4 [1609/3978 (40%)]\tLoss: 0.000474\n",
            "Train Epoch: 4 [1610/3978 (40%)]\tLoss: 0.079202\n",
            "Train Epoch: 4 [1611/3978 (40%)]\tLoss: 0.000029\n",
            "Train Epoch: 4 [1612/3978 (41%)]\tLoss: 0.002319\n",
            "Train Epoch: 4 [1613/3978 (41%)]\tLoss: 0.373237\n",
            "Train Epoch: 4 [1614/3978 (41%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1615/3978 (41%)]\tLoss: 3.557227\n",
            "Train Epoch: 4 [1616/3978 (41%)]\tLoss: 0.000035\n",
            "Train Epoch: 4 [1617/3978 (41%)]\tLoss: 1.422506\n",
            "Train Epoch: 4 [1618/3978 (41%)]\tLoss: 1.669097\n",
            "Train Epoch: 4 [1619/3978 (41%)]\tLoss: 2.927982\n",
            "Train Epoch: 4 [1620/3978 (41%)]\tLoss: 1.865563\n",
            "Train Epoch: 4 [1621/3978 (41%)]\tLoss: 0.000090\n",
            "Train Epoch: 4 [1622/3978 (41%)]\tLoss: 0.891254\n",
            "Train Epoch: 4 [1623/3978 (41%)]\tLoss: 0.962017\n",
            "Train Epoch: 4 [1624/3978 (41%)]\tLoss: 0.550703\n",
            "Train Epoch: 4 [1625/3978 (41%)]\tLoss: 0.021233\n",
            "Train Epoch: 4 [1626/3978 (41%)]\tLoss: 0.010461\n",
            "Train Epoch: 4 [1627/3978 (41%)]\tLoss: 1.630628\n",
            "Train Epoch: 4 [1628/3978 (41%)]\tLoss: 0.302794\n",
            "Train Epoch: 4 [1629/3978 (41%)]\tLoss: 0.000684\n",
            "Train Epoch: 4 [1630/3978 (41%)]\tLoss: 0.000024\n",
            "Train Epoch: 4 [1631/3978 (41%)]\tLoss: 2.974154\n",
            "Train Epoch: 4 [1632/3978 (41%)]\tLoss: 2.704193\n",
            "Train Epoch: 4 [1633/3978 (41%)]\tLoss: 0.517820\n",
            "Train Epoch: 4 [1634/3978 (41%)]\tLoss: 0.769150\n",
            "Train Epoch: 4 [1635/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1636/3978 (41%)]\tLoss: 4.580799\n",
            "Train Epoch: 4 [1637/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1638/3978 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1639/3978 (41%)]\tLoss: 2.093982\n",
            "Train Epoch: 4 [1640/3978 (41%)]\tLoss: 1.559780\n",
            "Train Epoch: 4 [1641/3978 (41%)]\tLoss: 0.719735\n",
            "Train Epoch: 4 [1642/3978 (41%)]\tLoss: 0.001907\n",
            "Train Epoch: 4 [1643/3978 (41%)]\tLoss: 0.181279\n",
            "Train Epoch: 4 [1644/3978 (41%)]\tLoss: 0.000500\n",
            "Train Epoch: 4 [1645/3978 (41%)]\tLoss: 0.099082\n",
            "Train Epoch: 4 [1646/3978 (41%)]\tLoss: 0.001182\n",
            "Train Epoch: 4 [1647/3978 (41%)]\tLoss: 1.693283\n",
            "Train Epoch: 4 [1648/3978 (41%)]\tLoss: 2.119373\n",
            "Train Epoch: 4 [1649/3978 (41%)]\tLoss: 1.899839\n",
            "Train Epoch: 4 [1650/3978 (41%)]\tLoss: 0.038649\n",
            "Train Epoch: 4 [1651/3978 (42%)]\tLoss: 0.030768\n",
            "Train Epoch: 4 [1652/3978 (42%)]\tLoss: 0.959955\n",
            "Train Epoch: 4 [1653/3978 (42%)]\tLoss: 1.093539\n",
            "Train Epoch: 4 [1654/3978 (42%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [1655/3978 (42%)]\tLoss: 0.000129\n",
            "Train Epoch: 4 [1656/3978 (42%)]\tLoss: 1.434207\n",
            "Train Epoch: 4 [1657/3978 (42%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [1658/3978 (42%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1659/3978 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1660/3978 (42%)]\tLoss: 1.476799\n",
            "Train Epoch: 4 [1661/3978 (42%)]\tLoss: 2.916858\n",
            "Train Epoch: 4 [1662/3978 (42%)]\tLoss: 1.183184\n",
            "Train Epoch: 4 [1663/3978 (42%)]\tLoss: 5.212962\n",
            "Train Epoch: 4 [1664/3978 (42%)]\tLoss: 1.932377\n",
            "Train Epoch: 4 [1665/3978 (42%)]\tLoss: 0.649827\n",
            "Train Epoch: 4 [1666/3978 (42%)]\tLoss: 2.082278\n",
            "Train Epoch: 4 [1667/3978 (42%)]\tLoss: 0.948033\n",
            "Train Epoch: 4 [1668/3978 (42%)]\tLoss: 1.600736\n",
            "Train Epoch: 4 [1669/3978 (42%)]\tLoss: 0.921371\n",
            "Train Epoch: 4 [1670/3978 (42%)]\tLoss: 5.889339\n",
            "Train Epoch: 4 [1671/3978 (42%)]\tLoss: 0.126936\n",
            "Train Epoch: 4 [1672/3978 (42%)]\tLoss: 0.001316\n",
            "Train Epoch: 4 [1673/3978 (42%)]\tLoss: 1.557898\n",
            "Train Epoch: 4 [1674/3978 (42%)]\tLoss: 4.318555\n",
            "Train Epoch: 4 [1675/3978 (42%)]\tLoss: 1.683294\n",
            "Train Epoch: 4 [1676/3978 (42%)]\tLoss: 1.036156\n",
            "Train Epoch: 4 [1677/3978 (42%)]\tLoss: 0.648302\n",
            "Train Epoch: 4 [1678/3978 (42%)]\tLoss: 0.004352\n",
            "Train Epoch: 4 [1679/3978 (42%)]\tLoss: 0.312751\n",
            "Train Epoch: 4 [1680/3978 (42%)]\tLoss: 0.935609\n",
            "Train Epoch: 4 [1681/3978 (42%)]\tLoss: 0.924042\n",
            "Train Epoch: 4 [1682/3978 (42%)]\tLoss: 0.001123\n",
            "Train Epoch: 4 [1683/3978 (42%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1684/3978 (42%)]\tLoss: 0.000048\n",
            "Train Epoch: 4 [1685/3978 (42%)]\tLoss: 0.086350\n",
            "Train Epoch: 4 [1686/3978 (42%)]\tLoss: 0.000152\n",
            "Train Epoch: 4 [1687/3978 (42%)]\tLoss: 1.860204\n",
            "Train Epoch: 4 [1688/3978 (42%)]\tLoss: 1.837309\n",
            "Train Epoch: 4 [1689/3978 (42%)]\tLoss: 2.189021\n",
            "Train Epoch: 4 [1690/3978 (42%)]\tLoss: 0.111679\n",
            "Train Epoch: 4 [1691/3978 (43%)]\tLoss: 0.000835\n",
            "Train Epoch: 4 [1692/3978 (43%)]\tLoss: 0.607360\n",
            "Train Epoch: 4 [1693/3978 (43%)]\tLoss: 2.035589\n",
            "Train Epoch: 4 [1694/3978 (43%)]\tLoss: 0.002668\n",
            "Train Epoch: 4 [1695/3978 (43%)]\tLoss: 0.000171\n",
            "Train Epoch: 4 [1696/3978 (43%)]\tLoss: 0.003401\n",
            "Train Epoch: 4 [1697/3978 (43%)]\tLoss: 1.167919\n",
            "Train Epoch: 4 [1698/3978 (43%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [1699/3978 (43%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1700/3978 (43%)]\tLoss: 0.546743\n",
            "Train Epoch: 4 [1701/3978 (43%)]\tLoss: 0.393514\n",
            "Train Epoch: 4 [1702/3978 (43%)]\tLoss: 0.175707\n",
            "Train Epoch: 4 [1703/3978 (43%)]\tLoss: 1.243769\n",
            "Train Epoch: 4 [1704/3978 (43%)]\tLoss: 1.760064\n",
            "Train Epoch: 4 [1705/3978 (43%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1706/3978 (43%)]\tLoss: 1.213452\n",
            "Train Epoch: 4 [1707/3978 (43%)]\tLoss: 0.546290\n",
            "Train Epoch: 4 [1708/3978 (43%)]\tLoss: 0.730619\n",
            "Train Epoch: 4 [1709/3978 (43%)]\tLoss: 0.022277\n",
            "Train Epoch: 4 [1710/3978 (43%)]\tLoss: 0.332528\n",
            "Train Epoch: 4 [1711/3978 (43%)]\tLoss: 0.002879\n",
            "Train Epoch: 4 [1712/3978 (43%)]\tLoss: 2.249701\n",
            "Train Epoch: 4 [1713/3978 (43%)]\tLoss: 1.279262\n",
            "Train Epoch: 4 [1714/3978 (43%)]\tLoss: 0.002173\n",
            "Train Epoch: 4 [1715/3978 (43%)]\tLoss: 4.329726\n",
            "Train Epoch: 4 [1716/3978 (43%)]\tLoss: 0.000079\n",
            "Train Epoch: 4 [1717/3978 (43%)]\tLoss: 0.945718\n",
            "Train Epoch: 4 [1718/3978 (43%)]\tLoss: 0.683982\n",
            "Train Epoch: 4 [1719/3978 (43%)]\tLoss: 3.285962\n",
            "Train Epoch: 4 [1720/3978 (43%)]\tLoss: 0.536591\n",
            "Train Epoch: 4 [1721/3978 (43%)]\tLoss: 2.705871\n",
            "Train Epoch: 4 [1722/3978 (43%)]\tLoss: 0.210679\n",
            "Train Epoch: 4 [1723/3978 (43%)]\tLoss: 0.006953\n",
            "Train Epoch: 4 [1724/3978 (43%)]\tLoss: 0.000067\n",
            "Train Epoch: 4 [1725/3978 (43%)]\tLoss: 0.000365\n",
            "Train Epoch: 4 [1726/3978 (43%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [1727/3978 (43%)]\tLoss: 1.395992\n",
            "Train Epoch: 4 [1728/3978 (43%)]\tLoss: 1.498770\n",
            "Train Epoch: 4 [1729/3978 (43%)]\tLoss: 1.628667\n",
            "Train Epoch: 4 [1730/3978 (43%)]\tLoss: 0.627628\n",
            "Train Epoch: 4 [1731/3978 (44%)]\tLoss: 0.484732\n",
            "Train Epoch: 4 [1732/3978 (44%)]\tLoss: 0.008744\n",
            "Train Epoch: 4 [1733/3978 (44%)]\tLoss: 0.203559\n",
            "Train Epoch: 4 [1734/3978 (44%)]\tLoss: 0.081998\n",
            "Train Epoch: 4 [1735/3978 (44%)]\tLoss: 0.741691\n",
            "Train Epoch: 4 [1736/3978 (44%)]\tLoss: 1.165752\n",
            "Train Epoch: 4 [1737/3978 (44%)]\tLoss: 0.254472\n",
            "Train Epoch: 4 [1738/3978 (44%)]\tLoss: 0.264152\n",
            "Train Epoch: 4 [1739/3978 (44%)]\tLoss: 0.001129\n",
            "Train Epoch: 4 [1740/3978 (44%)]\tLoss: 1.511239\n",
            "Train Epoch: 4 [1741/3978 (44%)]\tLoss: 3.557045\n",
            "Train Epoch: 4 [1742/3978 (44%)]\tLoss: 0.289878\n",
            "Train Epoch: 4 [1743/3978 (44%)]\tLoss: 0.506453\n",
            "Train Epoch: 4 [1744/3978 (44%)]\tLoss: 0.752942\n",
            "Train Epoch: 4 [1745/3978 (44%)]\tLoss: 0.561372\n",
            "Train Epoch: 4 [1746/3978 (44%)]\tLoss: 0.020624\n",
            "Train Epoch: 4 [1747/3978 (44%)]\tLoss: 0.064258\n",
            "Train Epoch: 4 [1748/3978 (44%)]\tLoss: 0.001880\n",
            "Train Epoch: 4 [1749/3978 (44%)]\tLoss: 0.227004\n",
            "Train Epoch: 4 [1750/3978 (44%)]\tLoss: 0.053182\n",
            "Train Epoch: 4 [1751/3978 (44%)]\tLoss: 0.499111\n",
            "Train Epoch: 4 [1752/3978 (44%)]\tLoss: 0.567513\n",
            "Train Epoch: 4 [1753/3978 (44%)]\tLoss: 0.120913\n",
            "Train Epoch: 4 [1754/3978 (44%)]\tLoss: 0.044614\n",
            "Train Epoch: 4 [1755/3978 (44%)]\tLoss: 0.000740\n",
            "Train Epoch: 4 [1756/3978 (44%)]\tLoss: 0.009104\n",
            "Train Epoch: 4 [1757/3978 (44%)]\tLoss: 0.161502\n",
            "Train Epoch: 4 [1758/3978 (44%)]\tLoss: 0.411047\n",
            "Train Epoch: 4 [1759/3978 (44%)]\tLoss: 0.551933\n",
            "Train Epoch: 4 [1760/3978 (44%)]\tLoss: 2.746866\n",
            "Train Epoch: 4 [1761/3978 (44%)]\tLoss: 1.873868\n",
            "Train Epoch: 4 [1762/3978 (44%)]\tLoss: 0.037155\n",
            "Train Epoch: 4 [1763/3978 (44%)]\tLoss: 2.426338\n",
            "Train Epoch: 4 [1764/3978 (44%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [1765/3978 (44%)]\tLoss: 0.009962\n",
            "Train Epoch: 4 [1766/3978 (44%)]\tLoss: 2.152065\n",
            "Train Epoch: 4 [1767/3978 (44%)]\tLoss: 0.572514\n",
            "Train Epoch: 4 [1768/3978 (44%)]\tLoss: 0.601339\n",
            "Train Epoch: 4 [1769/3978 (44%)]\tLoss: 0.671115\n",
            "Train Epoch: 4 [1770/3978 (44%)]\tLoss: 0.517935\n",
            "Train Epoch: 4 [1771/3978 (45%)]\tLoss: 1.278098\n",
            "Train Epoch: 4 [1772/3978 (45%)]\tLoss: 1.897292\n",
            "Train Epoch: 4 [1773/3978 (45%)]\tLoss: 1.453844\n",
            "Train Epoch: 4 [1774/3978 (45%)]\tLoss: 3.091108\n",
            "Train Epoch: 4 [1775/3978 (45%)]\tLoss: 0.000027\n",
            "Train Epoch: 4 [1776/3978 (45%)]\tLoss: 0.023413\n",
            "Train Epoch: 4 [1777/3978 (45%)]\tLoss: 0.024160\n",
            "Train Epoch: 4 [1778/3978 (45%)]\tLoss: 1.663349\n",
            "Train Epoch: 4 [1779/3978 (45%)]\tLoss: 0.562831\n",
            "Train Epoch: 4 [1780/3978 (45%)]\tLoss: 0.463487\n",
            "Train Epoch: 4 [1781/3978 (45%)]\tLoss: 0.337854\n",
            "Train Epoch: 4 [1782/3978 (45%)]\tLoss: 0.010783\n",
            "Train Epoch: 4 [1783/3978 (45%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [1784/3978 (45%)]\tLoss: 1.914839\n",
            "Train Epoch: 4 [1785/3978 (45%)]\tLoss: 1.582235\n",
            "Train Epoch: 4 [1786/3978 (45%)]\tLoss: 1.826989\n",
            "Train Epoch: 4 [1787/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1788/3978 (45%)]\tLoss: 1.995260\n",
            "Train Epoch: 4 [1789/3978 (45%)]\tLoss: 2.503881\n",
            "Train Epoch: 4 [1790/3978 (45%)]\tLoss: 0.425984\n",
            "Train Epoch: 4 [1791/3978 (45%)]\tLoss: 0.698015\n",
            "Train Epoch: 4 [1792/3978 (45%)]\tLoss: 0.001343\n",
            "Train Epoch: 4 [1793/3978 (45%)]\tLoss: 1.277867\n",
            "Train Epoch: 4 [1794/3978 (45%)]\tLoss: 1.783147\n",
            "Train Epoch: 4 [1795/3978 (45%)]\tLoss: 1.607499\n",
            "Train Epoch: 4 [1796/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1797/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1798/3978 (45%)]\tLoss: 1.515940\n",
            "Train Epoch: 4 [1799/3978 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1800/3978 (45%)]\tLoss: 1.006054\n",
            "Train Epoch: 4 [1801/3978 (45%)]\tLoss: 2.148482\n",
            "Train Epoch: 4 [1802/3978 (45%)]\tLoss: 0.032471\n",
            "Train Epoch: 4 [1803/3978 (45%)]\tLoss: 0.008856\n",
            "Train Epoch: 4 [1804/3978 (45%)]\tLoss: 0.342848\n",
            "Train Epoch: 4 [1805/3978 (45%)]\tLoss: 0.539157\n",
            "Train Epoch: 4 [1806/3978 (45%)]\tLoss: 0.536990\n",
            "Train Epoch: 4 [1807/3978 (45%)]\tLoss: 0.473058\n",
            "Train Epoch: 4 [1808/3978 (45%)]\tLoss: 0.640563\n",
            "Train Epoch: 4 [1809/3978 (45%)]\tLoss: 0.262806\n",
            "Train Epoch: 4 [1810/3978 (46%)]\tLoss: 0.357239\n",
            "Train Epoch: 4 [1811/3978 (46%)]\tLoss: 0.505199\n",
            "Train Epoch: 4 [1812/3978 (46%)]\tLoss: 0.016288\n",
            "Train Epoch: 4 [1813/3978 (46%)]\tLoss: 0.323603\n",
            "Train Epoch: 4 [1814/3978 (46%)]\tLoss: 0.541517\n",
            "Train Epoch: 4 [1815/3978 (46%)]\tLoss: 0.929262\n",
            "Train Epoch: 4 [1816/3978 (46%)]\tLoss: 1.066822\n",
            "Train Epoch: 4 [1817/3978 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1818/3978 (46%)]\tLoss: 0.417714\n",
            "Train Epoch: 4 [1819/3978 (46%)]\tLoss: 0.028627\n",
            "Train Epoch: 4 [1820/3978 (46%)]\tLoss: 0.006334\n",
            "Train Epoch: 4 [1821/3978 (46%)]\tLoss: 0.181543\n",
            "Train Epoch: 4 [1822/3978 (46%)]\tLoss: 0.017289\n",
            "Train Epoch: 4 [1823/3978 (46%)]\tLoss: 1.106942\n",
            "Train Epoch: 4 [1824/3978 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1825/3978 (46%)]\tLoss: 3.733464\n",
            "Train Epoch: 4 [1826/3978 (46%)]\tLoss: 1.578849\n",
            "Train Epoch: 4 [1827/3978 (46%)]\tLoss: 0.696393\n",
            "Train Epoch: 4 [1828/3978 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1829/3978 (46%)]\tLoss: 0.000436\n",
            "Train Epoch: 4 [1830/3978 (46%)]\tLoss: 0.003023\n",
            "Train Epoch: 4 [1831/3978 (46%)]\tLoss: 0.004220\n",
            "Train Epoch: 4 [1832/3978 (46%)]\tLoss: 0.210148\n",
            "Train Epoch: 4 [1833/3978 (46%)]\tLoss: 3.351676\n",
            "Train Epoch: 4 [1834/3978 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1835/3978 (46%)]\tLoss: 1.265573\n",
            "Train Epoch: 4 [1836/3978 (46%)]\tLoss: 0.607311\n",
            "Train Epoch: 4 [1837/3978 (46%)]\tLoss: 0.021480\n",
            "Train Epoch: 4 [1838/3978 (46%)]\tLoss: 0.001700\n",
            "Train Epoch: 4 [1839/3978 (46%)]\tLoss: 1.244894\n",
            "Train Epoch: 4 [1840/3978 (46%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [1841/3978 (46%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1842/3978 (46%)]\tLoss: 0.972001\n",
            "Train Epoch: 4 [1843/3978 (46%)]\tLoss: 0.000175\n",
            "Train Epoch: 4 [1844/3978 (46%)]\tLoss: 1.901368\n",
            "Train Epoch: 4 [1845/3978 (46%)]\tLoss: 1.731564\n",
            "Train Epoch: 4 [1846/3978 (46%)]\tLoss: 0.117077\n",
            "Train Epoch: 4 [1847/3978 (46%)]\tLoss: 0.170251\n",
            "Train Epoch: 4 [1848/3978 (46%)]\tLoss: 0.482581\n",
            "Train Epoch: 4 [1849/3978 (46%)]\tLoss: 0.277368\n",
            "Train Epoch: 4 [1850/3978 (47%)]\tLoss: 0.764535\n",
            "Train Epoch: 4 [1851/3978 (47%)]\tLoss: 3.803507\n",
            "Train Epoch: 4 [1852/3978 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1853/3978 (47%)]\tLoss: 2.585765\n",
            "Train Epoch: 4 [1854/3978 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1855/3978 (47%)]\tLoss: 0.293188\n",
            "Train Epoch: 4 [1856/3978 (47%)]\tLoss: 0.323930\n",
            "Train Epoch: 4 [1857/3978 (47%)]\tLoss: 0.000090\n",
            "Train Epoch: 4 [1858/3978 (47%)]\tLoss: 2.293882\n",
            "Train Epoch: 4 [1859/3978 (47%)]\tLoss: 2.620952\n",
            "Train Epoch: 4 [1860/3978 (47%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [1861/3978 (47%)]\tLoss: 0.000227\n",
            "Train Epoch: 4 [1862/3978 (47%)]\tLoss: 1.633547\n",
            "Train Epoch: 4 [1863/3978 (47%)]\tLoss: 0.474468\n",
            "Train Epoch: 4 [1864/3978 (47%)]\tLoss: 2.508890\n",
            "Train Epoch: 4 [1865/3978 (47%)]\tLoss: 0.827263\n",
            "Train Epoch: 4 [1866/3978 (47%)]\tLoss: 0.153463\n",
            "Train Epoch: 4 [1867/3978 (47%)]\tLoss: 0.800329\n",
            "Train Epoch: 4 [1868/3978 (47%)]\tLoss: 0.670930\n",
            "Train Epoch: 4 [1869/3978 (47%)]\tLoss: 0.039238\n",
            "Train Epoch: 4 [1870/3978 (47%)]\tLoss: 1.035394\n",
            "Train Epoch: 4 [1871/3978 (47%)]\tLoss: 0.004464\n",
            "Train Epoch: 4 [1872/3978 (47%)]\tLoss: 0.029683\n",
            "Train Epoch: 4 [1873/3978 (47%)]\tLoss: 0.102881\n",
            "Train Epoch: 4 [1874/3978 (47%)]\tLoss: 0.027692\n",
            "Train Epoch: 4 [1875/3978 (47%)]\tLoss: 0.050251\n",
            "Train Epoch: 4 [1876/3978 (47%)]\tLoss: 0.202709\n",
            "Train Epoch: 4 [1877/3978 (47%)]\tLoss: 0.000264\n",
            "Train Epoch: 4 [1878/3978 (47%)]\tLoss: 6.408281\n",
            "Train Epoch: 4 [1879/3978 (47%)]\tLoss: 0.000170\n",
            "Train Epoch: 4 [1880/3978 (47%)]\tLoss: 0.028207\n",
            "Train Epoch: 4 [1881/3978 (47%)]\tLoss: 1.458949\n",
            "Train Epoch: 4 [1882/3978 (47%)]\tLoss: 0.451554\n",
            "Train Epoch: 4 [1883/3978 (47%)]\tLoss: 0.970593\n",
            "Train Epoch: 4 [1884/3978 (47%)]\tLoss: 2.000047\n",
            "Train Epoch: 4 [1885/3978 (47%)]\tLoss: 0.084530\n",
            "Train Epoch: 4 [1886/3978 (47%)]\tLoss: 4.695182\n",
            "Train Epoch: 4 [1887/3978 (47%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [1888/3978 (47%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [1889/3978 (47%)]\tLoss: 0.286203\n",
            "Train Epoch: 4 [1890/3978 (48%)]\tLoss: 0.000200\n",
            "Train Epoch: 4 [1891/3978 (48%)]\tLoss: 0.126426\n",
            "Train Epoch: 4 [1892/3978 (48%)]\tLoss: 0.018479\n",
            "Train Epoch: 4 [1893/3978 (48%)]\tLoss: 0.092911\n",
            "Train Epoch: 4 [1894/3978 (48%)]\tLoss: 0.134808\n",
            "Train Epoch: 4 [1895/3978 (48%)]\tLoss: 0.043602\n",
            "Train Epoch: 4 [1896/3978 (48%)]\tLoss: 0.023186\n",
            "Train Epoch: 4 [1897/3978 (48%)]\tLoss: 3.922540\n",
            "Train Epoch: 4 [1898/3978 (48%)]\tLoss: 1.082129\n",
            "Train Epoch: 4 [1899/3978 (48%)]\tLoss: 0.001340\n",
            "Train Epoch: 4 [1900/3978 (48%)]\tLoss: 0.325587\n",
            "Train Epoch: 4 [1901/3978 (48%)]\tLoss: 0.339465\n",
            "Train Epoch: 4 [1902/3978 (48%)]\tLoss: 0.000968\n",
            "Train Epoch: 4 [1903/3978 (48%)]\tLoss: 1.152323\n",
            "Train Epoch: 4 [1904/3978 (48%)]\tLoss: 0.046605\n",
            "Train Epoch: 4 [1905/3978 (48%)]\tLoss: 2.618921\n",
            "Train Epoch: 4 [1906/3978 (48%)]\tLoss: 0.000113\n",
            "Train Epoch: 4 [1907/3978 (48%)]\tLoss: 0.000225\n",
            "Train Epoch: 4 [1908/3978 (48%)]\tLoss: 2.160781\n",
            "Train Epoch: 4 [1909/3978 (48%)]\tLoss: 0.941243\n",
            "Train Epoch: 4 [1910/3978 (48%)]\tLoss: 0.021118\n",
            "Train Epoch: 4 [1911/3978 (48%)]\tLoss: 0.710214\n",
            "Train Epoch: 4 [1912/3978 (48%)]\tLoss: 1.245765\n",
            "Train Epoch: 4 [1913/3978 (48%)]\tLoss: 0.048530\n",
            "Train Epoch: 4 [1914/3978 (48%)]\tLoss: 0.478898\n",
            "Train Epoch: 4 [1915/3978 (48%)]\tLoss: 0.173039\n",
            "Train Epoch: 4 [1916/3978 (48%)]\tLoss: 2.698209\n",
            "Train Epoch: 4 [1917/3978 (48%)]\tLoss: 0.164243\n",
            "Train Epoch: 4 [1918/3978 (48%)]\tLoss: 0.027571\n",
            "Train Epoch: 4 [1919/3978 (48%)]\tLoss: 1.960235\n",
            "Train Epoch: 4 [1920/3978 (48%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [1921/3978 (48%)]\tLoss: 0.000035\n",
            "Train Epoch: 4 [1922/3978 (48%)]\tLoss: 2.504483\n",
            "Train Epoch: 4 [1923/3978 (48%)]\tLoss: 1.525859\n",
            "Train Epoch: 4 [1924/3978 (48%)]\tLoss: 1.494300\n",
            "Train Epoch: 4 [1925/3978 (48%)]\tLoss: 1.077431\n",
            "Train Epoch: 4 [1926/3978 (48%)]\tLoss: 0.389846\n",
            "Train Epoch: 4 [1927/3978 (48%)]\tLoss: 0.094595\n",
            "Train Epoch: 4 [1928/3978 (48%)]\tLoss: 0.310646\n",
            "Train Epoch: 4 [1929/3978 (48%)]\tLoss: 1.137715\n",
            "Train Epoch: 4 [1930/3978 (49%)]\tLoss: 0.356414\n",
            "Train Epoch: 4 [1931/3978 (49%)]\tLoss: 0.011750\n",
            "Train Epoch: 4 [1932/3978 (49%)]\tLoss: 0.000049\n",
            "Train Epoch: 4 [1933/3978 (49%)]\tLoss: 0.511358\n",
            "Train Epoch: 4 [1934/3978 (49%)]\tLoss: 1.057681\n",
            "Train Epoch: 4 [1935/3978 (49%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [1936/3978 (49%)]\tLoss: 0.285453\n",
            "Train Epoch: 4 [1937/3978 (49%)]\tLoss: 0.353108\n",
            "Train Epoch: 4 [1938/3978 (49%)]\tLoss: 1.597579\n",
            "Train Epoch: 4 [1939/3978 (49%)]\tLoss: 3.830220\n",
            "Train Epoch: 4 [1940/3978 (49%)]\tLoss: 1.123320\n",
            "Train Epoch: 4 [1941/3978 (49%)]\tLoss: 0.005739\n",
            "Train Epoch: 4 [1942/3978 (49%)]\tLoss: 0.750356\n",
            "Train Epoch: 4 [1943/3978 (49%)]\tLoss: 1.112608\n",
            "Train Epoch: 4 [1944/3978 (49%)]\tLoss: 0.013075\n",
            "Train Epoch: 4 [1945/3978 (49%)]\tLoss: 0.402437\n",
            "Train Epoch: 4 [1946/3978 (49%)]\tLoss: 0.001631\n",
            "Train Epoch: 4 [1947/3978 (49%)]\tLoss: 0.432031\n",
            "Train Epoch: 4 [1948/3978 (49%)]\tLoss: 0.000036\n",
            "Train Epoch: 4 [1949/3978 (49%)]\tLoss: 1.245313\n",
            "Train Epoch: 4 [1950/3978 (49%)]\tLoss: 1.288201\n",
            "Train Epoch: 4 [1951/3978 (49%)]\tLoss: 0.000968\n",
            "Train Epoch: 4 [1952/3978 (49%)]\tLoss: 0.000508\n",
            "Train Epoch: 4 [1953/3978 (49%)]\tLoss: 0.164091\n",
            "Train Epoch: 4 [1954/3978 (49%)]\tLoss: 0.000071\n",
            "Train Epoch: 4 [1955/3978 (49%)]\tLoss: 0.014436\n",
            "Train Epoch: 4 [1956/3978 (49%)]\tLoss: 0.126173\n",
            "Train Epoch: 4 [1957/3978 (49%)]\tLoss: 0.078208\n",
            "Train Epoch: 4 [1958/3978 (49%)]\tLoss: 0.143219\n",
            "Train Epoch: 4 [1959/3978 (49%)]\tLoss: 0.052145\n",
            "Train Epoch: 4 [1960/3978 (49%)]\tLoss: 0.315719\n",
            "Train Epoch: 4 [1961/3978 (49%)]\tLoss: 0.154254\n",
            "Train Epoch: 4 [1962/3978 (49%)]\tLoss: 0.000104\n",
            "Train Epoch: 4 [1963/3978 (49%)]\tLoss: 2.120264\n",
            "Train Epoch: 4 [1964/3978 (49%)]\tLoss: 0.184909\n",
            "Train Epoch: 4 [1965/3978 (49%)]\tLoss: 0.052151\n",
            "Train Epoch: 4 [1966/3978 (49%)]\tLoss: 0.295064\n",
            "Train Epoch: 4 [1967/3978 (49%)]\tLoss: 0.116190\n",
            "Train Epoch: 4 [1968/3978 (49%)]\tLoss: 0.001123\n",
            "Train Epoch: 4 [1969/3978 (49%)]\tLoss: 0.042005\n",
            "Train Epoch: 4 [1970/3978 (50%)]\tLoss: 0.009082\n",
            "Train Epoch: 4 [1971/3978 (50%)]\tLoss: 1.076055\n",
            "Train Epoch: 4 [1972/3978 (50%)]\tLoss: 1.398249\n",
            "Train Epoch: 4 [1973/3978 (50%)]\tLoss: 0.430884\n",
            "Train Epoch: 4 [1974/3978 (50%)]\tLoss: 0.012844\n",
            "Train Epoch: 4 [1975/3978 (50%)]\tLoss: 0.000187\n",
            "Train Epoch: 4 [1976/3978 (50%)]\tLoss: 0.000275\n",
            "Train Epoch: 4 [1977/3978 (50%)]\tLoss: 0.927544\n",
            "Train Epoch: 4 [1978/3978 (50%)]\tLoss: 0.787247\n",
            "Train Epoch: 4 [1979/3978 (50%)]\tLoss: 0.728831\n",
            "Train Epoch: 4 [1980/3978 (50%)]\tLoss: 0.025202\n",
            "Train Epoch: 4 [1981/3978 (50%)]\tLoss: 0.195389\n",
            "Train Epoch: 4 [1982/3978 (50%)]\tLoss: 0.526164\n",
            "Train Epoch: 4 [1983/3978 (50%)]\tLoss: 0.002909\n",
            "Train Epoch: 4 [1984/3978 (50%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [1985/3978 (50%)]\tLoss: 0.775493\n",
            "Train Epoch: 4 [1986/3978 (50%)]\tLoss: 0.307946\n",
            "Train Epoch: 4 [1987/3978 (50%)]\tLoss: 0.004662\n",
            "Train Epoch: 4 [1988/3978 (50%)]\tLoss: 0.003593\n",
            "Train Epoch: 4 [1989/3978 (50%)]\tLoss: 0.053249\n",
            "Train Epoch: 4 [1990/3978 (50%)]\tLoss: 0.002817\n",
            "Train Epoch: 4 [1991/3978 (50%)]\tLoss: 0.783259\n",
            "Train Epoch: 4 [1992/3978 (50%)]\tLoss: 0.227623\n",
            "Train Epoch: 4 [1993/3978 (50%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [1994/3978 (50%)]\tLoss: 0.921791\n",
            "Train Epoch: 4 [1995/3978 (50%)]\tLoss: 0.026688\n",
            "Train Epoch: 4 [1996/3978 (50%)]\tLoss: 0.181533\n",
            "Train Epoch: 4 [1997/3978 (50%)]\tLoss: 1.956097\n",
            "Train Epoch: 4 [1998/3978 (50%)]\tLoss: 1.836379\n",
            "Train Epoch: 4 [1999/3978 (50%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [2000/3978 (50%)]\tLoss: 0.944457\n",
            "Train Epoch: 4 [2001/3978 (50%)]\tLoss: 0.039741\n",
            "Train Epoch: 4 [2002/3978 (50%)]\tLoss: 0.085462\n",
            "Train Epoch: 4 [2003/3978 (50%)]\tLoss: 2.693120\n",
            "Train Epoch: 4 [2004/3978 (50%)]\tLoss: 0.693196\n",
            "Train Epoch: 4 [2005/3978 (50%)]\tLoss: 2.236009\n",
            "Train Epoch: 4 [2006/3978 (50%)]\tLoss: 1.456112\n",
            "Train Epoch: 4 [2007/3978 (50%)]\tLoss: 0.016561\n",
            "Train Epoch: 4 [2008/3978 (50%)]\tLoss: 0.864096\n",
            "Train Epoch: 4 [2009/3978 (51%)]\tLoss: 0.001049\n",
            "Train Epoch: 4 [2010/3978 (51%)]\tLoss: 0.284413\n",
            "Train Epoch: 4 [2011/3978 (51%)]\tLoss: 0.000112\n",
            "Train Epoch: 4 [2012/3978 (51%)]\tLoss: 0.000110\n",
            "Train Epoch: 4 [2013/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2014/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2015/3978 (51%)]\tLoss: 1.713869\n",
            "Train Epoch: 4 [2016/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2017/3978 (51%)]\tLoss: 2.109775\n",
            "Train Epoch: 4 [2018/3978 (51%)]\tLoss: 2.222651\n",
            "Train Epoch: 4 [2019/3978 (51%)]\tLoss: 1.850181\n",
            "Train Epoch: 4 [2020/3978 (51%)]\tLoss: 1.094633\n",
            "Train Epoch: 4 [2021/3978 (51%)]\tLoss: 1.003612\n",
            "Train Epoch: 4 [2022/3978 (51%)]\tLoss: 3.811895\n",
            "Train Epoch: 4 [2023/3978 (51%)]\tLoss: 2.310817\n",
            "Train Epoch: 4 [2024/3978 (51%)]\tLoss: 2.783516\n",
            "Train Epoch: 4 [2025/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2026/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2027/3978 (51%)]\tLoss: 3.342093\n",
            "Train Epoch: 4 [2028/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2029/3978 (51%)]\tLoss: 3.056518\n",
            "Train Epoch: 4 [2030/3978 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2031/3978 (51%)]\tLoss: 0.005101\n",
            "Train Epoch: 4 [2032/3978 (51%)]\tLoss: 0.014389\n",
            "Train Epoch: 4 [2033/3978 (51%)]\tLoss: 0.001841\n",
            "Train Epoch: 4 [2034/3978 (51%)]\tLoss: 2.006101\n",
            "Train Epoch: 4 [2035/3978 (51%)]\tLoss: 2.345233\n",
            "Train Epoch: 4 [2036/3978 (51%)]\tLoss: 0.017750\n",
            "Train Epoch: 4 [2037/3978 (51%)]\tLoss: 0.328134\n",
            "Train Epoch: 4 [2038/3978 (51%)]\tLoss: 1.196429\n",
            "Train Epoch: 4 [2039/3978 (51%)]\tLoss: 0.237992\n",
            "Train Epoch: 4 [2040/3978 (51%)]\tLoss: 0.830471\n",
            "Train Epoch: 4 [2041/3978 (51%)]\tLoss: 0.006395\n",
            "Train Epoch: 4 [2042/3978 (51%)]\tLoss: 0.000639\n",
            "Train Epoch: 4 [2043/3978 (51%)]\tLoss: 0.845573\n",
            "Train Epoch: 4 [2044/3978 (51%)]\tLoss: 0.053350\n",
            "Train Epoch: 4 [2045/3978 (51%)]\tLoss: 1.744210\n",
            "Train Epoch: 4 [2046/3978 (51%)]\tLoss: 2.192304\n",
            "Train Epoch: 4 [2047/3978 (51%)]\tLoss: 0.257484\n",
            "Train Epoch: 4 [2048/3978 (51%)]\tLoss: 0.751353\n",
            "Train Epoch: 4 [2049/3978 (52%)]\tLoss: 0.022457\n",
            "Train Epoch: 4 [2050/3978 (52%)]\tLoss: 0.556535\n",
            "Train Epoch: 4 [2051/3978 (52%)]\tLoss: 0.814654\n",
            "Train Epoch: 4 [2052/3978 (52%)]\tLoss: 2.263331\n",
            "Train Epoch: 4 [2053/3978 (52%)]\tLoss: 0.495656\n",
            "Train Epoch: 4 [2054/3978 (52%)]\tLoss: 0.886321\n",
            "Train Epoch: 4 [2055/3978 (52%)]\tLoss: 0.026998\n",
            "Train Epoch: 4 [2056/3978 (52%)]\tLoss: 0.001827\n",
            "Train Epoch: 4 [2057/3978 (52%)]\tLoss: 0.083713\n",
            "Train Epoch: 4 [2058/3978 (52%)]\tLoss: 0.255246\n",
            "Train Epoch: 4 [2059/3978 (52%)]\tLoss: 1.187918\n",
            "Train Epoch: 4 [2060/3978 (52%)]\tLoss: 0.122606\n",
            "Train Epoch: 4 [2061/3978 (52%)]\tLoss: 0.303074\n",
            "Train Epoch: 4 [2062/3978 (52%)]\tLoss: 0.291547\n",
            "Train Epoch: 4 [2063/3978 (52%)]\tLoss: 0.223856\n",
            "Train Epoch: 4 [2064/3978 (52%)]\tLoss: 3.974528\n",
            "Train Epoch: 4 [2065/3978 (52%)]\tLoss: 0.080072\n",
            "Train Epoch: 4 [2066/3978 (52%)]\tLoss: 0.038371\n",
            "Train Epoch: 4 [2067/3978 (52%)]\tLoss: 0.406678\n",
            "Train Epoch: 4 [2068/3978 (52%)]\tLoss: 0.000740\n",
            "Train Epoch: 4 [2069/3978 (52%)]\tLoss: 1.935120\n",
            "Train Epoch: 4 [2070/3978 (52%)]\tLoss: 0.225387\n",
            "Train Epoch: 4 [2071/3978 (52%)]\tLoss: 1.247029\n",
            "Train Epoch: 4 [2072/3978 (52%)]\tLoss: 0.091105\n",
            "Train Epoch: 4 [2073/3978 (52%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [2074/3978 (52%)]\tLoss: 0.712361\n",
            "Train Epoch: 4 [2075/3978 (52%)]\tLoss: 0.341178\n",
            "Train Epoch: 4 [2076/3978 (52%)]\tLoss: 1.021738\n",
            "Train Epoch: 4 [2077/3978 (52%)]\tLoss: 0.646906\n",
            "Train Epoch: 4 [2078/3978 (52%)]\tLoss: 0.397531\n",
            "Train Epoch: 4 [2079/3978 (52%)]\tLoss: 1.226560\n",
            "Train Epoch: 4 [2080/3978 (52%)]\tLoss: 0.273573\n",
            "Train Epoch: 4 [2081/3978 (52%)]\tLoss: 1.028827\n",
            "Train Epoch: 4 [2082/3978 (52%)]\tLoss: 2.252810\n",
            "Train Epoch: 4 [2083/3978 (52%)]\tLoss: 0.896666\n",
            "Train Epoch: 4 [2084/3978 (52%)]\tLoss: 0.874297\n",
            "Train Epoch: 4 [2085/3978 (52%)]\tLoss: 0.026178\n",
            "Train Epoch: 4 [2086/3978 (52%)]\tLoss: 0.181036\n",
            "Train Epoch: 4 [2087/3978 (52%)]\tLoss: 0.209556\n",
            "Train Epoch: 4 [2088/3978 (52%)]\tLoss: 0.000034\n",
            "Train Epoch: 4 [2089/3978 (53%)]\tLoss: 0.894756\n",
            "Train Epoch: 4 [2090/3978 (53%)]\tLoss: 0.439067\n",
            "Train Epoch: 4 [2091/3978 (53%)]\tLoss: 0.276225\n",
            "Train Epoch: 4 [2092/3978 (53%)]\tLoss: 2.341042\n",
            "Train Epoch: 4 [2093/3978 (53%)]\tLoss: 0.396598\n",
            "Train Epoch: 4 [2094/3978 (53%)]\tLoss: 0.002940\n",
            "Train Epoch: 4 [2095/3978 (53%)]\tLoss: 0.807306\n",
            "Train Epoch: 4 [2096/3978 (53%)]\tLoss: 1.010734\n",
            "Train Epoch: 4 [2097/3978 (53%)]\tLoss: 0.111642\n",
            "Train Epoch: 4 [2098/3978 (53%)]\tLoss: 0.000437\n",
            "Train Epoch: 4 [2099/3978 (53%)]\tLoss: 0.000232\n",
            "Train Epoch: 4 [2100/3978 (53%)]\tLoss: 1.011445\n",
            "Train Epoch: 4 [2101/3978 (53%)]\tLoss: 0.484358\n",
            "Train Epoch: 4 [2102/3978 (53%)]\tLoss: 0.644272\n",
            "Train Epoch: 4 [2103/3978 (53%)]\tLoss: 1.683460\n",
            "Train Epoch: 4 [2104/3978 (53%)]\tLoss: 0.549285\n",
            "Train Epoch: 4 [2105/3978 (53%)]\tLoss: 0.646603\n",
            "Train Epoch: 4 [2106/3978 (53%)]\tLoss: 0.625076\n",
            "Train Epoch: 4 [2107/3978 (53%)]\tLoss: 0.152497\n",
            "Train Epoch: 4 [2108/3978 (53%)]\tLoss: 0.059343\n",
            "Train Epoch: 4 [2109/3978 (53%)]\tLoss: 0.028600\n",
            "Train Epoch: 4 [2110/3978 (53%)]\tLoss: 0.000353\n",
            "Train Epoch: 4 [2111/3978 (53%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [2112/3978 (53%)]\tLoss: 1.796586\n",
            "Train Epoch: 4 [2113/3978 (53%)]\tLoss: 1.836463\n",
            "Train Epoch: 4 [2114/3978 (53%)]\tLoss: 1.925216\n",
            "Train Epoch: 4 [2115/3978 (53%)]\tLoss: 1.779131\n",
            "Train Epoch: 4 [2116/3978 (53%)]\tLoss: 0.000125\n",
            "Train Epoch: 4 [2117/3978 (53%)]\tLoss: 1.478359\n",
            "Train Epoch: 4 [2118/3978 (53%)]\tLoss: 2.428679\n",
            "Train Epoch: 4 [2119/3978 (53%)]\tLoss: 0.570615\n",
            "Train Epoch: 4 [2120/3978 (53%)]\tLoss: 0.283939\n",
            "Train Epoch: 4 [2121/3978 (53%)]\tLoss: 0.000083\n",
            "Train Epoch: 4 [2122/3978 (53%)]\tLoss: 1.634779\n",
            "Train Epoch: 4 [2123/3978 (53%)]\tLoss: 0.000089\n",
            "Train Epoch: 4 [2124/3978 (53%)]\tLoss: 0.952441\n",
            "Train Epoch: 4 [2125/3978 (53%)]\tLoss: 2.199549\n",
            "Train Epoch: 4 [2126/3978 (53%)]\tLoss: 0.087605\n",
            "Train Epoch: 4 [2127/3978 (53%)]\tLoss: 0.185899\n",
            "Train Epoch: 4 [2128/3978 (53%)]\tLoss: 0.000876\n",
            "Train Epoch: 4 [2129/3978 (54%)]\tLoss: 0.104700\n",
            "Train Epoch: 4 [2130/3978 (54%)]\tLoss: 0.755256\n",
            "Train Epoch: 4 [2131/3978 (54%)]\tLoss: 0.411535\n",
            "Train Epoch: 4 [2132/3978 (54%)]\tLoss: 0.001221\n",
            "Train Epoch: 4 [2133/3978 (54%)]\tLoss: 0.025905\n",
            "Train Epoch: 4 [2134/3978 (54%)]\tLoss: 0.088606\n",
            "Train Epoch: 4 [2135/3978 (54%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2136/3978 (54%)]\tLoss: 0.631638\n",
            "Train Epoch: 4 [2137/3978 (54%)]\tLoss: 0.158778\n",
            "Train Epoch: 4 [2138/3978 (54%)]\tLoss: 0.404999\n",
            "Train Epoch: 4 [2139/3978 (54%)]\tLoss: 0.001856\n",
            "Train Epoch: 4 [2140/3978 (54%)]\tLoss: 0.585516\n",
            "Train Epoch: 4 [2141/3978 (54%)]\tLoss: 0.037087\n",
            "Train Epoch: 4 [2142/3978 (54%)]\tLoss: 0.700649\n",
            "Train Epoch: 4 [2143/3978 (54%)]\tLoss: 0.046737\n",
            "Train Epoch: 4 [2144/3978 (54%)]\tLoss: 0.632535\n",
            "Train Epoch: 4 [2145/3978 (54%)]\tLoss: 0.236595\n",
            "Train Epoch: 4 [2146/3978 (54%)]\tLoss: 0.040570\n",
            "Train Epoch: 4 [2147/3978 (54%)]\tLoss: 0.617378\n",
            "Train Epoch: 4 [2148/3978 (54%)]\tLoss: 0.074105\n",
            "Train Epoch: 4 [2149/3978 (54%)]\tLoss: 0.001963\n",
            "Train Epoch: 4 [2150/3978 (54%)]\tLoss: 2.830526\n",
            "Train Epoch: 4 [2151/3978 (54%)]\tLoss: 0.018020\n",
            "Train Epoch: 4 [2152/3978 (54%)]\tLoss: 0.130351\n",
            "Train Epoch: 4 [2153/3978 (54%)]\tLoss: 1.879425\n",
            "Train Epoch: 4 [2154/3978 (54%)]\tLoss: 0.001854\n",
            "Train Epoch: 4 [2155/3978 (54%)]\tLoss: 0.135621\n",
            "Train Epoch: 4 [2156/3978 (54%)]\tLoss: 0.118268\n",
            "Train Epoch: 4 [2157/3978 (54%)]\tLoss: 3.645827\n",
            "Train Epoch: 4 [2158/3978 (54%)]\tLoss: 0.165994\n",
            "Train Epoch: 4 [2159/3978 (54%)]\tLoss: 0.071739\n",
            "Train Epoch: 4 [2160/3978 (54%)]\tLoss: 1.853159\n",
            "Train Epoch: 4 [2161/3978 (54%)]\tLoss: 0.952061\n",
            "Train Epoch: 4 [2162/3978 (54%)]\tLoss: 0.014524\n",
            "Train Epoch: 4 [2163/3978 (54%)]\tLoss: 0.194364\n",
            "Train Epoch: 4 [2164/3978 (54%)]\tLoss: 0.341430\n",
            "Train Epoch: 4 [2165/3978 (54%)]\tLoss: 0.653889\n",
            "Train Epoch: 4 [2166/3978 (54%)]\tLoss: 0.004275\n",
            "Train Epoch: 4 [2167/3978 (54%)]\tLoss: 0.592423\n",
            "Train Epoch: 4 [2168/3978 (54%)]\tLoss: 0.000343\n",
            "Train Epoch: 4 [2169/3978 (55%)]\tLoss: 0.472004\n",
            "Train Epoch: 4 [2170/3978 (55%)]\tLoss: 2.440660\n",
            "Train Epoch: 4 [2171/3978 (55%)]\tLoss: 1.982445\n",
            "Train Epoch: 4 [2172/3978 (55%)]\tLoss: 0.120082\n",
            "Train Epoch: 4 [2173/3978 (55%)]\tLoss: 0.004621\n",
            "Train Epoch: 4 [2174/3978 (55%)]\tLoss: 0.816194\n",
            "Train Epoch: 4 [2175/3978 (55%)]\tLoss: 0.001437\n",
            "Train Epoch: 4 [2176/3978 (55%)]\tLoss: 0.149969\n",
            "Train Epoch: 4 [2177/3978 (55%)]\tLoss: 0.521731\n",
            "Train Epoch: 4 [2178/3978 (55%)]\tLoss: 0.463110\n",
            "Train Epoch: 4 [2179/3978 (55%)]\tLoss: 0.166587\n",
            "Train Epoch: 4 [2180/3978 (55%)]\tLoss: 0.435853\n",
            "Train Epoch: 4 [2181/3978 (55%)]\tLoss: 0.282141\n",
            "Train Epoch: 4 [2182/3978 (55%)]\tLoss: 0.001947\n",
            "Train Epoch: 4 [2183/3978 (55%)]\tLoss: 0.025822\n",
            "Train Epoch: 4 [2184/3978 (55%)]\tLoss: 1.470829\n",
            "Train Epoch: 4 [2185/3978 (55%)]\tLoss: 0.005540\n",
            "Train Epoch: 4 [2186/3978 (55%)]\tLoss: 0.001271\n",
            "Train Epoch: 4 [2187/3978 (55%)]\tLoss: 0.124227\n",
            "Train Epoch: 4 [2188/3978 (55%)]\tLoss: 0.230778\n",
            "Train Epoch: 4 [2189/3978 (55%)]\tLoss: 0.815271\n",
            "Train Epoch: 4 [2190/3978 (55%)]\tLoss: 0.000066\n",
            "Train Epoch: 4 [2191/3978 (55%)]\tLoss: 3.319101\n",
            "Train Epoch: 4 [2192/3978 (55%)]\tLoss: 2.297647\n",
            "Train Epoch: 4 [2193/3978 (55%)]\tLoss: 0.140049\n",
            "Train Epoch: 4 [2194/3978 (55%)]\tLoss: 0.069258\n",
            "Train Epoch: 4 [2195/3978 (55%)]\tLoss: 0.345285\n",
            "Train Epoch: 4 [2196/3978 (55%)]\tLoss: 0.140165\n",
            "Train Epoch: 4 [2197/3978 (55%)]\tLoss: 0.604251\n",
            "Train Epoch: 4 [2198/3978 (55%)]\tLoss: 0.517296\n",
            "Train Epoch: 4 [2199/3978 (55%)]\tLoss: 0.231884\n",
            "Train Epoch: 4 [2200/3978 (55%)]\tLoss: 0.007591\n",
            "Train Epoch: 4 [2201/3978 (55%)]\tLoss: 0.016602\n",
            "Train Epoch: 4 [2202/3978 (55%)]\tLoss: 0.385722\n",
            "Train Epoch: 4 [2203/3978 (55%)]\tLoss: 0.573606\n",
            "Train Epoch: 4 [2204/3978 (55%)]\tLoss: 0.004272\n",
            "Train Epoch: 4 [2205/3978 (55%)]\tLoss: 0.033662\n",
            "Train Epoch: 4 [2206/3978 (55%)]\tLoss: 0.815365\n",
            "Train Epoch: 4 [2207/3978 (55%)]\tLoss: 0.007362\n",
            "Train Epoch: 4 [2208/3978 (56%)]\tLoss: 1.313987\n",
            "Train Epoch: 4 [2209/3978 (56%)]\tLoss: 3.267429\n",
            "Train Epoch: 4 [2210/3978 (56%)]\tLoss: 0.877175\n",
            "Train Epoch: 4 [2211/3978 (56%)]\tLoss: 0.287252\n",
            "Train Epoch: 4 [2212/3978 (56%)]\tLoss: 0.000262\n",
            "Train Epoch: 4 [2213/3978 (56%)]\tLoss: 0.803879\n",
            "Train Epoch: 4 [2214/3978 (56%)]\tLoss: 0.985457\n",
            "Train Epoch: 4 [2215/3978 (56%)]\tLoss: 0.039886\n",
            "Train Epoch: 4 [2216/3978 (56%)]\tLoss: 2.747389\n",
            "Train Epoch: 4 [2217/3978 (56%)]\tLoss: 0.165979\n",
            "Train Epoch: 4 [2218/3978 (56%)]\tLoss: 0.604459\n",
            "Train Epoch: 4 [2219/3978 (56%)]\tLoss: 0.342278\n",
            "Train Epoch: 4 [2220/3978 (56%)]\tLoss: 1.736010\n",
            "Train Epoch: 4 [2221/3978 (56%)]\tLoss: 0.046821\n",
            "Train Epoch: 4 [2222/3978 (56%)]\tLoss: 0.172149\n",
            "Train Epoch: 4 [2223/3978 (56%)]\tLoss: 0.699567\n",
            "Train Epoch: 4 [2224/3978 (56%)]\tLoss: 0.648454\n",
            "Train Epoch: 4 [2225/3978 (56%)]\tLoss: 0.000030\n",
            "Train Epoch: 4 [2226/3978 (56%)]\tLoss: 1.155926\n",
            "Train Epoch: 4 [2227/3978 (56%)]\tLoss: 0.000095\n",
            "Train Epoch: 4 [2228/3978 (56%)]\tLoss: 0.845238\n",
            "Train Epoch: 4 [2229/3978 (56%)]\tLoss: 0.000117\n",
            "Train Epoch: 4 [2230/3978 (56%)]\tLoss: 0.011779\n",
            "Train Epoch: 4 [2231/3978 (56%)]\tLoss: 0.001170\n",
            "Train Epoch: 4 [2232/3978 (56%)]\tLoss: 0.003040\n",
            "Train Epoch: 4 [2233/3978 (56%)]\tLoss: 0.013323\n",
            "Train Epoch: 4 [2234/3978 (56%)]\tLoss: 0.001868\n",
            "Train Epoch: 4 [2235/3978 (56%)]\tLoss: 0.001993\n",
            "Train Epoch: 4 [2236/3978 (56%)]\tLoss: 0.549097\n",
            "Train Epoch: 4 [2237/3978 (56%)]\tLoss: 0.021178\n",
            "Train Epoch: 4 [2238/3978 (56%)]\tLoss: 2.250909\n",
            "Train Epoch: 4 [2239/3978 (56%)]\tLoss: 2.824477\n",
            "Train Epoch: 4 [2240/3978 (56%)]\tLoss: 0.007186\n",
            "Train Epoch: 4 [2241/3978 (56%)]\tLoss: 0.864119\n",
            "Train Epoch: 4 [2242/3978 (56%)]\tLoss: 0.023385\n",
            "Train Epoch: 4 [2243/3978 (56%)]\tLoss: 0.990029\n",
            "Train Epoch: 4 [2244/3978 (56%)]\tLoss: 0.400407\n",
            "Train Epoch: 4 [2245/3978 (56%)]\tLoss: 0.095758\n",
            "Train Epoch: 4 [2246/3978 (56%)]\tLoss: 0.566700\n",
            "Train Epoch: 4 [2247/3978 (56%)]\tLoss: 1.551046\n",
            "Train Epoch: 4 [2248/3978 (57%)]\tLoss: 0.956115\n",
            "Train Epoch: 4 [2249/3978 (57%)]\tLoss: 0.978837\n",
            "Train Epoch: 4 [2250/3978 (57%)]\tLoss: 0.608613\n",
            "Train Epoch: 4 [2251/3978 (57%)]\tLoss: 3.152846\n",
            "Train Epoch: 4 [2252/3978 (57%)]\tLoss: 0.000056\n",
            "Train Epoch: 4 [2253/3978 (57%)]\tLoss: 0.563231\n",
            "Train Epoch: 4 [2254/3978 (57%)]\tLoss: 0.334505\n",
            "Train Epoch: 4 [2255/3978 (57%)]\tLoss: 0.010067\n",
            "Train Epoch: 4 [2256/3978 (57%)]\tLoss: 0.020256\n",
            "Train Epoch: 4 [2257/3978 (57%)]\tLoss: 2.292428\n",
            "Train Epoch: 4 [2258/3978 (57%)]\tLoss: 2.284765\n",
            "Train Epoch: 4 [2259/3978 (57%)]\tLoss: 0.625661\n",
            "Train Epoch: 4 [2260/3978 (57%)]\tLoss: 0.040842\n",
            "Train Epoch: 4 [2261/3978 (57%)]\tLoss: 0.000128\n",
            "Train Epoch: 4 [2262/3978 (57%)]\tLoss: 0.087965\n",
            "Train Epoch: 4 [2263/3978 (57%)]\tLoss: 0.037156\n",
            "Train Epoch: 4 [2264/3978 (57%)]\tLoss: 0.000084\n",
            "Train Epoch: 4 [2265/3978 (57%)]\tLoss: 0.077371\n",
            "Train Epoch: 4 [2266/3978 (57%)]\tLoss: 0.218183\n",
            "Train Epoch: 4 [2267/3978 (57%)]\tLoss: 0.357320\n",
            "Train Epoch: 4 [2268/3978 (57%)]\tLoss: 0.428985\n",
            "Train Epoch: 4 [2269/3978 (57%)]\tLoss: 2.938358\n",
            "Train Epoch: 4 [2270/3978 (57%)]\tLoss: 5.625975\n",
            "Train Epoch: 4 [2271/3978 (57%)]\tLoss: 0.133225\n",
            "Train Epoch: 4 [2272/3978 (57%)]\tLoss: 0.162312\n",
            "Train Epoch: 4 [2273/3978 (57%)]\tLoss: 0.001804\n",
            "Train Epoch: 4 [2274/3978 (57%)]\tLoss: 0.011374\n",
            "Train Epoch: 4 [2275/3978 (57%)]\tLoss: 0.235876\n",
            "Train Epoch: 4 [2276/3978 (57%)]\tLoss: 0.703142\n",
            "Train Epoch: 4 [2277/3978 (57%)]\tLoss: 0.023144\n",
            "Train Epoch: 4 [2278/3978 (57%)]\tLoss: 1.110498\n",
            "Train Epoch: 4 [2279/3978 (57%)]\tLoss: 0.042146\n",
            "Train Epoch: 4 [2280/3978 (57%)]\tLoss: 0.933959\n",
            "Train Epoch: 4 [2281/3978 (57%)]\tLoss: 0.003768\n",
            "Train Epoch: 4 [2282/3978 (57%)]\tLoss: 0.030142\n",
            "Train Epoch: 4 [2283/3978 (57%)]\tLoss: 1.302634\n",
            "Train Epoch: 4 [2284/3978 (57%)]\tLoss: 1.943724\n",
            "Train Epoch: 4 [2285/3978 (57%)]\tLoss: 0.592375\n",
            "Train Epoch: 4 [2286/3978 (57%)]\tLoss: 0.886213\n",
            "Train Epoch: 4 [2287/3978 (57%)]\tLoss: 0.015141\n",
            "Train Epoch: 4 [2288/3978 (58%)]\tLoss: 0.504519\n",
            "Train Epoch: 4 [2289/3978 (58%)]\tLoss: 0.763288\n",
            "Train Epoch: 4 [2290/3978 (58%)]\tLoss: 0.314082\n",
            "Train Epoch: 4 [2291/3978 (58%)]\tLoss: 0.865786\n",
            "Train Epoch: 4 [2292/3978 (58%)]\tLoss: 1.039044\n",
            "Train Epoch: 4 [2293/3978 (58%)]\tLoss: 0.008188\n",
            "Train Epoch: 4 [2294/3978 (58%)]\tLoss: 0.001269\n",
            "Train Epoch: 4 [2295/3978 (58%)]\tLoss: 0.637600\n",
            "Train Epoch: 4 [2296/3978 (58%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [2297/3978 (58%)]\tLoss: 2.966779\n",
            "Train Epoch: 4 [2298/3978 (58%)]\tLoss: 0.004319\n",
            "Train Epoch: 4 [2299/3978 (58%)]\tLoss: 0.065179\n",
            "Train Epoch: 4 [2300/3978 (58%)]\tLoss: 0.000319\n",
            "Train Epoch: 4 [2301/3978 (58%)]\tLoss: 0.001396\n",
            "Train Epoch: 4 [2302/3978 (58%)]\tLoss: 5.028024\n",
            "Train Epoch: 4 [2303/3978 (58%)]\tLoss: 0.076788\n",
            "Train Epoch: 4 [2304/3978 (58%)]\tLoss: 0.080579\n",
            "Train Epoch: 4 [2305/3978 (58%)]\tLoss: 0.039020\n",
            "Train Epoch: 4 [2306/3978 (58%)]\tLoss: 0.003946\n",
            "Train Epoch: 4 [2307/3978 (58%)]\tLoss: 0.061317\n",
            "Train Epoch: 4 [2308/3978 (58%)]\tLoss: 0.077026\n",
            "Train Epoch: 4 [2309/3978 (58%)]\tLoss: 0.018338\n",
            "Train Epoch: 4 [2310/3978 (58%)]\tLoss: 0.235951\n",
            "Train Epoch: 4 [2311/3978 (58%)]\tLoss: 1.021102\n",
            "Train Epoch: 4 [2312/3978 (58%)]\tLoss: 1.036854\n",
            "Train Epoch: 4 [2313/3978 (58%)]\tLoss: 0.313991\n",
            "Train Epoch: 4 [2314/3978 (58%)]\tLoss: 4.511908\n",
            "Train Epoch: 4 [2315/3978 (58%)]\tLoss: 1.131668\n",
            "Train Epoch: 4 [2316/3978 (58%)]\tLoss: 0.228571\n",
            "Train Epoch: 4 [2317/3978 (58%)]\tLoss: 4.709044\n",
            "Train Epoch: 4 [2318/3978 (58%)]\tLoss: 2.364079\n",
            "Train Epoch: 4 [2319/3978 (58%)]\tLoss: 0.114886\n",
            "Train Epoch: 4 [2320/3978 (58%)]\tLoss: 0.521296\n",
            "Train Epoch: 4 [2321/3978 (58%)]\tLoss: 0.013919\n",
            "Train Epoch: 4 [2322/3978 (58%)]\tLoss: 0.594055\n",
            "Train Epoch: 4 [2323/3978 (58%)]\tLoss: 1.140449\n",
            "Train Epoch: 4 [2324/3978 (58%)]\tLoss: 2.896890\n",
            "Train Epoch: 4 [2325/3978 (58%)]\tLoss: 0.431909\n",
            "Train Epoch: 4 [2326/3978 (58%)]\tLoss: 0.222346\n",
            "Train Epoch: 4 [2327/3978 (58%)]\tLoss: 0.021827\n",
            "Train Epoch: 4 [2328/3978 (59%)]\tLoss: 2.879648\n",
            "Train Epoch: 4 [2329/3978 (59%)]\tLoss: 2.265001\n",
            "Train Epoch: 4 [2330/3978 (59%)]\tLoss: 0.000069\n",
            "Train Epoch: 4 [2331/3978 (59%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2332/3978 (59%)]\tLoss: 0.012529\n",
            "Train Epoch: 4 [2333/3978 (59%)]\tLoss: 0.000825\n",
            "Train Epoch: 4 [2334/3978 (59%)]\tLoss: 0.001636\n",
            "Train Epoch: 4 [2335/3978 (59%)]\tLoss: 0.003652\n",
            "Train Epoch: 4 [2336/3978 (59%)]\tLoss: 0.373615\n",
            "Train Epoch: 4 [2337/3978 (59%)]\tLoss: 1.160367\n",
            "Train Epoch: 4 [2338/3978 (59%)]\tLoss: 0.016788\n",
            "Train Epoch: 4 [2339/3978 (59%)]\tLoss: 0.055056\n",
            "Train Epoch: 4 [2340/3978 (59%)]\tLoss: 0.324654\n",
            "Train Epoch: 4 [2341/3978 (59%)]\tLoss: 0.000589\n",
            "Train Epoch: 4 [2342/3978 (59%)]\tLoss: 2.502690\n",
            "Train Epoch: 4 [2343/3978 (59%)]\tLoss: 1.579240\n",
            "Train Epoch: 4 [2344/3978 (59%)]\tLoss: 0.607582\n",
            "Train Epoch: 4 [2345/3978 (59%)]\tLoss: 0.386838\n",
            "Train Epoch: 4 [2346/3978 (59%)]\tLoss: 0.017474\n",
            "Train Epoch: 4 [2347/3978 (59%)]\tLoss: 1.162080\n",
            "Train Epoch: 4 [2348/3978 (59%)]\tLoss: 0.110035\n",
            "Train Epoch: 4 [2349/3978 (59%)]\tLoss: 0.556140\n",
            "Train Epoch: 4 [2350/3978 (59%)]\tLoss: 0.000256\n",
            "Train Epoch: 4 [2351/3978 (59%)]\tLoss: 0.000233\n",
            "Train Epoch: 4 [2352/3978 (59%)]\tLoss: 0.209159\n",
            "Train Epoch: 4 [2353/3978 (59%)]\tLoss: 0.000411\n",
            "Train Epoch: 4 [2354/3978 (59%)]\tLoss: 0.002573\n",
            "Train Epoch: 4 [2355/3978 (59%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [2356/3978 (59%)]\tLoss: 1.648089\n",
            "Train Epoch: 4 [2357/3978 (59%)]\tLoss: 0.007263\n",
            "Train Epoch: 4 [2358/3978 (59%)]\tLoss: 0.599174\n",
            "Train Epoch: 4 [2359/3978 (59%)]\tLoss: 3.324023\n",
            "Train Epoch: 4 [2360/3978 (59%)]\tLoss: 0.482032\n",
            "Train Epoch: 4 [2361/3978 (59%)]\tLoss: 0.000047\n",
            "Train Epoch: 4 [2362/3978 (59%)]\tLoss: 0.012892\n",
            "Train Epoch: 4 [2363/3978 (59%)]\tLoss: 1.911236\n",
            "Train Epoch: 4 [2364/3978 (59%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2365/3978 (59%)]\tLoss: 1.108329\n",
            "Train Epoch: 4 [2366/3978 (59%)]\tLoss: 3.811847\n",
            "Train Epoch: 4 [2367/3978 (60%)]\tLoss: 1.063678\n",
            "Train Epoch: 4 [2368/3978 (60%)]\tLoss: 0.000715\n",
            "Train Epoch: 4 [2369/3978 (60%)]\tLoss: 0.057155\n",
            "Train Epoch: 4 [2370/3978 (60%)]\tLoss: 0.116341\n",
            "Train Epoch: 4 [2371/3978 (60%)]\tLoss: 0.789509\n",
            "Train Epoch: 4 [2372/3978 (60%)]\tLoss: 0.140538\n",
            "Train Epoch: 4 [2373/3978 (60%)]\tLoss: 0.120705\n",
            "Train Epoch: 4 [2374/3978 (60%)]\tLoss: 1.162918\n",
            "Train Epoch: 4 [2375/3978 (60%)]\tLoss: 0.862316\n",
            "Train Epoch: 4 [2376/3978 (60%)]\tLoss: 0.000435\n",
            "Train Epoch: 4 [2377/3978 (60%)]\tLoss: 0.062753\n",
            "Train Epoch: 4 [2378/3978 (60%)]\tLoss: 1.159454\n",
            "Train Epoch: 4 [2379/3978 (60%)]\tLoss: 0.127813\n",
            "Train Epoch: 4 [2380/3978 (60%)]\tLoss: 0.025850\n",
            "Train Epoch: 4 [2381/3978 (60%)]\tLoss: 0.006662\n",
            "Train Epoch: 4 [2382/3978 (60%)]\tLoss: 0.409844\n",
            "Train Epoch: 4 [2383/3978 (60%)]\tLoss: 0.074334\n",
            "Train Epoch: 4 [2384/3978 (60%)]\tLoss: 0.428779\n",
            "Train Epoch: 4 [2385/3978 (60%)]\tLoss: 0.864234\n",
            "Train Epoch: 4 [2386/3978 (60%)]\tLoss: 0.182480\n",
            "Train Epoch: 4 [2387/3978 (60%)]\tLoss: 0.090793\n",
            "Train Epoch: 4 [2388/3978 (60%)]\tLoss: 2.231117\n",
            "Train Epoch: 4 [2389/3978 (60%)]\tLoss: 0.060648\n",
            "Train Epoch: 4 [2390/3978 (60%)]\tLoss: 2.953583\n",
            "Train Epoch: 4 [2391/3978 (60%)]\tLoss: 0.330040\n",
            "Train Epoch: 4 [2392/3978 (60%)]\tLoss: 0.628788\n",
            "Train Epoch: 4 [2393/3978 (60%)]\tLoss: 0.972125\n",
            "Train Epoch: 4 [2394/3978 (60%)]\tLoss: 0.392001\n",
            "Train Epoch: 4 [2395/3978 (60%)]\tLoss: 0.378735\n",
            "Train Epoch: 4 [2396/3978 (60%)]\tLoss: 0.109681\n",
            "Train Epoch: 4 [2397/3978 (60%)]\tLoss: 0.017236\n",
            "Train Epoch: 4 [2398/3978 (60%)]\tLoss: 0.242689\n",
            "Train Epoch: 4 [2399/3978 (60%)]\tLoss: 0.014286\n",
            "Train Epoch: 4 [2400/3978 (60%)]\tLoss: 0.600081\n",
            "Train Epoch: 4 [2401/3978 (60%)]\tLoss: 1.144776\n",
            "Train Epoch: 4 [2402/3978 (60%)]\tLoss: 0.069938\n",
            "Train Epoch: 4 [2403/3978 (60%)]\tLoss: 2.897739\n",
            "Train Epoch: 4 [2404/3978 (60%)]\tLoss: 0.038303\n",
            "Train Epoch: 4 [2405/3978 (60%)]\tLoss: 0.256571\n",
            "Train Epoch: 4 [2406/3978 (60%)]\tLoss: 0.109118\n",
            "Train Epoch: 4 [2407/3978 (61%)]\tLoss: 0.003490\n",
            "Train Epoch: 4 [2408/3978 (61%)]\tLoss: 0.251983\n",
            "Train Epoch: 4 [2409/3978 (61%)]\tLoss: 0.090423\n",
            "Train Epoch: 4 [2410/3978 (61%)]\tLoss: 0.000209\n",
            "Train Epoch: 4 [2411/3978 (61%)]\tLoss: 0.054092\n",
            "Train Epoch: 4 [2412/3978 (61%)]\tLoss: 0.000473\n",
            "Train Epoch: 4 [2413/3978 (61%)]\tLoss: 0.000050\n",
            "Train Epoch: 4 [2414/3978 (61%)]\tLoss: 0.021270\n",
            "Train Epoch: 4 [2415/3978 (61%)]\tLoss: 1.186723\n",
            "Train Epoch: 4 [2416/3978 (61%)]\tLoss: 0.111885\n",
            "Train Epoch: 4 [2417/3978 (61%)]\tLoss: 0.099288\n",
            "Train Epoch: 4 [2418/3978 (61%)]\tLoss: 0.108697\n",
            "Train Epoch: 4 [2419/3978 (61%)]\tLoss: 0.886267\n",
            "Train Epoch: 4 [2420/3978 (61%)]\tLoss: 1.927214\n",
            "Train Epoch: 4 [2421/3978 (61%)]\tLoss: 1.398014\n",
            "Train Epoch: 4 [2422/3978 (61%)]\tLoss: 0.125682\n",
            "Train Epoch: 4 [2423/3978 (61%)]\tLoss: 0.075134\n",
            "Train Epoch: 4 [2424/3978 (61%)]\tLoss: 0.098346\n",
            "Train Epoch: 4 [2425/3978 (61%)]\tLoss: 0.181622\n",
            "Train Epoch: 4 [2426/3978 (61%)]\tLoss: 0.177268\n",
            "Train Epoch: 4 [2427/3978 (61%)]\tLoss: 0.003688\n",
            "Train Epoch: 4 [2428/3978 (61%)]\tLoss: 0.658833\n",
            "Train Epoch: 4 [2429/3978 (61%)]\tLoss: 0.762376\n",
            "Train Epoch: 4 [2430/3978 (61%)]\tLoss: 0.484536\n",
            "Train Epoch: 4 [2431/3978 (61%)]\tLoss: 0.089226\n",
            "Train Epoch: 4 [2432/3978 (61%)]\tLoss: 0.063602\n",
            "Train Epoch: 4 [2433/3978 (61%)]\tLoss: 0.000450\n",
            "Train Epoch: 4 [2434/3978 (61%)]\tLoss: 0.029629\n",
            "Train Epoch: 4 [2435/3978 (61%)]\tLoss: 2.388894\n",
            "Train Epoch: 4 [2436/3978 (61%)]\tLoss: 0.781233\n",
            "Train Epoch: 4 [2437/3978 (61%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [2438/3978 (61%)]\tLoss: 0.062661\n",
            "Train Epoch: 4 [2439/3978 (61%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2440/3978 (61%)]\tLoss: 1.369747\n",
            "Train Epoch: 4 [2441/3978 (61%)]\tLoss: 0.509180\n",
            "Train Epoch: 4 [2442/3978 (61%)]\tLoss: 0.686014\n",
            "Train Epoch: 4 [2443/3978 (61%)]\tLoss: 1.874256\n",
            "Train Epoch: 4 [2444/3978 (61%)]\tLoss: 0.780964\n",
            "Train Epoch: 4 [2445/3978 (61%)]\tLoss: 0.000396\n",
            "Train Epoch: 4 [2446/3978 (61%)]\tLoss: 1.857257\n",
            "Train Epoch: 4 [2447/3978 (62%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [2448/3978 (62%)]\tLoss: 3.707708\n",
            "Train Epoch: 4 [2449/3978 (62%)]\tLoss: 0.000029\n",
            "Train Epoch: 4 [2450/3978 (62%)]\tLoss: 4.116762\n",
            "Train Epoch: 4 [2451/3978 (62%)]\tLoss: 3.320484\n",
            "Train Epoch: 4 [2452/3978 (62%)]\tLoss: 6.850918\n",
            "Train Epoch: 4 [2453/3978 (62%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2454/3978 (62%)]\tLoss: 0.150395\n",
            "Train Epoch: 4 [2455/3978 (62%)]\tLoss: 0.038427\n",
            "Train Epoch: 4 [2456/3978 (62%)]\tLoss: 0.389782\n",
            "Train Epoch: 4 [2457/3978 (62%)]\tLoss: 2.157426\n",
            "Train Epoch: 4 [2458/3978 (62%)]\tLoss: 0.058130\n",
            "Train Epoch: 4 [2459/3978 (62%)]\tLoss: 0.029056\n",
            "Train Epoch: 4 [2460/3978 (62%)]\tLoss: 1.163641\n",
            "Train Epoch: 4 [2461/3978 (62%)]\tLoss: 0.000113\n",
            "Train Epoch: 4 [2462/3978 (62%)]\tLoss: 0.968905\n",
            "Train Epoch: 4 [2463/3978 (62%)]\tLoss: 0.059656\n",
            "Train Epoch: 4 [2464/3978 (62%)]\tLoss: 2.248111\n",
            "Train Epoch: 4 [2465/3978 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2466/3978 (62%)]\tLoss: 1.543301\n",
            "Train Epoch: 4 [2467/3978 (62%)]\tLoss: 0.040973\n",
            "Train Epoch: 4 [2468/3978 (62%)]\tLoss: 0.237042\n",
            "Train Epoch: 4 [2469/3978 (62%)]\tLoss: 0.609580\n",
            "Train Epoch: 4 [2470/3978 (62%)]\tLoss: 0.006241\n",
            "Train Epoch: 4 [2471/3978 (62%)]\tLoss: 0.703707\n",
            "Train Epoch: 4 [2472/3978 (62%)]\tLoss: 0.516158\n",
            "Train Epoch: 4 [2473/3978 (62%)]\tLoss: 0.463328\n",
            "Train Epoch: 4 [2474/3978 (62%)]\tLoss: 0.570454\n",
            "Train Epoch: 4 [2475/3978 (62%)]\tLoss: 0.383957\n",
            "Train Epoch: 4 [2476/3978 (62%)]\tLoss: 0.563507\n",
            "Train Epoch: 4 [2477/3978 (62%)]\tLoss: 3.108174\n",
            "Train Epoch: 4 [2478/3978 (62%)]\tLoss: 0.456622\n",
            "Train Epoch: 4 [2479/3978 (62%)]\tLoss: 2.157038\n",
            "Train Epoch: 4 [2480/3978 (62%)]\tLoss: 0.111960\n",
            "Train Epoch: 4 [2481/3978 (62%)]\tLoss: 0.353375\n",
            "Train Epoch: 4 [2482/3978 (62%)]\tLoss: 0.241523\n",
            "Train Epoch: 4 [2483/3978 (62%)]\tLoss: 0.026965\n",
            "Train Epoch: 4 [2484/3978 (62%)]\tLoss: 0.151635\n",
            "Train Epoch: 4 [2485/3978 (62%)]\tLoss: 0.939284\n",
            "Train Epoch: 4 [2486/3978 (62%)]\tLoss: 0.255022\n",
            "Train Epoch: 4 [2487/3978 (63%)]\tLoss: 0.049170\n",
            "Train Epoch: 4 [2488/3978 (63%)]\tLoss: 0.001881\n",
            "Train Epoch: 4 [2489/3978 (63%)]\tLoss: 0.236232\n",
            "Train Epoch: 4 [2490/3978 (63%)]\tLoss: 4.444847\n",
            "Train Epoch: 4 [2491/3978 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2492/3978 (63%)]\tLoss: 3.929799\n",
            "Train Epoch: 4 [2493/3978 (63%)]\tLoss: 1.680449\n",
            "Train Epoch: 4 [2494/3978 (63%)]\tLoss: 0.002940\n",
            "Train Epoch: 4 [2495/3978 (63%)]\tLoss: 0.026828\n",
            "Train Epoch: 4 [2496/3978 (63%)]\tLoss: 0.208763\n",
            "Train Epoch: 4 [2497/3978 (63%)]\tLoss: 0.241719\n",
            "Train Epoch: 4 [2498/3978 (63%)]\tLoss: 0.440506\n",
            "Train Epoch: 4 [2499/3978 (63%)]\tLoss: 2.150876\n",
            "Train Epoch: 4 [2500/3978 (63%)]\tLoss: 0.015014\n",
            "Train Epoch: 4 [2501/3978 (63%)]\tLoss: 0.001648\n",
            "Train Epoch: 4 [2502/3978 (63%)]\tLoss: 0.003746\n",
            "Train Epoch: 4 [2503/3978 (63%)]\tLoss: 0.641356\n",
            "Train Epoch: 4 [2504/3978 (63%)]\tLoss: 1.283151\n",
            "Train Epoch: 4 [2505/3978 (63%)]\tLoss: 0.168869\n",
            "Train Epoch: 4 [2506/3978 (63%)]\tLoss: 0.189601\n",
            "Train Epoch: 4 [2507/3978 (63%)]\tLoss: 0.009968\n",
            "Train Epoch: 4 [2508/3978 (63%)]\tLoss: 0.009470\n",
            "Train Epoch: 4 [2509/3978 (63%)]\tLoss: 0.000358\n",
            "Train Epoch: 4 [2510/3978 (63%)]\tLoss: 0.095044\n",
            "Train Epoch: 4 [2511/3978 (63%)]\tLoss: 0.016510\n",
            "Train Epoch: 4 [2512/3978 (63%)]\tLoss: 0.007070\n",
            "Train Epoch: 4 [2513/3978 (63%)]\tLoss: 3.157529\n",
            "Train Epoch: 4 [2514/3978 (63%)]\tLoss: 2.231481\n",
            "Train Epoch: 4 [2515/3978 (63%)]\tLoss: 1.959234\n",
            "Train Epoch: 4 [2516/3978 (63%)]\tLoss: 2.217211\n",
            "Train Epoch: 4 [2517/3978 (63%)]\tLoss: 0.022881\n",
            "Train Epoch: 4 [2518/3978 (63%)]\tLoss: 0.129053\n",
            "Train Epoch: 4 [2519/3978 (63%)]\tLoss: 0.001323\n",
            "Train Epoch: 4 [2520/3978 (63%)]\tLoss: 0.797825\n",
            "Train Epoch: 4 [2521/3978 (63%)]\tLoss: 0.066026\n",
            "Train Epoch: 4 [2522/3978 (63%)]\tLoss: 0.178189\n",
            "Train Epoch: 4 [2523/3978 (63%)]\tLoss: 0.000733\n",
            "Train Epoch: 4 [2524/3978 (63%)]\tLoss: 0.000523\n",
            "Train Epoch: 4 [2525/3978 (63%)]\tLoss: 2.097218\n",
            "Train Epoch: 4 [2526/3978 (63%)]\tLoss: 3.200790\n",
            "Train Epoch: 4 [2527/3978 (64%)]\tLoss: 3.082618\n",
            "Train Epoch: 4 [2528/3978 (64%)]\tLoss: 2.180424\n",
            "Train Epoch: 4 [2529/3978 (64%)]\tLoss: 2.655945\n",
            "Train Epoch: 4 [2530/3978 (64%)]\tLoss: 2.417003\n",
            "Train Epoch: 4 [2531/3978 (64%)]\tLoss: 1.108569\n",
            "Train Epoch: 4 [2532/3978 (64%)]\tLoss: 1.095636\n",
            "Train Epoch: 4 [2533/3978 (64%)]\tLoss: 0.323507\n",
            "Train Epoch: 4 [2534/3978 (64%)]\tLoss: 0.431052\n",
            "Train Epoch: 4 [2535/3978 (64%)]\tLoss: 0.681437\n",
            "Train Epoch: 4 [2536/3978 (64%)]\tLoss: 0.339163\n",
            "Train Epoch: 4 [2537/3978 (64%)]\tLoss: 0.308706\n",
            "Train Epoch: 4 [2538/3978 (64%)]\tLoss: 0.003836\n",
            "Train Epoch: 4 [2539/3978 (64%)]\tLoss: 1.616323\n",
            "Train Epoch: 4 [2540/3978 (64%)]\tLoss: 0.147518\n",
            "Train Epoch: 4 [2541/3978 (64%)]\tLoss: 0.178175\n",
            "Train Epoch: 4 [2542/3978 (64%)]\tLoss: 0.007891\n",
            "Train Epoch: 4 [2543/3978 (64%)]\tLoss: 0.174237\n",
            "Train Epoch: 4 [2544/3978 (64%)]\tLoss: 0.046221\n",
            "Train Epoch: 4 [2545/3978 (64%)]\tLoss: 1.683252\n",
            "Train Epoch: 4 [2546/3978 (64%)]\tLoss: 0.244454\n",
            "Train Epoch: 4 [2547/3978 (64%)]\tLoss: 0.005207\n",
            "Train Epoch: 4 [2548/3978 (64%)]\tLoss: 0.043077\n",
            "Train Epoch: 4 [2549/3978 (64%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [2550/3978 (64%)]\tLoss: 0.013221\n",
            "Train Epoch: 4 [2551/3978 (64%)]\tLoss: 0.796401\n",
            "Train Epoch: 4 [2552/3978 (64%)]\tLoss: 0.674741\n",
            "Train Epoch: 4 [2553/3978 (64%)]\tLoss: 0.027708\n",
            "Train Epoch: 4 [2554/3978 (64%)]\tLoss: 0.216448\n",
            "Train Epoch: 4 [2555/3978 (64%)]\tLoss: 0.849346\n",
            "Train Epoch: 4 [2556/3978 (64%)]\tLoss: 0.008055\n",
            "Train Epoch: 4 [2557/3978 (64%)]\tLoss: 1.439919\n",
            "Train Epoch: 4 [2558/3978 (64%)]\tLoss: 1.441440\n",
            "Train Epoch: 4 [2559/3978 (64%)]\tLoss: 0.931700\n",
            "Train Epoch: 4 [2560/3978 (64%)]\tLoss: 0.000961\n",
            "Train Epoch: 4 [2561/3978 (64%)]\tLoss: 0.433440\n",
            "Train Epoch: 4 [2562/3978 (64%)]\tLoss: 0.003403\n",
            "Train Epoch: 4 [2563/3978 (64%)]\tLoss: 4.418339\n",
            "Train Epoch: 4 [2564/3978 (64%)]\tLoss: 0.000028\n",
            "Train Epoch: 4 [2565/3978 (64%)]\tLoss: 8.197435\n",
            "Train Epoch: 4 [2566/3978 (65%)]\tLoss: 0.000989\n",
            "Train Epoch: 4 [2567/3978 (65%)]\tLoss: 1.618419\n",
            "Train Epoch: 4 [2568/3978 (65%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2569/3978 (65%)]\tLoss: 0.000262\n",
            "Train Epoch: 4 [2570/3978 (65%)]\tLoss: 0.000461\n",
            "Train Epoch: 4 [2571/3978 (65%)]\tLoss: 2.279251\n",
            "Train Epoch: 4 [2572/3978 (65%)]\tLoss: 1.191817\n",
            "Train Epoch: 4 [2573/3978 (65%)]\tLoss: 0.001108\n",
            "Train Epoch: 4 [2574/3978 (65%)]\tLoss: 0.651149\n",
            "Train Epoch: 4 [2575/3978 (65%)]\tLoss: 0.023156\n",
            "Train Epoch: 4 [2576/3978 (65%)]\tLoss: 0.002020\n",
            "Train Epoch: 4 [2577/3978 (65%)]\tLoss: 0.408071\n",
            "Train Epoch: 4 [2578/3978 (65%)]\tLoss: 1.255951\n",
            "Train Epoch: 4 [2579/3978 (65%)]\tLoss: 2.500859\n",
            "Train Epoch: 4 [2580/3978 (65%)]\tLoss: 0.754970\n",
            "Train Epoch: 4 [2581/3978 (65%)]\tLoss: 1.510702\n",
            "Train Epoch: 4 [2582/3978 (65%)]\tLoss: 0.155337\n",
            "Train Epoch: 4 [2583/3978 (65%)]\tLoss: 0.051718\n",
            "Train Epoch: 4 [2584/3978 (65%)]\tLoss: 0.284815\n",
            "Train Epoch: 4 [2585/3978 (65%)]\tLoss: 0.564402\n",
            "Train Epoch: 4 [2586/3978 (65%)]\tLoss: 0.387308\n",
            "Train Epoch: 4 [2587/3978 (65%)]\tLoss: 0.460268\n",
            "Train Epoch: 4 [2588/3978 (65%)]\tLoss: 0.035875\n",
            "Train Epoch: 4 [2589/3978 (65%)]\tLoss: 2.120761\n",
            "Train Epoch: 4 [2590/3978 (65%)]\tLoss: 0.000038\n",
            "Train Epoch: 4 [2591/3978 (65%)]\tLoss: 1.281147\n",
            "Train Epoch: 4 [2592/3978 (65%)]\tLoss: 1.375966\n",
            "Train Epoch: 4 [2593/3978 (65%)]\tLoss: 0.822297\n",
            "Train Epoch: 4 [2594/3978 (65%)]\tLoss: 0.127175\n",
            "Train Epoch: 4 [2595/3978 (65%)]\tLoss: 0.610392\n",
            "Train Epoch: 4 [2596/3978 (65%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [2597/3978 (65%)]\tLoss: 0.463763\n",
            "Train Epoch: 4 [2598/3978 (65%)]\tLoss: 0.000087\n",
            "Train Epoch: 4 [2599/3978 (65%)]\tLoss: 0.068843\n",
            "Train Epoch: 4 [2600/3978 (65%)]\tLoss: 0.912892\n",
            "Train Epoch: 4 [2601/3978 (65%)]\tLoss: 0.001181\n",
            "Train Epoch: 4 [2602/3978 (65%)]\tLoss: 0.463544\n",
            "Train Epoch: 4 [2603/3978 (65%)]\tLoss: 2.529206\n",
            "Train Epoch: 4 [2604/3978 (65%)]\tLoss: 0.587764\n",
            "Train Epoch: 4 [2605/3978 (65%)]\tLoss: 0.266388\n",
            "Train Epoch: 4 [2606/3978 (66%)]\tLoss: 0.006004\n",
            "Train Epoch: 4 [2607/3978 (66%)]\tLoss: 0.203497\n",
            "Train Epoch: 4 [2608/3978 (66%)]\tLoss: 0.357307\n",
            "Train Epoch: 4 [2609/3978 (66%)]\tLoss: 3.447891\n",
            "Train Epoch: 4 [2610/3978 (66%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [2611/3978 (66%)]\tLoss: 0.017971\n",
            "Train Epoch: 4 [2612/3978 (66%)]\tLoss: 0.488008\n",
            "Train Epoch: 4 [2613/3978 (66%)]\tLoss: 0.032471\n",
            "Train Epoch: 4 [2614/3978 (66%)]\tLoss: 0.006027\n",
            "Train Epoch: 4 [2615/3978 (66%)]\tLoss: 0.010568\n",
            "Train Epoch: 4 [2616/3978 (66%)]\tLoss: 1.855876\n",
            "Train Epoch: 4 [2617/3978 (66%)]\tLoss: 0.897779\n",
            "Train Epoch: 4 [2618/3978 (66%)]\tLoss: 0.006529\n",
            "Train Epoch: 4 [2619/3978 (66%)]\tLoss: 0.000197\n",
            "Train Epoch: 4 [2620/3978 (66%)]\tLoss: 0.270321\n",
            "Train Epoch: 4 [2621/3978 (66%)]\tLoss: 0.082184\n",
            "Train Epoch: 4 [2622/3978 (66%)]\tLoss: 1.377670\n",
            "Train Epoch: 4 [2623/3978 (66%)]\tLoss: 0.398630\n",
            "Train Epoch: 4 [2624/3978 (66%)]\tLoss: 0.007123\n",
            "Train Epoch: 4 [2625/3978 (66%)]\tLoss: 0.131883\n",
            "Train Epoch: 4 [2626/3978 (66%)]\tLoss: 0.644881\n",
            "Train Epoch: 4 [2627/3978 (66%)]\tLoss: 2.816413\n",
            "Train Epoch: 4 [2628/3978 (66%)]\tLoss: 0.087903\n",
            "Train Epoch: 4 [2629/3978 (66%)]\tLoss: 0.082484\n",
            "Train Epoch: 4 [2630/3978 (66%)]\tLoss: 0.282015\n",
            "Train Epoch: 4 [2631/3978 (66%)]\tLoss: 2.184779\n",
            "Train Epoch: 4 [2632/3978 (66%)]\tLoss: 0.195807\n",
            "Train Epoch: 4 [2633/3978 (66%)]\tLoss: 0.548522\n",
            "Train Epoch: 4 [2634/3978 (66%)]\tLoss: 1.878677\n",
            "Train Epoch: 4 [2635/3978 (66%)]\tLoss: 0.165016\n",
            "Train Epoch: 4 [2636/3978 (66%)]\tLoss: 0.000718\n",
            "Train Epoch: 4 [2637/3978 (66%)]\tLoss: 0.219906\n",
            "Train Epoch: 4 [2638/3978 (66%)]\tLoss: 0.229058\n",
            "Train Epoch: 4 [2639/3978 (66%)]\tLoss: 2.711711\n",
            "Train Epoch: 4 [2640/3978 (66%)]\tLoss: 0.004404\n",
            "Train Epoch: 4 [2641/3978 (66%)]\tLoss: 0.000104\n",
            "Train Epoch: 4 [2642/3978 (66%)]\tLoss: 0.000134\n",
            "Train Epoch: 4 [2643/3978 (66%)]\tLoss: 1.511537\n",
            "Train Epoch: 4 [2644/3978 (66%)]\tLoss: 0.310954\n",
            "Train Epoch: 4 [2645/3978 (66%)]\tLoss: 0.138352\n",
            "Train Epoch: 4 [2646/3978 (67%)]\tLoss: 0.039482\n",
            "Train Epoch: 4 [2647/3978 (67%)]\tLoss: 1.597822\n",
            "Train Epoch: 4 [2648/3978 (67%)]\tLoss: 1.024556\n",
            "Train Epoch: 4 [2649/3978 (67%)]\tLoss: 0.034631\n",
            "Train Epoch: 4 [2650/3978 (67%)]\tLoss: 0.188419\n",
            "Train Epoch: 4 [2651/3978 (67%)]\tLoss: 0.139642\n",
            "Train Epoch: 4 [2652/3978 (67%)]\tLoss: 0.007095\n",
            "Train Epoch: 4 [2653/3978 (67%)]\tLoss: 0.168399\n",
            "Train Epoch: 4 [2654/3978 (67%)]\tLoss: 1.177692\n",
            "Train Epoch: 4 [2655/3978 (67%)]\tLoss: 0.018133\n",
            "Train Epoch: 4 [2656/3978 (67%)]\tLoss: 0.006354\n",
            "Train Epoch: 4 [2657/3978 (67%)]\tLoss: 0.304787\n",
            "Train Epoch: 4 [2658/3978 (67%)]\tLoss: 2.265258\n",
            "Train Epoch: 4 [2659/3978 (67%)]\tLoss: 2.963729\n",
            "Train Epoch: 4 [2660/3978 (67%)]\tLoss: 0.008892\n",
            "Train Epoch: 4 [2661/3978 (67%)]\tLoss: 0.001081\n",
            "Train Epoch: 4 [2662/3978 (67%)]\tLoss: 0.007220\n",
            "Train Epoch: 4 [2663/3978 (67%)]\tLoss: 0.075670\n",
            "Train Epoch: 4 [2664/3978 (67%)]\tLoss: 0.000056\n",
            "Train Epoch: 4 [2665/3978 (67%)]\tLoss: 0.722114\n",
            "Train Epoch: 4 [2666/3978 (67%)]\tLoss: 0.062940\n",
            "Train Epoch: 4 [2667/3978 (67%)]\tLoss: 1.089902\n",
            "Train Epoch: 4 [2668/3978 (67%)]\tLoss: 0.039240\n",
            "Train Epoch: 4 [2669/3978 (67%)]\tLoss: 0.856788\n",
            "Train Epoch: 4 [2670/3978 (67%)]\tLoss: 0.951621\n",
            "Train Epoch: 4 [2671/3978 (67%)]\tLoss: 0.778385\n",
            "Train Epoch: 4 [2672/3978 (67%)]\tLoss: 0.036988\n",
            "Train Epoch: 4 [2673/3978 (67%)]\tLoss: 2.596792\n",
            "Train Epoch: 4 [2674/3978 (67%)]\tLoss: 0.664512\n",
            "Train Epoch: 4 [2675/3978 (67%)]\tLoss: 0.175217\n",
            "Train Epoch: 4 [2676/3978 (67%)]\tLoss: 0.018804\n",
            "Train Epoch: 4 [2677/3978 (67%)]\tLoss: 0.048736\n",
            "Train Epoch: 4 [2678/3978 (67%)]\tLoss: 0.002349\n",
            "Train Epoch: 4 [2679/3978 (67%)]\tLoss: 0.941314\n",
            "Train Epoch: 4 [2680/3978 (67%)]\tLoss: 0.102084\n",
            "Train Epoch: 4 [2681/3978 (67%)]\tLoss: 0.031057\n",
            "Train Epoch: 4 [2682/3978 (67%)]\tLoss: 0.007899\n",
            "Train Epoch: 4 [2683/3978 (67%)]\tLoss: 0.120851\n",
            "Train Epoch: 4 [2684/3978 (67%)]\tLoss: 0.000134\n",
            "Train Epoch: 4 [2685/3978 (67%)]\tLoss: 6.577512\n",
            "Train Epoch: 4 [2686/3978 (68%)]\tLoss: 0.076830\n",
            "Train Epoch: 4 [2687/3978 (68%)]\tLoss: 1.954500\n",
            "Train Epoch: 4 [2688/3978 (68%)]\tLoss: 0.273470\n",
            "Train Epoch: 4 [2689/3978 (68%)]\tLoss: 0.040775\n",
            "Train Epoch: 4 [2690/3978 (68%)]\tLoss: 0.288038\n",
            "Train Epoch: 4 [2691/3978 (68%)]\tLoss: 0.149781\n",
            "Train Epoch: 4 [2692/3978 (68%)]\tLoss: 0.057973\n",
            "Train Epoch: 4 [2693/3978 (68%)]\tLoss: 0.388543\n",
            "Train Epoch: 4 [2694/3978 (68%)]\tLoss: 0.005390\n",
            "Train Epoch: 4 [2695/3978 (68%)]\tLoss: 0.015121\n",
            "Train Epoch: 4 [2696/3978 (68%)]\tLoss: 1.828203\n",
            "Train Epoch: 4 [2697/3978 (68%)]\tLoss: 0.365162\n",
            "Train Epoch: 4 [2698/3978 (68%)]\tLoss: 0.015288\n",
            "Train Epoch: 4 [2699/3978 (68%)]\tLoss: 0.244821\n",
            "Train Epoch: 4 [2700/3978 (68%)]\tLoss: 1.579827\n",
            "Train Epoch: 4 [2701/3978 (68%)]\tLoss: 0.428610\n",
            "Train Epoch: 4 [2702/3978 (68%)]\tLoss: 0.440399\n",
            "Train Epoch: 4 [2703/3978 (68%)]\tLoss: 1.036296\n",
            "Train Epoch: 4 [2704/3978 (68%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2705/3978 (68%)]\tLoss: 0.031968\n",
            "Train Epoch: 4 [2706/3978 (68%)]\tLoss: 1.127730\n",
            "Train Epoch: 4 [2707/3978 (68%)]\tLoss: 1.357772\n",
            "Train Epoch: 4 [2708/3978 (68%)]\tLoss: 0.305803\n",
            "Train Epoch: 4 [2709/3978 (68%)]\tLoss: 0.022472\n",
            "Train Epoch: 4 [2710/3978 (68%)]\tLoss: 0.315878\n",
            "Train Epoch: 4 [2711/3978 (68%)]\tLoss: 0.000094\n",
            "Train Epoch: 4 [2712/3978 (68%)]\tLoss: 2.081732\n",
            "Train Epoch: 4 [2713/3978 (68%)]\tLoss: 0.000042\n",
            "Train Epoch: 4 [2714/3978 (68%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [2715/3978 (68%)]\tLoss: 1.474630\n",
            "Train Epoch: 4 [2716/3978 (68%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [2717/3978 (68%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [2718/3978 (68%)]\tLoss: 0.322029\n",
            "Train Epoch: 4 [2719/3978 (68%)]\tLoss: 0.582827\n",
            "Train Epoch: 4 [2720/3978 (68%)]\tLoss: 0.017991\n",
            "Train Epoch: 4 [2721/3978 (68%)]\tLoss: 2.189688\n",
            "Train Epoch: 4 [2722/3978 (68%)]\tLoss: 0.002170\n",
            "Train Epoch: 4 [2723/3978 (68%)]\tLoss: 0.045834\n",
            "Train Epoch: 4 [2724/3978 (68%)]\tLoss: 0.002002\n",
            "Train Epoch: 4 [2725/3978 (69%)]\tLoss: 0.000598\n",
            "Train Epoch: 4 [2726/3978 (69%)]\tLoss: 0.016507\n",
            "Train Epoch: 4 [2727/3978 (69%)]\tLoss: 0.000838\n",
            "Train Epoch: 4 [2728/3978 (69%)]\tLoss: 0.267405\n",
            "Train Epoch: 4 [2729/3978 (69%)]\tLoss: 0.503772\n",
            "Train Epoch: 4 [2730/3978 (69%)]\tLoss: 0.001197\n",
            "Train Epoch: 4 [2731/3978 (69%)]\tLoss: 0.649522\n",
            "Train Epoch: 4 [2732/3978 (69%)]\tLoss: 0.471373\n",
            "Train Epoch: 4 [2733/3978 (69%)]\tLoss: 0.009435\n",
            "Train Epoch: 4 [2734/3978 (69%)]\tLoss: 0.768473\n",
            "Train Epoch: 4 [2735/3978 (69%)]\tLoss: 2.123709\n",
            "Train Epoch: 4 [2736/3978 (69%)]\tLoss: 0.031698\n",
            "Train Epoch: 4 [2737/3978 (69%)]\tLoss: 0.089113\n",
            "Train Epoch: 4 [2738/3978 (69%)]\tLoss: 0.415130\n",
            "Train Epoch: 4 [2739/3978 (69%)]\tLoss: 1.428698\n",
            "Train Epoch: 4 [2740/3978 (69%)]\tLoss: 0.668045\n",
            "Train Epoch: 4 [2741/3978 (69%)]\tLoss: 0.069299\n",
            "Train Epoch: 4 [2742/3978 (69%)]\tLoss: 0.214272\n",
            "Train Epoch: 4 [2743/3978 (69%)]\tLoss: 0.001488\n",
            "Train Epoch: 4 [2744/3978 (69%)]\tLoss: 0.356078\n",
            "Train Epoch: 4 [2745/3978 (69%)]\tLoss: 0.287896\n",
            "Train Epoch: 4 [2746/3978 (69%)]\tLoss: 0.004213\n",
            "Train Epoch: 4 [2747/3978 (69%)]\tLoss: 0.047346\n",
            "Train Epoch: 4 [2748/3978 (69%)]\tLoss: 1.284527\n",
            "Train Epoch: 4 [2749/3978 (69%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [2750/3978 (69%)]\tLoss: 4.967749\n",
            "Train Epoch: 4 [2751/3978 (69%)]\tLoss: 1.234613\n",
            "Train Epoch: 4 [2752/3978 (69%)]\tLoss: 0.000037\n",
            "Train Epoch: 4 [2753/3978 (69%)]\tLoss: 2.987428\n",
            "Train Epoch: 4 [2754/3978 (69%)]\tLoss: 0.332433\n",
            "Train Epoch: 4 [2755/3978 (69%)]\tLoss: 0.445752\n",
            "Train Epoch: 4 [2756/3978 (69%)]\tLoss: 0.563862\n",
            "Train Epoch: 4 [2757/3978 (69%)]\tLoss: 0.367272\n",
            "Train Epoch: 4 [2758/3978 (69%)]\tLoss: 0.719626\n",
            "Train Epoch: 4 [2759/3978 (69%)]\tLoss: 0.035301\n",
            "Train Epoch: 4 [2760/3978 (69%)]\tLoss: 0.000922\n",
            "Train Epoch: 4 [2761/3978 (69%)]\tLoss: 0.027469\n",
            "Train Epoch: 4 [2762/3978 (69%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [2763/3978 (69%)]\tLoss: 0.491587\n",
            "Train Epoch: 4 [2764/3978 (69%)]\tLoss: 0.019801\n",
            "Train Epoch: 4 [2765/3978 (70%)]\tLoss: 1.953793\n",
            "Train Epoch: 4 [2766/3978 (70%)]\tLoss: 0.000025\n",
            "Train Epoch: 4 [2767/3978 (70%)]\tLoss: 0.027361\n",
            "Train Epoch: 4 [2768/3978 (70%)]\tLoss: 0.017349\n",
            "Train Epoch: 4 [2769/3978 (70%)]\tLoss: 0.966978\n",
            "Train Epoch: 4 [2770/3978 (70%)]\tLoss: 0.456547\n",
            "Train Epoch: 4 [2771/3978 (70%)]\tLoss: 0.029224\n",
            "Train Epoch: 4 [2772/3978 (70%)]\tLoss: 1.681886\n",
            "Train Epoch: 4 [2773/3978 (70%)]\tLoss: 0.003241\n",
            "Train Epoch: 4 [2774/3978 (70%)]\tLoss: 1.085728\n",
            "Train Epoch: 4 [2775/3978 (70%)]\tLoss: 1.567888\n",
            "Train Epoch: 4 [2776/3978 (70%)]\tLoss: 0.610953\n",
            "Train Epoch: 4 [2777/3978 (70%)]\tLoss: 2.579300\n",
            "Train Epoch: 4 [2778/3978 (70%)]\tLoss: 0.039024\n",
            "Train Epoch: 4 [2779/3978 (70%)]\tLoss: 0.660621\n",
            "Train Epoch: 4 [2780/3978 (70%)]\tLoss: 0.453776\n",
            "Train Epoch: 4 [2781/3978 (70%)]\tLoss: 0.743680\n",
            "Train Epoch: 4 [2782/3978 (70%)]\tLoss: 0.001847\n",
            "Train Epoch: 4 [2783/3978 (70%)]\tLoss: 1.196082\n",
            "Train Epoch: 4 [2784/3978 (70%)]\tLoss: 2.114156\n",
            "Train Epoch: 4 [2785/3978 (70%)]\tLoss: 3.211371\n",
            "Train Epoch: 4 [2786/3978 (70%)]\tLoss: 0.041668\n",
            "Train Epoch: 4 [2787/3978 (70%)]\tLoss: 1.906759\n",
            "Train Epoch: 4 [2788/3978 (70%)]\tLoss: 0.049680\n",
            "Train Epoch: 4 [2789/3978 (70%)]\tLoss: 0.002550\n",
            "Train Epoch: 4 [2790/3978 (70%)]\tLoss: 0.009050\n",
            "Train Epoch: 4 [2791/3978 (70%)]\tLoss: 0.000438\n",
            "Train Epoch: 4 [2792/3978 (70%)]\tLoss: 0.018351\n",
            "Train Epoch: 4 [2793/3978 (70%)]\tLoss: 1.190359\n",
            "Train Epoch: 4 [2794/3978 (70%)]\tLoss: 0.005479\n",
            "Train Epoch: 4 [2795/3978 (70%)]\tLoss: 1.099668\n",
            "Train Epoch: 4 [2796/3978 (70%)]\tLoss: 0.811745\n",
            "Train Epoch: 4 [2797/3978 (70%)]\tLoss: 0.003428\n",
            "Train Epoch: 4 [2798/3978 (70%)]\tLoss: 0.846569\n",
            "Train Epoch: 4 [2799/3978 (70%)]\tLoss: 5.230321\n",
            "Train Epoch: 4 [2800/3978 (70%)]\tLoss: 0.015032\n",
            "Train Epoch: 4 [2801/3978 (70%)]\tLoss: 0.149106\n",
            "Train Epoch: 4 [2802/3978 (70%)]\tLoss: 0.065119\n",
            "Train Epoch: 4 [2803/3978 (70%)]\tLoss: 0.015743\n",
            "Train Epoch: 4 [2804/3978 (70%)]\tLoss: 1.344661\n",
            "Train Epoch: 4 [2805/3978 (71%)]\tLoss: 0.000502\n",
            "Train Epoch: 4 [2806/3978 (71%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [2807/3978 (71%)]\tLoss: 0.623732\n",
            "Train Epoch: 4 [2808/3978 (71%)]\tLoss: 0.034753\n",
            "Train Epoch: 4 [2809/3978 (71%)]\tLoss: 1.633156\n",
            "Train Epoch: 4 [2810/3978 (71%)]\tLoss: 0.002011\n",
            "Train Epoch: 4 [2811/3978 (71%)]\tLoss: 0.085180\n",
            "Train Epoch: 4 [2812/3978 (71%)]\tLoss: 0.458326\n",
            "Train Epoch: 4 [2813/3978 (71%)]\tLoss: 0.091115\n",
            "Train Epoch: 4 [2814/3978 (71%)]\tLoss: 1.631608\n",
            "Train Epoch: 4 [2815/3978 (71%)]\tLoss: 0.036260\n",
            "Train Epoch: 4 [2816/3978 (71%)]\tLoss: 0.000954\n",
            "Train Epoch: 4 [2817/3978 (71%)]\tLoss: 0.040566\n",
            "Train Epoch: 4 [2818/3978 (71%)]\tLoss: 0.011299\n",
            "Train Epoch: 4 [2819/3978 (71%)]\tLoss: 0.000662\n",
            "Train Epoch: 4 [2820/3978 (71%)]\tLoss: 3.201074\n",
            "Train Epoch: 4 [2821/3978 (71%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [2822/3978 (71%)]\tLoss: 0.016892\n",
            "Train Epoch: 4 [2823/3978 (71%)]\tLoss: 1.961207\n",
            "Train Epoch: 4 [2824/3978 (71%)]\tLoss: 0.226827\n",
            "Train Epoch: 4 [2825/3978 (71%)]\tLoss: 0.040841\n",
            "Train Epoch: 4 [2826/3978 (71%)]\tLoss: 0.083091\n",
            "Train Epoch: 4 [2827/3978 (71%)]\tLoss: 0.012794\n",
            "Train Epoch: 4 [2828/3978 (71%)]\tLoss: 1.384246\n",
            "Train Epoch: 4 [2829/3978 (71%)]\tLoss: 1.526097\n",
            "Train Epoch: 4 [2830/3978 (71%)]\tLoss: 1.742216\n",
            "Train Epoch: 4 [2831/3978 (71%)]\tLoss: 4.735642\n",
            "Train Epoch: 4 [2832/3978 (71%)]\tLoss: 2.437187\n",
            "Train Epoch: 4 [2833/3978 (71%)]\tLoss: 1.001307\n",
            "Train Epoch: 4 [2834/3978 (71%)]\tLoss: 1.482665\n",
            "Train Epoch: 4 [2835/3978 (71%)]\tLoss: 0.000079\n",
            "Train Epoch: 4 [2836/3978 (71%)]\tLoss: 0.758321\n",
            "Train Epoch: 4 [2837/3978 (71%)]\tLoss: 0.000024\n",
            "Train Epoch: 4 [2838/3978 (71%)]\tLoss: 0.001651\n",
            "Train Epoch: 4 [2839/3978 (71%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [2840/3978 (71%)]\tLoss: 1.059796\n",
            "Train Epoch: 4 [2841/3978 (71%)]\tLoss: 0.432600\n",
            "Train Epoch: 4 [2842/3978 (71%)]\tLoss: 0.011889\n",
            "Train Epoch: 4 [2843/3978 (71%)]\tLoss: 2.199221\n",
            "Train Epoch: 4 [2844/3978 (71%)]\tLoss: 0.002187\n",
            "Train Epoch: 4 [2845/3978 (72%)]\tLoss: 0.699979\n",
            "Train Epoch: 4 [2846/3978 (72%)]\tLoss: 0.059901\n",
            "Train Epoch: 4 [2847/3978 (72%)]\tLoss: 0.692391\n",
            "Train Epoch: 4 [2848/3978 (72%)]\tLoss: 2.504595\n",
            "Train Epoch: 4 [2849/3978 (72%)]\tLoss: 0.005918\n",
            "Train Epoch: 4 [2850/3978 (72%)]\tLoss: 1.273155\n",
            "Train Epoch: 4 [2851/3978 (72%)]\tLoss: 0.049386\n",
            "Train Epoch: 4 [2852/3978 (72%)]\tLoss: 1.377329\n",
            "Train Epoch: 4 [2853/3978 (72%)]\tLoss: 1.200502\n",
            "Train Epoch: 4 [2854/3978 (72%)]\tLoss: 0.042858\n",
            "Train Epoch: 4 [2855/3978 (72%)]\tLoss: 4.077334\n",
            "Train Epoch: 4 [2856/3978 (72%)]\tLoss: 0.642819\n",
            "Train Epoch: 4 [2857/3978 (72%)]\tLoss: 0.002596\n",
            "Train Epoch: 4 [2858/3978 (72%)]\tLoss: 0.355397\n",
            "Train Epoch: 4 [2859/3978 (72%)]\tLoss: 2.294595\n",
            "Train Epoch: 4 [2860/3978 (72%)]\tLoss: 0.000037\n",
            "Train Epoch: 4 [2861/3978 (72%)]\tLoss: 0.008368\n",
            "Train Epoch: 4 [2862/3978 (72%)]\tLoss: 0.227889\n",
            "Train Epoch: 4 [2863/3978 (72%)]\tLoss: 1.261568\n",
            "Train Epoch: 4 [2864/3978 (72%)]\tLoss: 0.361695\n",
            "Train Epoch: 4 [2865/3978 (72%)]\tLoss: 0.173963\n",
            "Train Epoch: 4 [2866/3978 (72%)]\tLoss: 0.001884\n",
            "Train Epoch: 4 [2867/3978 (72%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [2868/3978 (72%)]\tLoss: 0.147848\n",
            "Train Epoch: 4 [2869/3978 (72%)]\tLoss: 0.000320\n",
            "Train Epoch: 4 [2870/3978 (72%)]\tLoss: 2.666374\n",
            "Train Epoch: 4 [2871/3978 (72%)]\tLoss: 0.096297\n",
            "Train Epoch: 4 [2872/3978 (72%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [2873/3978 (72%)]\tLoss: 0.000295\n",
            "Train Epoch: 4 [2874/3978 (72%)]\tLoss: 0.000900\n",
            "Train Epoch: 4 [2875/3978 (72%)]\tLoss: 0.010344\n",
            "Train Epoch: 4 [2876/3978 (72%)]\tLoss: 0.492923\n",
            "Train Epoch: 4 [2877/3978 (72%)]\tLoss: 0.819125\n",
            "Train Epoch: 4 [2878/3978 (72%)]\tLoss: 0.000779\n",
            "Train Epoch: 4 [2879/3978 (72%)]\tLoss: 0.001524\n",
            "Train Epoch: 4 [2880/3978 (72%)]\tLoss: 0.058401\n",
            "Train Epoch: 4 [2881/3978 (72%)]\tLoss: 0.003310\n",
            "Train Epoch: 4 [2882/3978 (72%)]\tLoss: 0.949612\n",
            "Train Epoch: 4 [2883/3978 (72%)]\tLoss: 0.000004\n",
            "Train Epoch: 4 [2884/3978 (72%)]\tLoss: 7.481350\n",
            "Train Epoch: 4 [2885/3978 (73%)]\tLoss: 0.002980\n",
            "Train Epoch: 4 [2886/3978 (73%)]\tLoss: 0.011716\n",
            "Train Epoch: 4 [2887/3978 (73%)]\tLoss: 0.088388\n",
            "Train Epoch: 4 [2888/3978 (73%)]\tLoss: 0.025778\n",
            "Train Epoch: 4 [2889/3978 (73%)]\tLoss: 0.000422\n",
            "Train Epoch: 4 [2890/3978 (73%)]\tLoss: 0.007648\n",
            "Train Epoch: 4 [2891/3978 (73%)]\tLoss: 0.903199\n",
            "Train Epoch: 4 [2892/3978 (73%)]\tLoss: 0.000567\n",
            "Train Epoch: 4 [2893/3978 (73%)]\tLoss: 0.002194\n",
            "Train Epoch: 4 [2894/3978 (73%)]\tLoss: 0.003532\n",
            "Train Epoch: 4 [2895/3978 (73%)]\tLoss: 0.000011\n",
            "Train Epoch: 4 [2896/3978 (73%)]\tLoss: 0.626349\n",
            "Train Epoch: 4 [2897/3978 (73%)]\tLoss: 4.875575\n",
            "Train Epoch: 4 [2898/3978 (73%)]\tLoss: 0.040076\n",
            "Train Epoch: 4 [2899/3978 (73%)]\tLoss: 0.731516\n",
            "Train Epoch: 4 [2900/3978 (73%)]\tLoss: 0.054795\n",
            "Train Epoch: 4 [2901/3978 (73%)]\tLoss: 4.108200\n",
            "Train Epoch: 4 [2902/3978 (73%)]\tLoss: 0.000735\n",
            "Train Epoch: 4 [2903/3978 (73%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2904/3978 (73%)]\tLoss: 1.213287\n",
            "Train Epoch: 4 [2905/3978 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2906/3978 (73%)]\tLoss: 0.000039\n",
            "Train Epoch: 4 [2907/3978 (73%)]\tLoss: 0.593839\n",
            "Train Epoch: 4 [2908/3978 (73%)]\tLoss: 1.832460\n",
            "Train Epoch: 4 [2909/3978 (73%)]\tLoss: 0.634965\n",
            "Train Epoch: 4 [2910/3978 (73%)]\tLoss: 1.419818\n",
            "Train Epoch: 4 [2911/3978 (73%)]\tLoss: 1.041902\n",
            "Train Epoch: 4 [2912/3978 (73%)]\tLoss: 1.214599\n",
            "Train Epoch: 4 [2913/3978 (73%)]\tLoss: 0.660384\n",
            "Train Epoch: 4 [2914/3978 (73%)]\tLoss: 0.727848\n",
            "Train Epoch: 4 [2915/3978 (73%)]\tLoss: 0.000219\n",
            "Train Epoch: 4 [2916/3978 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2917/3978 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2918/3978 (73%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [2919/3978 (73%)]\tLoss: 2.915946\n",
            "Train Epoch: 4 [2920/3978 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2921/3978 (73%)]\tLoss: 2.879601\n",
            "Train Epoch: 4 [2922/3978 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2923/3978 (73%)]\tLoss: 2.590035\n",
            "Train Epoch: 4 [2924/3978 (74%)]\tLoss: 2.889668\n",
            "Train Epoch: 4 [2925/3978 (74%)]\tLoss: 1.452835\n",
            "Train Epoch: 4 [2926/3978 (74%)]\tLoss: 0.507597\n",
            "Train Epoch: 4 [2927/3978 (74%)]\tLoss: 0.000395\n",
            "Train Epoch: 4 [2928/3978 (74%)]\tLoss: 0.639542\n",
            "Train Epoch: 4 [2929/3978 (74%)]\tLoss: 6.475685\n",
            "Train Epoch: 4 [2930/3978 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2931/3978 (74%)]\tLoss: 1.857400\n",
            "Train Epoch: 4 [2932/3978 (74%)]\tLoss: 2.963738\n",
            "Train Epoch: 4 [2933/3978 (74%)]\tLoss: 1.910983\n",
            "Train Epoch: 4 [2934/3978 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [2935/3978 (74%)]\tLoss: 2.655947\n",
            "Train Epoch: 4 [2936/3978 (74%)]\tLoss: 0.010960\n",
            "Train Epoch: 4 [2937/3978 (74%)]\tLoss: 0.001122\n",
            "Train Epoch: 4 [2938/3978 (74%)]\tLoss: 7.671787\n",
            "Train Epoch: 4 [2939/3978 (74%)]\tLoss: 0.790077\n",
            "Train Epoch: 4 [2940/3978 (74%)]\tLoss: 3.443513\n",
            "Train Epoch: 4 [2941/3978 (74%)]\tLoss: 0.111353\n",
            "Train Epoch: 4 [2942/3978 (74%)]\tLoss: 0.038635\n",
            "Train Epoch: 4 [2943/3978 (74%)]\tLoss: 0.174438\n",
            "Train Epoch: 4 [2944/3978 (74%)]\tLoss: 0.295495\n",
            "Train Epoch: 4 [2945/3978 (74%)]\tLoss: 0.457117\n",
            "Train Epoch: 4 [2946/3978 (74%)]\tLoss: 0.347218\n",
            "Train Epoch: 4 [2947/3978 (74%)]\tLoss: 0.084516\n",
            "Train Epoch: 4 [2948/3978 (74%)]\tLoss: 3.136316\n",
            "Train Epoch: 4 [2949/3978 (74%)]\tLoss: 0.002762\n",
            "Train Epoch: 4 [2950/3978 (74%)]\tLoss: 1.058387\n",
            "Train Epoch: 4 [2951/3978 (74%)]\tLoss: 0.320816\n",
            "Train Epoch: 4 [2952/3978 (74%)]\tLoss: 0.144790\n",
            "Train Epoch: 4 [2953/3978 (74%)]\tLoss: 0.008267\n",
            "Train Epoch: 4 [2954/3978 (74%)]\tLoss: 0.356260\n",
            "Train Epoch: 4 [2955/3978 (74%)]\tLoss: 0.029249\n",
            "Train Epoch: 4 [2956/3978 (74%)]\tLoss: 0.002086\n",
            "Train Epoch: 4 [2957/3978 (74%)]\tLoss: 0.000440\n",
            "Train Epoch: 4 [2958/3978 (74%)]\tLoss: 0.203895\n",
            "Train Epoch: 4 [2959/3978 (74%)]\tLoss: 0.250683\n",
            "Train Epoch: 4 [2960/3978 (74%)]\tLoss: 0.197173\n",
            "Train Epoch: 4 [2961/3978 (74%)]\tLoss: 2.087498\n",
            "Train Epoch: 4 [2962/3978 (74%)]\tLoss: 0.001040\n",
            "Train Epoch: 4 [2963/3978 (74%)]\tLoss: 0.000017\n",
            "Train Epoch: 4 [2964/3978 (75%)]\tLoss: 1.603757\n",
            "Train Epoch: 4 [2965/3978 (75%)]\tLoss: 4.035847\n",
            "Train Epoch: 4 [2966/3978 (75%)]\tLoss: 0.739052\n",
            "Train Epoch: 4 [2967/3978 (75%)]\tLoss: 0.373240\n",
            "Train Epoch: 4 [2968/3978 (75%)]\tLoss: 0.631799\n",
            "Train Epoch: 4 [2969/3978 (75%)]\tLoss: 0.075436\n",
            "Train Epoch: 4 [2970/3978 (75%)]\tLoss: 1.171171\n",
            "Train Epoch: 4 [2971/3978 (75%)]\tLoss: 0.612148\n",
            "Train Epoch: 4 [2972/3978 (75%)]\tLoss: 1.479648\n",
            "Train Epoch: 4 [2973/3978 (75%)]\tLoss: 3.840011\n",
            "Train Epoch: 4 [2974/3978 (75%)]\tLoss: 2.289260\n",
            "Train Epoch: 4 [2975/3978 (75%)]\tLoss: 3.197431\n",
            "Train Epoch: 4 [2976/3978 (75%)]\tLoss: 0.218369\n",
            "Train Epoch: 4 [2977/3978 (75%)]\tLoss: 0.848973\n",
            "Train Epoch: 4 [2978/3978 (75%)]\tLoss: 0.145953\n",
            "Train Epoch: 4 [2979/3978 (75%)]\tLoss: 0.315577\n",
            "Train Epoch: 4 [2980/3978 (75%)]\tLoss: 0.000168\n",
            "Train Epoch: 4 [2981/3978 (75%)]\tLoss: 0.725806\n",
            "Train Epoch: 4 [2982/3978 (75%)]\tLoss: 0.011556\n",
            "Train Epoch: 4 [2983/3978 (75%)]\tLoss: 0.321251\n",
            "Train Epoch: 4 [2984/3978 (75%)]\tLoss: 1.932904\n",
            "Train Epoch: 4 [2985/3978 (75%)]\tLoss: 0.000106\n",
            "Train Epoch: 4 [2986/3978 (75%)]\tLoss: 0.691421\n",
            "Train Epoch: 4 [2987/3978 (75%)]\tLoss: 1.063635\n",
            "Train Epoch: 4 [2988/3978 (75%)]\tLoss: 0.000039\n",
            "Train Epoch: 4 [2989/3978 (75%)]\tLoss: 0.234344\n",
            "Train Epoch: 4 [2990/3978 (75%)]\tLoss: 0.203352\n",
            "Train Epoch: 4 [2991/3978 (75%)]\tLoss: 1.100008\n",
            "Train Epoch: 4 [2992/3978 (75%)]\tLoss: 0.999377\n",
            "Train Epoch: 4 [2993/3978 (75%)]\tLoss: 0.056503\n",
            "Train Epoch: 4 [2994/3978 (75%)]\tLoss: 0.881494\n",
            "Train Epoch: 4 [2995/3978 (75%)]\tLoss: 0.200889\n",
            "Train Epoch: 4 [2996/3978 (75%)]\tLoss: 1.470033\n",
            "Train Epoch: 4 [2997/3978 (75%)]\tLoss: 0.188776\n",
            "Train Epoch: 4 [2998/3978 (75%)]\tLoss: 0.089375\n",
            "Train Epoch: 4 [2999/3978 (75%)]\tLoss: 4.908310\n",
            "Train Epoch: 4 [3000/3978 (75%)]\tLoss: 0.315326\n",
            "Train Epoch: 4 [3001/3978 (75%)]\tLoss: 0.000038\n",
            "Train Epoch: 4 [3002/3978 (75%)]\tLoss: 0.104364\n",
            "Train Epoch: 4 [3003/3978 (75%)]\tLoss: 1.235817\n",
            "Train Epoch: 4 [3004/3978 (76%)]\tLoss: 0.105524\n",
            "Train Epoch: 4 [3005/3978 (76%)]\tLoss: 0.001962\n",
            "Train Epoch: 4 [3006/3978 (76%)]\tLoss: 1.525508\n",
            "Train Epoch: 4 [3007/3978 (76%)]\tLoss: 1.328258\n",
            "Train Epoch: 4 [3008/3978 (76%)]\tLoss: 2.991917\n",
            "Train Epoch: 4 [3009/3978 (76%)]\tLoss: 0.984884\n",
            "Train Epoch: 4 [3010/3978 (76%)]\tLoss: 0.254395\n",
            "Train Epoch: 4 [3011/3978 (76%)]\tLoss: 0.122708\n",
            "Train Epoch: 4 [3012/3978 (76%)]\tLoss: 1.798764\n",
            "Train Epoch: 4 [3013/3978 (76%)]\tLoss: 0.268981\n",
            "Train Epoch: 4 [3014/3978 (76%)]\tLoss: 0.239865\n",
            "Train Epoch: 4 [3015/3978 (76%)]\tLoss: 4.676229\n",
            "Train Epoch: 4 [3016/3978 (76%)]\tLoss: 1.456623\n",
            "Train Epoch: 4 [3017/3978 (76%)]\tLoss: 0.003455\n",
            "Train Epoch: 4 [3018/3978 (76%)]\tLoss: 0.072386\n",
            "Train Epoch: 4 [3019/3978 (76%)]\tLoss: 0.892421\n",
            "Train Epoch: 4 [3020/3978 (76%)]\tLoss: 1.228546\n",
            "Train Epoch: 4 [3021/3978 (76%)]\tLoss: 0.005507\n",
            "Train Epoch: 4 [3022/3978 (76%)]\tLoss: 0.088591\n",
            "Train Epoch: 4 [3023/3978 (76%)]\tLoss: 0.204670\n",
            "Train Epoch: 4 [3024/3978 (76%)]\tLoss: 0.000067\n",
            "Train Epoch: 4 [3025/3978 (76%)]\tLoss: 0.300353\n",
            "Train Epoch: 4 [3026/3978 (76%)]\tLoss: 0.009482\n",
            "Train Epoch: 4 [3027/3978 (76%)]\tLoss: 0.000016\n",
            "Train Epoch: 4 [3028/3978 (76%)]\tLoss: 0.111269\n",
            "Train Epoch: 4 [3029/3978 (76%)]\tLoss: 2.160930\n",
            "Train Epoch: 4 [3030/3978 (76%)]\tLoss: 0.186138\n",
            "Train Epoch: 4 [3031/3978 (76%)]\tLoss: 0.003480\n",
            "Train Epoch: 4 [3032/3978 (76%)]\tLoss: 0.005216\n",
            "Train Epoch: 4 [3033/3978 (76%)]\tLoss: 0.006014\n",
            "Train Epoch: 4 [3034/3978 (76%)]\tLoss: 0.002222\n",
            "Train Epoch: 4 [3035/3978 (76%)]\tLoss: 0.005439\n",
            "Train Epoch: 4 [3036/3978 (76%)]\tLoss: 2.871782\n",
            "Train Epoch: 4 [3037/3978 (76%)]\tLoss: 0.023894\n",
            "Train Epoch: 4 [3038/3978 (76%)]\tLoss: 3.635676\n",
            "Train Epoch: 4 [3039/3978 (76%)]\tLoss: 0.736412\n",
            "Train Epoch: 4 [3040/3978 (76%)]\tLoss: 0.003574\n",
            "Train Epoch: 4 [3041/3978 (76%)]\tLoss: 2.792397\n",
            "Train Epoch: 4 [3042/3978 (76%)]\tLoss: 0.867669\n",
            "Train Epoch: 4 [3043/3978 (76%)]\tLoss: 2.014760\n",
            "Train Epoch: 4 [3044/3978 (77%)]\tLoss: 0.295991\n",
            "Train Epoch: 4 [3045/3978 (77%)]\tLoss: 0.222412\n",
            "Train Epoch: 4 [3046/3978 (77%)]\tLoss: 0.172827\n",
            "Train Epoch: 4 [3047/3978 (77%)]\tLoss: 1.089876\n",
            "Train Epoch: 4 [3048/3978 (77%)]\tLoss: 0.099523\n",
            "Train Epoch: 4 [3049/3978 (77%)]\tLoss: 0.890692\n",
            "Train Epoch: 4 [3050/3978 (77%)]\tLoss: 0.816913\n",
            "Train Epoch: 4 [3051/3978 (77%)]\tLoss: 0.828900\n",
            "Train Epoch: 4 [3052/3978 (77%)]\tLoss: 1.124024\n",
            "Train Epoch: 4 [3053/3978 (77%)]\tLoss: 0.361604\n",
            "Train Epoch: 4 [3054/3978 (77%)]\tLoss: 0.044056\n",
            "Train Epoch: 4 [3055/3978 (77%)]\tLoss: 1.878987\n",
            "Train Epoch: 4 [3056/3978 (77%)]\tLoss: 0.760342\n",
            "Train Epoch: 4 [3057/3978 (77%)]\tLoss: 1.607309\n",
            "Train Epoch: 4 [3058/3978 (77%)]\tLoss: 0.186474\n",
            "Train Epoch: 4 [3059/3978 (77%)]\tLoss: 0.012827\n",
            "Train Epoch: 4 [3060/3978 (77%)]\tLoss: 0.425491\n",
            "Train Epoch: 4 [3061/3978 (77%)]\tLoss: 2.946047\n",
            "Train Epoch: 4 [3062/3978 (77%)]\tLoss: 0.242279\n",
            "Train Epoch: 4 [3063/3978 (77%)]\tLoss: 0.114027\n",
            "Train Epoch: 4 [3064/3978 (77%)]\tLoss: 0.919114\n",
            "Train Epoch: 4 [3065/3978 (77%)]\tLoss: 0.966567\n",
            "Train Epoch: 4 [3066/3978 (77%)]\tLoss: 0.705318\n",
            "Train Epoch: 4 [3067/3978 (77%)]\tLoss: 0.004467\n",
            "Train Epoch: 4 [3068/3978 (77%)]\tLoss: 0.008260\n",
            "Train Epoch: 4 [3069/3978 (77%)]\tLoss: 0.000019\n",
            "Train Epoch: 4 [3070/3978 (77%)]\tLoss: 0.669588\n",
            "Train Epoch: 4 [3071/3978 (77%)]\tLoss: 1.818059\n",
            "Train Epoch: 4 [3072/3978 (77%)]\tLoss: 0.667784\n",
            "Train Epoch: 4 [3073/3978 (77%)]\tLoss: 4.891638\n",
            "Train Epoch: 4 [3074/3978 (77%)]\tLoss: 0.038515\n",
            "Train Epoch: 4 [3075/3978 (77%)]\tLoss: 0.012651\n",
            "Train Epoch: 4 [3076/3978 (77%)]\tLoss: 0.729437\n",
            "Train Epoch: 4 [3077/3978 (77%)]\tLoss: 0.489208\n",
            "Train Epoch: 4 [3078/3978 (77%)]\tLoss: 0.045300\n",
            "Train Epoch: 4 [3079/3978 (77%)]\tLoss: 0.286314\n",
            "Train Epoch: 4 [3080/3978 (77%)]\tLoss: 0.363217\n",
            "Train Epoch: 4 [3081/3978 (77%)]\tLoss: 2.928323\n",
            "Train Epoch: 4 [3082/3978 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3083/3978 (78%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3084/3978 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3085/3978 (78%)]\tLoss: 0.000178\n",
            "Train Epoch: 4 [3086/3978 (78%)]\tLoss: 1.834012\n",
            "Train Epoch: 4 [3087/3978 (78%)]\tLoss: 4.956192\n",
            "Train Epoch: 4 [3088/3978 (78%)]\tLoss: 2.767039\n",
            "Train Epoch: 4 [3089/3978 (78%)]\tLoss: 0.065264\n",
            "Train Epoch: 4 [3090/3978 (78%)]\tLoss: 1.755590\n",
            "Train Epoch: 4 [3091/3978 (78%)]\tLoss: 0.038030\n",
            "Train Epoch: 4 [3092/3978 (78%)]\tLoss: 0.565197\n",
            "Train Epoch: 4 [3093/3978 (78%)]\tLoss: 0.000191\n",
            "Train Epoch: 4 [3094/3978 (78%)]\tLoss: 2.636626\n",
            "Train Epoch: 4 [3095/3978 (78%)]\tLoss: 2.380434\n",
            "Train Epoch: 4 [3096/3978 (78%)]\tLoss: 1.674939\n",
            "Train Epoch: 4 [3097/3978 (78%)]\tLoss: 0.007573\n",
            "Train Epoch: 4 [3098/3978 (78%)]\tLoss: 0.151458\n",
            "Train Epoch: 4 [3099/3978 (78%)]\tLoss: 0.510645\n",
            "Train Epoch: 4 [3100/3978 (78%)]\tLoss: 0.000219\n",
            "Train Epoch: 4 [3101/3978 (78%)]\tLoss: 0.005814\n",
            "Train Epoch: 4 [3102/3978 (78%)]\tLoss: 0.954140\n",
            "Train Epoch: 4 [3103/3978 (78%)]\tLoss: 0.466700\n",
            "Train Epoch: 4 [3104/3978 (78%)]\tLoss: 0.040096\n",
            "Train Epoch: 4 [3105/3978 (78%)]\tLoss: 0.001128\n",
            "Train Epoch: 4 [3106/3978 (78%)]\tLoss: 0.670472\n",
            "Train Epoch: 4 [3107/3978 (78%)]\tLoss: 4.534892\n",
            "Train Epoch: 4 [3108/3978 (78%)]\tLoss: 0.305793\n",
            "Train Epoch: 4 [3109/3978 (78%)]\tLoss: 0.026481\n",
            "Train Epoch: 4 [3110/3978 (78%)]\tLoss: 0.081838\n",
            "Train Epoch: 4 [3111/3978 (78%)]\tLoss: 0.014868\n",
            "Train Epoch: 4 [3112/3978 (78%)]\tLoss: 1.122482\n",
            "Train Epoch: 4 [3113/3978 (78%)]\tLoss: 0.995879\n",
            "Train Epoch: 4 [3114/3978 (78%)]\tLoss: 0.000130\n",
            "Train Epoch: 4 [3115/3978 (78%)]\tLoss: 1.128070\n",
            "Train Epoch: 4 [3116/3978 (78%)]\tLoss: 0.002067\n",
            "Train Epoch: 4 [3117/3978 (78%)]\tLoss: 0.001828\n",
            "Train Epoch: 4 [3118/3978 (78%)]\tLoss: 0.005253\n",
            "Train Epoch: 4 [3119/3978 (78%)]\tLoss: 2.124626\n",
            "Train Epoch: 4 [3120/3978 (78%)]\tLoss: 1.061837\n",
            "Train Epoch: 4 [3121/3978 (78%)]\tLoss: 0.000009\n",
            "Train Epoch: 4 [3122/3978 (78%)]\tLoss: 2.788797\n",
            "Train Epoch: 4 [3123/3978 (79%)]\tLoss: 0.021628\n",
            "Train Epoch: 4 [3124/3978 (79%)]\tLoss: 1.743808\n",
            "Train Epoch: 4 [3125/3978 (79%)]\tLoss: 0.157027\n",
            "Train Epoch: 4 [3126/3978 (79%)]\tLoss: 0.593616\n",
            "Train Epoch: 4 [3127/3978 (79%)]\tLoss: 0.930051\n",
            "Train Epoch: 4 [3128/3978 (79%)]\tLoss: 0.529718\n",
            "Train Epoch: 4 [3129/3978 (79%)]\tLoss: 0.030003\n",
            "Train Epoch: 4 [3130/3978 (79%)]\tLoss: 0.900050\n",
            "Train Epoch: 4 [3131/3978 (79%)]\tLoss: 0.027507\n",
            "Train Epoch: 4 [3132/3978 (79%)]\tLoss: 0.285009\n",
            "Train Epoch: 4 [3133/3978 (79%)]\tLoss: 0.593100\n",
            "Train Epoch: 4 [3134/3978 (79%)]\tLoss: 0.001860\n",
            "Train Epoch: 4 [3135/3978 (79%)]\tLoss: 1.377609\n",
            "Train Epoch: 4 [3136/3978 (79%)]\tLoss: 1.761758\n",
            "Train Epoch: 4 [3137/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3138/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3139/3978 (79%)]\tLoss: 1.981490\n",
            "Train Epoch: 4 [3140/3978 (79%)]\tLoss: 1.091553\n",
            "Train Epoch: 4 [3141/3978 (79%)]\tLoss: 0.000123\n",
            "Train Epoch: 4 [3142/3978 (79%)]\tLoss: 2.064056\n",
            "Train Epoch: 4 [3143/3978 (79%)]\tLoss: 0.002574\n",
            "Train Epoch: 4 [3144/3978 (79%)]\tLoss: 1.243306\n",
            "Train Epoch: 4 [3145/3978 (79%)]\tLoss: 0.111850\n",
            "Train Epoch: 4 [3146/3978 (79%)]\tLoss: 0.597355\n",
            "Train Epoch: 4 [3147/3978 (79%)]\tLoss: 0.208510\n",
            "Train Epoch: 4 [3148/3978 (79%)]\tLoss: 0.358102\n",
            "Train Epoch: 4 [3149/3978 (79%)]\tLoss: 0.044531\n",
            "Train Epoch: 4 [3150/3978 (79%)]\tLoss: 0.423046\n",
            "Train Epoch: 4 [3151/3978 (79%)]\tLoss: 4.172138\n",
            "Train Epoch: 4 [3152/3978 (79%)]\tLoss: 0.133858\n",
            "Train Epoch: 4 [3153/3978 (79%)]\tLoss: 0.460821\n",
            "Train Epoch: 4 [3154/3978 (79%)]\tLoss: 0.031082\n",
            "Train Epoch: 4 [3155/3978 (79%)]\tLoss: 0.000088\n",
            "Train Epoch: 4 [3156/3978 (79%)]\tLoss: 0.000333\n",
            "Train Epoch: 4 [3157/3978 (79%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [3158/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3159/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3160/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3161/3978 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3162/3978 (79%)]\tLoss: 3.115998\n",
            "Train Epoch: 4 [3163/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3164/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3165/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3166/3978 (80%)]\tLoss: 5.565032\n",
            "Train Epoch: 4 [3167/3978 (80%)]\tLoss: 1.870650\n",
            "Train Epoch: 4 [3168/3978 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3169/3978 (80%)]\tLoss: 1.029593\n",
            "Train Epoch: 4 [3170/3978 (80%)]\tLoss: 0.060458\n",
            "Train Epoch: 4 [3171/3978 (80%)]\tLoss: 0.035097\n",
            "Train Epoch: 4 [3172/3978 (80%)]\tLoss: 0.144680\n",
            "Train Epoch: 4 [3173/3978 (80%)]\tLoss: 0.484301\n",
            "Train Epoch: 4 [3174/3978 (80%)]\tLoss: 0.003385\n",
            "Train Epoch: 4 [3175/3978 (80%)]\tLoss: 0.000461\n",
            "Train Epoch: 4 [3176/3978 (80%)]\tLoss: 0.658532\n",
            "Train Epoch: 4 [3177/3978 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3178/3978 (80%)]\tLoss: 2.635223\n",
            "Train Epoch: 4 [3179/3978 (80%)]\tLoss: 0.004540\n",
            "Train Epoch: 4 [3180/3978 (80%)]\tLoss: 6.286122\n",
            "Train Epoch: 4 [3181/3978 (80%)]\tLoss: 0.033156\n",
            "Train Epoch: 4 [3182/3978 (80%)]\tLoss: 0.180791\n",
            "Train Epoch: 4 [3183/3978 (80%)]\tLoss: 0.000244\n",
            "Train Epoch: 4 [3184/3978 (80%)]\tLoss: 0.326580\n",
            "Train Epoch: 4 [3185/3978 (80%)]\tLoss: 0.000427\n",
            "Train Epoch: 4 [3186/3978 (80%)]\tLoss: 1.409943\n",
            "Train Epoch: 4 [3187/3978 (80%)]\tLoss: 2.593417\n",
            "Train Epoch: 4 [3188/3978 (80%)]\tLoss: 1.547766\n",
            "Train Epoch: 4 [3189/3978 (80%)]\tLoss: 1.120684\n",
            "Train Epoch: 4 [3190/3978 (80%)]\tLoss: 0.557765\n",
            "Train Epoch: 4 [3191/3978 (80%)]\tLoss: 1.448176\n",
            "Train Epoch: 4 [3192/3978 (80%)]\tLoss: 1.755159\n",
            "Train Epoch: 4 [3193/3978 (80%)]\tLoss: 1.752590\n",
            "Train Epoch: 4 [3194/3978 (80%)]\tLoss: 2.307131\n",
            "Train Epoch: 4 [3195/3978 (80%)]\tLoss: 1.647838\n",
            "Train Epoch: 4 [3196/3978 (80%)]\tLoss: 1.966557\n",
            "Train Epoch: 4 [3197/3978 (80%)]\tLoss: 1.139132\n",
            "Train Epoch: 4 [3198/3978 (80%)]\tLoss: 0.569104\n",
            "Train Epoch: 4 [3199/3978 (80%)]\tLoss: 0.013703\n",
            "Train Epoch: 4 [3200/3978 (80%)]\tLoss: 0.153796\n",
            "Train Epoch: 4 [3201/3978 (80%)]\tLoss: 0.218536\n",
            "Train Epoch: 4 [3202/3978 (80%)]\tLoss: 0.000578\n",
            "Train Epoch: 4 [3203/3978 (81%)]\tLoss: 0.462510\n",
            "Train Epoch: 4 [3204/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3205/3978 (81%)]\tLoss: 0.179413\n",
            "Train Epoch: 4 [3206/3978 (81%)]\tLoss: 0.000166\n",
            "Train Epoch: 4 [3207/3978 (81%)]\tLoss: 0.019251\n",
            "Train Epoch: 4 [3208/3978 (81%)]\tLoss: 3.740114\n",
            "Train Epoch: 4 [3209/3978 (81%)]\tLoss: 0.004790\n",
            "Train Epoch: 4 [3210/3978 (81%)]\tLoss: 1.195205\n",
            "Train Epoch: 4 [3211/3978 (81%)]\tLoss: 0.000084\n",
            "Train Epoch: 4 [3212/3978 (81%)]\tLoss: 0.025826\n",
            "Train Epoch: 4 [3213/3978 (81%)]\tLoss: 0.067243\n",
            "Train Epoch: 4 [3214/3978 (81%)]\tLoss: 0.895572\n",
            "Train Epoch: 4 [3215/3978 (81%)]\tLoss: 0.069236\n",
            "Train Epoch: 4 [3216/3978 (81%)]\tLoss: 0.299682\n",
            "Train Epoch: 4 [3217/3978 (81%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3218/3978 (81%)]\tLoss: 0.085442\n",
            "Train Epoch: 4 [3219/3978 (81%)]\tLoss: 4.570303\n",
            "Train Epoch: 4 [3220/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3221/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3222/3978 (81%)]\tLoss: 5.962445\n",
            "Train Epoch: 4 [3223/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3224/3978 (81%)]\tLoss: 3.458812\n",
            "Train Epoch: 4 [3225/3978 (81%)]\tLoss: 1.312491\n",
            "Train Epoch: 4 [3226/3978 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3227/3978 (81%)]\tLoss: 0.984424\n",
            "Train Epoch: 4 [3228/3978 (81%)]\tLoss: 1.653039\n",
            "Train Epoch: 4 [3229/3978 (81%)]\tLoss: 0.000684\n",
            "Train Epoch: 4 [3230/3978 (81%)]\tLoss: 0.410793\n",
            "Train Epoch: 4 [3231/3978 (81%)]\tLoss: 1.034588\n",
            "Train Epoch: 4 [3232/3978 (81%)]\tLoss: 1.337141\n",
            "Train Epoch: 4 [3233/3978 (81%)]\tLoss: 0.004961\n",
            "Train Epoch: 4 [3234/3978 (81%)]\tLoss: 8.366179\n",
            "Train Epoch: 4 [3235/3978 (81%)]\tLoss: 1.409666\n",
            "Train Epoch: 4 [3236/3978 (81%)]\tLoss: 0.377498\n",
            "Train Epoch: 4 [3237/3978 (81%)]\tLoss: 0.126832\n",
            "Train Epoch: 4 [3238/3978 (81%)]\tLoss: 0.022752\n",
            "Train Epoch: 4 [3239/3978 (81%)]\tLoss: 1.054088\n",
            "Train Epoch: 4 [3240/3978 (81%)]\tLoss: 0.000210\n",
            "Train Epoch: 4 [3241/3978 (81%)]\tLoss: 2.442077\n",
            "Train Epoch: 4 [3242/3978 (81%)]\tLoss: 0.536116\n",
            "Train Epoch: 4 [3243/3978 (82%)]\tLoss: 0.563997\n",
            "Train Epoch: 4 [3244/3978 (82%)]\tLoss: 0.410573\n",
            "Train Epoch: 4 [3245/3978 (82%)]\tLoss: 0.001102\n",
            "Train Epoch: 4 [3246/3978 (82%)]\tLoss: 0.163025\n",
            "Train Epoch: 4 [3247/3978 (82%)]\tLoss: 0.627547\n",
            "Train Epoch: 4 [3248/3978 (82%)]\tLoss: 0.004140\n",
            "Train Epoch: 4 [3249/3978 (82%)]\tLoss: 0.352510\n",
            "Train Epoch: 4 [3250/3978 (82%)]\tLoss: 0.030104\n",
            "Train Epoch: 4 [3251/3978 (82%)]\tLoss: 0.111401\n",
            "Train Epoch: 4 [3252/3978 (82%)]\tLoss: 0.505669\n",
            "Train Epoch: 4 [3253/3978 (82%)]\tLoss: 0.003755\n",
            "Train Epoch: 4 [3254/3978 (82%)]\tLoss: 0.003533\n",
            "Train Epoch: 4 [3255/3978 (82%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [3256/3978 (82%)]\tLoss: 0.854686\n",
            "Train Epoch: 4 [3257/3978 (82%)]\tLoss: 0.000023\n",
            "Train Epoch: 4 [3258/3978 (82%)]\tLoss: 0.000604\n",
            "Train Epoch: 4 [3259/3978 (82%)]\tLoss: 4.189751\n",
            "Train Epoch: 4 [3260/3978 (82%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3261/3978 (82%)]\tLoss: 0.359282\n",
            "Train Epoch: 4 [3262/3978 (82%)]\tLoss: 5.118409\n",
            "Train Epoch: 4 [3263/3978 (82%)]\tLoss: 2.573122\n",
            "Train Epoch: 4 [3264/3978 (82%)]\tLoss: 1.130219\n",
            "Train Epoch: 4 [3265/3978 (82%)]\tLoss: 1.128795\n",
            "Train Epoch: 4 [3266/3978 (82%)]\tLoss: 4.805522\n",
            "Train Epoch: 4 [3267/3978 (82%)]\tLoss: 0.000119\n",
            "Train Epoch: 4 [3268/3978 (82%)]\tLoss: 0.579471\n",
            "Train Epoch: 4 [3269/3978 (82%)]\tLoss: 0.786316\n",
            "Train Epoch: 4 [3270/3978 (82%)]\tLoss: 0.005345\n",
            "Train Epoch: 4 [3271/3978 (82%)]\tLoss: 3.153295\n",
            "Train Epoch: 4 [3272/3978 (82%)]\tLoss: 1.407815\n",
            "Train Epoch: 4 [3273/3978 (82%)]\tLoss: 1.196612\n",
            "Train Epoch: 4 [3274/3978 (82%)]\tLoss: 0.750952\n",
            "Train Epoch: 4 [3275/3978 (82%)]\tLoss: 0.331670\n",
            "Train Epoch: 4 [3276/3978 (82%)]\tLoss: 0.209349\n",
            "Train Epoch: 4 [3277/3978 (82%)]\tLoss: 0.002831\n",
            "Train Epoch: 4 [3278/3978 (82%)]\tLoss: 0.001538\n",
            "Train Epoch: 4 [3279/3978 (82%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [3280/3978 (82%)]\tLoss: 1.354273\n",
            "Train Epoch: 4 [3281/3978 (82%)]\tLoss: 2.013906\n",
            "Train Epoch: 4 [3282/3978 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3283/3978 (83%)]\tLoss: 2.226922\n",
            "Train Epoch: 4 [3284/3978 (83%)]\tLoss: 2.427894\n",
            "Train Epoch: 4 [3285/3978 (83%)]\tLoss: 0.533771\n",
            "Train Epoch: 4 [3286/3978 (83%)]\tLoss: 2.397986\n",
            "Train Epoch: 4 [3287/3978 (83%)]\tLoss: 0.001350\n",
            "Train Epoch: 4 [3288/3978 (83%)]\tLoss: 2.102832\n",
            "Train Epoch: 4 [3289/3978 (83%)]\tLoss: 1.848757\n",
            "Train Epoch: 4 [3290/3978 (83%)]\tLoss: 1.466503\n",
            "Train Epoch: 4 [3291/3978 (83%)]\tLoss: 0.022435\n",
            "Train Epoch: 4 [3292/3978 (83%)]\tLoss: 2.225822\n",
            "Train Epoch: 4 [3293/3978 (83%)]\tLoss: 0.899019\n",
            "Train Epoch: 4 [3294/3978 (83%)]\tLoss: 1.083123\n",
            "Train Epoch: 4 [3295/3978 (83%)]\tLoss: 1.040259\n",
            "Train Epoch: 4 [3296/3978 (83%)]\tLoss: 7.360956\n",
            "Train Epoch: 4 [3297/3978 (83%)]\tLoss: 2.141551\n",
            "Train Epoch: 4 [3298/3978 (83%)]\tLoss: 1.265527\n",
            "Train Epoch: 4 [3299/3978 (83%)]\tLoss: 2.347535\n",
            "Train Epoch: 4 [3300/3978 (83%)]\tLoss: 0.859797\n",
            "Train Epoch: 4 [3301/3978 (83%)]\tLoss: 2.161850\n",
            "Train Epoch: 4 [3302/3978 (83%)]\tLoss: 0.013690\n",
            "Train Epoch: 4 [3303/3978 (83%)]\tLoss: 3.597536\n",
            "Train Epoch: 4 [3304/3978 (83%)]\tLoss: 0.000064\n",
            "Train Epoch: 4 [3305/3978 (83%)]\tLoss: 0.000218\n",
            "Train Epoch: 4 [3306/3978 (83%)]\tLoss: 0.000432\n",
            "Train Epoch: 4 [3307/3978 (83%)]\tLoss: 2.716906\n",
            "Train Epoch: 4 [3308/3978 (83%)]\tLoss: 1.698949\n",
            "Train Epoch: 4 [3309/3978 (83%)]\tLoss: 1.216088\n",
            "Train Epoch: 4 [3310/3978 (83%)]\tLoss: 1.735021\n",
            "Train Epoch: 4 [3311/3978 (83%)]\tLoss: 0.835619\n",
            "Train Epoch: 4 [3312/3978 (83%)]\tLoss: 2.377908\n",
            "Train Epoch: 4 [3313/3978 (83%)]\tLoss: 1.106538\n",
            "Train Epoch: 4 [3314/3978 (83%)]\tLoss: 5.262246\n",
            "Train Epoch: 4 [3315/3978 (83%)]\tLoss: 0.000152\n",
            "Train Epoch: 4 [3316/3978 (83%)]\tLoss: 1.877404\n",
            "Train Epoch: 4 [3317/3978 (83%)]\tLoss: 2.282549\n",
            "Train Epoch: 4 [3318/3978 (83%)]\tLoss: 0.976896\n",
            "Train Epoch: 4 [3319/3978 (83%)]\tLoss: 2.097971\n",
            "Train Epoch: 4 [3320/3978 (83%)]\tLoss: 1.146265\n",
            "Train Epoch: 4 [3321/3978 (83%)]\tLoss: 1.781085\n",
            "Train Epoch: 4 [3322/3978 (84%)]\tLoss: 2.168672\n",
            "Train Epoch: 4 [3323/3978 (84%)]\tLoss: 2.015104\n",
            "Train Epoch: 4 [3324/3978 (84%)]\tLoss: 0.779537\n",
            "Train Epoch: 4 [3325/3978 (84%)]\tLoss: 0.619162\n",
            "Train Epoch: 4 [3326/3978 (84%)]\tLoss: 0.292380\n",
            "Train Epoch: 4 [3327/3978 (84%)]\tLoss: 2.289601\n",
            "Train Epoch: 4 [3328/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3329/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3330/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3331/3978 (84%)]\tLoss: 2.233889\n",
            "Train Epoch: 4 [3332/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3333/3978 (84%)]\tLoss: 0.000078\n",
            "Train Epoch: 4 [3334/3978 (84%)]\tLoss: 1.722903\n",
            "Train Epoch: 4 [3335/3978 (84%)]\tLoss: 1.378160\n",
            "Train Epoch: 4 [3336/3978 (84%)]\tLoss: 2.432085\n",
            "Train Epoch: 4 [3337/3978 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3338/3978 (84%)]\tLoss: 0.008709\n",
            "Train Epoch: 4 [3339/3978 (84%)]\tLoss: 2.202868\n",
            "Train Epoch: 4 [3340/3978 (84%)]\tLoss: 0.962274\n",
            "Train Epoch: 4 [3341/3978 (84%)]\tLoss: 1.077281\n",
            "Train Epoch: 4 [3342/3978 (84%)]\tLoss: 4.215053\n",
            "Train Epoch: 4 [3343/3978 (84%)]\tLoss: 0.227273\n",
            "Train Epoch: 4 [3344/3978 (84%)]\tLoss: 0.601860\n",
            "Train Epoch: 4 [3345/3978 (84%)]\tLoss: 1.876964\n",
            "Train Epoch: 4 [3346/3978 (84%)]\tLoss: 0.093935\n",
            "Train Epoch: 4 [3347/3978 (84%)]\tLoss: 0.901045\n",
            "Train Epoch: 4 [3348/3978 (84%)]\tLoss: 0.000024\n",
            "Train Epoch: 4 [3349/3978 (84%)]\tLoss: 0.028049\n",
            "Train Epoch: 4 [3350/3978 (84%)]\tLoss: 0.544283\n",
            "Train Epoch: 4 [3351/3978 (84%)]\tLoss: 0.164452\n",
            "Train Epoch: 4 [3352/3978 (84%)]\tLoss: 0.000140\n",
            "Train Epoch: 4 [3353/3978 (84%)]\tLoss: 1.792271\n",
            "Train Epoch: 4 [3354/3978 (84%)]\tLoss: 4.351904\n",
            "Train Epoch: 4 [3355/3978 (84%)]\tLoss: 1.072084\n",
            "Train Epoch: 4 [3356/3978 (84%)]\tLoss: 0.000624\n",
            "Train Epoch: 4 [3357/3978 (84%)]\tLoss: 1.189416\n",
            "Train Epoch: 4 [3358/3978 (84%)]\tLoss: 1.141477\n",
            "Train Epoch: 4 [3359/3978 (84%)]\tLoss: 0.054742\n",
            "Train Epoch: 4 [3360/3978 (84%)]\tLoss: 0.295015\n",
            "Train Epoch: 4 [3361/3978 (84%)]\tLoss: 0.643817\n",
            "Train Epoch: 4 [3362/3978 (85%)]\tLoss: 0.002021\n",
            "Train Epoch: 4 [3363/3978 (85%)]\tLoss: 1.839699\n",
            "Train Epoch: 4 [3364/3978 (85%)]\tLoss: 4.703427\n",
            "Train Epoch: 4 [3365/3978 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3366/3978 (85%)]\tLoss: 3.095737\n",
            "Train Epoch: 4 [3367/3978 (85%)]\tLoss: 0.091662\n",
            "Train Epoch: 4 [3368/3978 (85%)]\tLoss: 2.668124\n",
            "Train Epoch: 4 [3369/3978 (85%)]\tLoss: 0.501240\n",
            "Train Epoch: 4 [3370/3978 (85%)]\tLoss: 1.975802\n",
            "Train Epoch: 4 [3371/3978 (85%)]\tLoss: 0.529157\n",
            "Train Epoch: 4 [3372/3978 (85%)]\tLoss: 0.905612\n",
            "Train Epoch: 4 [3373/3978 (85%)]\tLoss: 0.666169\n",
            "Train Epoch: 4 [3374/3978 (85%)]\tLoss: 0.864217\n",
            "Train Epoch: 4 [3375/3978 (85%)]\tLoss: 0.000007\n",
            "Train Epoch: 4 [3376/3978 (85%)]\tLoss: 1.994103\n",
            "Train Epoch: 4 [3377/3978 (85%)]\tLoss: 0.875304\n",
            "Train Epoch: 4 [3378/3978 (85%)]\tLoss: 1.255191\n",
            "Train Epoch: 4 [3379/3978 (85%)]\tLoss: 2.094172\n",
            "Train Epoch: 4 [3380/3978 (85%)]\tLoss: 0.984753\n",
            "Train Epoch: 4 [3381/3978 (85%)]\tLoss: 0.613422\n",
            "Train Epoch: 4 [3382/3978 (85%)]\tLoss: 0.841981\n",
            "Train Epoch: 4 [3383/3978 (85%)]\tLoss: 0.527762\n",
            "Train Epoch: 4 [3384/3978 (85%)]\tLoss: 0.488836\n",
            "Train Epoch: 4 [3385/3978 (85%)]\tLoss: 1.991173\n",
            "Train Epoch: 4 [3386/3978 (85%)]\tLoss: 0.879505\n",
            "Train Epoch: 4 [3387/3978 (85%)]\tLoss: 0.112736\n",
            "Train Epoch: 4 [3388/3978 (85%)]\tLoss: 1.010762\n",
            "Train Epoch: 4 [3389/3978 (85%)]\tLoss: 0.008856\n",
            "Train Epoch: 4 [3390/3978 (85%)]\tLoss: 0.000407\n",
            "Train Epoch: 4 [3391/3978 (85%)]\tLoss: 6.250208\n",
            "Train Epoch: 4 [3392/3978 (85%)]\tLoss: 1.076236\n",
            "Train Epoch: 4 [3393/3978 (85%)]\tLoss: 0.017164\n",
            "Train Epoch: 4 [3394/3978 (85%)]\tLoss: 0.115977\n",
            "Train Epoch: 4 [3395/3978 (85%)]\tLoss: 0.007538\n",
            "Train Epoch: 4 [3396/3978 (85%)]\tLoss: 0.013466\n",
            "Train Epoch: 4 [3397/3978 (85%)]\tLoss: 0.107931\n",
            "Train Epoch: 4 [3398/3978 (85%)]\tLoss: 1.302255\n",
            "Train Epoch: 4 [3399/3978 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3400/3978 (85%)]\tLoss: 1.387753\n",
            "Train Epoch: 4 [3401/3978 (85%)]\tLoss: 0.000566\n",
            "Train Epoch: 4 [3402/3978 (86%)]\tLoss: 1.850245\n",
            "Train Epoch: 4 [3403/3978 (86%)]\tLoss: 0.461171\n",
            "Train Epoch: 4 [3404/3978 (86%)]\tLoss: 0.009040\n",
            "Train Epoch: 4 [3405/3978 (86%)]\tLoss: 0.433103\n",
            "Train Epoch: 4 [3406/3978 (86%)]\tLoss: 0.613055\n",
            "Train Epoch: 4 [3407/3978 (86%)]\tLoss: 0.415948\n",
            "Train Epoch: 4 [3408/3978 (86%)]\tLoss: 1.246180\n",
            "Train Epoch: 4 [3409/3978 (86%)]\tLoss: 4.017825\n",
            "Train Epoch: 4 [3410/3978 (86%)]\tLoss: 0.001026\n",
            "Train Epoch: 4 [3411/3978 (86%)]\tLoss: 0.251256\n",
            "Train Epoch: 4 [3412/3978 (86%)]\tLoss: 0.998801\n",
            "Train Epoch: 4 [3413/3978 (86%)]\tLoss: 0.008141\n",
            "Train Epoch: 4 [3414/3978 (86%)]\tLoss: 0.000095\n",
            "Train Epoch: 4 [3415/3978 (86%)]\tLoss: 0.157490\n",
            "Train Epoch: 4 [3416/3978 (86%)]\tLoss: 0.166460\n",
            "Train Epoch: 4 [3417/3978 (86%)]\tLoss: 0.016619\n",
            "Train Epoch: 4 [3418/3978 (86%)]\tLoss: 0.726127\n",
            "Train Epoch: 4 [3419/3978 (86%)]\tLoss: 0.055955\n",
            "Train Epoch: 4 [3420/3978 (86%)]\tLoss: 0.014915\n",
            "Train Epoch: 4 [3421/3978 (86%)]\tLoss: 1.654733\n",
            "Train Epoch: 4 [3422/3978 (86%)]\tLoss: 0.000029\n",
            "Train Epoch: 4 [3423/3978 (86%)]\tLoss: 0.452756\n",
            "Train Epoch: 4 [3424/3978 (86%)]\tLoss: 0.568442\n",
            "Train Epoch: 4 [3425/3978 (86%)]\tLoss: 0.051736\n",
            "Train Epoch: 4 [3426/3978 (86%)]\tLoss: 5.125488\n",
            "Train Epoch: 4 [3427/3978 (86%)]\tLoss: 0.388431\n",
            "Train Epoch: 4 [3428/3978 (86%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3429/3978 (86%)]\tLoss: 2.061019\n",
            "Train Epoch: 4 [3430/3978 (86%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3431/3978 (86%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3432/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3433/3978 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3434/3978 (86%)]\tLoss: 1.761840\n",
            "Train Epoch: 4 [3435/3978 (86%)]\tLoss: 2.306076\n",
            "Train Epoch: 4 [3436/3978 (86%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [3437/3978 (86%)]\tLoss: 1.582890\n",
            "Train Epoch: 4 [3438/3978 (86%)]\tLoss: 1.051508\n",
            "Train Epoch: 4 [3439/3978 (86%)]\tLoss: 0.415536\n",
            "Train Epoch: 4 [3440/3978 (86%)]\tLoss: 0.975727\n",
            "Train Epoch: 4 [3441/3978 (87%)]\tLoss: 0.041408\n",
            "Train Epoch: 4 [3442/3978 (87%)]\tLoss: 0.290450\n",
            "Train Epoch: 4 [3443/3978 (87%)]\tLoss: 3.166623\n",
            "Train Epoch: 4 [3444/3978 (87%)]\tLoss: 2.164969\n",
            "Train Epoch: 4 [3445/3978 (87%)]\tLoss: 0.000261\n",
            "Train Epoch: 4 [3446/3978 (87%)]\tLoss: 0.000210\n",
            "Train Epoch: 4 [3447/3978 (87%)]\tLoss: 0.000049\n",
            "Train Epoch: 4 [3448/3978 (87%)]\tLoss: 0.449005\n",
            "Train Epoch: 4 [3449/3978 (87%)]\tLoss: 0.017311\n",
            "Train Epoch: 4 [3450/3978 (87%)]\tLoss: 0.620863\n",
            "Train Epoch: 4 [3451/3978 (87%)]\tLoss: 0.104462\n",
            "Train Epoch: 4 [3452/3978 (87%)]\tLoss: 0.473025\n",
            "Train Epoch: 4 [3453/3978 (87%)]\tLoss: 0.910757\n",
            "Train Epoch: 4 [3454/3978 (87%)]\tLoss: 0.161852\n",
            "Train Epoch: 4 [3455/3978 (87%)]\tLoss: 0.477290\n",
            "Train Epoch: 4 [3456/3978 (87%)]\tLoss: 2.495732\n",
            "Train Epoch: 4 [3457/3978 (87%)]\tLoss: 0.005269\n",
            "Train Epoch: 4 [3458/3978 (87%)]\tLoss: 1.285541\n",
            "Train Epoch: 4 [3459/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3460/3978 (87%)]\tLoss: 0.769918\n",
            "Train Epoch: 4 [3461/3978 (87%)]\tLoss: 0.080917\n",
            "Train Epoch: 4 [3462/3978 (87%)]\tLoss: 1.352326\n",
            "Train Epoch: 4 [3463/3978 (87%)]\tLoss: 0.464285\n",
            "Train Epoch: 4 [3464/3978 (87%)]\tLoss: 0.643873\n",
            "Train Epoch: 4 [3465/3978 (87%)]\tLoss: 0.122191\n",
            "Train Epoch: 4 [3466/3978 (87%)]\tLoss: 0.002099\n",
            "Train Epoch: 4 [3467/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3468/3978 (87%)]\tLoss: 1.039694\n",
            "Train Epoch: 4 [3469/3978 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3470/3978 (87%)]\tLoss: 2.312669\n",
            "Train Epoch: 4 [3471/3978 (87%)]\tLoss: 0.936324\n",
            "Train Epoch: 4 [3472/3978 (87%)]\tLoss: 7.753366\n",
            "Train Epoch: 4 [3473/3978 (87%)]\tLoss: 1.652640\n",
            "Train Epoch: 4 [3474/3978 (87%)]\tLoss: 0.707732\n",
            "Train Epoch: 4 [3475/3978 (87%)]\tLoss: 2.107955\n",
            "Train Epoch: 4 [3476/3978 (87%)]\tLoss: 0.000149\n",
            "Train Epoch: 4 [3477/3978 (87%)]\tLoss: 0.029131\n",
            "Train Epoch: 4 [3478/3978 (87%)]\tLoss: 1.732674\n",
            "Train Epoch: 4 [3479/3978 (87%)]\tLoss: 1.319425\n",
            "Train Epoch: 4 [3480/3978 (87%)]\tLoss: 1.886728\n",
            "Train Epoch: 4 [3481/3978 (88%)]\tLoss: 0.117601\n",
            "Train Epoch: 4 [3482/3978 (88%)]\tLoss: 1.490732\n",
            "Train Epoch: 4 [3483/3978 (88%)]\tLoss: 1.426630\n",
            "Train Epoch: 4 [3484/3978 (88%)]\tLoss: 1.283744\n",
            "Train Epoch: 4 [3485/3978 (88%)]\tLoss: 0.780618\n",
            "Train Epoch: 4 [3486/3978 (88%)]\tLoss: 0.185841\n",
            "Train Epoch: 4 [3487/3978 (88%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [3488/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3489/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3490/3978 (88%)]\tLoss: 5.316246\n",
            "Train Epoch: 4 [3491/3978 (88%)]\tLoss: 3.295697\n",
            "Train Epoch: 4 [3492/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3493/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3494/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3495/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3496/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3497/3978 (88%)]\tLoss: 3.725674\n",
            "Train Epoch: 4 [3498/3978 (88%)]\tLoss: 2.957189\n",
            "Train Epoch: 4 [3499/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3500/3978 (88%)]\tLoss: 2.312283\n",
            "Train Epoch: 4 [3501/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3502/3978 (88%)]\tLoss: 1.105104\n",
            "Train Epoch: 4 [3503/3978 (88%)]\tLoss: 0.002501\n",
            "Train Epoch: 4 [3504/3978 (88%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3505/3978 (88%)]\tLoss: 0.655904\n",
            "Train Epoch: 4 [3506/3978 (88%)]\tLoss: 0.000079\n",
            "Train Epoch: 4 [3507/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3508/3978 (88%)]\tLoss: 1.343498\n",
            "Train Epoch: 4 [3509/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3510/3978 (88%)]\tLoss: 0.180546\n",
            "Train Epoch: 4 [3511/3978 (88%)]\tLoss: 0.646335\n",
            "Train Epoch: 4 [3512/3978 (88%)]\tLoss: 0.449183\n",
            "Train Epoch: 4 [3513/3978 (88%)]\tLoss: 2.635960\n",
            "Train Epoch: 4 [3514/3978 (88%)]\tLoss: 0.000691\n",
            "Train Epoch: 4 [3515/3978 (88%)]\tLoss: 5.132782\n",
            "Train Epoch: 4 [3516/3978 (88%)]\tLoss: 1.253406\n",
            "Train Epoch: 4 [3517/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3518/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3519/3978 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3520/3978 (88%)]\tLoss: 2.584049\n",
            "Train Epoch: 4 [3521/3978 (89%)]\tLoss: 1.971007\n",
            "Train Epoch: 4 [3522/3978 (89%)]\tLoss: 1.279998\n",
            "Train Epoch: 4 [3523/3978 (89%)]\tLoss: 2.621552\n",
            "Train Epoch: 4 [3524/3978 (89%)]\tLoss: 0.542329\n",
            "Train Epoch: 4 [3525/3978 (89%)]\tLoss: 0.045065\n",
            "Train Epoch: 4 [3526/3978 (89%)]\tLoss: 1.309433\n",
            "Train Epoch: 4 [3527/3978 (89%)]\tLoss: 0.002842\n",
            "Train Epoch: 4 [3528/3978 (89%)]\tLoss: 0.000062\n",
            "Train Epoch: 4 [3529/3978 (89%)]\tLoss: 0.000013\n",
            "Train Epoch: 4 [3530/3978 (89%)]\tLoss: 0.000045\n",
            "Train Epoch: 4 [3531/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3532/3978 (89%)]\tLoss: 3.667724\n",
            "Train Epoch: 4 [3533/3978 (89%)]\tLoss: 2.746259\n",
            "Train Epoch: 4 [3534/3978 (89%)]\tLoss: 0.000102\n",
            "Train Epoch: 4 [3535/3978 (89%)]\tLoss: 3.920461\n",
            "Train Epoch: 4 [3536/3978 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3537/3978 (89%)]\tLoss: 3.887427\n",
            "Train Epoch: 4 [3538/3978 (89%)]\tLoss: 0.027304\n",
            "Train Epoch: 4 [3539/3978 (89%)]\tLoss: 0.199101\n",
            "Train Epoch: 4 [3540/3978 (89%)]\tLoss: 0.048426\n",
            "Train Epoch: 4 [3541/3978 (89%)]\tLoss: 1.796445\n",
            "Train Epoch: 4 [3542/3978 (89%)]\tLoss: 0.064179\n",
            "Train Epoch: 4 [3543/3978 (89%)]\tLoss: 1.646165\n",
            "Train Epoch: 4 [3544/3978 (89%)]\tLoss: 1.868818\n",
            "Train Epoch: 4 [3545/3978 (89%)]\tLoss: 0.915625\n",
            "Train Epoch: 4 [3546/3978 (89%)]\tLoss: 0.041546\n",
            "Train Epoch: 4 [3547/3978 (89%)]\tLoss: 0.318079\n",
            "Train Epoch: 4 [3548/3978 (89%)]\tLoss: 0.784465\n",
            "Train Epoch: 4 [3549/3978 (89%)]\tLoss: 0.407586\n",
            "Train Epoch: 4 [3550/3978 (89%)]\tLoss: 1.004310\n",
            "Train Epoch: 4 [3551/3978 (89%)]\tLoss: 0.281338\n",
            "Train Epoch: 4 [3552/3978 (89%)]\tLoss: 1.432843\n",
            "Train Epoch: 4 [3553/3978 (89%)]\tLoss: 1.334775\n",
            "Train Epoch: 4 [3554/3978 (89%)]\tLoss: 0.003416\n",
            "Train Epoch: 4 [3555/3978 (89%)]\tLoss: 0.030625\n",
            "Train Epoch: 4 [3556/3978 (89%)]\tLoss: 1.553241\n",
            "Train Epoch: 4 [3557/3978 (89%)]\tLoss: 0.553014\n",
            "Train Epoch: 4 [3558/3978 (89%)]\tLoss: 0.219621\n",
            "Train Epoch: 4 [3559/3978 (89%)]\tLoss: 3.453097\n",
            "Train Epoch: 4 [3560/3978 (89%)]\tLoss: 0.034972\n",
            "Train Epoch: 4 [3561/3978 (90%)]\tLoss: 0.429281\n",
            "Train Epoch: 4 [3562/3978 (90%)]\tLoss: 0.216566\n",
            "Train Epoch: 4 [3563/3978 (90%)]\tLoss: 0.025894\n",
            "Train Epoch: 4 [3564/3978 (90%)]\tLoss: 0.007312\n",
            "Train Epoch: 4 [3565/3978 (90%)]\tLoss: 0.146132\n",
            "Train Epoch: 4 [3566/3978 (90%)]\tLoss: 0.027722\n",
            "Train Epoch: 4 [3567/3978 (90%)]\tLoss: 0.000083\n",
            "Train Epoch: 4 [3568/3978 (90%)]\tLoss: 0.465872\n",
            "Train Epoch: 4 [3569/3978 (90%)]\tLoss: 0.566800\n",
            "Train Epoch: 4 [3570/3978 (90%)]\tLoss: 0.000306\n",
            "Train Epoch: 4 [3571/3978 (90%)]\tLoss: 0.095504\n",
            "Train Epoch: 4 [3572/3978 (90%)]\tLoss: 0.001177\n",
            "Train Epoch: 4 [3573/3978 (90%)]\tLoss: 0.000442\n",
            "Train Epoch: 4 [3574/3978 (90%)]\tLoss: 2.231160\n",
            "Train Epoch: 4 [3575/3978 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3576/3978 (90%)]\tLoss: 1.810166\n",
            "Train Epoch: 4 [3577/3978 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3578/3978 (90%)]\tLoss: 1.480295\n",
            "Train Epoch: 4 [3579/3978 (90%)]\tLoss: 0.219244\n",
            "Train Epoch: 4 [3580/3978 (90%)]\tLoss: 0.000043\n",
            "Train Epoch: 4 [3581/3978 (90%)]\tLoss: 0.000008\n",
            "Train Epoch: 4 [3582/3978 (90%)]\tLoss: 2.057752\n",
            "Train Epoch: 4 [3583/3978 (90%)]\tLoss: 0.119634\n",
            "Train Epoch: 4 [3584/3978 (90%)]\tLoss: 0.110922\n",
            "Train Epoch: 4 [3585/3978 (90%)]\tLoss: 0.123394\n",
            "Train Epoch: 4 [3586/3978 (90%)]\tLoss: 0.029713\n",
            "Train Epoch: 4 [3587/3978 (90%)]\tLoss: 1.115365\n",
            "Train Epoch: 4 [3588/3978 (90%)]\tLoss: 1.170458\n",
            "Train Epoch: 4 [3589/3978 (90%)]\tLoss: 0.529547\n",
            "Train Epoch: 4 [3590/3978 (90%)]\tLoss: 0.057605\n",
            "Train Epoch: 4 [3591/3978 (90%)]\tLoss: 0.000775\n",
            "Train Epoch: 4 [3592/3978 (90%)]\tLoss: 0.951467\n",
            "Train Epoch: 4 [3593/3978 (90%)]\tLoss: 0.761449\n",
            "Train Epoch: 4 [3594/3978 (90%)]\tLoss: 4.390977\n",
            "Train Epoch: 4 [3595/3978 (90%)]\tLoss: 2.693088\n",
            "Train Epoch: 4 [3596/3978 (90%)]\tLoss: 2.227415\n",
            "Train Epoch: 4 [3597/3978 (90%)]\tLoss: 2.176996\n",
            "Train Epoch: 4 [3598/3978 (90%)]\tLoss: 3.773303\n",
            "Train Epoch: 4 [3599/3978 (90%)]\tLoss: 0.594523\n",
            "Train Epoch: 4 [3600/3978 (90%)]\tLoss: 0.088180\n",
            "Train Epoch: 4 [3601/3978 (91%)]\tLoss: 0.043573\n",
            "Train Epoch: 4 [3602/3978 (91%)]\tLoss: 0.448039\n",
            "Train Epoch: 4 [3603/3978 (91%)]\tLoss: 0.998551\n",
            "Train Epoch: 4 [3604/3978 (91%)]\tLoss: 0.183730\n",
            "Train Epoch: 4 [3605/3978 (91%)]\tLoss: 0.022444\n",
            "Train Epoch: 4 [3606/3978 (91%)]\tLoss: 0.389885\n",
            "Train Epoch: 4 [3607/3978 (91%)]\tLoss: 4.567709\n",
            "Train Epoch: 4 [3608/3978 (91%)]\tLoss: 0.068338\n",
            "Train Epoch: 4 [3609/3978 (91%)]\tLoss: 0.001053\n",
            "Train Epoch: 4 [3610/3978 (91%)]\tLoss: 0.052943\n",
            "Train Epoch: 4 [3611/3978 (91%)]\tLoss: 0.320112\n",
            "Train Epoch: 4 [3612/3978 (91%)]\tLoss: 0.085937\n",
            "Train Epoch: 4 [3613/3978 (91%)]\tLoss: 0.099258\n",
            "Train Epoch: 4 [3614/3978 (91%)]\tLoss: 0.311988\n",
            "Train Epoch: 4 [3615/3978 (91%)]\tLoss: 5.095961\n",
            "Train Epoch: 4 [3616/3978 (91%)]\tLoss: 2.656293\n",
            "Train Epoch: 4 [3617/3978 (91%)]\tLoss: 0.134498\n",
            "Train Epoch: 4 [3618/3978 (91%)]\tLoss: 4.338112\n",
            "Train Epoch: 4 [3619/3978 (91%)]\tLoss: 0.000012\n",
            "Train Epoch: 4 [3620/3978 (91%)]\tLoss: 0.003161\n",
            "Train Epoch: 4 [3621/3978 (91%)]\tLoss: 3.313873\n",
            "Train Epoch: 4 [3622/3978 (91%)]\tLoss: 0.003399\n",
            "Train Epoch: 4 [3623/3978 (91%)]\tLoss: 1.534609\n",
            "Train Epoch: 4 [3624/3978 (91%)]\tLoss: 0.000222\n",
            "Train Epoch: 4 [3625/3978 (91%)]\tLoss: 0.748079\n",
            "Train Epoch: 4 [3626/3978 (91%)]\tLoss: 0.011244\n",
            "Train Epoch: 4 [3627/3978 (91%)]\tLoss: 0.362545\n",
            "Train Epoch: 4 [3628/3978 (91%)]\tLoss: 0.267631\n",
            "Train Epoch: 4 [3629/3978 (91%)]\tLoss: 1.283106\n",
            "Train Epoch: 4 [3630/3978 (91%)]\tLoss: 0.904526\n",
            "Train Epoch: 4 [3631/3978 (91%)]\tLoss: 1.071722\n",
            "Train Epoch: 4 [3632/3978 (91%)]\tLoss: 1.409549\n",
            "Train Epoch: 4 [3633/3978 (91%)]\tLoss: 1.090969\n",
            "Train Epoch: 4 [3634/3978 (91%)]\tLoss: 0.022834\n",
            "Train Epoch: 4 [3635/3978 (91%)]\tLoss: 0.025165\n",
            "Train Epoch: 4 [3636/3978 (91%)]\tLoss: 0.331554\n",
            "Train Epoch: 4 [3637/3978 (91%)]\tLoss: 0.044812\n",
            "Train Epoch: 4 [3638/3978 (91%)]\tLoss: 1.522884\n",
            "Train Epoch: 4 [3639/3978 (91%)]\tLoss: 1.799721\n",
            "Train Epoch: 4 [3640/3978 (92%)]\tLoss: 2.544734\n",
            "Train Epoch: 4 [3641/3978 (92%)]\tLoss: 0.958336\n",
            "Train Epoch: 4 [3642/3978 (92%)]\tLoss: 3.904245\n",
            "Train Epoch: 4 [3643/3978 (92%)]\tLoss: 1.642284\n",
            "Train Epoch: 4 [3644/3978 (92%)]\tLoss: 0.476776\n",
            "Train Epoch: 4 [3645/3978 (92%)]\tLoss: 0.389350\n",
            "Train Epoch: 4 [3646/3978 (92%)]\tLoss: 0.447881\n",
            "Train Epoch: 4 [3647/3978 (92%)]\tLoss: 0.485867\n",
            "Train Epoch: 4 [3648/3978 (92%)]\tLoss: 0.000915\n",
            "Train Epoch: 4 [3649/3978 (92%)]\tLoss: 0.393150\n",
            "Train Epoch: 4 [3650/3978 (92%)]\tLoss: 2.219877\n",
            "Train Epoch: 4 [3651/3978 (92%)]\tLoss: 1.090162\n",
            "Train Epoch: 4 [3652/3978 (92%)]\tLoss: 0.090158\n",
            "Train Epoch: 4 [3653/3978 (92%)]\tLoss: 1.140875\n",
            "Train Epoch: 4 [3654/3978 (92%)]\tLoss: 1.204657\n",
            "Train Epoch: 4 [3655/3978 (92%)]\tLoss: 0.333503\n",
            "Train Epoch: 4 [3656/3978 (92%)]\tLoss: 0.381601\n",
            "Train Epoch: 4 [3657/3978 (92%)]\tLoss: 0.008350\n",
            "Train Epoch: 4 [3658/3978 (92%)]\tLoss: 0.002300\n",
            "Train Epoch: 4 [3659/3978 (92%)]\tLoss: 0.010759\n",
            "Train Epoch: 4 [3660/3978 (92%)]\tLoss: 0.000225\n",
            "Train Epoch: 4 [3661/3978 (92%)]\tLoss: 0.811556\n",
            "Train Epoch: 4 [3662/3978 (92%)]\tLoss: 1.836009\n",
            "Train Epoch: 4 [3663/3978 (92%)]\tLoss: 0.402986\n",
            "Train Epoch: 4 [3664/3978 (92%)]\tLoss: 0.967993\n",
            "Train Epoch: 4 [3665/3978 (92%)]\tLoss: 2.083504\n",
            "Train Epoch: 4 [3666/3978 (92%)]\tLoss: 0.001112\n",
            "Train Epoch: 4 [3667/3978 (92%)]\tLoss: 0.000403\n",
            "Train Epoch: 4 [3668/3978 (92%)]\tLoss: 3.614510\n",
            "Train Epoch: 4 [3669/3978 (92%)]\tLoss: 0.248653\n",
            "Train Epoch: 4 [3670/3978 (92%)]\tLoss: 0.066718\n",
            "Train Epoch: 4 [3671/3978 (92%)]\tLoss: 0.529208\n",
            "Train Epoch: 4 [3672/3978 (92%)]\tLoss: 0.419257\n",
            "Train Epoch: 4 [3673/3978 (92%)]\tLoss: 1.936679\n",
            "Train Epoch: 4 [3674/3978 (92%)]\tLoss: 0.132518\n",
            "Train Epoch: 4 [3675/3978 (92%)]\tLoss: 0.004756\n",
            "Train Epoch: 4 [3676/3978 (92%)]\tLoss: 1.687727\n",
            "Train Epoch: 4 [3677/3978 (92%)]\tLoss: 2.662272\n",
            "Train Epoch: 4 [3678/3978 (92%)]\tLoss: 1.031196\n",
            "Train Epoch: 4 [3679/3978 (92%)]\tLoss: 0.116664\n",
            "Train Epoch: 4 [3680/3978 (93%)]\tLoss: 0.143084\n",
            "Train Epoch: 4 [3681/3978 (93%)]\tLoss: 0.003005\n",
            "Train Epoch: 4 [3682/3978 (93%)]\tLoss: 0.000044\n",
            "Train Epoch: 4 [3683/3978 (93%)]\tLoss: 6.143606\n",
            "Train Epoch: 4 [3684/3978 (93%)]\tLoss: 1.212335\n",
            "Train Epoch: 4 [3685/3978 (93%)]\tLoss: 0.001400\n",
            "Train Epoch: 4 [3686/3978 (93%)]\tLoss: 1.853927\n",
            "Train Epoch: 4 [3687/3978 (93%)]\tLoss: 1.450183\n",
            "Train Epoch: 4 [3688/3978 (93%)]\tLoss: 0.377560\n",
            "Train Epoch: 4 [3689/3978 (93%)]\tLoss: 0.000144\n",
            "Train Epoch: 4 [3690/3978 (93%)]\tLoss: 0.995903\n",
            "Train Epoch: 4 [3691/3978 (93%)]\tLoss: 0.644335\n",
            "Train Epoch: 4 [3692/3978 (93%)]\tLoss: 0.088085\n",
            "Train Epoch: 4 [3693/3978 (93%)]\tLoss: 0.077031\n",
            "Train Epoch: 4 [3694/3978 (93%)]\tLoss: 0.009680\n",
            "Train Epoch: 4 [3695/3978 (93%)]\tLoss: 0.261898\n",
            "Train Epoch: 4 [3696/3978 (93%)]\tLoss: 6.783166\n",
            "Train Epoch: 4 [3697/3978 (93%)]\tLoss: 0.424070\n",
            "Train Epoch: 4 [3698/3978 (93%)]\tLoss: 0.291086\n",
            "Train Epoch: 4 [3699/3978 (93%)]\tLoss: 0.578397\n",
            "Train Epoch: 4 [3700/3978 (93%)]\tLoss: 0.004528\n",
            "Train Epoch: 4 [3701/3978 (93%)]\tLoss: 0.000003\n",
            "Train Epoch: 4 [3702/3978 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3703/3978 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3704/3978 (93%)]\tLoss: 1.636332\n",
            "Train Epoch: 4 [3705/3978 (93%)]\tLoss: 1.480569\n",
            "Train Epoch: 4 [3706/3978 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3707/3978 (93%)]\tLoss: 4.417515\n",
            "Train Epoch: 4 [3708/3978 (93%)]\tLoss: 0.342401\n",
            "Train Epoch: 4 [3709/3978 (93%)]\tLoss: 0.059335\n",
            "Train Epoch: 4 [3710/3978 (93%)]\tLoss: 0.002654\n",
            "Train Epoch: 4 [3711/3978 (93%)]\tLoss: 0.033536\n",
            "Train Epoch: 4 [3712/3978 (93%)]\tLoss: 0.000014\n",
            "Train Epoch: 4 [3713/3978 (93%)]\tLoss: 0.574298\n",
            "Train Epoch: 4 [3714/3978 (93%)]\tLoss: 0.692055\n",
            "Train Epoch: 4 [3715/3978 (93%)]\tLoss: 1.038426\n",
            "Train Epoch: 4 [3716/3978 (93%)]\tLoss: 0.000104\n",
            "Train Epoch: 4 [3717/3978 (93%)]\tLoss: 0.660857\n",
            "Train Epoch: 4 [3718/3978 (93%)]\tLoss: 0.041636\n",
            "Train Epoch: 4 [3719/3978 (93%)]\tLoss: 0.150448\n",
            "Train Epoch: 4 [3720/3978 (94%)]\tLoss: 0.021775\n",
            "Train Epoch: 4 [3721/3978 (94%)]\tLoss: 0.003006\n",
            "Train Epoch: 4 [3722/3978 (94%)]\tLoss: 0.363265\n",
            "Train Epoch: 4 [3723/3978 (94%)]\tLoss: 0.269547\n",
            "Train Epoch: 4 [3724/3978 (94%)]\tLoss: 0.212822\n",
            "Train Epoch: 4 [3725/3978 (94%)]\tLoss: 0.031582\n",
            "Train Epoch: 4 [3726/3978 (94%)]\tLoss: 0.013713\n",
            "Train Epoch: 4 [3727/3978 (94%)]\tLoss: 0.518105\n",
            "Train Epoch: 4 [3728/3978 (94%)]\tLoss: 0.008268\n",
            "Train Epoch: 4 [3729/3978 (94%)]\tLoss: 0.027684\n",
            "Train Epoch: 4 [3730/3978 (94%)]\tLoss: 0.003146\n",
            "Train Epoch: 4 [3731/3978 (94%)]\tLoss: 0.256670\n",
            "Train Epoch: 4 [3732/3978 (94%)]\tLoss: 0.322336\n",
            "Train Epoch: 4 [3733/3978 (94%)]\tLoss: 0.627283\n",
            "Train Epoch: 4 [3734/3978 (94%)]\tLoss: 0.687068\n",
            "Train Epoch: 4 [3735/3978 (94%)]\tLoss: 0.350378\n",
            "Train Epoch: 4 [3736/3978 (94%)]\tLoss: 1.047586\n",
            "Train Epoch: 4 [3737/3978 (94%)]\tLoss: 0.739507\n",
            "Train Epoch: 4 [3738/3978 (94%)]\tLoss: 0.000018\n",
            "Train Epoch: 4 [3739/3978 (94%)]\tLoss: 1.862038\n",
            "Train Epoch: 4 [3740/3978 (94%)]\tLoss: 1.311543\n",
            "Train Epoch: 4 [3741/3978 (94%)]\tLoss: 1.743410\n",
            "Train Epoch: 4 [3742/3978 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3743/3978 (94%)]\tLoss: 0.998705\n",
            "Train Epoch: 4 [3744/3978 (94%)]\tLoss: 0.548695\n",
            "Train Epoch: 4 [3745/3978 (94%)]\tLoss: 0.289004\n",
            "Train Epoch: 4 [3746/3978 (94%)]\tLoss: 0.004498\n",
            "Train Epoch: 4 [3747/3978 (94%)]\tLoss: 3.590221\n",
            "Train Epoch: 4 [3748/3978 (94%)]\tLoss: 1.638583\n",
            "Train Epoch: 4 [3749/3978 (94%)]\tLoss: 1.195379\n",
            "Train Epoch: 4 [3750/3978 (94%)]\tLoss: 0.000242\n",
            "Train Epoch: 4 [3751/3978 (94%)]\tLoss: 2.841511\n",
            "Train Epoch: 4 [3752/3978 (94%)]\tLoss: 4.592175\n",
            "Train Epoch: 4 [3753/3978 (94%)]\tLoss: 1.870309\n",
            "Train Epoch: 4 [3754/3978 (94%)]\tLoss: 0.001548\n",
            "Train Epoch: 4 [3755/3978 (94%)]\tLoss: 0.066780\n",
            "Train Epoch: 4 [3756/3978 (94%)]\tLoss: 2.973963\n",
            "Train Epoch: 4 [3757/3978 (94%)]\tLoss: 0.895917\n",
            "Train Epoch: 4 [3758/3978 (94%)]\tLoss: 0.229401\n",
            "Train Epoch: 4 [3759/3978 (94%)]\tLoss: 0.168846\n",
            "Train Epoch: 4 [3760/3978 (95%)]\tLoss: 0.698787\n",
            "Train Epoch: 4 [3761/3978 (95%)]\tLoss: 0.125173\n",
            "Train Epoch: 4 [3762/3978 (95%)]\tLoss: 0.003893\n",
            "Train Epoch: 4 [3763/3978 (95%)]\tLoss: 0.447810\n",
            "Train Epoch: 4 [3764/3978 (95%)]\tLoss: 2.996544\n",
            "Train Epoch: 4 [3765/3978 (95%)]\tLoss: 2.185450\n",
            "Train Epoch: 4 [3766/3978 (95%)]\tLoss: 0.662768\n",
            "Train Epoch: 4 [3767/3978 (95%)]\tLoss: 1.624498\n",
            "Train Epoch: 4 [3768/3978 (95%)]\tLoss: 0.256262\n",
            "Train Epoch: 4 [3769/3978 (95%)]\tLoss: 0.528750\n",
            "Train Epoch: 4 [3770/3978 (95%)]\tLoss: 0.031480\n",
            "Train Epoch: 4 [3771/3978 (95%)]\tLoss: 1.140811\n",
            "Train Epoch: 4 [3772/3978 (95%)]\tLoss: 0.758494\n",
            "Train Epoch: 4 [3773/3978 (95%)]\tLoss: 1.721929\n",
            "Train Epoch: 4 [3774/3978 (95%)]\tLoss: 0.386542\n",
            "Train Epoch: 4 [3775/3978 (95%)]\tLoss: 0.114469\n",
            "Train Epoch: 4 [3776/3978 (95%)]\tLoss: 0.406855\n",
            "Train Epoch: 4 [3777/3978 (95%)]\tLoss: 0.270903\n",
            "Train Epoch: 4 [3778/3978 (95%)]\tLoss: 0.062801\n",
            "Train Epoch: 4 [3779/3978 (95%)]\tLoss: 0.868926\n",
            "Train Epoch: 4 [3780/3978 (95%)]\tLoss: 0.193112\n",
            "Train Epoch: 4 [3781/3978 (95%)]\tLoss: 0.010117\n",
            "Train Epoch: 4 [3782/3978 (95%)]\tLoss: 0.528895\n",
            "Train Epoch: 4 [3783/3978 (95%)]\tLoss: 0.014258\n",
            "Train Epoch: 4 [3784/3978 (95%)]\tLoss: 0.209388\n",
            "Train Epoch: 4 [3785/3978 (95%)]\tLoss: 0.000069\n",
            "Train Epoch: 4 [3786/3978 (95%)]\tLoss: 2.876473\n",
            "Train Epoch: 4 [3787/3978 (95%)]\tLoss: 1.836869\n",
            "Train Epoch: 4 [3788/3978 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3789/3978 (95%)]\tLoss: 3.086484\n",
            "Train Epoch: 4 [3790/3978 (95%)]\tLoss: 1.525710\n",
            "Train Epoch: 4 [3791/3978 (95%)]\tLoss: 0.712827\n",
            "Train Epoch: 4 [3792/3978 (95%)]\tLoss: 0.511214\n",
            "Train Epoch: 4 [3793/3978 (95%)]\tLoss: 0.744190\n",
            "Train Epoch: 4 [3794/3978 (95%)]\tLoss: 1.143329\n",
            "Train Epoch: 4 [3795/3978 (95%)]\tLoss: 0.835595\n",
            "Train Epoch: 4 [3796/3978 (95%)]\tLoss: 0.000021\n",
            "Train Epoch: 4 [3797/3978 (95%)]\tLoss: 0.003755\n",
            "Train Epoch: 4 [3798/3978 (95%)]\tLoss: 1.571415\n",
            "Train Epoch: 4 [3799/3978 (96%)]\tLoss: 1.127083\n",
            "Train Epoch: 4 [3800/3978 (96%)]\tLoss: 2.015725\n",
            "Train Epoch: 4 [3801/3978 (96%)]\tLoss: 1.782424\n",
            "Train Epoch: 4 [3802/3978 (96%)]\tLoss: 0.019096\n",
            "Train Epoch: 4 [3803/3978 (96%)]\tLoss: 0.462363\n",
            "Train Epoch: 4 [3804/3978 (96%)]\tLoss: 0.027797\n",
            "Train Epoch: 4 [3805/3978 (96%)]\tLoss: 1.050652\n",
            "Train Epoch: 4 [3806/3978 (96%)]\tLoss: 1.276173\n",
            "Train Epoch: 4 [3807/3978 (96%)]\tLoss: 0.747703\n",
            "Train Epoch: 4 [3808/3978 (96%)]\tLoss: 1.063730\n",
            "Train Epoch: 4 [3809/3978 (96%)]\tLoss: 0.055770\n",
            "Train Epoch: 4 [3810/3978 (96%)]\tLoss: 0.059091\n",
            "Train Epoch: 4 [3811/3978 (96%)]\tLoss: 0.849288\n",
            "Train Epoch: 4 [3812/3978 (96%)]\tLoss: 0.402305\n",
            "Train Epoch: 4 [3813/3978 (96%)]\tLoss: 0.433759\n",
            "Train Epoch: 4 [3814/3978 (96%)]\tLoss: 0.852348\n",
            "Train Epoch: 4 [3815/3978 (96%)]\tLoss: 0.004703\n",
            "Train Epoch: 4 [3816/3978 (96%)]\tLoss: 1.822543\n",
            "Train Epoch: 4 [3817/3978 (96%)]\tLoss: 2.068655\n",
            "Train Epoch: 4 [3818/3978 (96%)]\tLoss: 1.907425\n",
            "Train Epoch: 4 [3819/3978 (96%)]\tLoss: 1.530411\n",
            "Train Epoch: 4 [3820/3978 (96%)]\tLoss: 0.081593\n",
            "Train Epoch: 4 [3821/3978 (96%)]\tLoss: 0.211648\n",
            "Train Epoch: 4 [3822/3978 (96%)]\tLoss: 0.931199\n",
            "Train Epoch: 4 [3823/3978 (96%)]\tLoss: 1.447676\n",
            "Train Epoch: 4 [3824/3978 (96%)]\tLoss: 1.570194\n",
            "Train Epoch: 4 [3825/3978 (96%)]\tLoss: 0.007454\n",
            "Train Epoch: 4 [3826/3978 (96%)]\tLoss: 0.066204\n",
            "Train Epoch: 4 [3827/3978 (96%)]\tLoss: 1.348150\n",
            "Train Epoch: 4 [3828/3978 (96%)]\tLoss: 0.189947\n",
            "Train Epoch: 4 [3829/3978 (96%)]\tLoss: 0.403307\n",
            "Train Epoch: 4 [3830/3978 (96%)]\tLoss: 2.171912\n",
            "Train Epoch: 4 [3831/3978 (96%)]\tLoss: 0.001949\n",
            "Train Epoch: 4 [3832/3978 (96%)]\tLoss: 0.538410\n",
            "Train Epoch: 4 [3833/3978 (96%)]\tLoss: 0.111761\n",
            "Train Epoch: 4 [3834/3978 (96%)]\tLoss: 0.364802\n",
            "Train Epoch: 4 [3835/3978 (96%)]\tLoss: 0.321588\n",
            "Train Epoch: 4 [3836/3978 (96%)]\tLoss: 1.004646\n",
            "Train Epoch: 4 [3837/3978 (96%)]\tLoss: 0.000028\n",
            "Train Epoch: 4 [3838/3978 (96%)]\tLoss: 3.716905\n",
            "Train Epoch: 4 [3839/3978 (97%)]\tLoss: 0.573296\n",
            "Train Epoch: 4 [3840/3978 (97%)]\tLoss: 0.401764\n",
            "Train Epoch: 4 [3841/3978 (97%)]\tLoss: 0.428135\n",
            "Train Epoch: 4 [3842/3978 (97%)]\tLoss: 0.019962\n",
            "Train Epoch: 4 [3843/3978 (97%)]\tLoss: 1.125727\n",
            "Train Epoch: 4 [3844/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3845/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3846/3978 (97%)]\tLoss: 0.000034\n",
            "Train Epoch: 4 [3847/3978 (97%)]\tLoss: 2.512513\n",
            "Train Epoch: 4 [3848/3978 (97%)]\tLoss: 2.236547\n",
            "Train Epoch: 4 [3849/3978 (97%)]\tLoss: 2.076502\n",
            "Train Epoch: 4 [3850/3978 (97%)]\tLoss: 4.277712\n",
            "Train Epoch: 4 [3851/3978 (97%)]\tLoss: 0.000652\n",
            "Train Epoch: 4 [3852/3978 (97%)]\tLoss: 0.006541\n",
            "Train Epoch: 4 [3853/3978 (97%)]\tLoss: 0.738856\n",
            "Train Epoch: 4 [3854/3978 (97%)]\tLoss: 0.168911\n",
            "Train Epoch: 4 [3855/3978 (97%)]\tLoss: 0.073516\n",
            "Train Epoch: 4 [3856/3978 (97%)]\tLoss: 0.121734\n",
            "Train Epoch: 4 [3857/3978 (97%)]\tLoss: 0.000020\n",
            "Train Epoch: 4 [3858/3978 (97%)]\tLoss: 0.366079\n",
            "Train Epoch: 4 [3859/3978 (97%)]\tLoss: 1.267406\n",
            "Train Epoch: 4 [3860/3978 (97%)]\tLoss: 0.000002\n",
            "Train Epoch: 4 [3861/3978 (97%)]\tLoss: 0.202373\n",
            "Train Epoch: 4 [3862/3978 (97%)]\tLoss: 0.144074\n",
            "Train Epoch: 4 [3863/3978 (97%)]\tLoss: 1.012852\n",
            "Train Epoch: 4 [3864/3978 (97%)]\tLoss: 1.362947\n",
            "Train Epoch: 4 [3865/3978 (97%)]\tLoss: 0.000764\n",
            "Train Epoch: 4 [3866/3978 (97%)]\tLoss: 0.378312\n",
            "Train Epoch: 4 [3867/3978 (97%)]\tLoss: 0.001956\n",
            "Train Epoch: 4 [3868/3978 (97%)]\tLoss: 2.740404\n",
            "Train Epoch: 4 [3869/3978 (97%)]\tLoss: 0.000573\n",
            "Train Epoch: 4 [3870/3978 (97%)]\tLoss: 0.000006\n",
            "Train Epoch: 4 [3871/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3872/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3873/3978 (97%)]\tLoss: 3.613560\n",
            "Train Epoch: 4 [3874/3978 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3875/3978 (97%)]\tLoss: 1.694467\n",
            "Train Epoch: 4 [3876/3978 (97%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [3877/3978 (97%)]\tLoss: 1.588210\n",
            "Train Epoch: 4 [3878/3978 (97%)]\tLoss: 0.009510\n",
            "Train Epoch: 4 [3879/3978 (98%)]\tLoss: 0.000594\n",
            "Train Epoch: 4 [3880/3978 (98%)]\tLoss: 0.061764\n",
            "Train Epoch: 4 [3881/3978 (98%)]\tLoss: 0.165060\n",
            "Train Epoch: 4 [3882/3978 (98%)]\tLoss: 2.816567\n",
            "Train Epoch: 4 [3883/3978 (98%)]\tLoss: 0.503419\n",
            "Train Epoch: 4 [3884/3978 (98%)]\tLoss: 0.375685\n",
            "Train Epoch: 4 [3885/3978 (98%)]\tLoss: 0.180052\n",
            "Train Epoch: 4 [3886/3978 (98%)]\tLoss: 0.300756\n",
            "Train Epoch: 4 [3887/3978 (98%)]\tLoss: 0.053500\n",
            "Train Epoch: 4 [3888/3978 (98%)]\tLoss: 0.156184\n",
            "Train Epoch: 4 [3889/3978 (98%)]\tLoss: 0.339838\n",
            "Train Epoch: 4 [3890/3978 (98%)]\tLoss: 0.001554\n",
            "Train Epoch: 4 [3891/3978 (98%)]\tLoss: 1.512494\n",
            "Train Epoch: 4 [3892/3978 (98%)]\tLoss: 0.000005\n",
            "Train Epoch: 4 [3893/3978 (98%)]\tLoss: 2.360071\n",
            "Train Epoch: 4 [3894/3978 (98%)]\tLoss: 1.732221\n",
            "Train Epoch: 4 [3895/3978 (98%)]\tLoss: 0.000765\n",
            "Train Epoch: 4 [3896/3978 (98%)]\tLoss: 0.214010\n",
            "Train Epoch: 4 [3897/3978 (98%)]\tLoss: 0.937378\n",
            "Train Epoch: 4 [3898/3978 (98%)]\tLoss: 0.043963\n",
            "Train Epoch: 4 [3899/3978 (98%)]\tLoss: 0.538301\n",
            "Train Epoch: 4 [3900/3978 (98%)]\tLoss: 2.062865\n",
            "Train Epoch: 4 [3901/3978 (98%)]\tLoss: 0.722177\n",
            "Train Epoch: 4 [3902/3978 (98%)]\tLoss: 0.835802\n",
            "Train Epoch: 4 [3903/3978 (98%)]\tLoss: 1.246810\n",
            "Train Epoch: 4 [3904/3978 (98%)]\tLoss: 0.187874\n",
            "Train Epoch: 4 [3905/3978 (98%)]\tLoss: 0.017611\n",
            "Train Epoch: 4 [3906/3978 (98%)]\tLoss: 0.001266\n",
            "Train Epoch: 4 [3907/3978 (98%)]\tLoss: 0.791593\n",
            "Train Epoch: 4 [3908/3978 (98%)]\tLoss: 1.670508\n",
            "Train Epoch: 4 [3909/3978 (98%)]\tLoss: 2.369641\n",
            "Train Epoch: 4 [3910/3978 (98%)]\tLoss: 2.739801\n",
            "Train Epoch: 4 [3911/3978 (98%)]\tLoss: 0.022594\n",
            "Train Epoch: 4 [3912/3978 (98%)]\tLoss: 0.002114\n",
            "Train Epoch: 4 [3913/3978 (98%)]\tLoss: 2.319294\n",
            "Train Epoch: 4 [3914/3978 (98%)]\tLoss: 0.544059\n",
            "Train Epoch: 4 [3915/3978 (98%)]\tLoss: 0.067154\n",
            "Train Epoch: 4 [3916/3978 (98%)]\tLoss: 0.607326\n",
            "Train Epoch: 4 [3917/3978 (98%)]\tLoss: 0.004536\n",
            "Train Epoch: 4 [3918/3978 (98%)]\tLoss: 0.634604\n",
            "Train Epoch: 4 [3919/3978 (99%)]\tLoss: 0.091566\n",
            "Train Epoch: 4 [3920/3978 (99%)]\tLoss: 1.594554\n",
            "Train Epoch: 4 [3921/3978 (99%)]\tLoss: 0.447122\n",
            "Train Epoch: 4 [3922/3978 (99%)]\tLoss: 0.101228\n",
            "Train Epoch: 4 [3923/3978 (99%)]\tLoss: 0.045237\n",
            "Train Epoch: 4 [3924/3978 (99%)]\tLoss: 1.530641\n",
            "Train Epoch: 4 [3925/3978 (99%)]\tLoss: 0.001931\n",
            "Train Epoch: 4 [3926/3978 (99%)]\tLoss: 0.000627\n",
            "Train Epoch: 4 [3927/3978 (99%)]\tLoss: 0.000455\n",
            "Train Epoch: 4 [3928/3978 (99%)]\tLoss: 1.737790\n",
            "Train Epoch: 4 [3929/3978 (99%)]\tLoss: 2.177363\n",
            "Train Epoch: 4 [3930/3978 (99%)]\tLoss: 1.064431\n",
            "Train Epoch: 4 [3931/3978 (99%)]\tLoss: 1.089570\n",
            "Train Epoch: 4 [3932/3978 (99%)]\tLoss: 0.005923\n",
            "Train Epoch: 4 [3933/3978 (99%)]\tLoss: 1.763171\n",
            "Train Epoch: 4 [3934/3978 (99%)]\tLoss: 0.588393\n",
            "Train Epoch: 4 [3935/3978 (99%)]\tLoss: 0.537398\n",
            "Train Epoch: 4 [3936/3978 (99%)]\tLoss: 0.053259\n",
            "Train Epoch: 4 [3937/3978 (99%)]\tLoss: 0.153712\n",
            "Train Epoch: 4 [3938/3978 (99%)]\tLoss: 0.001656\n",
            "Train Epoch: 4 [3939/3978 (99%)]\tLoss: 0.948220\n",
            "Train Epoch: 4 [3940/3978 (99%)]\tLoss: 0.014228\n",
            "Train Epoch: 4 [3941/3978 (99%)]\tLoss: 1.154922\n",
            "Train Epoch: 4 [3942/3978 (99%)]\tLoss: 2.418344\n",
            "Train Epoch: 4 [3943/3978 (99%)]\tLoss: 0.163595\n",
            "Train Epoch: 4 [3944/3978 (99%)]\tLoss: 0.254809\n",
            "Train Epoch: 4 [3945/3978 (99%)]\tLoss: 0.193560\n",
            "Train Epoch: 4 [3946/3978 (99%)]\tLoss: 3.579117\n",
            "Train Epoch: 4 [3947/3978 (99%)]\tLoss: 3.723315\n",
            "Train Epoch: 4 [3948/3978 (99%)]\tLoss: 1.339746\n",
            "Train Epoch: 4 [3949/3978 (99%)]\tLoss: 2.386746\n",
            "Train Epoch: 4 [3950/3978 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [3951/3978 (99%)]\tLoss: 0.100643\n",
            "Train Epoch: 4 [3952/3978 (99%)]\tLoss: 0.026534\n",
            "Train Epoch: 4 [3953/3978 (99%)]\tLoss: 0.869973\n",
            "Train Epoch: 4 [3954/3978 (99%)]\tLoss: 0.004761\n",
            "Train Epoch: 4 [3955/3978 (99%)]\tLoss: 0.064283\n",
            "Train Epoch: 4 [3956/3978 (99%)]\tLoss: 0.330425\n",
            "Train Epoch: 4 [3957/3978 (99%)]\tLoss: 0.346472\n",
            "Train Epoch: 4 [3958/3978 (99%)]\tLoss: 0.659594\n",
            "Train Epoch: 4 [3959/3978 (100%)]\tLoss: 0.873233\n",
            "Train Epoch: 4 [3960/3978 (100%)]\tLoss: 0.115374\n",
            "Train Epoch: 4 [3961/3978 (100%)]\tLoss: 0.389293\n",
            "Train Epoch: 4 [3962/3978 (100%)]\tLoss: 0.000127\n",
            "Train Epoch: 4 [3963/3978 (100%)]\tLoss: 5.103285\n",
            "Train Epoch: 4 [3964/3978 (100%)]\tLoss: 0.418046\n",
            "Train Epoch: 4 [3965/3978 (100%)]\tLoss: 0.000380\n",
            "Train Epoch: 4 [3966/3978 (100%)]\tLoss: 0.001307\n",
            "Train Epoch: 4 [3967/3978 (100%)]\tLoss: 3.307739\n",
            "Train Epoch: 4 [3968/3978 (100%)]\tLoss: 0.000347\n",
            "Train Epoch: 4 [3969/3978 (100%)]\tLoss: 2.205120\n",
            "Train Epoch: 4 [3970/3978 (100%)]\tLoss: 0.729466\n",
            "Train Epoch: 4 [3971/3978 (100%)]\tLoss: 2.388103\n",
            "Train Epoch: 4 [3972/3978 (100%)]\tLoss: 0.618870\n",
            "Train Epoch: 4 [3973/3978 (100%)]\tLoss: 0.102466\n",
            "Train Epoch: 4 [3974/3978 (100%)]\tLoss: 0.814990\n",
            "Train Epoch: 4 [3975/3978 (100%)]\tLoss: 0.026441\n",
            "Train Epoch: 4 [3976/3978 (100%)]\tLoss: 0.133593\n",
            "Train Epoch: 4 [3977/3978 (100%)]\tLoss: 1.360970\n",
            "Epoch\n",
            "train/train_loss: 1.3609697818756104\n",
            "\n",
            "Train Loss: 1.361, Valid Loss: 0.739563, Accuracy: 0.36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='405.963 MB of 405.963 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "594cbd9216664d31a708dfeefb371fa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train/loss</td><td>▁▁▁▁▁▁▂█▄▁▅▁▃▄▁▂▃▃▁▁▁▁▁▁▁▁▁▁▂▃▁▁▂▃▁▂▁▃▁▃</td></tr><tr><td>validation/accuracy</td><td>▁█▁██</td></tr><tr><td>validation/loss</td><td>▂▂█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/loss</td><td>1.36097</td></tr><tr><td>validation/accuracy</td><td>0.36494</td></tr><tr><td>validation/loss</td><td>0.73956</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">likely-sweep-3</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/tywfuxmo' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/tywfuxmo</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240829_181728-tywfuxmo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: usll2fd7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240829_185733-usll2fd7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/usll2fd7' target=\"_blank\">dry-sweep-4</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/usll2fd7' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/usll2fd7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/3978 (0%)]\tLoss: 0.522164\n",
            "Train Epoch: 0 [5/3978 (0%)]\tLoss: 0.394372\n",
            "Train Epoch: 0 [10/3978 (0%)]\tLoss: 0.432889\n",
            "Train Epoch: 0 [15/3978 (0%)]\tLoss: 0.283766\n",
            "Train Epoch: 0 [20/3978 (1%)]\tLoss: 0.336204\n",
            "Train Epoch: 0 [25/3978 (1%)]\tLoss: 0.382162\n",
            "Train Epoch: 0 [30/3978 (1%)]\tLoss: 0.469002\n",
            "Train Epoch: 0 [35/3978 (1%)]\tLoss: 0.158389\n",
            "Train Epoch: 0 [40/3978 (1%)]\tLoss: 0.177090\n",
            "Train Epoch: 0 [45/3978 (1%)]\tLoss: 0.482528\n",
            "Train Epoch: 0 [50/3978 (1%)]\tLoss: 0.219692\n",
            "Train Epoch: 0 [55/3978 (1%)]\tLoss: 0.097653\n",
            "Train Epoch: 0 [60/3978 (2%)]\tLoss: 0.691310\n",
            "Train Epoch: 0 [65/3978 (2%)]\tLoss: 0.062457\n",
            "Train Epoch: 0 [70/3978 (2%)]\tLoss: 0.644258\n",
            "Train Epoch: 0 [75/3978 (2%)]\tLoss: 0.158761\n",
            "Train Epoch: 0 [80/3978 (2%)]\tLoss: 0.202594\n",
            "Train Epoch: 0 [85/3978 (2%)]\tLoss: 0.281268\n",
            "Train Epoch: 0 [90/3978 (2%)]\tLoss: 0.070451\n",
            "Train Epoch: 0 [95/3978 (2%)]\tLoss: 0.208480\n",
            "Train Epoch: 0 [100/3978 (3%)]\tLoss: 0.613953\n",
            "Train Epoch: 0 [105/3978 (3%)]\tLoss: 0.155662\n",
            "Train Epoch: 0 [110/3978 (3%)]\tLoss: 0.030861\n",
            "Train Epoch: 0 [115/3978 (3%)]\tLoss: 0.418224\n",
            "Train Epoch: 0 [120/3978 (3%)]\tLoss: 0.321683\n",
            "Train Epoch: 0 [125/3978 (3%)]\tLoss: 0.066998\n",
            "Train Epoch: 0 [130/3978 (3%)]\tLoss: 0.224886\n",
            "Train Epoch: 0 [135/3978 (3%)]\tLoss: 0.074636\n",
            "Train Epoch: 0 [140/3978 (4%)]\tLoss: 0.199009\n",
            "Train Epoch: 0 [145/3978 (4%)]\tLoss: 0.049920\n",
            "Train Epoch: 0 [150/3978 (4%)]\tLoss: 0.082229\n",
            "Train Epoch: 0 [155/3978 (4%)]\tLoss: 0.128919\n",
            "Train Epoch: 0 [160/3978 (4%)]\tLoss: 0.278076\n",
            "Train Epoch: 0 [165/3978 (4%)]\tLoss: 0.453132\n",
            "Train Epoch: 0 [170/3978 (4%)]\tLoss: 0.337210\n",
            "Train Epoch: 0 [175/3978 (4%)]\tLoss: 0.151080\n",
            "Train Epoch: 0 [180/3978 (5%)]\tLoss: 0.113921\n",
            "Train Epoch: 0 [185/3978 (5%)]\tLoss: 0.391272\n",
            "Train Epoch: 0 [190/3978 (5%)]\tLoss: 0.426935\n",
            "Train Epoch: 0 [195/3978 (5%)]\tLoss: 0.168907\n",
            "Train Epoch: 0 [200/3978 (5%)]\tLoss: 0.540810\n",
            "Train Epoch: 0 [205/3978 (5%)]\tLoss: 0.171061\n",
            "Train Epoch: 0 [210/3978 (5%)]\tLoss: 0.131026\n",
            "Train Epoch: 0 [215/3978 (5%)]\tLoss: 0.640685\n",
            "Train Epoch: 0 [220/3978 (6%)]\tLoss: 0.160180\n",
            "Train Epoch: 0 [225/3978 (6%)]\tLoss: 0.107832\n",
            "Train Epoch: 0 [230/3978 (6%)]\tLoss: 0.278796\n",
            "Train Epoch: 0 [235/3978 (6%)]\tLoss: 0.210747\n",
            "Train Epoch: 0 [240/3978 (6%)]\tLoss: 0.429500\n",
            "Train Epoch: 0 [245/3978 (6%)]\tLoss: 0.077035\n",
            "Train Epoch: 0 [250/3978 (6%)]\tLoss: 0.145898\n",
            "Train Epoch: 0 [255/3978 (6%)]\tLoss: 0.391154\n",
            "Train Epoch: 0 [260/3978 (7%)]\tLoss: 0.269247\n",
            "Train Epoch: 0 [265/3978 (7%)]\tLoss: 0.354785\n",
            "Train Epoch: 0 [270/3978 (7%)]\tLoss: 0.213572\n",
            "Train Epoch: 0 [275/3978 (7%)]\tLoss: 0.087535\n",
            "Train Epoch: 0 [280/3978 (7%)]\tLoss: 0.446847\n",
            "Train Epoch: 0 [285/3978 (7%)]\tLoss: 0.146062\n",
            "Train Epoch: 0 [290/3978 (7%)]\tLoss: 0.260132\n",
            "Train Epoch: 0 [295/3978 (7%)]\tLoss: 0.283254\n",
            "Train Epoch: 0 [300/3978 (8%)]\tLoss: 0.550777\n",
            "Train Epoch: 0 [305/3978 (8%)]\tLoss: 0.300458\n",
            "Train Epoch: 0 [310/3978 (8%)]\tLoss: 0.171986\n",
            "Train Epoch: 0 [315/3978 (8%)]\tLoss: 0.174804\n",
            "Train Epoch: 0 [320/3978 (8%)]\tLoss: 0.056444\n",
            "Train Epoch: 0 [325/3978 (8%)]\tLoss: 0.139090\n",
            "Train Epoch: 0 [330/3978 (8%)]\tLoss: 0.086253\n",
            "Train Epoch: 0 [335/3978 (8%)]\tLoss: 0.405476\n",
            "Train Epoch: 0 [340/3978 (9%)]\tLoss: 0.091160\n",
            "Train Epoch: 0 [345/3978 (9%)]\tLoss: 0.154156\n",
            "Train Epoch: 0 [350/3978 (9%)]\tLoss: 0.664635\n",
            "Train Epoch: 0 [355/3978 (9%)]\tLoss: 0.400390\n",
            "Train Epoch: 0 [360/3978 (9%)]\tLoss: 0.190659\n",
            "Train Epoch: 0 [365/3978 (9%)]\tLoss: 0.319517\n",
            "Train Epoch: 0 [370/3978 (9%)]\tLoss: 0.221466\n",
            "Train Epoch: 0 [375/3978 (9%)]\tLoss: 0.162495\n",
            "Train Epoch: 0 [380/3978 (10%)]\tLoss: 0.099516\n",
            "Train Epoch: 0 [385/3978 (10%)]\tLoss: 0.253745\n",
            "Train Epoch: 0 [390/3978 (10%)]\tLoss: 0.247836\n",
            "Train Epoch: 0 [395/3978 (10%)]\tLoss: 0.110458\n",
            "Train Epoch: 0 [400/3978 (10%)]\tLoss: 0.363513\n",
            "Train Epoch: 0 [405/3978 (10%)]\tLoss: 0.154635\n",
            "Train Epoch: 0 [410/3978 (10%)]\tLoss: 0.250420\n",
            "Train Epoch: 0 [415/3978 (10%)]\tLoss: 0.208272\n",
            "Train Epoch: 0 [420/3978 (11%)]\tLoss: 0.079488\n",
            "Train Epoch: 0 [425/3978 (11%)]\tLoss: 0.260717\n",
            "Train Epoch: 0 [430/3978 (11%)]\tLoss: 0.079278\n",
            "Train Epoch: 0 [435/3978 (11%)]\tLoss: 0.353762\n",
            "Train Epoch: 0 [440/3978 (11%)]\tLoss: 0.320117\n",
            "Train Epoch: 0 [445/3978 (11%)]\tLoss: 0.353663\n",
            "Train Epoch: 0 [450/3978 (11%)]\tLoss: 0.169094\n",
            "Train Epoch: 0 [455/3978 (11%)]\tLoss: 0.248481\n",
            "Train Epoch: 0 [460/3978 (12%)]\tLoss: 0.876465\n",
            "Train Epoch: 0 [465/3978 (12%)]\tLoss: 0.199651\n",
            "Train Epoch: 0 [470/3978 (12%)]\tLoss: 0.105170\n",
            "Train Epoch: 0 [475/3978 (12%)]\tLoss: 0.497375\n",
            "Train Epoch: 0 [480/3978 (12%)]\tLoss: 0.326272\n",
            "Train Epoch: 0 [485/3978 (12%)]\tLoss: 0.115576\n",
            "Train Epoch: 0 [490/3978 (12%)]\tLoss: 0.128984\n",
            "Train Epoch: 0 [495/3978 (12%)]\tLoss: 0.287131\n",
            "Train Epoch: 0 [500/3978 (13%)]\tLoss: 0.120862\n",
            "Train Epoch: 0 [505/3978 (13%)]\tLoss: 0.273061\n",
            "Train Epoch: 0 [510/3978 (13%)]\tLoss: 0.265113\n",
            "Train Epoch: 0 [515/3978 (13%)]\tLoss: 0.079741\n",
            "Train Epoch: 0 [520/3978 (13%)]\tLoss: 0.062990\n",
            "Train Epoch: 0 [525/3978 (13%)]\tLoss: 0.202363\n",
            "Train Epoch: 0 [530/3978 (13%)]\tLoss: 0.565583\n",
            "Train Epoch: 0 [535/3978 (13%)]\tLoss: 0.211656\n",
            "Train Epoch: 0 [540/3978 (14%)]\tLoss: 0.108817\n",
            "Train Epoch: 0 [545/3978 (14%)]\tLoss: 0.070687\n",
            "Train Epoch: 0 [550/3978 (14%)]\tLoss: 0.069534\n",
            "Train Epoch: 0 [555/3978 (14%)]\tLoss: 0.078355\n",
            "Train Epoch: 0 [560/3978 (14%)]\tLoss: 0.062115\n",
            "Train Epoch: 0 [565/3978 (14%)]\tLoss: 0.201193\n",
            "Train Epoch: 0 [570/3978 (14%)]\tLoss: 0.429021\n",
            "Train Epoch: 0 [575/3978 (14%)]\tLoss: 0.183537\n",
            "Train Epoch: 0 [580/3978 (15%)]\tLoss: 0.210673\n",
            "Train Epoch: 0 [585/3978 (15%)]\tLoss: 0.056947\n",
            "Train Epoch: 0 [590/3978 (15%)]\tLoss: 0.083083\n",
            "Train Epoch: 0 [595/3978 (15%)]\tLoss: 0.988012\n",
            "Train Epoch: 0 [600/3978 (15%)]\tLoss: 0.692560\n",
            "Train Epoch: 0 [605/3978 (15%)]\tLoss: 0.077496\n",
            "Train Epoch: 0 [610/3978 (15%)]\tLoss: 0.333541\n",
            "Train Epoch: 0 [615/3978 (15%)]\tLoss: 0.081858\n",
            "Train Epoch: 0 [620/3978 (16%)]\tLoss: 0.366676\n",
            "Train Epoch: 0 [625/3978 (16%)]\tLoss: 0.122019\n",
            "Train Epoch: 0 [630/3978 (16%)]\tLoss: 0.108957\n",
            "Train Epoch: 0 [635/3978 (16%)]\tLoss: 0.183178\n",
            "Train Epoch: 0 [640/3978 (16%)]\tLoss: 0.569556\n",
            "Train Epoch: 0 [645/3978 (16%)]\tLoss: 0.231220\n",
            "Train Epoch: 0 [650/3978 (16%)]\tLoss: 0.099628\n",
            "Train Epoch: 0 [655/3978 (16%)]\tLoss: 0.102692\n",
            "Train Epoch: 0 [660/3978 (17%)]\tLoss: 0.101273\n",
            "Train Epoch: 0 [665/3978 (17%)]\tLoss: 0.074911\n",
            "Train Epoch: 0 [670/3978 (17%)]\tLoss: 0.110793\n",
            "Train Epoch: 0 [675/3978 (17%)]\tLoss: 0.427736\n",
            "Train Epoch: 0 [680/3978 (17%)]\tLoss: 0.202275\n",
            "Train Epoch: 0 [685/3978 (17%)]\tLoss: 0.381910\n",
            "Train Epoch: 0 [690/3978 (17%)]\tLoss: 0.093458\n",
            "Train Epoch: 0 [695/3978 (17%)]\tLoss: 0.383578\n",
            "Train Epoch: 0 [700/3978 (18%)]\tLoss: 0.402675\n",
            "Train Epoch: 0 [705/3978 (18%)]\tLoss: 0.078757\n",
            "Train Epoch: 0 [710/3978 (18%)]\tLoss: 0.736129\n",
            "Train Epoch: 0 [715/3978 (18%)]\tLoss: 0.285584\n",
            "Train Epoch: 0 [720/3978 (18%)]\tLoss: 0.071688\n",
            "Train Epoch: 0 [725/3978 (18%)]\tLoss: 0.178609\n",
            "Train Epoch: 0 [730/3978 (18%)]\tLoss: 0.237128\n",
            "Train Epoch: 0 [735/3978 (18%)]\tLoss: 0.171780\n",
            "Train Epoch: 0 [740/3978 (19%)]\tLoss: 0.193107\n",
            "Train Epoch: 0 [745/3978 (19%)]\tLoss: 0.356143\n",
            "Train Epoch: 0 [750/3978 (19%)]\tLoss: 0.091147\n",
            "Train Epoch: 0 [755/3978 (19%)]\tLoss: 0.105430\n",
            "Train Epoch: 0 [760/3978 (19%)]\tLoss: 0.454504\n",
            "Train Epoch: 0 [765/3978 (19%)]\tLoss: 0.100403\n",
            "Train Epoch: 0 [770/3978 (19%)]\tLoss: 0.348245\n",
            "Train Epoch: 0 [775/3978 (19%)]\tLoss: 0.230373\n",
            "Train Epoch: 0 [780/3978 (20%)]\tLoss: 0.193414\n",
            "Train Epoch: 0 [785/3978 (20%)]\tLoss: 0.138672\n",
            "Train Epoch: 0 [790/3978 (20%)]\tLoss: 0.576005\n",
            "Train Epoch: 0 [795/3978 (20%)]\tLoss: 0.319421\n",
            "Train Epoch: 0 [800/3978 (20%)]\tLoss: 0.522270\n",
            "Train Epoch: 0 [805/3978 (20%)]\tLoss: 0.072836\n",
            "Train Epoch: 0 [810/3978 (20%)]\tLoss: 0.108149\n",
            "Train Epoch: 0 [815/3978 (20%)]\tLoss: 0.286498\n",
            "Train Epoch: 0 [820/3978 (21%)]\tLoss: 0.075028\n",
            "Train Epoch: 0 [825/3978 (21%)]\tLoss: 0.230729\n",
            "Train Epoch: 0 [830/3978 (21%)]\tLoss: 0.198917\n",
            "Train Epoch: 0 [835/3978 (21%)]\tLoss: 0.316673\n",
            "Train Epoch: 0 [840/3978 (21%)]\tLoss: 0.302986\n",
            "Train Epoch: 0 [845/3978 (21%)]\tLoss: 0.106983\n",
            "Train Epoch: 0 [850/3978 (21%)]\tLoss: 0.541245\n",
            "Train Epoch: 0 [855/3978 (21%)]\tLoss: 0.100685\n",
            "Train Epoch: 0 [860/3978 (22%)]\tLoss: 0.098657\n",
            "Train Epoch: 0 [865/3978 (22%)]\tLoss: 0.163711\n",
            "Train Epoch: 0 [870/3978 (22%)]\tLoss: 0.302847\n",
            "Train Epoch: 0 [875/3978 (22%)]\tLoss: 0.263149\n",
            "Train Epoch: 0 [880/3978 (22%)]\tLoss: 0.234305\n",
            "Train Epoch: 0 [885/3978 (22%)]\tLoss: 0.083468\n",
            "Train Epoch: 0 [890/3978 (22%)]\tLoss: 0.242128\n",
            "Train Epoch: 0 [895/3978 (22%)]\tLoss: 0.407279\n",
            "Train Epoch: 0 [900/3978 (23%)]\tLoss: 0.062515\n",
            "Train Epoch: 0 [905/3978 (23%)]\tLoss: 0.452413\n",
            "Train Epoch: 0 [910/3978 (23%)]\tLoss: 0.082988\n",
            "Train Epoch: 0 [915/3978 (23%)]\tLoss: 0.220284\n",
            "Train Epoch: 0 [920/3978 (23%)]\tLoss: 0.481919\n",
            "Train Epoch: 0 [925/3978 (23%)]\tLoss: 0.360350\n",
            "Train Epoch: 0 [930/3978 (23%)]\tLoss: 0.235236\n",
            "Train Epoch: 0 [935/3978 (23%)]\tLoss: 0.042568\n",
            "Train Epoch: 0 [940/3978 (24%)]\tLoss: 0.279977\n",
            "Train Epoch: 0 [945/3978 (24%)]\tLoss: 0.066717\n",
            "Train Epoch: 0 [950/3978 (24%)]\tLoss: 0.227848\n",
            "Train Epoch: 0 [955/3978 (24%)]\tLoss: 0.340922\n",
            "Train Epoch: 0 [960/3978 (24%)]\tLoss: 0.261385\n",
            "Train Epoch: 0 [965/3978 (24%)]\tLoss: 0.208314\n",
            "Train Epoch: 0 [970/3978 (24%)]\tLoss: 0.255459\n",
            "Train Epoch: 0 [975/3978 (24%)]\tLoss: 0.254823\n",
            "Train Epoch: 0 [980/3978 (25%)]\tLoss: 0.246685\n",
            "Train Epoch: 0 [985/3978 (25%)]\tLoss: 0.333121\n",
            "Train Epoch: 0 [990/3978 (25%)]\tLoss: 0.087081\n",
            "Train Epoch: 0 [995/3978 (25%)]\tLoss: 0.132618\n",
            "Train Epoch: 0 [1000/3978 (25%)]\tLoss: 0.152704\n",
            "Train Epoch: 0 [1005/3978 (25%)]\tLoss: 0.156025\n",
            "Train Epoch: 0 [1010/3978 (25%)]\tLoss: 0.270623\n",
            "Train Epoch: 0 [1015/3978 (26%)]\tLoss: 0.099725\n",
            "Train Epoch: 0 [1020/3978 (26%)]\tLoss: 0.183909\n",
            "Train Epoch: 0 [1025/3978 (26%)]\tLoss: 0.515409\n",
            "Train Epoch: 0 [1030/3978 (26%)]\tLoss: 0.107847\n",
            "Train Epoch: 0 [1035/3978 (26%)]\tLoss: 0.344992\n",
            "Train Epoch: 0 [1040/3978 (26%)]\tLoss: 0.413542\n",
            "Train Epoch: 0 [1045/3978 (26%)]\tLoss: 0.091579\n",
            "Train Epoch: 0 [1050/3978 (26%)]\tLoss: 0.379053\n",
            "Train Epoch: 0 [1055/3978 (27%)]\tLoss: 0.082010\n",
            "Train Epoch: 0 [1060/3978 (27%)]\tLoss: 0.080174\n",
            "Train Epoch: 0 [1065/3978 (27%)]\tLoss: 0.169770\n",
            "Train Epoch: 0 [1070/3978 (27%)]\tLoss: 0.485097\n",
            "Train Epoch: 0 [1075/3978 (27%)]\tLoss: 0.638037\n",
            "Train Epoch: 0 [1080/3978 (27%)]\tLoss: 0.375353\n",
            "Train Epoch: 0 [1085/3978 (27%)]\tLoss: 0.451939\n",
            "Train Epoch: 0 [1090/3978 (27%)]\tLoss: 0.093928\n",
            "Train Epoch: 0 [1095/3978 (28%)]\tLoss: 0.297335\n",
            "Train Epoch: 0 [1100/3978 (28%)]\tLoss: 0.071067\n",
            "Train Epoch: 0 [1105/3978 (28%)]\tLoss: 0.478267\n",
            "Train Epoch: 0 [1110/3978 (28%)]\tLoss: 0.389840\n",
            "Train Epoch: 0 [1115/3978 (28%)]\tLoss: 0.354649\n",
            "Train Epoch: 0 [1120/3978 (28%)]\tLoss: 0.156453\n",
            "Train Epoch: 0 [1125/3978 (28%)]\tLoss: 0.205516\n",
            "Train Epoch: 0 [1130/3978 (28%)]\tLoss: 0.384427\n",
            "Train Epoch: 0 [1135/3978 (29%)]\tLoss: 0.205822\n",
            "Train Epoch: 0 [1140/3978 (29%)]\tLoss: 0.627107\n",
            "Train Epoch: 0 [1145/3978 (29%)]\tLoss: 0.190014\n",
            "Train Epoch: 0 [1150/3978 (29%)]\tLoss: 0.196937\n",
            "Train Epoch: 0 [1155/3978 (29%)]\tLoss: 0.304924\n",
            "Train Epoch: 0 [1160/3978 (29%)]\tLoss: 0.170163\n",
            "Train Epoch: 0 [1165/3978 (29%)]\tLoss: 0.202819\n",
            "Train Epoch: 0 [1170/3978 (29%)]\tLoss: 0.146703\n",
            "Train Epoch: 0 [1175/3978 (30%)]\tLoss: 0.213289\n",
            "Train Epoch: 0 [1180/3978 (30%)]\tLoss: 0.101970\n",
            "Train Epoch: 0 [1185/3978 (30%)]\tLoss: 0.084267\n",
            "Train Epoch: 0 [1190/3978 (30%)]\tLoss: 0.637728\n",
            "Train Epoch: 0 [1195/3978 (30%)]\tLoss: 0.088727\n",
            "Train Epoch: 0 [1200/3978 (30%)]\tLoss: 0.102174\n",
            "Train Epoch: 0 [1205/3978 (30%)]\tLoss: 0.214308\n",
            "Train Epoch: 0 [1210/3978 (30%)]\tLoss: 0.175180\n",
            "Train Epoch: 0 [1215/3978 (31%)]\tLoss: 0.087501\n",
            "Train Epoch: 0 [1220/3978 (31%)]\tLoss: 0.235831\n",
            "Train Epoch: 0 [1225/3978 (31%)]\tLoss: 0.647585\n",
            "Train Epoch: 0 [1230/3978 (31%)]\tLoss: 0.270521\n",
            "Train Epoch: 0 [1235/3978 (31%)]\tLoss: 0.073824\n",
            "Train Epoch: 0 [1240/3978 (31%)]\tLoss: 0.254367\n",
            "Train Epoch: 0 [1245/3978 (31%)]\tLoss: 0.070710\n",
            "Train Epoch: 0 [1250/3978 (31%)]\tLoss: 0.061114\n",
            "Train Epoch: 0 [1255/3978 (32%)]\tLoss: 0.045980\n",
            "Train Epoch: 0 [1260/3978 (32%)]\tLoss: 0.085691\n",
            "Train Epoch: 0 [1265/3978 (32%)]\tLoss: 0.219271\n",
            "Train Epoch: 0 [1270/3978 (32%)]\tLoss: 0.065323\n",
            "Train Epoch: 0 [1275/3978 (32%)]\tLoss: 0.183819\n",
            "Train Epoch: 0 [1280/3978 (32%)]\tLoss: 0.250821\n",
            "Train Epoch: 0 [1285/3978 (32%)]\tLoss: 0.084416\n",
            "Train Epoch: 0 [1290/3978 (32%)]\tLoss: 0.542882\n",
            "Train Epoch: 0 [1295/3978 (33%)]\tLoss: 0.064985\n",
            "Train Epoch: 0 [1300/3978 (33%)]\tLoss: 0.064445\n",
            "Train Epoch: 0 [1305/3978 (33%)]\tLoss: 0.064307\n",
            "Train Epoch: 0 [1310/3978 (33%)]\tLoss: 0.063881\n",
            "Train Epoch: 0 [1315/3978 (33%)]\tLoss: 0.129693\n",
            "Train Epoch: 0 [1320/3978 (33%)]\tLoss: 0.430386\n",
            "Train Epoch: 0 [1325/3978 (33%)]\tLoss: 0.499014\n",
            "Train Epoch: 0 [1330/3978 (33%)]\tLoss: 0.126383\n",
            "Train Epoch: 0 [1335/3978 (34%)]\tLoss: 0.514924\n",
            "Train Epoch: 0 [1340/3978 (34%)]\tLoss: 0.184883\n",
            "Train Epoch: 0 [1345/3978 (34%)]\tLoss: 0.061398\n",
            "Train Epoch: 0 [1350/3978 (34%)]\tLoss: 0.468352\n",
            "Train Epoch: 0 [1355/3978 (34%)]\tLoss: 0.042599\n",
            "Train Epoch: 0 [1360/3978 (34%)]\tLoss: 0.333713\n",
            "Train Epoch: 0 [1365/3978 (34%)]\tLoss: 0.041255\n",
            "Train Epoch: 0 [1370/3978 (34%)]\tLoss: 0.103246\n",
            "Train Epoch: 0 [1375/3978 (35%)]\tLoss: 0.772035\n",
            "Train Epoch: 0 [1380/3978 (35%)]\tLoss: 0.460225\n",
            "Train Epoch: 0 [1385/3978 (35%)]\tLoss: 0.599084\n",
            "Train Epoch: 0 [1390/3978 (35%)]\tLoss: 0.523524\n",
            "Train Epoch: 0 [1395/3978 (35%)]\tLoss: 0.215482\n",
            "Train Epoch: 0 [1400/3978 (35%)]\tLoss: 0.179254\n",
            "Train Epoch: 0 [1405/3978 (35%)]\tLoss: 0.726563\n",
            "Train Epoch: 0 [1410/3978 (35%)]\tLoss: 0.183979\n",
            "Train Epoch: 0 [1415/3978 (36%)]\tLoss: 0.322575\n",
            "Train Epoch: 0 [1420/3978 (36%)]\tLoss: 0.349276\n",
            "Train Epoch: 0 [1425/3978 (36%)]\tLoss: 0.227842\n",
            "Train Epoch: 0 [1430/3978 (36%)]\tLoss: 0.277660\n",
            "Train Epoch: 0 [1435/3978 (36%)]\tLoss: 0.079944\n",
            "Train Epoch: 0 [1440/3978 (36%)]\tLoss: 0.120140\n",
            "Train Epoch: 0 [1445/3978 (36%)]\tLoss: 0.355306\n",
            "Train Epoch: 0 [1450/3978 (36%)]\tLoss: 0.372527\n",
            "Train Epoch: 0 [1455/3978 (37%)]\tLoss: 0.483669\n",
            "Train Epoch: 0 [1460/3978 (37%)]\tLoss: 0.172273\n",
            "Train Epoch: 0 [1465/3978 (37%)]\tLoss: 0.091801\n",
            "Train Epoch: 0 [1470/3978 (37%)]\tLoss: 0.283920\n",
            "Train Epoch: 0 [1475/3978 (37%)]\tLoss: 0.112456\n",
            "Train Epoch: 0 [1480/3978 (37%)]\tLoss: 0.121489\n",
            "Train Epoch: 0 [1485/3978 (37%)]\tLoss: 0.105860\n",
            "Train Epoch: 0 [1490/3978 (37%)]\tLoss: 0.104061\n",
            "Train Epoch: 0 [1495/3978 (38%)]\tLoss: 0.096944\n",
            "Train Epoch: 0 [1500/3978 (38%)]\tLoss: 0.501131\n",
            "Train Epoch: 0 [1505/3978 (38%)]\tLoss: 0.106266\n",
            "Train Epoch: 0 [1510/3978 (38%)]\tLoss: 0.286528\n",
            "Train Epoch: 0 [1515/3978 (38%)]\tLoss: 0.385201\n",
            "Train Epoch: 0 [1520/3978 (38%)]\tLoss: 0.129406\n",
            "Train Epoch: 0 [1525/3978 (38%)]\tLoss: 0.478568\n",
            "Train Epoch: 0 [1530/3978 (38%)]\tLoss: 0.266218\n",
            "Train Epoch: 0 [1535/3978 (39%)]\tLoss: 0.450697\n",
            "Train Epoch: 0 [1540/3978 (39%)]\tLoss: 0.278149\n",
            "Train Epoch: 0 [1545/3978 (39%)]\tLoss: 0.177545\n",
            "Train Epoch: 0 [1550/3978 (39%)]\tLoss: 0.247227\n",
            "Train Epoch: 0 [1555/3978 (39%)]\tLoss: 0.470797\n",
            "Train Epoch: 0 [1560/3978 (39%)]\tLoss: 0.282433\n",
            "Train Epoch: 0 [1565/3978 (39%)]\tLoss: 0.179465\n",
            "Train Epoch: 0 [1570/3978 (39%)]\tLoss: 0.136826\n",
            "Train Epoch: 0 [1575/3978 (40%)]\tLoss: 0.276640\n",
            "Train Epoch: 0 [1580/3978 (40%)]\tLoss: 0.232647\n",
            "Train Epoch: 0 [1585/3978 (40%)]\tLoss: 0.465138\n",
            "Train Epoch: 0 [1590/3978 (40%)]\tLoss: 0.092489\n",
            "Train Epoch: 0 [1595/3978 (40%)]\tLoss: 0.120726\n",
            "Train Epoch: 0 [1600/3978 (40%)]\tLoss: 0.104764\n",
            "Train Epoch: 0 [1605/3978 (40%)]\tLoss: 0.317752\n",
            "Train Epoch: 0 [1610/3978 (40%)]\tLoss: 0.177616\n",
            "Train Epoch: 0 [1615/3978 (41%)]\tLoss: 0.218418\n",
            "Train Epoch: 0 [1620/3978 (41%)]\tLoss: 0.195559\n",
            "Train Epoch: 0 [1625/3978 (41%)]\tLoss: 0.272294\n",
            "Train Epoch: 0 [1630/3978 (41%)]\tLoss: 0.077638\n",
            "Train Epoch: 0 [1635/3978 (41%)]\tLoss: 0.065012\n",
            "Train Epoch: 0 [1640/3978 (41%)]\tLoss: 0.087368\n",
            "Train Epoch: 0 [1645/3978 (41%)]\tLoss: 0.216821\n",
            "Train Epoch: 0 [1650/3978 (41%)]\tLoss: 0.068957\n",
            "Train Epoch: 0 [1655/3978 (42%)]\tLoss: 0.107922\n",
            "Train Epoch: 0 [1660/3978 (42%)]\tLoss: 0.520012\n",
            "Train Epoch: 0 [1665/3978 (42%)]\tLoss: 0.067172\n",
            "Train Epoch: 0 [1670/3978 (42%)]\tLoss: 0.489262\n",
            "Train Epoch: 0 [1675/3978 (42%)]\tLoss: 0.227709\n",
            "Train Epoch: 0 [1680/3978 (42%)]\tLoss: 0.624939\n",
            "Train Epoch: 0 [1685/3978 (42%)]\tLoss: 0.356453\n",
            "Train Epoch: 0 [1690/3978 (42%)]\tLoss: 0.072087\n",
            "Train Epoch: 0 [1695/3978 (43%)]\tLoss: 0.079693\n",
            "Train Epoch: 0 [1700/3978 (43%)]\tLoss: 0.320427\n",
            "Train Epoch: 0 [1705/3978 (43%)]\tLoss: 0.123240\n",
            "Train Epoch: 0 [1710/3978 (43%)]\tLoss: 0.275496\n",
            "Train Epoch: 0 [1715/3978 (43%)]\tLoss: 0.249297\n",
            "Train Epoch: 0 [1720/3978 (43%)]\tLoss: 0.254451\n",
            "Train Epoch: 0 [1725/3978 (43%)]\tLoss: 0.157846\n",
            "Train Epoch: 0 [1730/3978 (43%)]\tLoss: 0.455971\n",
            "Train Epoch: 0 [1735/3978 (44%)]\tLoss: 0.351439\n",
            "Train Epoch: 0 [1740/3978 (44%)]\tLoss: 0.129616\n",
            "Train Epoch: 0 [1745/3978 (44%)]\tLoss: 0.091572\n",
            "Train Epoch: 0 [1750/3978 (44%)]\tLoss: 0.244254\n",
            "Train Epoch: 0 [1755/3978 (44%)]\tLoss: 0.092993\n",
            "Train Epoch: 0 [1760/3978 (44%)]\tLoss: 0.060771\n",
            "Train Epoch: 0 [1765/3978 (44%)]\tLoss: 0.248281\n",
            "Train Epoch: 0 [1770/3978 (44%)]\tLoss: 0.219351\n",
            "Train Epoch: 0 [1775/3978 (45%)]\tLoss: 0.322896\n",
            "Train Epoch: 0 [1780/3978 (45%)]\tLoss: 0.227539\n",
            "Train Epoch: 0 [1785/3978 (45%)]\tLoss: 0.048206\n",
            "Train Epoch: 0 [1790/3978 (45%)]\tLoss: 0.592131\n",
            "Train Epoch: 0 [1795/3978 (45%)]\tLoss: 0.374228\n",
            "Train Epoch: 0 [1800/3978 (45%)]\tLoss: 0.230158\n",
            "Train Epoch: 0 [1805/3978 (45%)]\tLoss: 0.063160\n",
            "Train Epoch: 0 [1810/3978 (45%)]\tLoss: 0.371684\n",
            "Train Epoch: 0 [1815/3978 (46%)]\tLoss: 0.077444\n",
            "Train Epoch: 0 [1820/3978 (46%)]\tLoss: 0.191061\n",
            "Train Epoch: 0 [1825/3978 (46%)]\tLoss: 0.079441\n",
            "Train Epoch: 0 [1830/3978 (46%)]\tLoss: 0.352453\n",
            "Train Epoch: 0 [1835/3978 (46%)]\tLoss: 0.110045\n",
            "Train Epoch: 0 [1840/3978 (46%)]\tLoss: 0.211452\n",
            "Train Epoch: 0 [1845/3978 (46%)]\tLoss: 0.075880\n",
            "Train Epoch: 0 [1850/3978 (46%)]\tLoss: 0.282465\n",
            "Train Epoch: 0 [1855/3978 (47%)]\tLoss: 0.269590\n",
            "Train Epoch: 0 [1860/3978 (47%)]\tLoss: 0.201413\n",
            "Train Epoch: 0 [1865/3978 (47%)]\tLoss: 0.266076\n",
            "Train Epoch: 0 [1870/3978 (47%)]\tLoss: 0.732529\n",
            "Train Epoch: 0 [1875/3978 (47%)]\tLoss: 0.492899\n",
            "Train Epoch: 0 [1880/3978 (47%)]\tLoss: 0.135003\n",
            "Train Epoch: 0 [1885/3978 (47%)]\tLoss: 0.162293\n",
            "Train Epoch: 0 [1890/3978 (47%)]\tLoss: 0.442073\n",
            "Train Epoch: 0 [1895/3978 (48%)]\tLoss: 0.190150\n",
            "Train Epoch: 0 [1900/3978 (48%)]\tLoss: 0.257662\n",
            "Train Epoch: 0 [1905/3978 (48%)]\tLoss: 0.426741\n",
            "Train Epoch: 0 [1910/3978 (48%)]\tLoss: 0.204001\n",
            "Train Epoch: 0 [1915/3978 (48%)]\tLoss: 0.359036\n",
            "Train Epoch: 0 [1920/3978 (48%)]\tLoss: 0.543620\n",
            "Train Epoch: 0 [1925/3978 (48%)]\tLoss: 0.137001\n",
            "Train Epoch: 0 [1930/3978 (48%)]\tLoss: 0.146709\n",
            "Train Epoch: 0 [1935/3978 (49%)]\tLoss: 0.126161\n",
            "Train Epoch: 0 [1940/3978 (49%)]\tLoss: 0.391988\n",
            "Train Epoch: 0 [1945/3978 (49%)]\tLoss: 0.374369\n",
            "Train Epoch: 0 [1950/3978 (49%)]\tLoss: 0.066742\n",
            "Train Epoch: 0 [1955/3978 (49%)]\tLoss: 0.199437\n",
            "Train Epoch: 0 [1960/3978 (49%)]\tLoss: 0.217069\n",
            "Train Epoch: 0 [1965/3978 (49%)]\tLoss: 0.203163\n",
            "Train Epoch: 0 [1970/3978 (49%)]\tLoss: 0.180804\n",
            "Train Epoch: 0 [1975/3978 (50%)]\tLoss: 0.272743\n",
            "Train Epoch: 0 [1980/3978 (50%)]\tLoss: 0.124339\n",
            "Train Epoch: 0 [1985/3978 (50%)]\tLoss: 0.281177\n",
            "Train Epoch: 0 [1990/3978 (50%)]\tLoss: 0.369330\n",
            "Train Epoch: 0 [1995/3978 (50%)]\tLoss: 1.272993\n",
            "Train Epoch: 0 [2000/3978 (50%)]\tLoss: 0.356682\n",
            "Train Epoch: 0 [2005/3978 (50%)]\tLoss: 0.078608\n",
            "Train Epoch: 0 [2010/3978 (51%)]\tLoss: 0.353242\n",
            "Train Epoch: 0 [2015/3978 (51%)]\tLoss: 0.510096\n",
            "Train Epoch: 0 [2020/3978 (51%)]\tLoss: 0.202078\n",
            "Train Epoch: 0 [2025/3978 (51%)]\tLoss: 0.465059\n",
            "Train Epoch: 0 [2030/3978 (51%)]\tLoss: 0.171391\n",
            "Train Epoch: 0 [2035/3978 (51%)]\tLoss: 0.436871\n",
            "Train Epoch: 0 [2040/3978 (51%)]\tLoss: 0.406609\n",
            "Train Epoch: 0 [2045/3978 (51%)]\tLoss: 0.574677\n",
            "Train Epoch: 0 [2050/3978 (52%)]\tLoss: 0.238208\n",
            "Train Epoch: 0 [2055/3978 (52%)]\tLoss: 0.165475\n",
            "Train Epoch: 0 [2060/3978 (52%)]\tLoss: 0.267773\n",
            "Train Epoch: 0 [2065/3978 (52%)]\tLoss: 0.309442\n",
            "Train Epoch: 0 [2070/3978 (52%)]\tLoss: 0.244218\n",
            "Train Epoch: 0 [2075/3978 (52%)]\tLoss: 0.108962\n",
            "Train Epoch: 0 [2080/3978 (52%)]\tLoss: 0.105135\n",
            "Train Epoch: 0 [2085/3978 (52%)]\tLoss: 0.397114\n",
            "Train Epoch: 0 [2090/3978 (53%)]\tLoss: 0.091838\n",
            "Train Epoch: 0 [2095/3978 (53%)]\tLoss: 0.195938\n",
            "Train Epoch: 0 [2100/3978 (53%)]\tLoss: 0.308933\n",
            "Train Epoch: 0 [2105/3978 (53%)]\tLoss: 0.450049\n",
            "Train Epoch: 0 [2110/3978 (53%)]\tLoss: 0.267345\n",
            "Train Epoch: 0 [2115/3978 (53%)]\tLoss: 0.302799\n",
            "Train Epoch: 0 [2120/3978 (53%)]\tLoss: 0.270524\n",
            "Train Epoch: 0 [2125/3978 (53%)]\tLoss: 0.097637\n",
            "Train Epoch: 0 [2130/3978 (54%)]\tLoss: 0.235191\n",
            "Train Epoch: 0 [2135/3978 (54%)]\tLoss: 0.133301\n",
            "Train Epoch: 0 [2140/3978 (54%)]\tLoss: 0.429156\n",
            "Train Epoch: 0 [2145/3978 (54%)]\tLoss: 0.223739\n",
            "Train Epoch: 0 [2150/3978 (54%)]\tLoss: 0.093829\n",
            "Train Epoch: 0 [2155/3978 (54%)]\tLoss: 0.495234\n",
            "Train Epoch: 0 [2160/3978 (54%)]\tLoss: 0.206223\n",
            "Train Epoch: 0 [2165/3978 (54%)]\tLoss: 0.129250\n",
            "Train Epoch: 0 [2170/3978 (55%)]\tLoss: 0.616502\n",
            "Train Epoch: 0 [2175/3978 (55%)]\tLoss: 0.343139\n",
            "Train Epoch: 0 [2180/3978 (55%)]\tLoss: 0.347234\n",
            "Train Epoch: 0 [2185/3978 (55%)]\tLoss: 0.113007\n",
            "Train Epoch: 0 [2190/3978 (55%)]\tLoss: 0.212053\n",
            "Train Epoch: 0 [2195/3978 (55%)]\tLoss: 0.084514\n",
            "Train Epoch: 0 [2200/3978 (55%)]\tLoss: 0.127271\n",
            "Train Epoch: 0 [2205/3978 (55%)]\tLoss: 0.594025\n",
            "Train Epoch: 0 [2210/3978 (56%)]\tLoss: 0.377027\n",
            "Train Epoch: 0 [2215/3978 (56%)]\tLoss: 0.190772\n",
            "Train Epoch: 0 [2220/3978 (56%)]\tLoss: 0.132867\n",
            "Train Epoch: 0 [2225/3978 (56%)]\tLoss: 0.077345\n",
            "Train Epoch: 0 [2230/3978 (56%)]\tLoss: 0.078975\n",
            "Train Epoch: 0 [2235/3978 (56%)]\tLoss: 0.308218\n",
            "Train Epoch: 0 [2240/3978 (56%)]\tLoss: 0.444372\n",
            "Train Epoch: 0 [2245/3978 (56%)]\tLoss: 0.062740\n",
            "Train Epoch: 0 [2250/3978 (57%)]\tLoss: 0.340329\n",
            "Train Epoch: 0 [2255/3978 (57%)]\tLoss: 0.090641\n",
            "Train Epoch: 0 [2260/3978 (57%)]\tLoss: 0.241550\n",
            "Train Epoch: 0 [2265/3978 (57%)]\tLoss: 0.196027\n",
            "Train Epoch: 0 [2270/3978 (57%)]\tLoss: 0.355857\n",
            "Train Epoch: 0 [2275/3978 (57%)]\tLoss: 0.294752\n",
            "Train Epoch: 0 [2280/3978 (57%)]\tLoss: 0.171952\n",
            "Train Epoch: 0 [2285/3978 (57%)]\tLoss: 0.233591\n",
            "Train Epoch: 0 [2290/3978 (58%)]\tLoss: 0.186825\n",
            "Train Epoch: 0 [2295/3978 (58%)]\tLoss: 0.022566\n",
            "Train Epoch: 0 [2300/3978 (58%)]\tLoss: 0.331941\n",
            "Train Epoch: 0 [2305/3978 (58%)]\tLoss: 0.314137\n",
            "Train Epoch: 0 [2310/3978 (58%)]\tLoss: 0.284782\n",
            "Train Epoch: 0 [2315/3978 (58%)]\tLoss: 0.536345\n",
            "Train Epoch: 0 [2320/3978 (58%)]\tLoss: 0.207946\n",
            "Train Epoch: 0 [2325/3978 (58%)]\tLoss: 0.249288\n",
            "Train Epoch: 0 [2330/3978 (59%)]\tLoss: 0.334886\n",
            "Train Epoch: 0 [2335/3978 (59%)]\tLoss: 0.271927\n",
            "Train Epoch: 0 [2340/3978 (59%)]\tLoss: 0.392325\n",
            "Train Epoch: 0 [2345/3978 (59%)]\tLoss: 0.183669\n",
            "Train Epoch: 0 [2350/3978 (59%)]\tLoss: 0.120391\n",
            "Train Epoch: 0 [2355/3978 (59%)]\tLoss: 0.119497\n",
            "Train Epoch: 0 [2360/3978 (59%)]\tLoss: 0.086939\n",
            "Train Epoch: 0 [2365/3978 (59%)]\tLoss: 0.431903\n",
            "Train Epoch: 0 [2370/3978 (60%)]\tLoss: 0.226220\n",
            "Train Epoch: 0 [2375/3978 (60%)]\tLoss: 0.294101\n",
            "Train Epoch: 0 [2380/3978 (60%)]\tLoss: 0.617461\n",
            "Train Epoch: 0 [2385/3978 (60%)]\tLoss: 0.333772\n",
            "Train Epoch: 0 [2390/3978 (60%)]\tLoss: 0.295616\n",
            "Train Epoch: 0 [2395/3978 (60%)]\tLoss: 0.217258\n",
            "Train Epoch: 0 [2400/3978 (60%)]\tLoss: 0.100760\n",
            "Train Epoch: 0 [2405/3978 (60%)]\tLoss: 0.434311\n",
            "Train Epoch: 0 [2410/3978 (61%)]\tLoss: 0.166542\n",
            "Train Epoch: 0 [2415/3978 (61%)]\tLoss: 0.109670\n",
            "Train Epoch: 0 [2420/3978 (61%)]\tLoss: 0.250883\n",
            "Train Epoch: 0 [2425/3978 (61%)]\tLoss: 0.335541\n",
            "Train Epoch: 0 [2430/3978 (61%)]\tLoss: 0.226762\n",
            "Train Epoch: 0 [2435/3978 (61%)]\tLoss: 0.365213\n",
            "Train Epoch: 0 [2440/3978 (61%)]\tLoss: 0.376156\n",
            "Train Epoch: 0 [2445/3978 (61%)]\tLoss: 0.225943\n",
            "Train Epoch: 0 [2450/3978 (62%)]\tLoss: 0.061565\n",
            "Train Epoch: 0 [2455/3978 (62%)]\tLoss: 0.172904\n",
            "Train Epoch: 0 [2460/3978 (62%)]\tLoss: 0.605856\n",
            "Train Epoch: 0 [2465/3978 (62%)]\tLoss: 0.233474\n",
            "Train Epoch: 0 [2470/3978 (62%)]\tLoss: 0.057578\n",
            "Train Epoch: 0 [2475/3978 (62%)]\tLoss: 0.512573\n",
            "Train Epoch: 0 [2480/3978 (62%)]\tLoss: 0.239707\n",
            "Train Epoch: 0 [2485/3978 (62%)]\tLoss: 0.344166\n",
            "Train Epoch: 0 [2490/3978 (63%)]\tLoss: 0.237025\n",
            "Train Epoch: 0 [2495/3978 (63%)]\tLoss: 0.440097\n",
            "Train Epoch: 0 [2500/3978 (63%)]\tLoss: 0.403721\n",
            "Train Epoch: 0 [2505/3978 (63%)]\tLoss: 0.122196\n",
            "Train Epoch: 0 [2510/3978 (63%)]\tLoss: 0.225029\n",
            "Train Epoch: 0 [2515/3978 (63%)]\tLoss: 0.271729\n",
            "Train Epoch: 0 [2520/3978 (63%)]\tLoss: 0.121537\n",
            "Train Epoch: 0 [2525/3978 (63%)]\tLoss: 0.271614\n",
            "Train Epoch: 0 [2530/3978 (64%)]\tLoss: 0.344778\n",
            "Train Epoch: 0 [2535/3978 (64%)]\tLoss: 0.503828\n",
            "Train Epoch: 0 [2540/3978 (64%)]\tLoss: 0.394258\n",
            "Train Epoch: 0 [2545/3978 (64%)]\tLoss: 0.202409\n",
            "Train Epoch: 0 [2550/3978 (64%)]\tLoss: 0.125937\n",
            "Train Epoch: 0 [2555/3978 (64%)]\tLoss: 0.087411\n",
            "Train Epoch: 0 [2560/3978 (64%)]\tLoss: 0.093556\n",
            "Train Epoch: 0 [2565/3978 (64%)]\tLoss: 0.082021\n",
            "Train Epoch: 0 [2570/3978 (65%)]\tLoss: 0.279451\n",
            "Train Epoch: 0 [2575/3978 (65%)]\tLoss: 0.076723\n",
            "Train Epoch: 0 [2580/3978 (65%)]\tLoss: 0.218417\n",
            "Train Epoch: 0 [2585/3978 (65%)]\tLoss: 0.034231\n",
            "Train Epoch: 0 [2590/3978 (65%)]\tLoss: 0.157478\n",
            "Train Epoch: 0 [2595/3978 (65%)]\tLoss: 0.031049\n",
            "Train Epoch: 0 [2600/3978 (65%)]\tLoss: 0.710946\n",
            "Train Epoch: 0 [2605/3978 (65%)]\tLoss: 0.504611\n",
            "Train Epoch: 0 [2610/3978 (66%)]\tLoss: 0.330615\n",
            "Train Epoch: 0 [2615/3978 (66%)]\tLoss: 0.031993\n",
            "Train Epoch: 0 [2620/3978 (66%)]\tLoss: 0.463213\n",
            "Train Epoch: 0 [2625/3978 (66%)]\tLoss: 0.130931\n",
            "Train Epoch: 0 [2630/3978 (66%)]\tLoss: 0.337683\n",
            "Train Epoch: 0 [2635/3978 (66%)]\tLoss: 0.102079\n",
            "Train Epoch: 0 [2640/3978 (66%)]\tLoss: 0.578281\n",
            "Train Epoch: 0 [2645/3978 (66%)]\tLoss: 0.170858\n",
            "Train Epoch: 0 [2650/3978 (67%)]\tLoss: 0.220749\n",
            "Train Epoch: 0 [2655/3978 (67%)]\tLoss: 0.256684\n",
            "Train Epoch: 0 [2660/3978 (67%)]\tLoss: 0.384361\n",
            "Train Epoch: 0 [2665/3978 (67%)]\tLoss: 0.106702\n",
            "Train Epoch: 0 [2670/3978 (67%)]\tLoss: 0.111434\n",
            "Train Epoch: 0 [2675/3978 (67%)]\tLoss: 0.176167\n",
            "Train Epoch: 0 [2680/3978 (67%)]\tLoss: 0.123638\n",
            "Train Epoch: 0 [2685/3978 (67%)]\tLoss: 0.115666\n",
            "Train Epoch: 0 [2690/3978 (68%)]\tLoss: 0.174773\n",
            "Train Epoch: 0 [2695/3978 (68%)]\tLoss: 0.108556\n",
            "Train Epoch: 0 [2700/3978 (68%)]\tLoss: 0.280108\n",
            "Train Epoch: 0 [2705/3978 (68%)]\tLoss: 0.227542\n",
            "Train Epoch: 0 [2710/3978 (68%)]\tLoss: 0.276174\n",
            "Train Epoch: 0 [2715/3978 (68%)]\tLoss: 0.465949\n",
            "Train Epoch: 0 [2720/3978 (68%)]\tLoss: 0.530373\n",
            "Train Epoch: 0 [2725/3978 (68%)]\tLoss: 0.427355\n",
            "Train Epoch: 0 [2730/3978 (69%)]\tLoss: 0.221385\n",
            "Train Epoch: 0 [2735/3978 (69%)]\tLoss: 0.203930\n",
            "Train Epoch: 0 [2740/3978 (69%)]\tLoss: 0.083715\n",
            "Train Epoch: 0 [2745/3978 (69%)]\tLoss: 0.077389\n",
            "Train Epoch: 0 [2750/3978 (69%)]\tLoss: 0.075397\n",
            "Train Epoch: 0 [2755/3978 (69%)]\tLoss: 0.050030\n",
            "Train Epoch: 0 [2760/3978 (69%)]\tLoss: 0.191860\n",
            "Train Epoch: 0 [2765/3978 (69%)]\tLoss: 0.320476\n",
            "Train Epoch: 0 [2770/3978 (70%)]\tLoss: 0.496327\n",
            "Train Epoch: 0 [2775/3978 (70%)]\tLoss: 0.077203\n",
            "Train Epoch: 0 [2780/3978 (70%)]\tLoss: 0.280013\n",
            "Train Epoch: 0 [2785/3978 (70%)]\tLoss: 0.194085\n",
            "Train Epoch: 0 [2790/3978 (70%)]\tLoss: 0.071368\n",
            "Train Epoch: 0 [2795/3978 (70%)]\tLoss: 0.075295\n",
            "Train Epoch: 0 [2800/3978 (70%)]\tLoss: 0.198360\n",
            "Train Epoch: 0 [2805/3978 (70%)]\tLoss: 0.077515\n",
            "Train Epoch: 0 [2810/3978 (71%)]\tLoss: 0.187526\n",
            "Train Epoch: 0 [2815/3978 (71%)]\tLoss: 0.365994\n",
            "Train Epoch: 0 [2820/3978 (71%)]\tLoss: 0.072103\n",
            "Train Epoch: 0 [2825/3978 (71%)]\tLoss: 0.255863\n",
            "Train Epoch: 0 [2830/3978 (71%)]\tLoss: 0.212083\n",
            "Train Epoch: 0 [2835/3978 (71%)]\tLoss: 0.058958\n",
            "Train Epoch: 0 [2840/3978 (71%)]\tLoss: 0.318103\n",
            "Train Epoch: 0 [2845/3978 (71%)]\tLoss: 0.415030\n",
            "Train Epoch: 0 [2850/3978 (72%)]\tLoss: 0.089960\n",
            "Train Epoch: 0 [2855/3978 (72%)]\tLoss: 0.102813\n",
            "Train Epoch: 0 [2860/3978 (72%)]\tLoss: 0.212188\n",
            "Train Epoch: 0 [2865/3978 (72%)]\tLoss: 0.362610\n",
            "Train Epoch: 0 [2870/3978 (72%)]\tLoss: 0.417199\n",
            "Train Epoch: 0 [2875/3978 (72%)]\tLoss: 0.211390\n",
            "Train Epoch: 0 [2880/3978 (72%)]\tLoss: 0.536719\n",
            "Train Epoch: 0 [2885/3978 (72%)]\tLoss: 0.162622\n",
            "Train Epoch: 0 [2890/3978 (73%)]\tLoss: 0.163447\n",
            "Train Epoch: 0 [2895/3978 (73%)]\tLoss: 0.208575\n",
            "Train Epoch: 0 [2900/3978 (73%)]\tLoss: 0.748020\n",
            "Train Epoch: 0 [2905/3978 (73%)]\tLoss: 0.094234\n",
            "Train Epoch: 0 [2910/3978 (73%)]\tLoss: 0.517963\n",
            "Train Epoch: 0 [2915/3978 (73%)]\tLoss: 0.163914\n",
            "Train Epoch: 0 [2920/3978 (73%)]\tLoss: 0.568441\n",
            "Train Epoch: 0 [2925/3978 (73%)]\tLoss: 0.277360\n",
            "Train Epoch: 0 [2930/3978 (74%)]\tLoss: 0.293501\n",
            "Train Epoch: 0 [2935/3978 (74%)]\tLoss: 0.086437\n",
            "Train Epoch: 0 [2940/3978 (74%)]\tLoss: 0.422844\n",
            "Train Epoch: 0 [2945/3978 (74%)]\tLoss: 0.491889\n",
            "Train Epoch: 0 [2950/3978 (74%)]\tLoss: 0.385574\n",
            "Train Epoch: 0 [2955/3978 (74%)]\tLoss: 0.320181\n",
            "Train Epoch: 0 [2960/3978 (74%)]\tLoss: 0.239759\n",
            "Train Epoch: 0 [2965/3978 (74%)]\tLoss: 0.319910\n",
            "Train Epoch: 0 [2970/3978 (75%)]\tLoss: 0.182349\n",
            "Train Epoch: 0 [2975/3978 (75%)]\tLoss: 0.209487\n",
            "Train Epoch: 0 [2980/3978 (75%)]\tLoss: 0.493051\n",
            "Train Epoch: 0 [2985/3978 (75%)]\tLoss: 0.315419\n",
            "Train Epoch: 0 [2990/3978 (75%)]\tLoss: 0.107445\n",
            "Train Epoch: 0 [2995/3978 (75%)]\tLoss: 0.220823\n",
            "Train Epoch: 0 [3000/3978 (75%)]\tLoss: 0.209638\n",
            "Train Epoch: 0 [3005/3978 (76%)]\tLoss: 0.099476\n",
            "Train Epoch: 0 [3010/3978 (76%)]\tLoss: 0.449321\n",
            "Train Epoch: 0 [3015/3978 (76%)]\tLoss: 0.105123\n",
            "Train Epoch: 0 [3020/3978 (76%)]\tLoss: 0.411656\n",
            "Train Epoch: 0 [3025/3978 (76%)]\tLoss: 0.093253\n",
            "Train Epoch: 0 [3030/3978 (76%)]\tLoss: 0.113182\n",
            "Train Epoch: 0 [3035/3978 (76%)]\tLoss: 0.266378\n",
            "Train Epoch: 0 [3040/3978 (76%)]\tLoss: 0.147795\n",
            "Train Epoch: 0 [3045/3978 (77%)]\tLoss: 0.177126\n",
            "Train Epoch: 0 [3050/3978 (77%)]\tLoss: 0.095344\n",
            "Train Epoch: 0 [3055/3978 (77%)]\tLoss: 0.085912\n",
            "Train Epoch: 0 [3060/3978 (77%)]\tLoss: 0.643523\n",
            "Train Epoch: 0 [3065/3978 (77%)]\tLoss: 0.171546\n",
            "Train Epoch: 0 [3070/3978 (77%)]\tLoss: 0.174074\n",
            "Train Epoch: 0 [3075/3978 (77%)]\tLoss: 0.212313\n",
            "Train Epoch: 0 [3080/3978 (77%)]\tLoss: 0.175363\n",
            "Train Epoch: 0 [3085/3978 (78%)]\tLoss: 0.066278\n",
            "Train Epoch: 0 [3090/3978 (78%)]\tLoss: 0.274359\n",
            "Train Epoch: 0 [3095/3978 (78%)]\tLoss: 0.313333\n",
            "Train Epoch: 0 [3100/3978 (78%)]\tLoss: 0.427614\n",
            "Train Epoch: 0 [3105/3978 (78%)]\tLoss: 0.082075\n",
            "Train Epoch: 0 [3110/3978 (78%)]\tLoss: 0.170285\n",
            "Train Epoch: 0 [3115/3978 (78%)]\tLoss: 0.244244\n",
            "Train Epoch: 0 [3120/3978 (78%)]\tLoss: 0.204689\n",
            "Train Epoch: 0 [3125/3978 (79%)]\tLoss: 0.248292\n",
            "Train Epoch: 0 [3130/3978 (79%)]\tLoss: 0.076091\n",
            "Train Epoch: 0 [3135/3978 (79%)]\tLoss: 0.234085\n",
            "Train Epoch: 0 [3140/3978 (79%)]\tLoss: 0.090236\n",
            "Train Epoch: 0 [3145/3978 (79%)]\tLoss: 0.084892\n",
            "Train Epoch: 0 [3150/3978 (79%)]\tLoss: 0.512548\n",
            "Train Epoch: 0 [3155/3978 (79%)]\tLoss: 0.333887\n",
            "Train Epoch: 0 [3160/3978 (79%)]\tLoss: 0.305799\n",
            "Train Epoch: 0 [3165/3978 (80%)]\tLoss: 0.284900\n",
            "Train Epoch: 0 [3170/3978 (80%)]\tLoss: 0.416591\n",
            "Train Epoch: 0 [3175/3978 (80%)]\tLoss: 0.293527\n",
            "Train Epoch: 0 [3180/3978 (80%)]\tLoss: 0.135278\n",
            "Train Epoch: 0 [3185/3978 (80%)]\tLoss: 0.419374\n",
            "Train Epoch: 0 [3190/3978 (80%)]\tLoss: 0.456283\n",
            "Train Epoch: 0 [3195/3978 (80%)]\tLoss: 0.161289\n",
            "Train Epoch: 0 [3200/3978 (80%)]\tLoss: 0.144243\n",
            "Train Epoch: 0 [3205/3978 (81%)]\tLoss: 0.143005\n",
            "Train Epoch: 0 [3210/3978 (81%)]\tLoss: 0.252322\n",
            "Train Epoch: 0 [3215/3978 (81%)]\tLoss: 0.189760\n",
            "Train Epoch: 0 [3220/3978 (81%)]\tLoss: 0.116185\n",
            "Train Epoch: 0 [3225/3978 (81%)]\tLoss: 0.198986\n",
            "Train Epoch: 0 [3230/3978 (81%)]\tLoss: 0.326423\n",
            "Train Epoch: 0 [3235/3978 (81%)]\tLoss: 0.251219\n",
            "Train Epoch: 0 [3240/3978 (81%)]\tLoss: 0.190559\n",
            "Train Epoch: 0 [3245/3978 (82%)]\tLoss: 0.348421\n",
            "Train Epoch: 0 [3250/3978 (82%)]\tLoss: 0.683460\n",
            "Train Epoch: 0 [3255/3978 (82%)]\tLoss: 0.468460\n",
            "Train Epoch: 0 [3260/3978 (82%)]\tLoss: 0.057303\n",
            "Train Epoch: 0 [3265/3978 (82%)]\tLoss: 0.177858\n",
            "Train Epoch: 0 [3270/3978 (82%)]\tLoss: 0.143066\n",
            "Train Epoch: 0 [3275/3978 (82%)]\tLoss: 0.062587\n",
            "Train Epoch: 0 [3280/3978 (82%)]\tLoss: 0.334484\n",
            "Train Epoch: 0 [3285/3978 (83%)]\tLoss: 0.403197\n",
            "Train Epoch: 0 [3290/3978 (83%)]\tLoss: 0.249253\n",
            "Train Epoch: 0 [3295/3978 (83%)]\tLoss: 0.114492\n",
            "Train Epoch: 0 [3300/3978 (83%)]\tLoss: 0.079947\n",
            "Train Epoch: 0 [3305/3978 (83%)]\tLoss: 0.189350\n",
            "Train Epoch: 0 [3310/3978 (83%)]\tLoss: 0.175635\n",
            "Train Epoch: 0 [3315/3978 (83%)]\tLoss: 0.234086\n",
            "Train Epoch: 0 [3320/3978 (83%)]\tLoss: 0.117781\n",
            "Train Epoch: 0 [3325/3978 (84%)]\tLoss: 0.264629\n",
            "Train Epoch: 0 [3330/3978 (84%)]\tLoss: 0.131436\n",
            "Train Epoch: 0 [3335/3978 (84%)]\tLoss: 0.101171\n",
            "Train Epoch: 0 [3340/3978 (84%)]\tLoss: 0.473019\n",
            "Train Epoch: 0 [3345/3978 (84%)]\tLoss: 0.146135\n",
            "Train Epoch: 0 [3350/3978 (84%)]\tLoss: 0.223028\n",
            "Train Epoch: 0 [3355/3978 (84%)]\tLoss: 0.491863\n",
            "Train Epoch: 0 [3360/3978 (84%)]\tLoss: 0.078161\n",
            "Train Epoch: 0 [3365/3978 (85%)]\tLoss: 0.085765\n",
            "Train Epoch: 0 [3370/3978 (85%)]\tLoss: 0.197632\n",
            "Train Epoch: 0 [3375/3978 (85%)]\tLoss: 0.079120\n",
            "Train Epoch: 0 [3380/3978 (85%)]\tLoss: 0.156838\n",
            "Train Epoch: 0 [3385/3978 (85%)]\tLoss: 0.239133\n",
            "Train Epoch: 0 [3390/3978 (85%)]\tLoss: 0.350157\n",
            "Train Epoch: 0 [3395/3978 (85%)]\tLoss: 0.367057\n",
            "Train Epoch: 0 [3400/3978 (85%)]\tLoss: 0.703637\n",
            "Train Epoch: 0 [3405/3978 (86%)]\tLoss: 0.139482\n",
            "Train Epoch: 0 [3410/3978 (86%)]\tLoss: 0.290973\n",
            "Train Epoch: 0 [3415/3978 (86%)]\tLoss: 0.583436\n",
            "Train Epoch: 0 [3420/3978 (86%)]\tLoss: 0.430089\n",
            "Train Epoch: 0 [3425/3978 (86%)]\tLoss: 0.156252\n",
            "Train Epoch: 0 [3430/3978 (86%)]\tLoss: 0.408220\n",
            "Train Epoch: 0 [3435/3978 (86%)]\tLoss: 0.517120\n",
            "Train Epoch: 0 [3440/3978 (86%)]\tLoss: 0.273005\n",
            "Train Epoch: 0 [3445/3978 (87%)]\tLoss: 0.115256\n",
            "Train Epoch: 0 [3450/3978 (87%)]\tLoss: 0.302408\n",
            "Train Epoch: 0 [3455/3978 (87%)]\tLoss: 0.184551\n",
            "Train Epoch: 0 [3460/3978 (87%)]\tLoss: 0.444059\n",
            "Train Epoch: 0 [3465/3978 (87%)]\tLoss: 0.191589\n",
            "Train Epoch: 0 [3470/3978 (87%)]\tLoss: 0.287599\n",
            "Train Epoch: 0 [3475/3978 (87%)]\tLoss: 0.269764\n",
            "Train Epoch: 0 [3480/3978 (87%)]\tLoss: 0.392876\n",
            "Train Epoch: 0 [3485/3978 (88%)]\tLoss: 0.268406\n",
            "Train Epoch: 0 [3490/3978 (88%)]\tLoss: 0.144035\n",
            "Train Epoch: 0 [3495/3978 (88%)]\tLoss: 0.206979\n",
            "Train Epoch: 0 [3500/3978 (88%)]\tLoss: 0.297318\n",
            "Train Epoch: 0 [3505/3978 (88%)]\tLoss: 0.165164\n",
            "Train Epoch: 0 [3510/3978 (88%)]\tLoss: 0.162386\n",
            "Train Epoch: 0 [3515/3978 (88%)]\tLoss: 0.065909\n",
            "Train Epoch: 0 [3520/3978 (88%)]\tLoss: 0.109332\n",
            "Train Epoch: 0 [3525/3978 (89%)]\tLoss: 0.316611\n",
            "Train Epoch: 0 [3530/3978 (89%)]\tLoss: 0.391285\n",
            "Train Epoch: 0 [3535/3978 (89%)]\tLoss: 0.147833\n",
            "Train Epoch: 0 [3540/3978 (89%)]\tLoss: 0.185983\n",
            "Train Epoch: 0 [3545/3978 (89%)]\tLoss: 0.516753\n",
            "Train Epoch: 0 [3550/3978 (89%)]\tLoss: 0.333054\n",
            "Train Epoch: 0 [3555/3978 (89%)]\tLoss: 0.094064\n",
            "Train Epoch: 0 [3560/3978 (89%)]\tLoss: 0.085935\n",
            "Train Epoch: 0 [3565/3978 (90%)]\tLoss: 0.076615\n",
            "Train Epoch: 0 [3570/3978 (90%)]\tLoss: 0.072475\n",
            "Train Epoch: 0 [3575/3978 (90%)]\tLoss: 0.071258\n",
            "Train Epoch: 0 [3580/3978 (90%)]\tLoss: 0.470871\n",
            "Train Epoch: 0 [3585/3978 (90%)]\tLoss: 0.341651\n",
            "Train Epoch: 0 [3590/3978 (90%)]\tLoss: 0.311564\n",
            "Train Epoch: 0 [3595/3978 (90%)]\tLoss: 0.033371\n",
            "Train Epoch: 0 [3600/3978 (90%)]\tLoss: 0.178297\n",
            "Train Epoch: 0 [3605/3978 (91%)]\tLoss: 0.042741\n",
            "Train Epoch: 0 [3610/3978 (91%)]\tLoss: 0.314102\n",
            "Train Epoch: 0 [3615/3978 (91%)]\tLoss: 0.080816\n",
            "Train Epoch: 0 [3620/3978 (91%)]\tLoss: 0.725471\n",
            "Train Epoch: 0 [3625/3978 (91%)]\tLoss: 0.272452\n",
            "Train Epoch: 0 [3630/3978 (91%)]\tLoss: 0.286963\n",
            "Train Epoch: 0 [3635/3978 (91%)]\tLoss: 0.208918\n",
            "Train Epoch: 0 [3640/3978 (91%)]\tLoss: 0.316611\n",
            "Train Epoch: 0 [3645/3978 (92%)]\tLoss: 0.367816\n",
            "Train Epoch: 0 [3650/3978 (92%)]\tLoss: 0.101163\n",
            "Train Epoch: 0 [3655/3978 (92%)]\tLoss: 0.105596\n",
            "Train Epoch: 0 [3660/3978 (92%)]\tLoss: 0.092231\n",
            "Train Epoch: 0 [3665/3978 (92%)]\tLoss: 0.456439\n",
            "Train Epoch: 0 [3670/3978 (92%)]\tLoss: 0.202049\n",
            "Train Epoch: 0 [3675/3978 (92%)]\tLoss: 0.650079\n",
            "Train Epoch: 0 [3680/3978 (92%)]\tLoss: 0.276317\n",
            "Train Epoch: 0 [3685/3978 (93%)]\tLoss: 0.071969\n",
            "Train Epoch: 0 [3690/3978 (93%)]\tLoss: 0.087903\n",
            "Train Epoch: 0 [3695/3978 (93%)]\tLoss: 0.335389\n",
            "Train Epoch: 0 [3700/3978 (93%)]\tLoss: 0.131361\n",
            "Train Epoch: 0 [3705/3978 (93%)]\tLoss: 0.349023\n",
            "Train Epoch: 0 [3710/3978 (93%)]\tLoss: 0.212392\n",
            "Train Epoch: 0 [3715/3978 (93%)]\tLoss: 0.308300\n",
            "Train Epoch: 0 [3720/3978 (93%)]\tLoss: 0.133770\n",
            "Train Epoch: 0 [3725/3978 (94%)]\tLoss: 0.713436\n",
            "Train Epoch: 0 [3730/3978 (94%)]\tLoss: 0.460332\n",
            "Train Epoch: 0 [3735/3978 (94%)]\tLoss: 0.137754\n",
            "Train Epoch: 0 [3740/3978 (94%)]\tLoss: 0.098018\n",
            "Train Epoch: 0 [3745/3978 (94%)]\tLoss: 0.254996\n",
            "Train Epoch: 0 [3750/3978 (94%)]\tLoss: 0.245981\n",
            "Train Epoch: 0 [3755/3978 (94%)]\tLoss: 0.201102\n",
            "Train Epoch: 0 [3760/3978 (94%)]\tLoss: 0.159577\n",
            "Train Epoch: 0 [3765/3978 (95%)]\tLoss: 0.193411\n",
            "Train Epoch: 0 [3770/3978 (95%)]\tLoss: 0.161330\n",
            "Train Epoch: 0 [3775/3978 (95%)]\tLoss: 0.052543\n",
            "Train Epoch: 0 [3780/3978 (95%)]\tLoss: 0.318230\n",
            "Train Epoch: 0 [3785/3978 (95%)]\tLoss: 0.085580\n",
            "Train Epoch: 0 [3790/3978 (95%)]\tLoss: 0.183060\n",
            "Train Epoch: 0 [3795/3978 (95%)]\tLoss: 0.226915\n",
            "Train Epoch: 0 [3800/3978 (95%)]\tLoss: 0.198445\n",
            "Train Epoch: 0 [3805/3978 (96%)]\tLoss: 0.161164\n",
            "Train Epoch: 0 [3810/3978 (96%)]\tLoss: 0.517423\n",
            "Train Epoch: 0 [3815/3978 (96%)]\tLoss: 0.070902\n",
            "Train Epoch: 0 [3820/3978 (96%)]\tLoss: 0.198324\n",
            "Train Epoch: 0 [3825/3978 (96%)]\tLoss: 0.570321\n",
            "Train Epoch: 0 [3830/3978 (96%)]\tLoss: 0.184803\n",
            "Train Epoch: 0 [3835/3978 (96%)]\tLoss: 0.025546\n",
            "Train Epoch: 0 [3840/3978 (96%)]\tLoss: 0.112044\n",
            "Train Epoch: 0 [3845/3978 (97%)]\tLoss: 1.057693\n",
            "Train Epoch: 0 [3850/3978 (97%)]\tLoss: 0.567470\n",
            "Train Epoch: 0 [3855/3978 (97%)]\tLoss: 0.394075\n",
            "Train Epoch: 0 [3860/3978 (97%)]\tLoss: 0.214573\n",
            "Train Epoch: 0 [3865/3978 (97%)]\tLoss: 0.415741\n",
            "Train Epoch: 0 [3870/3978 (97%)]\tLoss: 0.132751\n",
            "Train Epoch: 0 [3875/3978 (97%)]\tLoss: 0.087823\n",
            "Train Epoch: 0 [3880/3978 (97%)]\tLoss: 0.644280\n",
            "Train Epoch: 0 [3885/3978 (98%)]\tLoss: 0.286749\n",
            "Train Epoch: 0 [3890/3978 (98%)]\tLoss: 0.349321\n",
            "Train Epoch: 0 [3895/3978 (98%)]\tLoss: 0.248894\n",
            "Train Epoch: 0 [3900/3978 (98%)]\tLoss: 0.516878\n",
            "Train Epoch: 0 [3905/3978 (98%)]\tLoss: 0.642933\n",
            "Train Epoch: 0 [3910/3978 (98%)]\tLoss: 0.123215\n",
            "Train Epoch: 0 [3915/3978 (98%)]\tLoss: 0.194750\n",
            "Train Epoch: 0 [3920/3978 (98%)]\tLoss: 0.211736\n",
            "Train Epoch: 0 [3925/3978 (99%)]\tLoss: 0.259269\n",
            "Train Epoch: 0 [3930/3978 (99%)]\tLoss: 0.120646\n",
            "Train Epoch: 0 [3935/3978 (99%)]\tLoss: 0.111606\n",
            "Train Epoch: 0 [3940/3978 (99%)]\tLoss: 0.175761\n",
            "Train Epoch: 0 [3945/3978 (99%)]\tLoss: 0.184061\n",
            "Train Epoch: 0 [3950/3978 (99%)]\tLoss: 0.638517\n",
            "Train Epoch: 0 [3955/3978 (99%)]\tLoss: 0.289890\n",
            "Train Epoch: 0 [3960/3978 (99%)]\tLoss: 0.103330\n",
            "Train Epoch: 0 [3965/3978 (100%)]\tLoss: 0.227313\n",
            "Train Epoch: 0 [3970/3978 (100%)]\tLoss: 0.250412\n",
            "Train Epoch: 0 [2385/3978 (100%)]\tLoss: 0.214669\n",
            "Epoch\n",
            "train/train_loss: 0.21466882526874542\n",
            "\n",
            "Train Loss: 0.215, Valid Loss: 0.302981, Accuracy: 0.36\n",
            "Train Epoch: 1 [0/3978 (0%)]\tLoss: 0.094515\n",
            "Train Epoch: 1 [5/3978 (0%)]\tLoss: 0.150687\n",
            "Train Epoch: 1 [10/3978 (0%)]\tLoss: 0.093324\n",
            "Train Epoch: 1 [15/3978 (0%)]\tLoss: 0.340479\n",
            "Train Epoch: 1 [20/3978 (1%)]\tLoss: 0.150431\n",
            "Train Epoch: 1 [25/3978 (1%)]\tLoss: 0.324880\n",
            "Train Epoch: 1 [30/3978 (1%)]\tLoss: 0.404470\n",
            "Train Epoch: 1 [35/3978 (1%)]\tLoss: 0.094005\n",
            "Train Epoch: 1 [40/3978 (1%)]\tLoss: 0.291550\n",
            "Train Epoch: 1 [45/3978 (1%)]\tLoss: 0.093299\n",
            "Train Epoch: 1 [50/3978 (1%)]\tLoss: 0.145006\n",
            "Train Epoch: 1 [55/3978 (1%)]\tLoss: 0.215655\n",
            "Train Epoch: 1 [60/3978 (2%)]\tLoss: 0.083602\n",
            "Train Epoch: 1 [65/3978 (2%)]\tLoss: 0.301496\n",
            "Train Epoch: 1 [70/3978 (2%)]\tLoss: 0.369168\n",
            "Train Epoch: 1 [75/3978 (2%)]\tLoss: 0.477012\n",
            "Train Epoch: 1 [80/3978 (2%)]\tLoss: 0.472217\n",
            "Train Epoch: 1 [85/3978 (2%)]\tLoss: 0.228280\n",
            "Train Epoch: 1 [90/3978 (2%)]\tLoss: 0.447213\n",
            "Train Epoch: 1 [95/3978 (2%)]\tLoss: 0.084368\n",
            "Train Epoch: 1 [100/3978 (3%)]\tLoss: 0.094192\n",
            "Train Epoch: 1 [105/3978 (3%)]\tLoss: 0.266886\n",
            "Train Epoch: 1 [110/3978 (3%)]\tLoss: 0.120166\n",
            "Train Epoch: 1 [115/3978 (3%)]\tLoss: 0.106787\n",
            "Train Epoch: 1 [120/3978 (3%)]\tLoss: 0.210927\n",
            "Train Epoch: 1 [125/3978 (3%)]\tLoss: 0.108713\n",
            "Train Epoch: 1 [130/3978 (3%)]\tLoss: 0.489229\n",
            "Train Epoch: 1 [135/3978 (3%)]\tLoss: 0.236714\n",
            "Train Epoch: 1 [140/3978 (4%)]\tLoss: 0.303429\n",
            "Train Epoch: 1 [145/3978 (4%)]\tLoss: 0.093813\n",
            "Train Epoch: 1 [150/3978 (4%)]\tLoss: 0.217021\n",
            "Train Epoch: 1 [155/3978 (4%)]\tLoss: 0.087968\n",
            "Train Epoch: 1 [160/3978 (4%)]\tLoss: 0.401399\n",
            "Train Epoch: 1 [165/3978 (4%)]\tLoss: 0.433900\n",
            "Train Epoch: 1 [170/3978 (4%)]\tLoss: 0.082900\n",
            "Train Epoch: 1 [175/3978 (4%)]\tLoss: 0.287912\n",
            "Train Epoch: 1 [180/3978 (5%)]\tLoss: 0.167435\n",
            "Train Epoch: 1 [185/3978 (5%)]\tLoss: 0.180912\n",
            "Train Epoch: 1 [190/3978 (5%)]\tLoss: 0.210882\n",
            "Train Epoch: 1 [195/3978 (5%)]\tLoss: 0.270122\n",
            "Train Epoch: 1 [200/3978 (5%)]\tLoss: 0.065839\n",
            "Train Epoch: 1 [205/3978 (5%)]\tLoss: 0.173255\n",
            "Train Epoch: 1 [210/3978 (5%)]\tLoss: 0.386006\n",
            "Train Epoch: 1 [215/3978 (5%)]\tLoss: 0.523443\n",
            "Train Epoch: 1 [220/3978 (6%)]\tLoss: 0.244123\n",
            "Train Epoch: 1 [225/3978 (6%)]\tLoss: 0.563868\n",
            "Train Epoch: 1 [230/3978 (6%)]\tLoss: 0.173726\n",
            "Train Epoch: 1 [235/3978 (6%)]\tLoss: 0.095523\n",
            "Train Epoch: 1 [240/3978 (6%)]\tLoss: 0.102310\n",
            "Train Epoch: 1 [245/3978 (6%)]\tLoss: 0.184626\n",
            "Train Epoch: 1 [250/3978 (6%)]\tLoss: 0.302481\n",
            "Train Epoch: 1 [255/3978 (6%)]\tLoss: 0.096468\n",
            "Train Epoch: 1 [260/3978 (7%)]\tLoss: 0.622502\n",
            "Train Epoch: 1 [265/3978 (7%)]\tLoss: 0.452867\n",
            "Train Epoch: 1 [270/3978 (7%)]\tLoss: 0.121155\n",
            "Train Epoch: 1 [275/3978 (7%)]\tLoss: 0.216054\n",
            "Train Epoch: 1 [280/3978 (7%)]\tLoss: 0.296542\n",
            "Train Epoch: 1 [285/3978 (7%)]\tLoss: 0.232186\n",
            "Train Epoch: 1 [290/3978 (7%)]\tLoss: 0.340489\n",
            "Train Epoch: 1 [295/3978 (7%)]\tLoss: 0.198910\n",
            "Train Epoch: 1 [300/3978 (8%)]\tLoss: 0.307913\n",
            "Train Epoch: 1 [305/3978 (8%)]\tLoss: 0.248425\n",
            "Train Epoch: 1 [310/3978 (8%)]\tLoss: 0.420497\n",
            "Train Epoch: 1 [315/3978 (8%)]\tLoss: 0.390159\n",
            "Train Epoch: 1 [320/3978 (8%)]\tLoss: 0.106718\n",
            "Train Epoch: 1 [325/3978 (8%)]\tLoss: 0.110451\n",
            "Train Epoch: 1 [330/3978 (8%)]\tLoss: 0.351473\n",
            "Train Epoch: 1 [335/3978 (8%)]\tLoss: 0.090460\n",
            "Train Epoch: 1 [340/3978 (9%)]\tLoss: 0.232551\n",
            "Train Epoch: 1 [345/3978 (9%)]\tLoss: 0.185555\n",
            "Train Epoch: 1 [350/3978 (9%)]\tLoss: 0.093303\n",
            "Train Epoch: 1 [355/3978 (9%)]\tLoss: 0.322552\n",
            "Train Epoch: 1 [360/3978 (9%)]\tLoss: 0.287044\n",
            "Train Epoch: 1 [365/3978 (9%)]\tLoss: 0.217146\n",
            "Train Epoch: 1 [370/3978 (9%)]\tLoss: 0.093262\n",
            "Train Epoch: 1 [375/3978 (9%)]\tLoss: 0.178807\n",
            "Train Epoch: 1 [380/3978 (10%)]\tLoss: 0.230047\n",
            "Train Epoch: 1 [385/3978 (10%)]\tLoss: 0.267796\n",
            "Train Epoch: 1 [390/3978 (10%)]\tLoss: 0.192243\n",
            "Train Epoch: 1 [395/3978 (10%)]\tLoss: 0.166878\n",
            "Train Epoch: 1 [400/3978 (10%)]\tLoss: 0.790639\n",
            "Train Epoch: 1 [405/3978 (10%)]\tLoss: 0.387030\n",
            "Train Epoch: 1 [410/3978 (10%)]\tLoss: 0.097300\n",
            "Train Epoch: 1 [415/3978 (10%)]\tLoss: 0.096885\n",
            "Train Epoch: 1 [420/3978 (11%)]\tLoss: 0.416254\n",
            "Train Epoch: 1 [425/3978 (11%)]\tLoss: 0.238708\n",
            "Train Epoch: 1 [430/3978 (11%)]\tLoss: 0.544354\n",
            "Train Epoch: 1 [435/3978 (11%)]\tLoss: 0.078108\n",
            "Train Epoch: 1 [440/3978 (11%)]\tLoss: 0.297816\n",
            "Train Epoch: 1 [445/3978 (11%)]\tLoss: 0.184429\n",
            "Train Epoch: 1 [450/3978 (11%)]\tLoss: 0.482742\n",
            "Train Epoch: 1 [455/3978 (11%)]\tLoss: 0.083396\n",
            "Train Epoch: 1 [460/3978 (12%)]\tLoss: 0.388093\n",
            "Train Epoch: 1 [465/3978 (12%)]\tLoss: 0.226570\n",
            "Train Epoch: 1 [470/3978 (12%)]\tLoss: 0.148657\n",
            "Train Epoch: 1 [475/3978 (12%)]\tLoss: 0.214480\n",
            "Train Epoch: 1 [480/3978 (12%)]\tLoss: 0.417527\n",
            "Train Epoch: 1 [485/3978 (12%)]\tLoss: 0.115229\n",
            "Train Epoch: 1 [490/3978 (12%)]\tLoss: 0.086891\n",
            "Train Epoch: 1 [495/3978 (12%)]\tLoss: 0.423026\n",
            "Train Epoch: 1 [500/3978 (13%)]\tLoss: 0.530367\n",
            "Train Epoch: 1 [505/3978 (13%)]\tLoss: 0.145802\n",
            "Train Epoch: 1 [510/3978 (13%)]\tLoss: 0.450111\n",
            "Train Epoch: 1 [515/3978 (13%)]\tLoss: 0.339105\n",
            "Train Epoch: 1 [520/3978 (13%)]\tLoss: 0.579577\n",
            "Train Epoch: 1 [525/3978 (13%)]\tLoss: 0.137722\n",
            "Train Epoch: 1 [530/3978 (13%)]\tLoss: 0.310103\n",
            "Train Epoch: 1 [535/3978 (13%)]\tLoss: 0.229188\n",
            "Train Epoch: 1 [540/3978 (14%)]\tLoss: 0.091449\n",
            "Train Epoch: 1 [545/3978 (14%)]\tLoss: 0.079360\n",
            "Train Epoch: 1 [550/3978 (14%)]\tLoss: 0.063878\n",
            "Train Epoch: 1 [555/3978 (14%)]\tLoss: 0.258704\n",
            "Train Epoch: 1 [560/3978 (14%)]\tLoss: 0.353096\n",
            "Train Epoch: 1 [565/3978 (14%)]\tLoss: 0.443243\n",
            "Train Epoch: 1 [570/3978 (14%)]\tLoss: 0.179363\n",
            "Train Epoch: 1 [575/3978 (14%)]\tLoss: 0.405616\n",
            "Train Epoch: 1 [580/3978 (15%)]\tLoss: 0.509260\n",
            "Train Epoch: 1 [585/3978 (15%)]\tLoss: 0.220847\n",
            "Train Epoch: 1 [590/3978 (15%)]\tLoss: 0.320458\n",
            "Train Epoch: 1 [595/3978 (15%)]\tLoss: 0.083945\n",
            "Train Epoch: 1 [600/3978 (15%)]\tLoss: 0.464964\n",
            "Train Epoch: 1 [605/3978 (15%)]\tLoss: 0.238104\n",
            "Train Epoch: 1 [610/3978 (15%)]\tLoss: 0.220294\n",
            "Train Epoch: 1 [615/3978 (15%)]\tLoss: 0.063507\n",
            "Train Epoch: 1 [620/3978 (16%)]\tLoss: 0.195684\n",
            "Train Epoch: 1 [625/3978 (16%)]\tLoss: 0.443610\n",
            "Train Epoch: 1 [630/3978 (16%)]\tLoss: 0.125799\n",
            "Train Epoch: 1 [635/3978 (16%)]\tLoss: 0.212895\n",
            "Train Epoch: 1 [640/3978 (16%)]\tLoss: 0.583486\n",
            "Train Epoch: 1 [645/3978 (16%)]\tLoss: 0.148012\n",
            "Train Epoch: 1 [650/3978 (16%)]\tLoss: 0.089338\n",
            "Train Epoch: 1 [655/3978 (16%)]\tLoss: 0.186595\n",
            "Train Epoch: 1 [660/3978 (17%)]\tLoss: 0.081022\n",
            "Train Epoch: 1 [665/3978 (17%)]\tLoss: 0.590229\n",
            "Train Epoch: 1 [670/3978 (17%)]\tLoss: 0.108882\n",
            "Train Epoch: 1 [675/3978 (17%)]\tLoss: 0.272240\n",
            "Train Epoch: 1 [680/3978 (17%)]\tLoss: 0.074593\n",
            "Train Epoch: 1 [685/3978 (17%)]\tLoss: 0.258588\n",
            "Train Epoch: 1 [690/3978 (17%)]\tLoss: 0.284699\n",
            "Train Epoch: 1 [695/3978 (17%)]\tLoss: 0.172994\n",
            "Train Epoch: 1 [700/3978 (18%)]\tLoss: 0.068585\n",
            "Train Epoch: 1 [705/3978 (18%)]\tLoss: 0.519987\n",
            "Train Epoch: 1 [710/3978 (18%)]\tLoss: 0.232193\n",
            "Train Epoch: 1 [715/3978 (18%)]\tLoss: 0.568646\n",
            "Train Epoch: 1 [720/3978 (18%)]\tLoss: 0.064465\n",
            "Train Epoch: 1 [725/3978 (18%)]\tLoss: 0.085191\n",
            "Train Epoch: 1 [730/3978 (18%)]\tLoss: 0.283468\n",
            "Train Epoch: 1 [735/3978 (18%)]\tLoss: 0.189162\n",
            "Train Epoch: 1 [740/3978 (19%)]\tLoss: 0.260917\n",
            "Train Epoch: 1 [745/3978 (19%)]\tLoss: 0.172720\n",
            "Train Epoch: 1 [750/3978 (19%)]\tLoss: 0.782344\n",
            "Train Epoch: 1 [755/3978 (19%)]\tLoss: 0.175444\n",
            "Train Epoch: 1 [760/3978 (19%)]\tLoss: 0.084413\n",
            "Train Epoch: 1 [765/3978 (19%)]\tLoss: 0.610405\n",
            "Train Epoch: 1 [770/3978 (19%)]\tLoss: 0.101258\n",
            "Train Epoch: 1 [775/3978 (19%)]\tLoss: 0.252026\n",
            "Train Epoch: 1 [780/3978 (20%)]\tLoss: 0.236273\n",
            "Train Epoch: 1 [785/3978 (20%)]\tLoss: 0.209667\n",
            "Train Epoch: 1 [790/3978 (20%)]\tLoss: 0.375483\n",
            "Train Epoch: 1 [795/3978 (20%)]\tLoss: 0.449818\n",
            "Train Epoch: 1 [800/3978 (20%)]\tLoss: 0.137534\n",
            "Train Epoch: 1 [805/3978 (20%)]\tLoss: 0.235148\n",
            "Train Epoch: 1 [810/3978 (20%)]\tLoss: 0.350611\n",
            "Train Epoch: 1 [815/3978 (20%)]\tLoss: 0.126154\n",
            "Train Epoch: 1 [820/3978 (21%)]\tLoss: 0.108763\n",
            "Train Epoch: 1 [825/3978 (21%)]\tLoss: 0.112563\n",
            "Train Epoch: 1 [830/3978 (21%)]\tLoss: 0.202465\n",
            "Train Epoch: 1 [835/3978 (21%)]\tLoss: 0.184986\n",
            "Train Epoch: 1 [840/3978 (21%)]\tLoss: 0.085743\n",
            "Train Epoch: 1 [845/3978 (21%)]\tLoss: 0.083620\n",
            "Train Epoch: 1 [850/3978 (21%)]\tLoss: 0.555371\n",
            "Train Epoch: 1 [855/3978 (21%)]\tLoss: 0.234073\n",
            "Train Epoch: 1 [860/3978 (22%)]\tLoss: 0.432260\n",
            "Train Epoch: 1 [865/3978 (22%)]\tLoss: 0.201535\n",
            "Train Epoch: 1 [870/3978 (22%)]\tLoss: 0.077734\n",
            "Train Epoch: 1 [875/3978 (22%)]\tLoss: 0.385523\n",
            "Train Epoch: 1 [880/3978 (22%)]\tLoss: 0.218654\n",
            "Train Epoch: 1 [885/3978 (22%)]\tLoss: 0.307100\n",
            "Train Epoch: 1 [890/3978 (22%)]\tLoss: 0.068362\n",
            "Train Epoch: 1 [895/3978 (22%)]\tLoss: 0.186616\n",
            "Train Epoch: 1 [900/3978 (23%)]\tLoss: 0.312078\n",
            "Train Epoch: 1 [905/3978 (23%)]\tLoss: 0.105987\n",
            "Train Epoch: 1 [910/3978 (23%)]\tLoss: 0.180593\n",
            "Train Epoch: 1 [915/3978 (23%)]\tLoss: 0.230383\n",
            "Train Epoch: 1 [920/3978 (23%)]\tLoss: 0.380670\n",
            "Train Epoch: 1 [925/3978 (23%)]\tLoss: 0.113018\n",
            "Train Epoch: 1 [930/3978 (23%)]\tLoss: 0.291318\n",
            "Train Epoch: 1 [935/3978 (23%)]\tLoss: 0.298728\n",
            "Train Epoch: 1 [940/3978 (24%)]\tLoss: 0.090159\n",
            "Train Epoch: 1 [945/3978 (24%)]\tLoss: 0.096519\n",
            "Train Epoch: 1 [950/3978 (24%)]\tLoss: 0.077034\n",
            "Train Epoch: 1 [955/3978 (24%)]\tLoss: 0.106723\n",
            "Train Epoch: 1 [960/3978 (24%)]\tLoss: 0.351446\n",
            "Train Epoch: 1 [965/3978 (24%)]\tLoss: 0.110219\n",
            "Train Epoch: 1 [970/3978 (24%)]\tLoss: 0.218458\n",
            "Train Epoch: 1 [975/3978 (24%)]\tLoss: 0.302416\n",
            "Train Epoch: 1 [980/3978 (25%)]\tLoss: 0.168634\n",
            "Train Epoch: 1 [985/3978 (25%)]\tLoss: 0.169765\n",
            "Train Epoch: 1 [990/3978 (25%)]\tLoss: 0.322820\n",
            "Train Epoch: 1 [995/3978 (25%)]\tLoss: 0.181944\n",
            "Train Epoch: 1 [1000/3978 (25%)]\tLoss: 0.246305\n",
            "Train Epoch: 1 [1005/3978 (25%)]\tLoss: 0.190940\n",
            "Train Epoch: 1 [1010/3978 (25%)]\tLoss: 0.208834\n",
            "Train Epoch: 1 [1015/3978 (26%)]\tLoss: 0.339362\n",
            "Train Epoch: 1 [1020/3978 (26%)]\tLoss: 0.069922\n",
            "Train Epoch: 1 [1025/3978 (26%)]\tLoss: 0.168514\n",
            "Train Epoch: 1 [1030/3978 (26%)]\tLoss: 0.107099\n",
            "Train Epoch: 1 [1035/3978 (26%)]\tLoss: 0.129242\n",
            "Train Epoch: 1 [1040/3978 (26%)]\tLoss: 0.182026\n",
            "Train Epoch: 1 [1045/3978 (26%)]\tLoss: 0.439315\n",
            "Train Epoch: 1 [1050/3978 (26%)]\tLoss: 0.083990\n",
            "Train Epoch: 1 [1055/3978 (27%)]\tLoss: 0.374198\n",
            "Train Epoch: 1 [1060/3978 (27%)]\tLoss: 0.339233\n",
            "Train Epoch: 1 [1065/3978 (27%)]\tLoss: 0.261457\n",
            "Train Epoch: 1 [1070/3978 (27%)]\tLoss: 0.077078\n",
            "Train Epoch: 1 [1075/3978 (27%)]\tLoss: 0.956248\n",
            "Train Epoch: 1 [1080/3978 (27%)]\tLoss: 0.251543\n",
            "Train Epoch: 1 [1085/3978 (27%)]\tLoss: 0.532004\n",
            "Train Epoch: 1 [1090/3978 (27%)]\tLoss: 0.072229\n",
            "Train Epoch: 1 [1095/3978 (28%)]\tLoss: 0.375057\n",
            "Train Epoch: 1 [1100/3978 (28%)]\tLoss: 0.127008\n",
            "Train Epoch: 1 [1105/3978 (28%)]\tLoss: 0.064276\n",
            "Train Epoch: 1 [1110/3978 (28%)]\tLoss: 0.090974\n",
            "Train Epoch: 1 [1115/3978 (28%)]\tLoss: 0.481644\n",
            "Train Epoch: 1 [1120/3978 (28%)]\tLoss: 0.087471\n",
            "Train Epoch: 1 [1125/3978 (28%)]\tLoss: 0.081802\n",
            "Train Epoch: 1 [1130/3978 (28%)]\tLoss: 0.088024\n",
            "Train Epoch: 1 [1135/3978 (29%)]\tLoss: 0.396214\n",
            "Train Epoch: 1 [1140/3978 (29%)]\tLoss: 0.086097\n",
            "Train Epoch: 1 [1145/3978 (29%)]\tLoss: 0.076147\n",
            "Train Epoch: 1 [1150/3978 (29%)]\tLoss: 0.471735\n",
            "Train Epoch: 1 [1155/3978 (29%)]\tLoss: 0.117925\n",
            "Train Epoch: 1 [1160/3978 (29%)]\tLoss: 0.076821\n",
            "Train Epoch: 1 [1165/3978 (29%)]\tLoss: 0.256509\n",
            "Train Epoch: 1 [1170/3978 (29%)]\tLoss: 0.295521\n",
            "Train Epoch: 1 [1175/3978 (30%)]\tLoss: 0.044585\n",
            "Train Epoch: 1 [1180/3978 (30%)]\tLoss: 0.548551\n",
            "Train Epoch: 1 [1185/3978 (30%)]\tLoss: 0.538860\n",
            "Train Epoch: 1 [1190/3978 (30%)]\tLoss: 0.279974\n",
            "Train Epoch: 1 [1195/3978 (30%)]\tLoss: 0.547515\n",
            "Train Epoch: 1 [1200/3978 (30%)]\tLoss: 0.243790\n",
            "Train Epoch: 1 [1205/3978 (30%)]\tLoss: 0.328265\n",
            "Train Epoch: 1 [1210/3978 (30%)]\tLoss: 0.258763\n",
            "Train Epoch: 1 [1215/3978 (31%)]\tLoss: 0.127031\n",
            "Train Epoch: 1 [1220/3978 (31%)]\tLoss: 0.133425\n",
            "Train Epoch: 1 [1225/3978 (31%)]\tLoss: 0.340281\n",
            "Train Epoch: 1 [1230/3978 (31%)]\tLoss: 0.222839\n",
            "Train Epoch: 1 [1235/3978 (31%)]\tLoss: 0.196298\n",
            "Train Epoch: 1 [1240/3978 (31%)]\tLoss: 0.104427\n",
            "Train Epoch: 1 [1245/3978 (31%)]\tLoss: 0.129183\n",
            "Train Epoch: 1 [1250/3978 (31%)]\tLoss: 0.291134\n",
            "Train Epoch: 1 [1255/3978 (32%)]\tLoss: 0.240480\n",
            "Train Epoch: 1 [1260/3978 (32%)]\tLoss: 0.264738\n",
            "Train Epoch: 1 [1265/3978 (32%)]\tLoss: 0.395643\n",
            "Train Epoch: 1 [1270/3978 (32%)]\tLoss: 0.235452\n",
            "Train Epoch: 1 [1275/3978 (32%)]\tLoss: 0.187884\n",
            "Train Epoch: 1 [1280/3978 (32%)]\tLoss: 0.940812\n",
            "Train Epoch: 1 [1285/3978 (32%)]\tLoss: 0.253096\n",
            "Train Epoch: 1 [1290/3978 (32%)]\tLoss: 0.370760\n",
            "Train Epoch: 1 [1295/3978 (33%)]\tLoss: 0.088620\n",
            "Train Epoch: 1 [1300/3978 (33%)]\tLoss: 0.074050\n",
            "Train Epoch: 1 [1305/3978 (33%)]\tLoss: 0.076404\n",
            "Train Epoch: 1 [1310/3978 (33%)]\tLoss: 0.126686\n",
            "Train Epoch: 1 [1315/3978 (33%)]\tLoss: 0.437936\n",
            "Train Epoch: 1 [1320/3978 (33%)]\tLoss: 0.260466\n",
            "Train Epoch: 1 [1325/3978 (33%)]\tLoss: 0.159755\n",
            "Train Epoch: 1 [1330/3978 (33%)]\tLoss: 0.106679\n",
            "Train Epoch: 1 [1335/3978 (34%)]\tLoss: 0.231915\n",
            "Train Epoch: 1 [1340/3978 (34%)]\tLoss: 0.087077\n",
            "Train Epoch: 1 [1345/3978 (34%)]\tLoss: 0.078375\n",
            "Train Epoch: 1 [1350/3978 (34%)]\tLoss: 0.225599\n",
            "Train Epoch: 1 [1355/3978 (34%)]\tLoss: 0.537167\n",
            "Train Epoch: 1 [1360/3978 (34%)]\tLoss: 0.247012\n",
            "Train Epoch: 1 [1365/3978 (34%)]\tLoss: 0.235911\n",
            "Train Epoch: 1 [1370/3978 (34%)]\tLoss: 0.313006\n",
            "Train Epoch: 1 [1375/3978 (35%)]\tLoss: 0.266932\n",
            "Train Epoch: 1 [1380/3978 (35%)]\tLoss: 0.487235\n",
            "Train Epoch: 1 [1385/3978 (35%)]\tLoss: 0.265741\n",
            "Train Epoch: 1 [1390/3978 (35%)]\tLoss: 0.080723\n",
            "Train Epoch: 1 [1395/3978 (35%)]\tLoss: 0.384641\n",
            "Train Epoch: 1 [1400/3978 (35%)]\tLoss: 0.375508\n",
            "Train Epoch: 1 [1405/3978 (35%)]\tLoss: 0.250999\n",
            "Train Epoch: 1 [1410/3978 (35%)]\tLoss: 0.183623\n",
            "Train Epoch: 1 [1415/3978 (36%)]\tLoss: 0.084630\n",
            "Train Epoch: 1 [1420/3978 (36%)]\tLoss: 0.070408\n",
            "Train Epoch: 1 [1425/3978 (36%)]\tLoss: 0.125037\n",
            "Train Epoch: 1 [1430/3978 (36%)]\tLoss: 0.356878\n",
            "Train Epoch: 1 [1435/3978 (36%)]\tLoss: 0.091998\n",
            "Train Epoch: 1 [1440/3978 (36%)]\tLoss: 0.439557\n",
            "Train Epoch: 1 [1445/3978 (36%)]\tLoss: 0.263716\n",
            "Train Epoch: 1 [1450/3978 (36%)]\tLoss: 0.660869\n",
            "Train Epoch: 1 [1455/3978 (37%)]\tLoss: 0.164376\n",
            "Train Epoch: 1 [1460/3978 (37%)]\tLoss: 0.464168\n",
            "Train Epoch: 1 [1465/3978 (37%)]\tLoss: 0.119141\n",
            "Train Epoch: 1 [1470/3978 (37%)]\tLoss: 0.178888\n",
            "Train Epoch: 1 [1475/3978 (37%)]\tLoss: 0.113101\n",
            "Train Epoch: 1 [1480/3978 (37%)]\tLoss: 0.434556\n",
            "Train Epoch: 1 [1485/3978 (37%)]\tLoss: 0.289473\n",
            "Train Epoch: 1 [1490/3978 (37%)]\tLoss: 0.197799\n",
            "Train Epoch: 1 [1495/3978 (38%)]\tLoss: 0.298321\n",
            "Train Epoch: 1 [1500/3978 (38%)]\tLoss: 0.099583\n",
            "Train Epoch: 1 [1505/3978 (38%)]\tLoss: 0.361058\n",
            "Train Epoch: 1 [1510/3978 (38%)]\tLoss: 0.467719\n",
            "Train Epoch: 1 [1515/3978 (38%)]\tLoss: 0.159627\n",
            "Train Epoch: 1 [1520/3978 (38%)]\tLoss: 0.099101\n",
            "Train Epoch: 1 [1525/3978 (38%)]\tLoss: 0.097595\n",
            "Train Epoch: 1 [1530/3978 (38%)]\tLoss: 0.389674\n",
            "Train Epoch: 1 [1535/3978 (39%)]\tLoss: 0.069519\n",
            "Train Epoch: 1 [1540/3978 (39%)]\tLoss: 0.264081\n",
            "Train Epoch: 1 [1545/3978 (39%)]\tLoss: 0.135059\n",
            "Train Epoch: 1 [1550/3978 (39%)]\tLoss: 0.354155\n",
            "Train Epoch: 1 [1555/3978 (39%)]\tLoss: 0.430733\n",
            "Train Epoch: 1 [1560/3978 (39%)]\tLoss: 0.236594\n",
            "Train Epoch: 1 [1565/3978 (39%)]\tLoss: 0.092685\n",
            "Train Epoch: 1 [1570/3978 (39%)]\tLoss: 0.130644\n",
            "Train Epoch: 1 [1575/3978 (40%)]\tLoss: 0.357868\n",
            "Train Epoch: 1 [1580/3978 (40%)]\tLoss: 0.132479\n",
            "Train Epoch: 1 [1585/3978 (40%)]\tLoss: 0.244657\n",
            "Train Epoch: 1 [1590/3978 (40%)]\tLoss: 0.239063\n",
            "Train Epoch: 1 [1595/3978 (40%)]\tLoss: 0.092527\n",
            "Train Epoch: 1 [1600/3978 (40%)]\tLoss: 0.210990\n",
            "Train Epoch: 1 [1605/3978 (40%)]\tLoss: 0.377908\n",
            "Train Epoch: 1 [1610/3978 (40%)]\tLoss: 0.299435\n",
            "Train Epoch: 1 [1615/3978 (41%)]\tLoss: 0.165913\n",
            "Train Epoch: 1 [1620/3978 (41%)]\tLoss: 0.255061\n",
            "Train Epoch: 1 [1625/3978 (41%)]\tLoss: 0.496755\n",
            "Train Epoch: 1 [1630/3978 (41%)]\tLoss: 0.091671\n",
            "Train Epoch: 1 [1635/3978 (41%)]\tLoss: 0.301694\n",
            "Train Epoch: 1 [1640/3978 (41%)]\tLoss: 0.130142\n",
            "Train Epoch: 1 [1645/3978 (41%)]\tLoss: 0.029996\n",
            "Train Epoch: 1 [1650/3978 (41%)]\tLoss: 0.024483\n",
            "Train Epoch: 1 [1655/3978 (42%)]\tLoss: 0.302806\n",
            "Train Epoch: 1 [1660/3978 (42%)]\tLoss: 0.019507\n",
            "Train Epoch: 1 [1665/3978 (42%)]\tLoss: 0.183766\n",
            "Train Epoch: 1 [1670/3978 (42%)]\tLoss: 0.076567\n",
            "Train Epoch: 1 [1675/3978 (42%)]\tLoss: 0.104576\n",
            "Train Epoch: 1 [1680/3978 (42%)]\tLoss: 0.840799\n",
            "Train Epoch: 1 [1685/3978 (42%)]\tLoss: 0.075895\n",
            "Train Epoch: 1 [1690/3978 (42%)]\tLoss: 0.326523\n",
            "Train Epoch: 1 [1695/3978 (43%)]\tLoss: 0.065636\n",
            "Train Epoch: 1 [1700/3978 (43%)]\tLoss: 0.267653\n",
            "Train Epoch: 1 [1705/3978 (43%)]\tLoss: 0.062077\n",
            "Train Epoch: 1 [1710/3978 (43%)]\tLoss: 0.038006\n",
            "Train Epoch: 1 [1715/3978 (43%)]\tLoss: 0.213252\n",
            "Train Epoch: 1 [1720/3978 (43%)]\tLoss: 0.417346\n",
            "Train Epoch: 1 [1725/3978 (43%)]\tLoss: 0.197529\n",
            "Train Epoch: 1 [1730/3978 (43%)]\tLoss: 0.327435\n",
            "Train Epoch: 1 [1735/3978 (44%)]\tLoss: 0.678465\n",
            "Train Epoch: 1 [1740/3978 (44%)]\tLoss: 0.037244\n",
            "Train Epoch: 1 [1745/3978 (44%)]\tLoss: 0.104953\n",
            "Train Epoch: 1 [1750/3978 (44%)]\tLoss: 0.073245\n",
            "Train Epoch: 1 [1755/3978 (44%)]\tLoss: 0.250898\n",
            "Train Epoch: 1 [1760/3978 (44%)]\tLoss: 0.521965\n",
            "Train Epoch: 1 [1765/3978 (44%)]\tLoss: 0.235645\n",
            "Train Epoch: 1 [1770/3978 (44%)]\tLoss: 0.380954\n",
            "Train Epoch: 1 [1775/3978 (45%)]\tLoss: 0.211143\n",
            "Train Epoch: 1 [1780/3978 (45%)]\tLoss: 0.344236\n",
            "Train Epoch: 1 [1785/3978 (45%)]\tLoss: 0.412834\n",
            "Train Epoch: 1 [1790/3978 (45%)]\tLoss: 0.427019\n",
            "Train Epoch: 1 [1795/3978 (45%)]\tLoss: 0.358422\n",
            "Train Epoch: 1 [1800/3978 (45%)]\tLoss: 0.196676\n",
            "Train Epoch: 1 [1805/3978 (45%)]\tLoss: 0.218644\n",
            "Train Epoch: 1 [1810/3978 (45%)]\tLoss: 0.132772\n",
            "Train Epoch: 1 [1815/3978 (46%)]\tLoss: 0.229480\n",
            "Train Epoch: 1 [1820/3978 (46%)]\tLoss: 0.130502\n",
            "Train Epoch: 1 [1825/3978 (46%)]\tLoss: 0.131212\n",
            "Train Epoch: 1 [1830/3978 (46%)]\tLoss: 0.200854\n",
            "Train Epoch: 1 [1835/3978 (46%)]\tLoss: 0.202154\n",
            "Train Epoch: 1 [1840/3978 (46%)]\tLoss: 0.367128\n",
            "Train Epoch: 1 [1845/3978 (46%)]\tLoss: 0.106552\n",
            "Train Epoch: 1 [1850/3978 (46%)]\tLoss: 0.350346\n",
            "Train Epoch: 1 [1855/3978 (47%)]\tLoss: 0.253929\n",
            "Train Epoch: 1 [1860/3978 (47%)]\tLoss: 0.270125\n",
            "Train Epoch: 1 [1865/3978 (47%)]\tLoss: 0.082979\n",
            "Train Epoch: 1 [1870/3978 (47%)]\tLoss: 0.416828\n",
            "Train Epoch: 1 [1875/3978 (47%)]\tLoss: 0.096975\n",
            "Train Epoch: 1 [1880/3978 (47%)]\tLoss: 0.133471\n",
            "Train Epoch: 1 [1885/3978 (47%)]\tLoss: 0.126335\n",
            "Train Epoch: 1 [1890/3978 (47%)]\tLoss: 0.283867\n",
            "Train Epoch: 1 [1895/3978 (48%)]\tLoss: 0.311059\n",
            "Train Epoch: 1 [1900/3978 (48%)]\tLoss: 0.083336\n",
            "Train Epoch: 1 [1905/3978 (48%)]\tLoss: 0.111598\n",
            "Train Epoch: 1 [1910/3978 (48%)]\tLoss: 0.243726\n",
            "Train Epoch: 1 [1915/3978 (48%)]\tLoss: 0.398075\n",
            "Train Epoch: 1 [1920/3978 (48%)]\tLoss: 0.088029\n",
            "Train Epoch: 1 [1925/3978 (48%)]\tLoss: 0.593080\n",
            "Train Epoch: 1 [1930/3978 (48%)]\tLoss: 0.162920\n",
            "Train Epoch: 1 [1935/3978 (49%)]\tLoss: 0.047163\n",
            "Train Epoch: 1 [1940/3978 (49%)]\tLoss: 0.232851\n",
            "Train Epoch: 1 [1945/3978 (49%)]\tLoss: 0.425528\n",
            "Train Epoch: 1 [1950/3978 (49%)]\tLoss: 0.222123\n",
            "Train Epoch: 1 [1955/3978 (49%)]\tLoss: 0.104938\n",
            "Train Epoch: 1 [1960/3978 (49%)]\tLoss: 0.253453\n",
            "Train Epoch: 1 [1965/3978 (49%)]\tLoss: 0.140978\n",
            "Train Epoch: 1 [1970/3978 (49%)]\tLoss: 0.134938\n",
            "Train Epoch: 1 [1975/3978 (50%)]\tLoss: 0.269310\n",
            "Train Epoch: 1 [1980/3978 (50%)]\tLoss: 0.106910\n",
            "Train Epoch: 1 [1985/3978 (50%)]\tLoss: 0.071925\n",
            "Train Epoch: 1 [1990/3978 (50%)]\tLoss: 0.092861\n",
            "Train Epoch: 1 [1995/3978 (50%)]\tLoss: 0.181287\n",
            "Train Epoch: 1 [2000/3978 (50%)]\tLoss: 0.193257\n",
            "Train Epoch: 1 [2005/3978 (50%)]\tLoss: 0.075018\n",
            "Train Epoch: 1 [2010/3978 (51%)]\tLoss: 0.195035\n",
            "Train Epoch: 1 [2015/3978 (51%)]\tLoss: 0.294463\n",
            "Train Epoch: 1 [2020/3978 (51%)]\tLoss: 0.079956\n",
            "Train Epoch: 1 [2025/3978 (51%)]\tLoss: 0.102653\n",
            "Train Epoch: 1 [2030/3978 (51%)]\tLoss: 0.145976\n",
            "Train Epoch: 1 [2035/3978 (51%)]\tLoss: 0.191860\n",
            "Train Epoch: 1 [2040/3978 (51%)]\tLoss: 0.235198\n",
            "Train Epoch: 1 [2045/3978 (51%)]\tLoss: 0.082180\n",
            "Train Epoch: 1 [2050/3978 (52%)]\tLoss: 0.318504\n",
            "Train Epoch: 1 [2055/3978 (52%)]\tLoss: 0.300476\n",
            "Train Epoch: 1 [2060/3978 (52%)]\tLoss: 0.292252\n",
            "Train Epoch: 1 [2065/3978 (52%)]\tLoss: 0.083730\n",
            "Train Epoch: 1 [2070/3978 (52%)]\tLoss: 0.298922\n",
            "Train Epoch: 1 [2075/3978 (52%)]\tLoss: 0.703778\n",
            "Train Epoch: 1 [2080/3978 (52%)]\tLoss: 0.255074\n",
            "Train Epoch: 1 [2085/3978 (52%)]\tLoss: 0.080094\n",
            "Train Epoch: 1 [2090/3978 (53%)]\tLoss: 0.090893\n",
            "Train Epoch: 1 [2095/3978 (53%)]\tLoss: 0.324150\n",
            "Train Epoch: 1 [2100/3978 (53%)]\tLoss: 0.086338\n",
            "Train Epoch: 1 [2105/3978 (53%)]\tLoss: 0.206151\n",
            "Train Epoch: 1 [2110/3978 (53%)]\tLoss: 0.075102\n",
            "Train Epoch: 1 [2115/3978 (53%)]\tLoss: 0.080279\n",
            "Train Epoch: 1 [2120/3978 (53%)]\tLoss: 0.168392\n",
            "Train Epoch: 1 [2125/3978 (53%)]\tLoss: 0.331284\n",
            "Train Epoch: 1 [2130/3978 (54%)]\tLoss: 0.139777\n",
            "Train Epoch: 1 [2135/3978 (54%)]\tLoss: 0.288406\n",
            "Train Epoch: 1 [2140/3978 (54%)]\tLoss: 0.242458\n",
            "Train Epoch: 1 [2145/3978 (54%)]\tLoss: 0.301343\n",
            "Train Epoch: 1 [2150/3978 (54%)]\tLoss: 0.303620\n",
            "Train Epoch: 1 [2155/3978 (54%)]\tLoss: 0.064363\n",
            "Train Epoch: 1 [2160/3978 (54%)]\tLoss: 0.113286\n",
            "Train Epoch: 1 [2165/3978 (54%)]\tLoss: 0.309671\n",
            "Train Epoch: 1 [2170/3978 (55%)]\tLoss: 0.296382\n",
            "Train Epoch: 1 [2175/3978 (55%)]\tLoss: 0.232167\n",
            "Train Epoch: 1 [2180/3978 (55%)]\tLoss: 0.480651\n",
            "Train Epoch: 1 [2185/3978 (55%)]\tLoss: 0.267744\n",
            "Train Epoch: 1 [2190/3978 (55%)]\tLoss: 0.107883\n",
            "Train Epoch: 1 [2195/3978 (55%)]\tLoss: 0.410149\n",
            "Train Epoch: 1 [2200/3978 (55%)]\tLoss: 0.194815\n",
            "Train Epoch: 1 [2205/3978 (55%)]\tLoss: 0.256722\n",
            "Train Epoch: 1 [2210/3978 (56%)]\tLoss: 0.093236\n",
            "Train Epoch: 1 [2215/3978 (56%)]\tLoss: 0.104674\n",
            "Train Epoch: 1 [2220/3978 (56%)]\tLoss: 0.083715\n",
            "Train Epoch: 1 [2225/3978 (56%)]\tLoss: 0.312755\n",
            "Train Epoch: 1 [2230/3978 (56%)]\tLoss: 0.341134\n",
            "Train Epoch: 1 [2235/3978 (56%)]\tLoss: 0.071918\n",
            "Train Epoch: 1 [2240/3978 (56%)]\tLoss: 0.068891\n",
            "Train Epoch: 1 [2245/3978 (56%)]\tLoss: 0.181686\n",
            "Train Epoch: 1 [2250/3978 (57%)]\tLoss: 0.233778\n",
            "Train Epoch: 1 [2255/3978 (57%)]\tLoss: 0.215024\n",
            "Train Epoch: 1 [2260/3978 (57%)]\tLoss: 0.246400\n",
            "Train Epoch: 1 [2265/3978 (57%)]\tLoss: 0.370125\n",
            "Train Epoch: 1 [2270/3978 (57%)]\tLoss: 0.462933\n",
            "Train Epoch: 1 [2275/3978 (57%)]\tLoss: 0.221047\n",
            "Train Epoch: 1 [2280/3978 (57%)]\tLoss: 0.356170\n",
            "Train Epoch: 1 [2285/3978 (57%)]\tLoss: 0.098113\n",
            "Train Epoch: 1 [2290/3978 (58%)]\tLoss: 0.099393\n",
            "Train Epoch: 1 [2295/3978 (58%)]\tLoss: 0.156438\n",
            "Train Epoch: 1 [2300/3978 (58%)]\tLoss: 0.228929\n",
            "Train Epoch: 1 [2305/3978 (58%)]\tLoss: 0.632980\n",
            "Train Epoch: 1 [2310/3978 (58%)]\tLoss: 0.095213\n",
            "Train Epoch: 1 [2315/3978 (58%)]\tLoss: 0.267536\n",
            "Train Epoch: 1 [2320/3978 (58%)]\tLoss: 0.352202\n",
            "Train Epoch: 1 [2325/3978 (58%)]\tLoss: 0.098000\n",
            "Train Epoch: 1 [2330/3978 (59%)]\tLoss: 0.314193\n",
            "Train Epoch: 1 [2335/3978 (59%)]\tLoss: 0.289449\n",
            "Train Epoch: 1 [2340/3978 (59%)]\tLoss: 0.524058\n",
            "Train Epoch: 1 [2345/3978 (59%)]\tLoss: 0.115202\n",
            "Train Epoch: 1 [2350/3978 (59%)]\tLoss: 0.541074\n",
            "Train Epoch: 1 [2355/3978 (59%)]\tLoss: 0.205062\n",
            "Train Epoch: 1 [2360/3978 (59%)]\tLoss: 0.093863\n",
            "Train Epoch: 1 [2365/3978 (59%)]\tLoss: 0.168015\n",
            "Train Epoch: 1 [2370/3978 (60%)]\tLoss: 0.062726\n",
            "Train Epoch: 1 [2375/3978 (60%)]\tLoss: 0.441809\n",
            "Train Epoch: 1 [2380/3978 (60%)]\tLoss: 0.231857\n",
            "Train Epoch: 1 [2385/3978 (60%)]\tLoss: 0.356785\n",
            "Train Epoch: 1 [2390/3978 (60%)]\tLoss: 0.302843\n",
            "Train Epoch: 1 [2395/3978 (60%)]\tLoss: 0.123529\n",
            "Train Epoch: 1 [2400/3978 (60%)]\tLoss: 0.508581\n",
            "Train Epoch: 1 [2405/3978 (60%)]\tLoss: 0.310419\n",
            "Train Epoch: 1 [2410/3978 (61%)]\tLoss: 0.207256\n",
            "Train Epoch: 1 [2415/3978 (61%)]\tLoss: 0.247811\n",
            "Train Epoch: 1 [2420/3978 (61%)]\tLoss: 0.226590\n",
            "Train Epoch: 1 [2425/3978 (61%)]\tLoss: 0.117864\n",
            "Train Epoch: 1 [2430/3978 (61%)]\tLoss: 0.269575\n",
            "Train Epoch: 1 [2435/3978 (61%)]\tLoss: 0.484465\n",
            "Train Epoch: 1 [2440/3978 (61%)]\tLoss: 0.106339\n",
            "Train Epoch: 1 [2445/3978 (61%)]\tLoss: 0.102127\n",
            "Train Epoch: 1 [2450/3978 (62%)]\tLoss: 0.120466\n",
            "Train Epoch: 1 [2455/3978 (62%)]\tLoss: 0.233216\n",
            "Train Epoch: 1 [2460/3978 (62%)]\tLoss: 0.072714\n",
            "Train Epoch: 1 [2465/3978 (62%)]\tLoss: 0.087809\n",
            "Train Epoch: 1 [2470/3978 (62%)]\tLoss: 0.085959\n",
            "Train Epoch: 1 [2475/3978 (62%)]\tLoss: 0.200330\n",
            "Train Epoch: 1 [2480/3978 (62%)]\tLoss: 0.314586\n",
            "Train Epoch: 1 [2485/3978 (62%)]\tLoss: 0.074377\n",
            "Train Epoch: 1 [2490/3978 (63%)]\tLoss: 0.055039\n",
            "Train Epoch: 1 [2495/3978 (63%)]\tLoss: 0.289880\n",
            "Train Epoch: 1 [2500/3978 (63%)]\tLoss: 0.402856\n",
            "Train Epoch: 1 [2505/3978 (63%)]\tLoss: 0.068622\n",
            "Train Epoch: 1 [2510/3978 (63%)]\tLoss: 0.187483\n",
            "Train Epoch: 1 [2515/3978 (63%)]\tLoss: 0.518091\n",
            "Train Epoch: 1 [2520/3978 (63%)]\tLoss: 0.063061\n",
            "Train Epoch: 1 [2525/3978 (63%)]\tLoss: 0.244714\n",
            "Train Epoch: 1 [2530/3978 (64%)]\tLoss: 0.235164\n",
            "Train Epoch: 1 [2535/3978 (64%)]\tLoss: 0.062902\n",
            "Train Epoch: 1 [2540/3978 (64%)]\tLoss: 0.256047\n",
            "Train Epoch: 1 [2545/3978 (64%)]\tLoss: 0.179737\n",
            "Train Epoch: 1 [2550/3978 (64%)]\tLoss: 0.241941\n",
            "Train Epoch: 1 [2555/3978 (64%)]\tLoss: 0.035489\n",
            "Train Epoch: 1 [2560/3978 (64%)]\tLoss: 0.189883\n",
            "Train Epoch: 1 [2565/3978 (64%)]\tLoss: 0.362508\n",
            "Train Epoch: 1 [2570/3978 (65%)]\tLoss: 0.357825\n",
            "Train Epoch: 1 [2575/3978 (65%)]\tLoss: 0.517966\n",
            "Train Epoch: 1 [2580/3978 (65%)]\tLoss: 0.255162\n",
            "Train Epoch: 1 [2585/3978 (65%)]\tLoss: 0.300615\n",
            "Train Epoch: 1 [2590/3978 (65%)]\tLoss: 0.080048\n",
            "Train Epoch: 1 [2595/3978 (65%)]\tLoss: 0.232136\n",
            "Train Epoch: 1 [2600/3978 (65%)]\tLoss: 0.282446\n",
            "Train Epoch: 1 [2605/3978 (65%)]\tLoss: 0.056301\n",
            "Train Epoch: 1 [2610/3978 (66%)]\tLoss: 0.504701\n",
            "Train Epoch: 1 [2615/3978 (66%)]\tLoss: 0.420294\n",
            "Train Epoch: 1 [2620/3978 (66%)]\tLoss: 0.222819\n",
            "Train Epoch: 1 [2625/3978 (66%)]\tLoss: 0.362996\n",
            "Train Epoch: 1 [2630/3978 (66%)]\tLoss: 0.140179\n",
            "Train Epoch: 1 [2635/3978 (66%)]\tLoss: 0.133337\n",
            "Train Epoch: 1 [2640/3978 (66%)]\tLoss: 0.141230\n",
            "Train Epoch: 1 [2645/3978 (66%)]\tLoss: 0.473486\n",
            "Train Epoch: 1 [2650/3978 (67%)]\tLoss: 0.309086\n",
            "Train Epoch: 1 [2655/3978 (67%)]\tLoss: 0.178474\n",
            "Train Epoch: 1 [2660/3978 (67%)]\tLoss: 0.207429\n",
            "Train Epoch: 1 [2665/3978 (67%)]\tLoss: 0.144280\n",
            "Train Epoch: 1 [2670/3978 (67%)]\tLoss: 0.235630\n",
            "Train Epoch: 1 [2675/3978 (67%)]\tLoss: 0.376573\n",
            "Train Epoch: 1 [2680/3978 (67%)]\tLoss: 0.637363\n",
            "Train Epoch: 1 [2685/3978 (67%)]\tLoss: 0.603493\n",
            "Train Epoch: 1 [2690/3978 (68%)]\tLoss: 0.278071\n",
            "Train Epoch: 1 [2695/3978 (68%)]\tLoss: 0.053391\n",
            "Train Epoch: 1 [2700/3978 (68%)]\tLoss: 0.340234\n",
            "Train Epoch: 1 [2705/3978 (68%)]\tLoss: 0.199287\n",
            "Train Epoch: 1 [2710/3978 (68%)]\tLoss: 0.377565\n",
            "Train Epoch: 1 [2715/3978 (68%)]\tLoss: 0.388941\n",
            "Train Epoch: 1 [2720/3978 (68%)]\tLoss: 0.120708\n",
            "Train Epoch: 1 [2725/3978 (68%)]\tLoss: 0.376631\n",
            "Train Epoch: 1 [2730/3978 (69%)]\tLoss: 0.105080\n",
            "Train Epoch: 1 [2735/3978 (69%)]\tLoss: 0.127373\n",
            "Train Epoch: 1 [2740/3978 (69%)]\tLoss: 0.442349\n",
            "Train Epoch: 1 [2745/3978 (69%)]\tLoss: 0.158892\n",
            "Train Epoch: 1 [2750/3978 (69%)]\tLoss: 0.345658\n",
            "Train Epoch: 1 [2755/3978 (69%)]\tLoss: 0.382255\n",
            "Train Epoch: 1 [2760/3978 (69%)]\tLoss: 0.445792\n",
            "Train Epoch: 1 [2765/3978 (69%)]\tLoss: 0.082842\n",
            "Train Epoch: 1 [2770/3978 (70%)]\tLoss: 0.175696\n",
            "Train Epoch: 1 [2775/3978 (70%)]\tLoss: 0.100307\n",
            "Train Epoch: 1 [2780/3978 (70%)]\tLoss: 0.259016\n",
            "Train Epoch: 1 [2785/3978 (70%)]\tLoss: 0.266244\n",
            "Train Epoch: 1 [2790/3978 (70%)]\tLoss: 0.259775\n",
            "Train Epoch: 1 [2795/3978 (70%)]\tLoss: 0.325903\n",
            "Train Epoch: 1 [2800/3978 (70%)]\tLoss: 0.100318\n",
            "Train Epoch: 1 [2805/3978 (70%)]\tLoss: 0.251636\n",
            "Train Epoch: 1 [2810/3978 (71%)]\tLoss: 0.189250\n",
            "Train Epoch: 1 [2815/3978 (71%)]\tLoss: 0.080155\n",
            "Train Epoch: 1 [2820/3978 (71%)]\tLoss: 0.502672\n",
            "Train Epoch: 1 [2825/3978 (71%)]\tLoss: 0.314884\n",
            "Train Epoch: 1 [2830/3978 (71%)]\tLoss: 0.344040\n",
            "Train Epoch: 1 [2835/3978 (71%)]\tLoss: 0.516876\n",
            "Train Epoch: 1 [2840/3978 (71%)]\tLoss: 0.078599\n",
            "Train Epoch: 1 [2845/3978 (71%)]\tLoss: 0.067259\n",
            "Train Epoch: 1 [2850/3978 (72%)]\tLoss: 0.476514\n",
            "Train Epoch: 1 [2855/3978 (72%)]\tLoss: 0.266175\n",
            "Train Epoch: 1 [2860/3978 (72%)]\tLoss: 0.093882\n",
            "Train Epoch: 1 [2865/3978 (72%)]\tLoss: 0.281365\n",
            "Train Epoch: 1 [2870/3978 (72%)]\tLoss: 0.539537\n",
            "Train Epoch: 1 [2875/3978 (72%)]\tLoss: 0.189859\n",
            "Train Epoch: 1 [2880/3978 (72%)]\tLoss: 0.324847\n",
            "Train Epoch: 1 [2885/3978 (72%)]\tLoss: 0.286627\n",
            "Train Epoch: 1 [2890/3978 (73%)]\tLoss: 0.090355\n",
            "Train Epoch: 1 [2895/3978 (73%)]\tLoss: 0.243977\n",
            "Train Epoch: 1 [2900/3978 (73%)]\tLoss: 0.089330\n",
            "Train Epoch: 1 [2905/3978 (73%)]\tLoss: 0.174986\n",
            "Train Epoch: 1 [2910/3978 (73%)]\tLoss: 0.239817\n",
            "Train Epoch: 1 [2915/3978 (73%)]\tLoss: 0.529403\n",
            "Train Epoch: 1 [2920/3978 (73%)]\tLoss: 0.518648\n",
            "Train Epoch: 1 [2925/3978 (73%)]\tLoss: 0.197765\n",
            "Train Epoch: 1 [2930/3978 (74%)]\tLoss: 0.096055\n",
            "Train Epoch: 1 [2935/3978 (74%)]\tLoss: 0.273425\n",
            "Train Epoch: 1 [2940/3978 (74%)]\tLoss: 0.223020\n",
            "Train Epoch: 1 [2945/3978 (74%)]\tLoss: 0.266548\n",
            "Train Epoch: 1 [2950/3978 (74%)]\tLoss: 0.658665\n",
            "Train Epoch: 1 [2955/3978 (74%)]\tLoss: 0.153466\n",
            "Train Epoch: 1 [2960/3978 (74%)]\tLoss: 0.154413\n",
            "Train Epoch: 1 [2965/3978 (74%)]\tLoss: 0.321377\n",
            "Train Epoch: 1 [2970/3978 (75%)]\tLoss: 0.146563\n",
            "Train Epoch: 1 [2975/3978 (75%)]\tLoss: 0.264803\n",
            "Train Epoch: 1 [2980/3978 (75%)]\tLoss: 0.101866\n",
            "Train Epoch: 1 [2985/3978 (75%)]\tLoss: 0.378756\n",
            "Train Epoch: 1 [2990/3978 (75%)]\tLoss: 0.585123\n",
            "Train Epoch: 1 [2995/3978 (75%)]\tLoss: 0.502435\n",
            "Train Epoch: 1 [3000/3978 (75%)]\tLoss: 0.465962\n",
            "Train Epoch: 1 [3005/3978 (76%)]\tLoss: 0.104653\n",
            "Train Epoch: 1 [3010/3978 (76%)]\tLoss: 0.433545\n",
            "Train Epoch: 1 [3015/3978 (76%)]\tLoss: 0.187598\n",
            "Train Epoch: 1 [3020/3978 (76%)]\tLoss: 0.093670\n",
            "Train Epoch: 1 [3025/3978 (76%)]\tLoss: 0.364841\n",
            "Train Epoch: 1 [3030/3978 (76%)]\tLoss: 0.123472\n",
            "Train Epoch: 1 [3035/3978 (76%)]\tLoss: 0.119382\n",
            "Train Epoch: 1 [3040/3978 (76%)]\tLoss: 0.235817\n",
            "Train Epoch: 1 [3045/3978 (77%)]\tLoss: 0.396882\n",
            "Train Epoch: 1 [3050/3978 (77%)]\tLoss: 0.529653\n",
            "Train Epoch: 1 [3055/3978 (77%)]\tLoss: 0.161440\n",
            "Train Epoch: 1 [3060/3978 (77%)]\tLoss: 0.225727\n",
            "Train Epoch: 1 [3065/3978 (77%)]\tLoss: 0.207450\n",
            "Train Epoch: 1 [3070/3978 (77%)]\tLoss: 0.092494\n",
            "Train Epoch: 1 [3075/3978 (77%)]\tLoss: 0.358153\n",
            "Train Epoch: 1 [3080/3978 (77%)]\tLoss: 0.225173\n",
            "Train Epoch: 1 [3085/3978 (78%)]\tLoss: 0.421477\n",
            "Train Epoch: 1 [3090/3978 (78%)]\tLoss: 0.106820\n",
            "Train Epoch: 1 [3095/3978 (78%)]\tLoss: 0.103433\n",
            "Train Epoch: 1 [3100/3978 (78%)]\tLoss: 0.608388\n",
            "Train Epoch: 1 [3105/3978 (78%)]\tLoss: 0.221989\n",
            "Train Epoch: 1 [3110/3978 (78%)]\tLoss: 0.268146\n",
            "Train Epoch: 1 [3115/3978 (78%)]\tLoss: 0.164423\n",
            "Train Epoch: 1 [3120/3978 (78%)]\tLoss: 0.169603\n",
            "Train Epoch: 1 [3125/3978 (79%)]\tLoss: 0.068236\n",
            "Train Epoch: 1 [3130/3978 (79%)]\tLoss: 0.126845\n",
            "Train Epoch: 1 [3135/3978 (79%)]\tLoss: 0.345237\n",
            "Train Epoch: 1 [3140/3978 (79%)]\tLoss: 0.185291\n",
            "Train Epoch: 1 [3145/3978 (79%)]\tLoss: 0.638379\n",
            "Train Epoch: 1 [3150/3978 (79%)]\tLoss: 0.217048\n",
            "Train Epoch: 1 [3155/3978 (79%)]\tLoss: 0.100489\n",
            "Train Epoch: 1 [3160/3978 (79%)]\tLoss: 0.317465\n",
            "Train Epoch: 1 [3165/3978 (80%)]\tLoss: 0.092541\n",
            "Train Epoch: 1 [3170/3978 (80%)]\tLoss: 0.394158\n",
            "Train Epoch: 1 [3175/3978 (80%)]\tLoss: 0.090914\n",
            "Train Epoch: 1 [3180/3978 (80%)]\tLoss: 0.088868\n",
            "Train Epoch: 1 [3185/3978 (80%)]\tLoss: 0.113947\n",
            "Train Epoch: 1 [3190/3978 (80%)]\tLoss: 0.187803\n",
            "Train Epoch: 1 [3195/3978 (80%)]\tLoss: 0.377647\n",
            "Train Epoch: 1 [3200/3978 (80%)]\tLoss: 0.239719\n",
            "Train Epoch: 1 [3205/3978 (81%)]\tLoss: 0.071601\n",
            "Train Epoch: 1 [3210/3978 (81%)]\tLoss: 0.383676\n",
            "Train Epoch: 1 [3215/3978 (81%)]\tLoss: 0.075259\n",
            "Train Epoch: 1 [3220/3978 (81%)]\tLoss: 0.078007\n",
            "Train Epoch: 1 [3225/3978 (81%)]\tLoss: 0.237185\n",
            "Train Epoch: 1 [3230/3978 (81%)]\tLoss: 0.241102\n",
            "Train Epoch: 1 [3235/3978 (81%)]\tLoss: 0.220940\n",
            "Train Epoch: 1 [3240/3978 (81%)]\tLoss: 0.340306\n",
            "Train Epoch: 1 [3245/3978 (82%)]\tLoss: 0.219197\n",
            "Train Epoch: 1 [3250/3978 (82%)]\tLoss: 0.408718\n",
            "Train Epoch: 1 [3255/3978 (82%)]\tLoss: 0.394272\n",
            "Train Epoch: 1 [3260/3978 (82%)]\tLoss: 0.206865\n",
            "Train Epoch: 1 [3265/3978 (82%)]\tLoss: 0.085075\n",
            "Train Epoch: 1 [3270/3978 (82%)]\tLoss: 0.544433\n",
            "Train Epoch: 1 [3275/3978 (82%)]\tLoss: 0.236222\n",
            "Train Epoch: 1 [3280/3978 (82%)]\tLoss: 0.186888\n",
            "Train Epoch: 1 [3285/3978 (83%)]\tLoss: 0.110490\n",
            "Train Epoch: 1 [3290/3978 (83%)]\tLoss: 0.363742\n",
            "Train Epoch: 1 [3295/3978 (83%)]\tLoss: 0.099858\n",
            "Train Epoch: 1 [3300/3978 (83%)]\tLoss: 0.479769\n",
            "Train Epoch: 1 [3305/3978 (83%)]\tLoss: 0.226318\n",
            "Train Epoch: 1 [3310/3978 (83%)]\tLoss: 0.288217\n",
            "Train Epoch: 1 [3315/3978 (83%)]\tLoss: 0.212394\n",
            "Train Epoch: 1 [3320/3978 (83%)]\tLoss: 0.125546\n",
            "Train Epoch: 1 [3325/3978 (84%)]\tLoss: 0.276088\n",
            "Train Epoch: 1 [3330/3978 (84%)]\tLoss: 0.272190\n",
            "Train Epoch: 1 [3335/3978 (84%)]\tLoss: 0.252855\n",
            "Train Epoch: 1 [3340/3978 (84%)]\tLoss: 0.146019\n",
            "Train Epoch: 1 [3345/3978 (84%)]\tLoss: 0.380471\n",
            "Train Epoch: 1 [3350/3978 (84%)]\tLoss: 0.142197\n",
            "Train Epoch: 1 [3355/3978 (84%)]\tLoss: 0.448890\n",
            "Train Epoch: 1 [3360/3978 (84%)]\tLoss: 0.437561\n",
            "Train Epoch: 1 [3365/3978 (85%)]\tLoss: 0.441101\n",
            "Train Epoch: 1 [3370/3978 (85%)]\tLoss: 0.095826\n",
            "Train Epoch: 1 [3375/3978 (85%)]\tLoss: 0.434408\n",
            "Train Epoch: 1 [3380/3978 (85%)]\tLoss: 0.202871\n",
            "Train Epoch: 1 [3385/3978 (85%)]\tLoss: 0.092293\n",
            "Train Epoch: 1 [3390/3978 (85%)]\tLoss: 0.112841\n",
            "Train Epoch: 1 [3395/3978 (85%)]\tLoss: 0.484107\n",
            "Train Epoch: 1 [3400/3978 (85%)]\tLoss: 0.413376\n",
            "Train Epoch: 1 [3405/3978 (86%)]\tLoss: 0.205624\n",
            "Train Epoch: 1 [3410/3978 (86%)]\tLoss: 0.156489\n",
            "Train Epoch: 1 [3415/3978 (86%)]\tLoss: 0.708090\n",
            "Train Epoch: 1 [3420/3978 (86%)]\tLoss: 0.083631\n",
            "Train Epoch: 1 [3425/3978 (86%)]\tLoss: 0.241109\n",
            "Train Epoch: 1 [3430/3978 (86%)]\tLoss: 0.196804\n",
            "Train Epoch: 1 [3435/3978 (86%)]\tLoss: 0.406558\n",
            "Train Epoch: 1 [3440/3978 (86%)]\tLoss: 0.345029\n",
            "Train Epoch: 1 [3445/3978 (87%)]\tLoss: 0.286744\n",
            "Train Epoch: 1 [3450/3978 (87%)]\tLoss: 0.461146\n",
            "Train Epoch: 1 [3455/3978 (87%)]\tLoss: 0.313677\n",
            "Train Epoch: 1 [3460/3978 (87%)]\tLoss: 0.288976\n",
            "Train Epoch: 1 [3465/3978 (87%)]\tLoss: 0.216934\n",
            "Train Epoch: 1 [3470/3978 (87%)]\tLoss: 0.442994\n",
            "Train Epoch: 1 [3475/3978 (87%)]\tLoss: 0.266551\n",
            "Train Epoch: 1 [3480/3978 (87%)]\tLoss: 0.259556\n",
            "Train Epoch: 1 [3485/3978 (88%)]\tLoss: 0.254717\n",
            "Train Epoch: 1 [3490/3978 (88%)]\tLoss: 0.129999\n",
            "Train Epoch: 1 [3495/3978 (88%)]\tLoss: 0.376157\n",
            "Train Epoch: 1 [3500/3978 (88%)]\tLoss: 0.160484\n",
            "Train Epoch: 1 [3505/3978 (88%)]\tLoss: 0.131681\n",
            "Train Epoch: 1 [3510/3978 (88%)]\tLoss: 0.139108\n",
            "Train Epoch: 1 [3515/3978 (88%)]\tLoss: 0.223797\n",
            "Train Epoch: 1 [3520/3978 (88%)]\tLoss: 0.344165\n",
            "Train Epoch: 1 [3525/3978 (89%)]\tLoss: 0.089523\n",
            "Train Epoch: 1 [3530/3978 (89%)]\tLoss: 0.220642\n",
            "Train Epoch: 1 [3535/3978 (89%)]\tLoss: 0.066360\n",
            "Train Epoch: 1 [3540/3978 (89%)]\tLoss: 0.219092\n",
            "Train Epoch: 1 [3545/3978 (89%)]\tLoss: 0.319856\n",
            "Train Epoch: 1 [3550/3978 (89%)]\tLoss: 0.163531\n",
            "Train Epoch: 1 [3555/3978 (89%)]\tLoss: 0.041769\n",
            "Train Epoch: 1 [3560/3978 (89%)]\tLoss: 0.141209\n",
            "Train Epoch: 1 [3565/3978 (90%)]\tLoss: 0.037042\n",
            "Train Epoch: 1 [3570/3978 (90%)]\tLoss: 0.093776\n",
            "Train Epoch: 1 [3575/3978 (90%)]\tLoss: 0.325462\n",
            "Train Epoch: 1 [3580/3978 (90%)]\tLoss: 0.122393\n",
            "Train Epoch: 1 [3585/3978 (90%)]\tLoss: 0.347735\n",
            "Train Epoch: 1 [3590/3978 (90%)]\tLoss: 0.197245\n",
            "Train Epoch: 1 [3595/3978 (90%)]\tLoss: 0.215646\n",
            "Train Epoch: 1 [3600/3978 (90%)]\tLoss: 0.192635\n",
            "Train Epoch: 1 [3605/3978 (91%)]\tLoss: 0.364174\n",
            "Train Epoch: 1 [3610/3978 (91%)]\tLoss: 0.269295\n",
            "Train Epoch: 1 [3615/3978 (91%)]\tLoss: 0.729139\n",
            "Train Epoch: 1 [3620/3978 (91%)]\tLoss: 0.163518\n",
            "Train Epoch: 1 [3625/3978 (91%)]\tLoss: 0.092097\n",
            "Train Epoch: 1 [3630/3978 (91%)]\tLoss: 0.103317\n",
            "Train Epoch: 1 [3635/3978 (91%)]\tLoss: 0.354460\n",
            "Train Epoch: 1 [3640/3978 (91%)]\tLoss: 0.517906\n",
            "Train Epoch: 1 [3645/3978 (92%)]\tLoss: 0.154163\n",
            "Train Epoch: 1 [3650/3978 (92%)]\tLoss: 0.506141\n",
            "Train Epoch: 1 [3655/3978 (92%)]\tLoss: 0.143530\n",
            "Train Epoch: 1 [3660/3978 (92%)]\tLoss: 0.403955\n",
            "Train Epoch: 1 [3665/3978 (92%)]\tLoss: 0.165121\n",
            "Train Epoch: 1 [3670/3978 (92%)]\tLoss: 0.331288\n",
            "Train Epoch: 1 [3675/3978 (92%)]\tLoss: 0.316816\n",
            "Train Epoch: 1 [3680/3978 (92%)]\tLoss: 0.168675\n",
            "Train Epoch: 1 [3685/3978 (93%)]\tLoss: 0.127466\n",
            "Train Epoch: 1 [3690/3978 (93%)]\tLoss: 0.132723\n",
            "Train Epoch: 1 [3695/3978 (93%)]\tLoss: 0.253106\n",
            "Train Epoch: 1 [3700/3978 (93%)]\tLoss: 0.097405\n",
            "Train Epoch: 1 [3705/3978 (93%)]\tLoss: 0.251462\n",
            "Train Epoch: 1 [3710/3978 (93%)]\tLoss: 0.301943\n",
            "Train Epoch: 1 [3715/3978 (93%)]\tLoss: 0.242653\n",
            "Train Epoch: 1 [3720/3978 (93%)]\tLoss: 0.046695\n",
            "Train Epoch: 1 [3725/3978 (94%)]\tLoss: 0.085388\n",
            "Train Epoch: 1 [3730/3978 (94%)]\tLoss: 0.061283\n",
            "Train Epoch: 1 [3735/3978 (94%)]\tLoss: 0.364675\n",
            "Train Epoch: 1 [3740/3978 (94%)]\tLoss: 0.070361\n",
            "Train Epoch: 1 [3745/3978 (94%)]\tLoss: 0.368838\n",
            "Train Epoch: 1 [3750/3978 (94%)]\tLoss: 0.267659\n",
            "Train Epoch: 1 [3755/3978 (94%)]\tLoss: 0.241117\n",
            "Train Epoch: 1 [3760/3978 (94%)]\tLoss: 0.269230\n",
            "Train Epoch: 1 [3765/3978 (95%)]\tLoss: 0.385126\n",
            "Train Epoch: 1 [3770/3978 (95%)]\tLoss: 0.447167\n",
            "Train Epoch: 1 [3775/3978 (95%)]\tLoss: 0.082442\n",
            "Train Epoch: 1 [3780/3978 (95%)]\tLoss: 0.368436\n",
            "Train Epoch: 1 [3785/3978 (95%)]\tLoss: 0.192146\n",
            "Train Epoch: 1 [3790/3978 (95%)]\tLoss: 0.069230\n",
            "Train Epoch: 1 [3795/3978 (95%)]\tLoss: 0.649973\n",
            "Train Epoch: 1 [3800/3978 (95%)]\tLoss: 0.081867\n",
            "Train Epoch: 1 [3805/3978 (96%)]\tLoss: 0.238927\n",
            "Train Epoch: 1 [3810/3978 (96%)]\tLoss: 0.631370\n",
            "Train Epoch: 1 [3815/3978 (96%)]\tLoss: 0.201299\n",
            "Train Epoch: 1 [3820/3978 (96%)]\tLoss: 0.116268\n",
            "Train Epoch: 1 [3825/3978 (96%)]\tLoss: 0.535828\n",
            "Train Epoch: 1 [3830/3978 (96%)]\tLoss: 0.319960\n",
            "Train Epoch: 1 [3835/3978 (96%)]\tLoss: 0.404409\n",
            "Train Epoch: 1 [3840/3978 (96%)]\tLoss: 0.109152\n",
            "Train Epoch: 1 [3845/3978 (97%)]\tLoss: 0.132598\n",
            "Train Epoch: 1 [3850/3978 (97%)]\tLoss: 0.111985\n",
            "Train Epoch: 1 [3855/3978 (97%)]\tLoss: 0.191770\n",
            "Train Epoch: 1 [3860/3978 (97%)]\tLoss: 0.296359\n",
            "Train Epoch: 1 [3865/3978 (97%)]\tLoss: 0.107859\n",
            "Train Epoch: 1 [3870/3978 (97%)]\tLoss: 0.113284\n",
            "Train Epoch: 1 [3875/3978 (97%)]\tLoss: 0.321473\n",
            "Train Epoch: 1 [3880/3978 (97%)]\tLoss: 0.177095\n",
            "Train Epoch: 1 [3885/3978 (98%)]\tLoss: 0.396672\n",
            "Train Epoch: 1 [3890/3978 (98%)]\tLoss: 0.184449\n",
            "Train Epoch: 1 [3895/3978 (98%)]\tLoss: 0.492714\n",
            "Train Epoch: 1 [3900/3978 (98%)]\tLoss: 0.201660\n",
            "Train Epoch: 1 [3905/3978 (98%)]\tLoss: 0.196578\n",
            "Train Epoch: 1 [3910/3978 (98%)]\tLoss: 0.225303\n",
            "Train Epoch: 1 [3915/3978 (98%)]\tLoss: 0.452313\n",
            "Train Epoch: 1 [3920/3978 (98%)]\tLoss: 0.104395\n",
            "Train Epoch: 1 [3925/3978 (99%)]\tLoss: 0.208625\n",
            "Train Epoch: 1 [3930/3978 (99%)]\tLoss: 0.259311\n",
            "Train Epoch: 1 [3935/3978 (99%)]\tLoss: 0.258773\n",
            "Train Epoch: 1 [3940/3978 (99%)]\tLoss: 0.242914\n",
            "Train Epoch: 1 [3945/3978 (99%)]\tLoss: 0.427918\n",
            "Train Epoch: 1 [3950/3978 (99%)]\tLoss: 0.277674\n",
            "Train Epoch: 1 [3955/3978 (99%)]\tLoss: 0.230136\n",
            "Train Epoch: 1 [3960/3978 (99%)]\tLoss: 0.253681\n",
            "Train Epoch: 1 [3965/3978 (100%)]\tLoss: 0.564861\n",
            "Train Epoch: 1 [3970/3978 (100%)]\tLoss: 0.063038\n",
            "Train Epoch: 1 [2385/3978 (100%)]\tLoss: 0.442131\n",
            "Epoch\n",
            "train/train_loss: 0.4421306848526001\n",
            "\n",
            "Train Loss: 0.442, Valid Loss: 0.310181, Accuracy: 0.36\n",
            "Train Epoch: 2 [0/3978 (0%)]\tLoss: 0.402768\n",
            "Train Epoch: 2 [5/3978 (0%)]\tLoss: 0.282187\n",
            "Train Epoch: 2 [10/3978 (0%)]\tLoss: 0.239247\n",
            "Train Epoch: 2 [15/3978 (0%)]\tLoss: 0.084544\n",
            "Train Epoch: 2 [20/3978 (1%)]\tLoss: 0.084450\n",
            "Train Epoch: 2 [25/3978 (1%)]\tLoss: 0.200320\n",
            "Train Epoch: 2 [30/3978 (1%)]\tLoss: 0.216166\n",
            "Train Epoch: 2 [35/3978 (1%)]\tLoss: 0.433679\n",
            "Train Epoch: 2 [40/3978 (1%)]\tLoss: 0.509571\n",
            "Train Epoch: 2 [45/3978 (1%)]\tLoss: 0.338624\n",
            "Train Epoch: 2 [50/3978 (1%)]\tLoss: 0.086511\n",
            "Train Epoch: 2 [55/3978 (1%)]\tLoss: 0.386966\n",
            "Train Epoch: 2 [60/3978 (2%)]\tLoss: 0.119914\n",
            "Train Epoch: 2 [65/3978 (2%)]\tLoss: 0.295734\n",
            "Train Epoch: 2 [70/3978 (2%)]\tLoss: 0.389252\n",
            "Train Epoch: 2 [75/3978 (2%)]\tLoss: 0.112665\n",
            "Train Epoch: 2 [80/3978 (2%)]\tLoss: 0.248366\n",
            "Train Epoch: 2 [85/3978 (2%)]\tLoss: 0.435327\n",
            "Train Epoch: 2 [90/3978 (2%)]\tLoss: 0.471836\n",
            "Train Epoch: 2 [95/3978 (2%)]\tLoss: 0.248798\n",
            "Train Epoch: 2 [100/3978 (3%)]\tLoss: 0.484547\n",
            "Train Epoch: 2 [105/3978 (3%)]\tLoss: 0.457874\n",
            "Train Epoch: 2 [110/3978 (3%)]\tLoss: 0.093171\n",
            "Train Epoch: 2 [115/3978 (3%)]\tLoss: 0.204072\n",
            "Train Epoch: 2 [120/3978 (3%)]\tLoss: 0.119075\n",
            "Train Epoch: 2 [125/3978 (3%)]\tLoss: 0.213773\n",
            "Train Epoch: 2 [130/3978 (3%)]\tLoss: 0.098549\n",
            "Train Epoch: 2 [135/3978 (3%)]\tLoss: 0.097803\n",
            "Train Epoch: 2 [140/3978 (4%)]\tLoss: 0.165142\n",
            "Train Epoch: 2 [145/3978 (4%)]\tLoss: 0.092081\n",
            "Train Epoch: 2 [150/3978 (4%)]\tLoss: 0.163249\n",
            "Train Epoch: 2 [155/3978 (4%)]\tLoss: 0.092259\n",
            "Train Epoch: 2 [160/3978 (4%)]\tLoss: 0.237736\n",
            "Train Epoch: 2 [165/3978 (4%)]\tLoss: 0.080260\n",
            "Train Epoch: 2 [170/3978 (4%)]\tLoss: 0.339605\n",
            "Train Epoch: 2 [175/3978 (4%)]\tLoss: 0.229000\n",
            "Train Epoch: 2 [180/3978 (5%)]\tLoss: 0.072579\n",
            "Train Epoch: 2 [185/3978 (5%)]\tLoss: 0.227918\n",
            "Train Epoch: 2 [190/3978 (5%)]\tLoss: 0.243224\n",
            "Train Epoch: 2 [195/3978 (5%)]\tLoss: 0.483086\n",
            "Train Epoch: 2 [200/3978 (5%)]\tLoss: 0.220018\n",
            "Train Epoch: 2 [205/3978 (5%)]\tLoss: 0.066175\n",
            "Train Epoch: 2 [210/3978 (5%)]\tLoss: 0.071910\n",
            "Train Epoch: 2 [215/3978 (5%)]\tLoss: 0.065963\n",
            "Train Epoch: 2 [220/3978 (6%)]\tLoss: 0.200606\n",
            "Train Epoch: 2 [225/3978 (6%)]\tLoss: 0.073368\n",
            "Train Epoch: 2 [230/3978 (6%)]\tLoss: 0.502316\n",
            "Train Epoch: 2 [235/3978 (6%)]\tLoss: 0.192903\n",
            "Train Epoch: 2 [240/3978 (6%)]\tLoss: 0.293194\n",
            "Train Epoch: 2 [245/3978 (6%)]\tLoss: 0.229651\n",
            "Train Epoch: 2 [250/3978 (6%)]\tLoss: 0.417221\n",
            "Train Epoch: 2 [255/3978 (6%)]\tLoss: 0.052339\n",
            "Train Epoch: 2 [260/3978 (7%)]\tLoss: 0.180753\n",
            "Train Epoch: 2 [265/3978 (7%)]\tLoss: 0.174044\n",
            "Train Epoch: 2 [270/3978 (7%)]\tLoss: 0.445626\n",
            "Train Epoch: 2 [275/3978 (7%)]\tLoss: 0.178303\n",
            "Train Epoch: 2 [280/3978 (7%)]\tLoss: 0.231172\n",
            "Train Epoch: 2 [285/3978 (7%)]\tLoss: 0.311878\n",
            "Train Epoch: 2 [290/3978 (7%)]\tLoss: 0.076485\n",
            "Train Epoch: 2 [295/3978 (7%)]\tLoss: 0.327339\n",
            "Train Epoch: 2 [300/3978 (8%)]\tLoss: 0.215648\n",
            "Train Epoch: 2 [305/3978 (8%)]\tLoss: 0.088296\n",
            "Train Epoch: 2 [310/3978 (8%)]\tLoss: 0.221309\n",
            "Train Epoch: 2 [315/3978 (8%)]\tLoss: 0.191762\n",
            "Train Epoch: 2 [320/3978 (8%)]\tLoss: 0.252370\n",
            "Train Epoch: 2 [325/3978 (8%)]\tLoss: 0.089253\n",
            "Train Epoch: 2 [330/3978 (8%)]\tLoss: 0.185675\n",
            "Train Epoch: 2 [335/3978 (8%)]\tLoss: 0.091937\n",
            "Train Epoch: 2 [340/3978 (9%)]\tLoss: 0.489435\n",
            "Train Epoch: 2 [345/3978 (9%)]\tLoss: 0.085753\n",
            "Train Epoch: 2 [350/3978 (9%)]\tLoss: 0.158986\n",
            "Train Epoch: 2 [355/3978 (9%)]\tLoss: 0.099866\n",
            "Train Epoch: 2 [360/3978 (9%)]\tLoss: 0.217453\n",
            "Train Epoch: 2 [365/3978 (9%)]\tLoss: 0.067174\n",
            "Train Epoch: 2 [370/3978 (9%)]\tLoss: 0.067297\n",
            "Train Epoch: 2 [375/3978 (9%)]\tLoss: 0.167349\n",
            "Train Epoch: 2 [380/3978 (10%)]\tLoss: 0.412522\n",
            "Train Epoch: 2 [385/3978 (10%)]\tLoss: 0.472710\n",
            "Train Epoch: 2 [390/3978 (10%)]\tLoss: 0.089189\n",
            "Train Epoch: 2 [395/3978 (10%)]\tLoss: 0.201162\n",
            "Train Epoch: 2 [400/3978 (10%)]\tLoss: 0.273904\n",
            "Train Epoch: 2 [405/3978 (10%)]\tLoss: 0.500357\n",
            "Train Epoch: 2 [410/3978 (10%)]\tLoss: 0.217657\n",
            "Train Epoch: 2 [415/3978 (10%)]\tLoss: 0.389193\n",
            "Train Epoch: 2 [420/3978 (11%)]\tLoss: 0.333919\n",
            "Train Epoch: 2 [425/3978 (11%)]\tLoss: 0.320000\n",
            "Train Epoch: 2 [430/3978 (11%)]\tLoss: 0.326336\n",
            "Train Epoch: 2 [435/3978 (11%)]\tLoss: 0.105418\n",
            "Train Epoch: 2 [440/3978 (11%)]\tLoss: 0.109840\n",
            "Train Epoch: 2 [445/3978 (11%)]\tLoss: 0.102352\n",
            "Train Epoch: 2 [450/3978 (11%)]\tLoss: 0.363268\n",
            "Train Epoch: 2 [455/3978 (11%)]\tLoss: 0.100353\n",
            "Train Epoch: 2 [460/3978 (12%)]\tLoss: 0.215756\n",
            "Train Epoch: 2 [465/3978 (12%)]\tLoss: 0.297281\n",
            "Train Epoch: 2 [470/3978 (12%)]\tLoss: 0.292534\n",
            "Train Epoch: 2 [475/3978 (12%)]\tLoss: 0.723201\n",
            "Train Epoch: 2 [480/3978 (12%)]\tLoss: 0.176325\n",
            "Train Epoch: 2 [485/3978 (12%)]\tLoss: 0.357359\n",
            "Train Epoch: 2 [490/3978 (12%)]\tLoss: 0.335959\n",
            "Train Epoch: 2 [495/3978 (12%)]\tLoss: 0.178381\n",
            "Train Epoch: 2 [500/3978 (13%)]\tLoss: 0.390167\n",
            "Train Epoch: 2 [505/3978 (13%)]\tLoss: 0.107082\n",
            "Train Epoch: 2 [510/3978 (13%)]\tLoss: 0.093544\n",
            "Train Epoch: 2 [515/3978 (13%)]\tLoss: 0.195180\n",
            "Train Epoch: 2 [520/3978 (13%)]\tLoss: 0.198038\n",
            "Train Epoch: 2 [525/3978 (13%)]\tLoss: 0.096102\n",
            "Train Epoch: 2 [530/3978 (13%)]\tLoss: 0.275490\n",
            "Train Epoch: 2 [535/3978 (13%)]\tLoss: 0.329584\n",
            "Train Epoch: 2 [540/3978 (14%)]\tLoss: 0.160805\n",
            "Train Epoch: 2 [545/3978 (14%)]\tLoss: 0.139871\n",
            "Train Epoch: 2 [550/3978 (14%)]\tLoss: 0.079711\n",
            "Train Epoch: 2 [555/3978 (14%)]\tLoss: 0.074815\n",
            "Train Epoch: 2 [560/3978 (14%)]\tLoss: 0.444002\n",
            "Train Epoch: 2 [565/3978 (14%)]\tLoss: 0.233754\n",
            "Train Epoch: 2 [570/3978 (14%)]\tLoss: 0.081863\n",
            "Train Epoch: 2 [575/3978 (14%)]\tLoss: 0.076337\n",
            "Train Epoch: 2 [580/3978 (15%)]\tLoss: 0.036946\n",
            "Train Epoch: 2 [585/3978 (15%)]\tLoss: 0.853924\n",
            "Train Epoch: 2 [590/3978 (15%)]\tLoss: 0.406939\n",
            "Train Epoch: 2 [595/3978 (15%)]\tLoss: 0.113770\n",
            "Train Epoch: 2 [600/3978 (15%)]\tLoss: 0.060752\n",
            "Train Epoch: 2 [605/3978 (15%)]\tLoss: 0.403145\n",
            "Train Epoch: 2 [610/3978 (15%)]\tLoss: 0.068608\n",
            "Train Epoch: 2 [615/3978 (15%)]\tLoss: 0.555224\n",
            "Train Epoch: 2 [620/3978 (16%)]\tLoss: 0.359849\n",
            "Train Epoch: 2 [625/3978 (16%)]\tLoss: 0.073200\n",
            "Train Epoch: 2 [630/3978 (16%)]\tLoss: 0.216836\n",
            "Train Epoch: 2 [635/3978 (16%)]\tLoss: 0.231462\n",
            "Train Epoch: 2 [640/3978 (16%)]\tLoss: 0.361460\n",
            "Train Epoch: 2 [645/3978 (16%)]\tLoss: 0.397557\n",
            "Train Epoch: 2 [650/3978 (16%)]\tLoss: 0.091720\n",
            "Train Epoch: 2 [655/3978 (16%)]\tLoss: 0.243455\n",
            "Train Epoch: 2 [660/3978 (17%)]\tLoss: 0.292553\n",
            "Train Epoch: 2 [665/3978 (17%)]\tLoss: 0.342950\n",
            "Train Epoch: 2 [670/3978 (17%)]\tLoss: 0.511124\n",
            "Train Epoch: 2 [675/3978 (17%)]\tLoss: 0.165318\n",
            "Train Epoch: 2 [680/3978 (17%)]\tLoss: 0.188663\n",
            "Train Epoch: 2 [685/3978 (17%)]\tLoss: 0.126383\n",
            "Train Epoch: 2 [690/3978 (17%)]\tLoss: 0.203683\n",
            "Train Epoch: 2 [695/3978 (17%)]\tLoss: 0.305326\n",
            "Train Epoch: 2 [700/3978 (18%)]\tLoss: 0.146411\n",
            "Train Epoch: 2 [705/3978 (18%)]\tLoss: 0.472723\n",
            "Train Epoch: 2 [710/3978 (18%)]\tLoss: 0.110952\n",
            "Train Epoch: 2 [715/3978 (18%)]\tLoss: 0.099080\n",
            "Train Epoch: 2 [720/3978 (18%)]\tLoss: 0.213965\n",
            "Train Epoch: 2 [725/3978 (18%)]\tLoss: 0.258921\n",
            "Train Epoch: 2 [730/3978 (18%)]\tLoss: 0.351060\n",
            "Train Epoch: 2 [735/3978 (18%)]\tLoss: 0.058866\n",
            "Train Epoch: 2 [740/3978 (19%)]\tLoss: 0.435832\n",
            "Train Epoch: 2 [745/3978 (19%)]\tLoss: 0.183827\n",
            "Train Epoch: 2 [750/3978 (19%)]\tLoss: 0.168073\n",
            "Train Epoch: 2 [755/3978 (19%)]\tLoss: 0.082695\n",
            "Train Epoch: 2 [760/3978 (19%)]\tLoss: 0.175516\n",
            "Train Epoch: 2 [765/3978 (19%)]\tLoss: 0.292061\n",
            "Train Epoch: 2 [770/3978 (19%)]\tLoss: 0.197579\n",
            "Train Epoch: 2 [775/3978 (19%)]\tLoss: 0.325745\n",
            "Train Epoch: 2 [780/3978 (20%)]\tLoss: 0.328448\n",
            "Train Epoch: 2 [785/3978 (20%)]\tLoss: 0.226058\n",
            "Train Epoch: 2 [790/3978 (20%)]\tLoss: 0.375842\n",
            "Train Epoch: 2 [795/3978 (20%)]\tLoss: 0.165918\n",
            "Train Epoch: 2 [800/3978 (20%)]\tLoss: 0.341618\n",
            "Train Epoch: 2 [805/3978 (20%)]\tLoss: 0.302808\n",
            "Train Epoch: 2 [810/3978 (20%)]\tLoss: 0.105415\n",
            "Train Epoch: 2 [815/3978 (20%)]\tLoss: 0.371125\n",
            "Train Epoch: 2 [820/3978 (21%)]\tLoss: 0.086560\n",
            "Train Epoch: 2 [825/3978 (21%)]\tLoss: 0.112801\n",
            "Train Epoch: 2 [830/3978 (21%)]\tLoss: 0.341450\n",
            "Train Epoch: 2 [835/3978 (21%)]\tLoss: 0.557477\n",
            "Train Epoch: 2 [840/3978 (21%)]\tLoss: 0.303655\n",
            "Train Epoch: 2 [845/3978 (21%)]\tLoss: 0.355084\n",
            "Train Epoch: 2 [850/3978 (21%)]\tLoss: 0.084177\n",
            "Train Epoch: 2 [855/3978 (21%)]\tLoss: 0.231761\n",
            "Train Epoch: 2 [860/3978 (22%)]\tLoss: 0.364328\n",
            "Train Epoch: 2 [865/3978 (22%)]\tLoss: 0.087478\n",
            "Train Epoch: 2 [870/3978 (22%)]\tLoss: 0.266112\n",
            "Train Epoch: 2 [875/3978 (22%)]\tLoss: 0.089663\n",
            "Train Epoch: 2 [880/3978 (22%)]\tLoss: 0.336206\n",
            "Train Epoch: 2 [885/3978 (22%)]\tLoss: 0.238207\n",
            "Train Epoch: 2 [890/3978 (22%)]\tLoss: 0.328549\n",
            "Train Epoch: 2 [895/3978 (22%)]\tLoss: 0.058267\n",
            "Train Epoch: 2 [900/3978 (23%)]\tLoss: 0.448228\n",
            "Train Epoch: 2 [905/3978 (23%)]\tLoss: 0.155568\n",
            "Train Epoch: 2 [910/3978 (23%)]\tLoss: 0.363956\n",
            "Train Epoch: 2 [915/3978 (23%)]\tLoss: 0.158025\n",
            "Train Epoch: 2 [920/3978 (23%)]\tLoss: 0.674559\n",
            "Train Epoch: 2 [925/3978 (23%)]\tLoss: 0.147142\n",
            "Train Epoch: 2 [930/3978 (23%)]\tLoss: 0.629667\n",
            "Train Epoch: 2 [935/3978 (23%)]\tLoss: 0.198553\n",
            "Train Epoch: 2 [940/3978 (24%)]\tLoss: 0.119270\n",
            "Train Epoch: 2 [945/3978 (24%)]\tLoss: 0.110760\n",
            "Train Epoch: 2 [950/3978 (24%)]\tLoss: 0.188188\n",
            "Train Epoch: 2 [955/3978 (24%)]\tLoss: 0.124752\n",
            "Train Epoch: 2 [960/3978 (24%)]\tLoss: 0.124595\n",
            "Train Epoch: 2 [965/3978 (24%)]\tLoss: 0.469090\n",
            "Train Epoch: 2 [970/3978 (24%)]\tLoss: 0.319061\n",
            "Train Epoch: 2 [975/3978 (24%)]\tLoss: 0.524253\n",
            "Train Epoch: 2 [980/3978 (25%)]\tLoss: 0.571863\n",
            "Train Epoch: 2 [985/3978 (25%)]\tLoss: 0.216917\n",
            "Train Epoch: 2 [990/3978 (25%)]\tLoss: 0.369175\n",
            "Train Epoch: 2 [995/3978 (25%)]\tLoss: 0.090519\n",
            "Train Epoch: 2 [1000/3978 (25%)]\tLoss: 0.089743\n",
            "Train Epoch: 2 [1005/3978 (25%)]\tLoss: 0.167790\n",
            "Train Epoch: 2 [1010/3978 (25%)]\tLoss: 0.214897\n",
            "Train Epoch: 2 [1015/3978 (26%)]\tLoss: 0.590097\n",
            "Train Epoch: 2 [1020/3978 (26%)]\tLoss: 0.084337\n",
            "Train Epoch: 2 [1025/3978 (26%)]\tLoss: 0.080850\n",
            "Train Epoch: 2 [1030/3978 (26%)]\tLoss: 0.263175\n",
            "Train Epoch: 2 [1035/3978 (26%)]\tLoss: 0.108344\n",
            "Train Epoch: 2 [1040/3978 (26%)]\tLoss: 0.064431\n",
            "Train Epoch: 2 [1045/3978 (26%)]\tLoss: 0.282845\n",
            "Train Epoch: 2 [1050/3978 (26%)]\tLoss: 0.246936\n",
            "Train Epoch: 2 [1055/3978 (27%)]\tLoss: 0.081393\n",
            "Train Epoch: 2 [1060/3978 (27%)]\tLoss: 0.364836\n",
            "Train Epoch: 2 [1065/3978 (27%)]\tLoss: 0.284264\n",
            "Train Epoch: 2 [1070/3978 (27%)]\tLoss: 0.235332\n",
            "Train Epoch: 2 [1075/3978 (27%)]\tLoss: 0.400699\n",
            "Train Epoch: 2 [1080/3978 (27%)]\tLoss: 0.073422\n",
            "Train Epoch: 2 [1085/3978 (27%)]\tLoss: 0.142826\n",
            "Train Epoch: 2 [1090/3978 (27%)]\tLoss: 0.099820\n",
            "Train Epoch: 2 [1095/3978 (28%)]\tLoss: 0.438940\n",
            "Train Epoch: 2 [1100/3978 (28%)]\tLoss: 0.328973\n",
            "Train Epoch: 2 [1105/3978 (28%)]\tLoss: 0.083735\n",
            "Train Epoch: 2 [1110/3978 (28%)]\tLoss: 0.182541\n",
            "Train Epoch: 2 [1115/3978 (28%)]\tLoss: 0.618184\n",
            "Train Epoch: 2 [1120/3978 (28%)]\tLoss: 0.103473\n",
            "Train Epoch: 2 [1125/3978 (28%)]\tLoss: 0.475902\n",
            "Train Epoch: 2 [1130/3978 (28%)]\tLoss: 0.584905\n",
            "Train Epoch: 2 [1135/3978 (29%)]\tLoss: 0.260626\n",
            "Train Epoch: 2 [1140/3978 (29%)]\tLoss: 0.241092\n",
            "Train Epoch: 2 [1145/3978 (29%)]\tLoss: 0.215544\n",
            "Train Epoch: 2 [1150/3978 (29%)]\tLoss: 0.222888\n",
            "Train Epoch: 2 [1155/3978 (29%)]\tLoss: 0.253002\n",
            "Train Epoch: 2 [1160/3978 (29%)]\tLoss: 0.229417\n",
            "Train Epoch: 2 [1165/3978 (29%)]\tLoss: 0.089585\n",
            "Train Epoch: 2 [1170/3978 (29%)]\tLoss: 0.251852\n",
            "Train Epoch: 2 [1175/3978 (30%)]\tLoss: 0.251942\n",
            "Train Epoch: 2 [1180/3978 (30%)]\tLoss: 0.091886\n",
            "Train Epoch: 2 [1185/3978 (30%)]\tLoss: 0.081263\n",
            "Train Epoch: 2 [1190/3978 (30%)]\tLoss: 0.187845\n",
            "Train Epoch: 2 [1195/3978 (30%)]\tLoss: 0.212630\n",
            "Train Epoch: 2 [1200/3978 (30%)]\tLoss: 0.422048\n",
            "Train Epoch: 2 [1205/3978 (30%)]\tLoss: 0.179853\n",
            "Train Epoch: 2 [1210/3978 (30%)]\tLoss: 0.074848\n",
            "Train Epoch: 2 [1215/3978 (31%)]\tLoss: 0.050692\n",
            "Train Epoch: 2 [1220/3978 (31%)]\tLoss: 0.124219\n",
            "Train Epoch: 2 [1225/3978 (31%)]\tLoss: 0.415122\n",
            "Train Epoch: 2 [1230/3978 (31%)]\tLoss: 0.423113\n",
            "Train Epoch: 2 [1235/3978 (31%)]\tLoss: 0.071045\n",
            "Train Epoch: 2 [1240/3978 (31%)]\tLoss: 0.265118\n",
            "Train Epoch: 2 [1245/3978 (31%)]\tLoss: 0.077594\n",
            "Train Epoch: 2 [1250/3978 (31%)]\tLoss: 0.648499\n",
            "Train Epoch: 2 [1255/3978 (32%)]\tLoss: 0.071349\n",
            "Train Epoch: 2 [1260/3978 (32%)]\tLoss: 0.544655\n",
            "Train Epoch: 2 [1265/3978 (32%)]\tLoss: 0.072930\n",
            "Train Epoch: 2 [1270/3978 (32%)]\tLoss: 0.213169\n",
            "Train Epoch: 2 [1275/3978 (32%)]\tLoss: 0.239599\n",
            "Train Epoch: 2 [1280/3978 (32%)]\tLoss: 0.211614\n",
            "Train Epoch: 2 [1285/3978 (32%)]\tLoss: 0.095880\n",
            "Train Epoch: 2 [1290/3978 (32%)]\tLoss: 0.198142\n",
            "Train Epoch: 2 [1295/3978 (33%)]\tLoss: 0.343895\n",
            "Train Epoch: 2 [1300/3978 (33%)]\tLoss: 0.087127\n",
            "Train Epoch: 2 [1305/3978 (33%)]\tLoss: 0.298409\n",
            "Train Epoch: 2 [1310/3978 (33%)]\tLoss: 0.526983\n",
            "Train Epoch: 2 [1315/3978 (33%)]\tLoss: 0.427554\n",
            "Train Epoch: 2 [1320/3978 (33%)]\tLoss: 0.346911\n",
            "Train Epoch: 2 [1325/3978 (33%)]\tLoss: 0.161417\n",
            "Train Epoch: 2 [1330/3978 (33%)]\tLoss: 0.129994\n",
            "Train Epoch: 2 [1335/3978 (34%)]\tLoss: 0.200078\n",
            "Train Epoch: 2 [1340/3978 (34%)]\tLoss: 0.321497\n",
            "Train Epoch: 2 [1345/3978 (34%)]\tLoss: 0.117306\n",
            "Train Epoch: 2 [1350/3978 (34%)]\tLoss: 0.437868\n",
            "Train Epoch: 2 [1355/3978 (34%)]\tLoss: 0.328324\n",
            "Train Epoch: 2 [1360/3978 (34%)]\tLoss: 0.176751\n",
            "Train Epoch: 2 [1365/3978 (34%)]\tLoss: 0.270718\n",
            "Train Epoch: 2 [1370/3978 (34%)]\tLoss: 0.121229\n",
            "Train Epoch: 2 [1375/3978 (35%)]\tLoss: 0.285013\n",
            "Train Epoch: 2 [1380/3978 (35%)]\tLoss: 0.091623\n",
            "Train Epoch: 2 [1385/3978 (35%)]\tLoss: 0.240674\n",
            "Train Epoch: 2 [1390/3978 (35%)]\tLoss: 0.282686\n",
            "Train Epoch: 2 [1395/3978 (35%)]\tLoss: 0.109219\n",
            "Train Epoch: 2 [1400/3978 (35%)]\tLoss: 0.079716\n",
            "Train Epoch: 2 [1405/3978 (35%)]\tLoss: 0.206758\n",
            "Train Epoch: 2 [1410/3978 (35%)]\tLoss: 0.102937\n",
            "Train Epoch: 2 [1415/3978 (36%)]\tLoss: 0.170156\n",
            "Train Epoch: 2 [1420/3978 (36%)]\tLoss: 0.106238\n",
            "Train Epoch: 2 [1425/3978 (36%)]\tLoss: 0.763804\n",
            "Train Epoch: 2 [1430/3978 (36%)]\tLoss: 0.467647\n",
            "Train Epoch: 2 [1435/3978 (36%)]\tLoss: 0.070173\n",
            "Train Epoch: 2 [1440/3978 (36%)]\tLoss: 0.068100\n",
            "Train Epoch: 2 [1445/3978 (36%)]\tLoss: 0.142321\n",
            "Train Epoch: 2 [1450/3978 (36%)]\tLoss: 0.723845\n",
            "Train Epoch: 2 [1455/3978 (37%)]\tLoss: 0.065341\n",
            "Train Epoch: 2 [1460/3978 (37%)]\tLoss: 0.329395\n",
            "Train Epoch: 2 [1465/3978 (37%)]\tLoss: 0.210571\n",
            "Train Epoch: 2 [1470/3978 (37%)]\tLoss: 0.047306\n",
            "Train Epoch: 2 [1475/3978 (37%)]\tLoss: 0.349092\n",
            "Train Epoch: 2 [1480/3978 (37%)]\tLoss: 0.155627\n",
            "Train Epoch: 2 [1485/3978 (37%)]\tLoss: 0.674128\n",
            "Train Epoch: 2 [1490/3978 (37%)]\tLoss: 0.275536\n",
            "Train Epoch: 2 [1495/3978 (38%)]\tLoss: 0.073746\n",
            "Train Epoch: 2 [1500/3978 (38%)]\tLoss: 0.211072\n",
            "Train Epoch: 2 [1505/3978 (38%)]\tLoss: 0.091033\n",
            "Train Epoch: 2 [1510/3978 (38%)]\tLoss: 0.256149\n",
            "Train Epoch: 2 [1515/3978 (38%)]\tLoss: 0.309794\n",
            "Train Epoch: 2 [1520/3978 (38%)]\tLoss: 0.093403\n",
            "Train Epoch: 2 [1525/3978 (38%)]\tLoss: 0.276181\n",
            "Train Epoch: 2 [1530/3978 (38%)]\tLoss: 0.361125\n",
            "Train Epoch: 2 [1535/3978 (39%)]\tLoss: 0.114892\n",
            "Train Epoch: 2 [1540/3978 (39%)]\tLoss: 0.155726\n",
            "Train Epoch: 2 [1545/3978 (39%)]\tLoss: 0.257999\n",
            "Train Epoch: 2 [1550/3978 (39%)]\tLoss: 0.362783\n",
            "Train Epoch: 2 [1555/3978 (39%)]\tLoss: 0.184121\n",
            "Train Epoch: 2 [1560/3978 (39%)]\tLoss: 0.358113\n",
            "Train Epoch: 2 [1565/3978 (39%)]\tLoss: 0.161617\n",
            "Train Epoch: 2 [1570/3978 (39%)]\tLoss: 0.110192\n",
            "Train Epoch: 2 [1575/3978 (40%)]\tLoss: 0.119988\n",
            "Train Epoch: 2 [1580/3978 (40%)]\tLoss: 0.198389\n",
            "Train Epoch: 2 [1585/3978 (40%)]\tLoss: 0.061164\n",
            "Train Epoch: 2 [1590/3978 (40%)]\tLoss: 0.418805\n",
            "Train Epoch: 2 [1595/3978 (40%)]\tLoss: 0.412376\n",
            "Train Epoch: 2 [1600/3978 (40%)]\tLoss: 0.200528\n",
            "Train Epoch: 2 [1605/3978 (40%)]\tLoss: 0.303938\n",
            "Train Epoch: 2 [1610/3978 (40%)]\tLoss: 0.086612\n",
            "Train Epoch: 2 [1615/3978 (41%)]\tLoss: 0.199957\n",
            "Train Epoch: 2 [1620/3978 (41%)]\tLoss: 0.239817\n",
            "Train Epoch: 2 [1625/3978 (41%)]\tLoss: 0.492662\n",
            "Train Epoch: 2 [1630/3978 (41%)]\tLoss: 0.322931\n",
            "Train Epoch: 2 [1635/3978 (41%)]\tLoss: 0.320722\n",
            "Train Epoch: 2 [1640/3978 (41%)]\tLoss: 0.276162\n",
            "Train Epoch: 2 [1645/3978 (41%)]\tLoss: 0.167633\n",
            "Train Epoch: 2 [1650/3978 (41%)]\tLoss: 0.129542\n",
            "Train Epoch: 2 [1655/3978 (42%)]\tLoss: 0.213611\n",
            "Train Epoch: 2 [1660/3978 (42%)]\tLoss: 0.206526\n",
            "Train Epoch: 2 [1665/3978 (42%)]\tLoss: 0.174813\n",
            "Train Epoch: 2 [1670/3978 (42%)]\tLoss: 0.509176\n",
            "Train Epoch: 2 [1675/3978 (42%)]\tLoss: 0.263057\n",
            "Train Epoch: 2 [1680/3978 (42%)]\tLoss: 0.234221\n",
            "Train Epoch: 2 [1685/3978 (42%)]\tLoss: 0.300069\n",
            "Train Epoch: 2 [1690/3978 (42%)]\tLoss: 0.182005\n",
            "Train Epoch: 2 [1695/3978 (43%)]\tLoss: 0.154731\n",
            "Train Epoch: 2 [1700/3978 (43%)]\tLoss: 0.218391\n",
            "Train Epoch: 2 [1705/3978 (43%)]\tLoss: 0.097426\n",
            "Train Epoch: 2 [1710/3978 (43%)]\tLoss: 0.318156\n",
            "Train Epoch: 2 [1715/3978 (43%)]\tLoss: 0.084583\n",
            "Train Epoch: 2 [1720/3978 (43%)]\tLoss: 0.089242\n",
            "Train Epoch: 2 [1725/3978 (43%)]\tLoss: 0.242798\n",
            "Train Epoch: 2 [1730/3978 (43%)]\tLoss: 0.076337\n",
            "Train Epoch: 2 [1735/3978 (44%)]\tLoss: 0.077626\n",
            "Train Epoch: 2 [1740/3978 (44%)]\tLoss: 0.288600\n",
            "Train Epoch: 2 [1745/3978 (44%)]\tLoss: 0.404811\n",
            "Train Epoch: 2 [1750/3978 (44%)]\tLoss: 0.191041\n",
            "Train Epoch: 2 [1755/3978 (44%)]\tLoss: 0.798283\n",
            "Train Epoch: 2 [1760/3978 (44%)]\tLoss: 0.455739\n",
            "Train Epoch: 2 [1765/3978 (44%)]\tLoss: 0.201613\n",
            "Train Epoch: 2 [1770/3978 (44%)]\tLoss: 0.283809\n",
            "Train Epoch: 2 [1775/3978 (45%)]\tLoss: 0.628047\n",
            "Train Epoch: 2 [1780/3978 (45%)]\tLoss: 0.371662\n",
            "Train Epoch: 2 [1785/3978 (45%)]\tLoss: 0.271083\n",
            "Train Epoch: 2 [1790/3978 (45%)]\tLoss: 0.218422\n",
            "Train Epoch: 2 [1795/3978 (45%)]\tLoss: 0.249812\n",
            "Train Epoch: 2 [1800/3978 (45%)]\tLoss: 0.236812\n",
            "Train Epoch: 2 [1805/3978 (45%)]\tLoss: 0.110345\n",
            "Train Epoch: 2 [1810/3978 (45%)]\tLoss: 0.359480\n",
            "Train Epoch: 2 [1815/3978 (46%)]\tLoss: 0.195134\n",
            "Train Epoch: 2 [1820/3978 (46%)]\tLoss: 0.265793\n",
            "Train Epoch: 2 [1825/3978 (46%)]\tLoss: 0.102210\n",
            "Train Epoch: 2 [1830/3978 (46%)]\tLoss: 0.108097\n",
            "Train Epoch: 2 [1835/3978 (46%)]\tLoss: 0.503720\n",
            "Train Epoch: 2 [1840/3978 (46%)]\tLoss: 0.614137\n",
            "Train Epoch: 2 [1845/3978 (46%)]\tLoss: 0.346514\n",
            "Train Epoch: 2 [1850/3978 (46%)]\tLoss: 0.450698\n",
            "Train Epoch: 2 [1855/3978 (47%)]\tLoss: 0.065961\n",
            "Train Epoch: 2 [1860/3978 (47%)]\tLoss: 0.429287\n",
            "Train Epoch: 2 [1865/3978 (47%)]\tLoss: 0.172884\n",
            "Train Epoch: 2 [1870/3978 (47%)]\tLoss: 0.222598\n",
            "Train Epoch: 2 [1875/3978 (47%)]\tLoss: 0.241623\n",
            "Train Epoch: 2 [1880/3978 (47%)]\tLoss: 0.324091\n",
            "Train Epoch: 2 [1885/3978 (47%)]\tLoss: 0.116025\n",
            "Train Epoch: 2 [1890/3978 (47%)]\tLoss: 0.353212\n",
            "Train Epoch: 2 [1895/3978 (48%)]\tLoss: 0.292658\n",
            "Train Epoch: 2 [1900/3978 (48%)]\tLoss: 0.255155\n",
            "Train Epoch: 2 [1905/3978 (48%)]\tLoss: 0.526054\n",
            "Train Epoch: 2 [1910/3978 (48%)]\tLoss: 0.248930\n",
            "Train Epoch: 2 [1915/3978 (48%)]\tLoss: 0.426269\n",
            "Train Epoch: 2 [1920/3978 (48%)]\tLoss: 0.168835\n",
            "Train Epoch: 2 [1925/3978 (48%)]\tLoss: 0.115737\n",
            "Train Epoch: 2 [1930/3978 (48%)]\tLoss: 0.097890\n",
            "Train Epoch: 2 [1935/3978 (49%)]\tLoss: 0.274700\n",
            "Train Epoch: 2 [1940/3978 (49%)]\tLoss: 0.107467\n",
            "Train Epoch: 2 [1945/3978 (49%)]\tLoss: 0.103059\n",
            "Train Epoch: 2 [1950/3978 (49%)]\tLoss: 0.068412\n",
            "Train Epoch: 2 [1955/3978 (49%)]\tLoss: 0.247249\n",
            "Train Epoch: 2 [1960/3978 (49%)]\tLoss: 0.377419\n",
            "Train Epoch: 2 [1965/3978 (49%)]\tLoss: 0.474013\n",
            "Train Epoch: 2 [1970/3978 (49%)]\tLoss: 0.409990\n",
            "Train Epoch: 2 [1975/3978 (50%)]\tLoss: 0.061570\n",
            "Train Epoch: 2 [1980/3978 (50%)]\tLoss: 0.072510\n",
            "Train Epoch: 2 [1985/3978 (50%)]\tLoss: 0.082414\n",
            "Train Epoch: 2 [1990/3978 (50%)]\tLoss: 0.496653\n",
            "Train Epoch: 2 [1995/3978 (50%)]\tLoss: 0.155245\n",
            "Train Epoch: 2 [2000/3978 (50%)]\tLoss: 0.246555\n",
            "Train Epoch: 2 [2005/3978 (50%)]\tLoss: 0.414912\n",
            "Train Epoch: 2 [2010/3978 (51%)]\tLoss: 0.081301\n",
            "Train Epoch: 2 [2015/3978 (51%)]\tLoss: 0.146088\n",
            "Train Epoch: 2 [2020/3978 (51%)]\tLoss: 0.405637\n",
            "Train Epoch: 2 [2025/3978 (51%)]\tLoss: 0.152279\n",
            "Train Epoch: 2 [2030/3978 (51%)]\tLoss: 0.210628\n",
            "Train Epoch: 2 [2035/3978 (51%)]\tLoss: 0.098694\n",
            "Train Epoch: 2 [2040/3978 (51%)]\tLoss: 0.346200\n",
            "Train Epoch: 2 [2045/3978 (51%)]\tLoss: 0.232209\n",
            "Train Epoch: 2 [2050/3978 (52%)]\tLoss: 0.159209\n",
            "Train Epoch: 2 [2055/3978 (52%)]\tLoss: 0.319921\n",
            "Train Epoch: 2 [2060/3978 (52%)]\tLoss: 0.544569\n",
            "Train Epoch: 2 [2065/3978 (52%)]\tLoss: 0.167721\n",
            "Train Epoch: 2 [2070/3978 (52%)]\tLoss: 0.222760\n",
            "Train Epoch: 2 [2075/3978 (52%)]\tLoss: 0.220317\n",
            "Train Epoch: 2 [2080/3978 (52%)]\tLoss: 0.105450\n",
            "Train Epoch: 2 [2085/3978 (52%)]\tLoss: 0.295391\n",
            "Train Epoch: 2 [2090/3978 (53%)]\tLoss: 0.207940\n",
            "Train Epoch: 2 [2095/3978 (53%)]\tLoss: 0.187207\n",
            "Train Epoch: 2 [2100/3978 (53%)]\tLoss: 0.108308\n",
            "Train Epoch: 2 [2105/3978 (53%)]\tLoss: 0.168741\n",
            "Train Epoch: 2 [2110/3978 (53%)]\tLoss: 0.190518\n",
            "Train Epoch: 2 [2115/3978 (53%)]\tLoss: 0.096436\n",
            "Train Epoch: 2 [2120/3978 (53%)]\tLoss: 0.082569\n",
            "Train Epoch: 2 [2125/3978 (53%)]\tLoss: 0.289693\n",
            "Train Epoch: 2 [2130/3978 (54%)]\tLoss: 0.082620\n",
            "Train Epoch: 2 [2135/3978 (54%)]\tLoss: 0.371986\n",
            "Train Epoch: 2 [2140/3978 (54%)]\tLoss: 0.077064\n",
            "Train Epoch: 2 [2145/3978 (54%)]\tLoss: 0.077007\n",
            "Train Epoch: 2 [2150/3978 (54%)]\tLoss: 0.378756\n",
            "Train Epoch: 2 [2155/3978 (54%)]\tLoss: 0.328700\n",
            "Train Epoch: 2 [2160/3978 (54%)]\tLoss: 0.172491\n",
            "Train Epoch: 2 [2165/3978 (54%)]\tLoss: 0.130807\n",
            "Train Epoch: 2 [2170/3978 (55%)]\tLoss: 0.189143\n",
            "Train Epoch: 2 [2175/3978 (55%)]\tLoss: 0.058322\n",
            "Train Epoch: 2 [2180/3978 (55%)]\tLoss: 0.100752\n",
            "Train Epoch: 2 [2185/3978 (55%)]\tLoss: 0.523504\n",
            "Train Epoch: 2 [2190/3978 (55%)]\tLoss: 0.048869\n",
            "Train Epoch: 2 [2195/3978 (55%)]\tLoss: 0.177598\n",
            "Train Epoch: 2 [2200/3978 (55%)]\tLoss: 0.047137\n",
            "Train Epoch: 2 [2205/3978 (55%)]\tLoss: 0.117312\n",
            "Train Epoch: 2 [2210/3978 (56%)]\tLoss: 0.042063\n",
            "Train Epoch: 2 [2215/3978 (56%)]\tLoss: 0.040519\n",
            "Train Epoch: 2 [2220/3978 (56%)]\tLoss: 0.453713\n",
            "Train Epoch: 2 [2225/3978 (56%)]\tLoss: 0.103618\n",
            "Train Epoch: 2 [2230/3978 (56%)]\tLoss: 0.234604\n",
            "Train Epoch: 2 [2235/3978 (56%)]\tLoss: 0.250734\n",
            "Train Epoch: 2 [2240/3978 (56%)]\tLoss: 0.196479\n",
            "Train Epoch: 2 [2245/3978 (56%)]\tLoss: 0.195730\n",
            "Train Epoch: 2 [2250/3978 (57%)]\tLoss: 0.066669\n",
            "Train Epoch: 2 [2255/3978 (57%)]\tLoss: 0.181984\n",
            "Train Epoch: 2 [2260/3978 (57%)]\tLoss: 0.091641\n",
            "Train Epoch: 2 [2265/3978 (57%)]\tLoss: 0.193438\n",
            "Train Epoch: 2 [2270/3978 (57%)]\tLoss: 0.215690\n",
            "Train Epoch: 2 [2275/3978 (57%)]\tLoss: 0.208747\n",
            "Train Epoch: 2 [2280/3978 (57%)]\tLoss: 0.380322\n",
            "Train Epoch: 2 [2285/3978 (57%)]\tLoss: 0.205860\n",
            "Train Epoch: 2 [2290/3978 (58%)]\tLoss: 0.119872\n",
            "Train Epoch: 2 [2295/3978 (58%)]\tLoss: 0.070741\n",
            "Train Epoch: 2 [2300/3978 (58%)]\tLoss: 0.460073\n",
            "Train Epoch: 2 [2305/3978 (58%)]\tLoss: 0.451571\n",
            "Train Epoch: 2 [2310/3978 (58%)]\tLoss: 0.155828\n",
            "Train Epoch: 2 [2315/3978 (58%)]\tLoss: 0.093569\n",
            "Train Epoch: 2 [2320/3978 (58%)]\tLoss: 0.093908\n",
            "Train Epoch: 2 [2325/3978 (58%)]\tLoss: 0.083669\n",
            "Train Epoch: 2 [2330/3978 (59%)]\tLoss: 0.347845\n",
            "Train Epoch: 2 [2335/3978 (59%)]\tLoss: 0.554070\n",
            "Train Epoch: 2 [2340/3978 (59%)]\tLoss: 0.230342\n",
            "Train Epoch: 2 [2345/3978 (59%)]\tLoss: 0.182266\n",
            "Train Epoch: 2 [2350/3978 (59%)]\tLoss: 0.196460\n",
            "Train Epoch: 2 [2355/3978 (59%)]\tLoss: 0.062235\n",
            "Train Epoch: 2 [2360/3978 (59%)]\tLoss: 0.252757\n",
            "Train Epoch: 2 [2365/3978 (59%)]\tLoss: 0.377258\n",
            "Train Epoch: 2 [2370/3978 (60%)]\tLoss: 0.120770\n",
            "Train Epoch: 2 [2375/3978 (60%)]\tLoss: 0.454246\n",
            "Train Epoch: 2 [2380/3978 (60%)]\tLoss: 0.244706\n",
            "Train Epoch: 2 [2385/3978 (60%)]\tLoss: 0.407751\n",
            "Train Epoch: 2 [2390/3978 (60%)]\tLoss: 0.570497\n",
            "Train Epoch: 2 [2395/3978 (60%)]\tLoss: 0.148434\n",
            "Train Epoch: 2 [2400/3978 (60%)]\tLoss: 0.107439\n",
            "Train Epoch: 2 [2405/3978 (60%)]\tLoss: 0.119134\n",
            "Train Epoch: 2 [2410/3978 (61%)]\tLoss: 0.112758\n",
            "Train Epoch: 2 [2415/3978 (61%)]\tLoss: 0.212326\n",
            "Train Epoch: 2 [2420/3978 (61%)]\tLoss: 0.323141\n",
            "Train Epoch: 2 [2425/3978 (61%)]\tLoss: 0.598925\n",
            "Train Epoch: 2 [2430/3978 (61%)]\tLoss: 0.436176\n",
            "Train Epoch: 2 [2435/3978 (61%)]\tLoss: 0.145037\n",
            "Train Epoch: 2 [2440/3978 (61%)]\tLoss: 0.239651\n",
            "Train Epoch: 2 [2445/3978 (61%)]\tLoss: 0.303697\n",
            "Train Epoch: 2 [2450/3978 (62%)]\tLoss: 0.233412\n",
            "Train Epoch: 2 [2455/3978 (62%)]\tLoss: 0.104468\n",
            "Train Epoch: 2 [2460/3978 (62%)]\tLoss: 0.224780\n",
            "Train Epoch: 2 [2465/3978 (62%)]\tLoss: 0.099790\n",
            "Train Epoch: 2 [2470/3978 (62%)]\tLoss: 0.230918\n",
            "Train Epoch: 2 [2475/3978 (62%)]\tLoss: 0.880265\n",
            "Train Epoch: 2 [2480/3978 (62%)]\tLoss: 0.336906\n",
            "Train Epoch: 2 [2485/3978 (62%)]\tLoss: 0.063470\n",
            "Train Epoch: 2 [2490/3978 (63%)]\tLoss: 0.162751\n",
            "Train Epoch: 2 [2495/3978 (63%)]\tLoss: 0.232177\n",
            "Train Epoch: 2 [2500/3978 (63%)]\tLoss: 0.237555\n",
            "Train Epoch: 2 [2505/3978 (63%)]\tLoss: 0.130393\n",
            "Train Epoch: 2 [2510/3978 (63%)]\tLoss: 0.271604\n",
            "Train Epoch: 2 [2515/3978 (63%)]\tLoss: 0.072183\n",
            "Train Epoch: 2 [2520/3978 (63%)]\tLoss: 0.383267\n",
            "Train Epoch: 2 [2525/3978 (63%)]\tLoss: 0.221646\n",
            "Train Epoch: 2 [2530/3978 (64%)]\tLoss: 0.235624\n",
            "Train Epoch: 2 [2535/3978 (64%)]\tLoss: 0.074552\n",
            "Train Epoch: 2 [2540/3978 (64%)]\tLoss: 0.222039\n",
            "Train Epoch: 2 [2545/3978 (64%)]\tLoss: 0.070378\n",
            "Train Epoch: 2 [2550/3978 (64%)]\tLoss: 0.207342\n",
            "Train Epoch: 2 [2555/3978 (64%)]\tLoss: 0.050030\n",
            "Train Epoch: 2 [2560/3978 (64%)]\tLoss: 0.213016\n",
            "Train Epoch: 2 [2565/3978 (64%)]\tLoss: 0.237448\n",
            "Train Epoch: 2 [2570/3978 (65%)]\tLoss: 0.186268\n",
            "Train Epoch: 2 [2575/3978 (65%)]\tLoss: 0.302922\n",
            "Train Epoch: 2 [2580/3978 (65%)]\tLoss: 0.123418\n",
            "Train Epoch: 2 [2585/3978 (65%)]\tLoss: 0.016670\n",
            "Train Epoch: 2 [2590/3978 (65%)]\tLoss: 0.609730\n",
            "Train Epoch: 2 [2595/3978 (65%)]\tLoss: 0.039634\n",
            "Train Epoch: 2 [2600/3978 (65%)]\tLoss: 0.393431\n",
            "Train Epoch: 2 [2605/3978 (65%)]\tLoss: 0.168123\n",
            "Train Epoch: 2 [2610/3978 (66%)]\tLoss: 0.754303\n",
            "Train Epoch: 2 [2615/3978 (66%)]\tLoss: 0.325657\n",
            "Train Epoch: 2 [2620/3978 (66%)]\tLoss: 0.440187\n",
            "Train Epoch: 2 [2625/3978 (66%)]\tLoss: 0.228598\n",
            "Train Epoch: 2 [2630/3978 (66%)]\tLoss: 0.467033\n",
            "Train Epoch: 2 [2635/3978 (66%)]\tLoss: 0.361867\n",
            "Train Epoch: 2 [2640/3978 (66%)]\tLoss: 0.262573\n",
            "Train Epoch: 2 [2645/3978 (66%)]\tLoss: 0.231406\n",
            "Train Epoch: 2 [2650/3978 (67%)]\tLoss: 0.157309\n",
            "Train Epoch: 2 [2655/3978 (67%)]\tLoss: 0.144521\n",
            "Train Epoch: 2 [2660/3978 (67%)]\tLoss: 0.353314\n",
            "Train Epoch: 2 [2665/3978 (67%)]\tLoss: 0.119131\n",
            "Train Epoch: 2 [2670/3978 (67%)]\tLoss: 0.331952\n",
            "Train Epoch: 2 [2675/3978 (67%)]\tLoss: 0.236933\n",
            "Train Epoch: 2 [2680/3978 (67%)]\tLoss: 0.088317\n",
            "Train Epoch: 2 [2685/3978 (67%)]\tLoss: 0.302350\n",
            "Train Epoch: 2 [2690/3978 (68%)]\tLoss: 0.180054\n",
            "Train Epoch: 2 [2695/3978 (68%)]\tLoss: 0.373696\n",
            "Train Epoch: 2 [2700/3978 (68%)]\tLoss: 0.236960\n",
            "Train Epoch: 2 [2705/3978 (68%)]\tLoss: 0.169203\n",
            "Train Epoch: 2 [2710/3978 (68%)]\tLoss: 0.167800\n",
            "Train Epoch: 2 [2715/3978 (68%)]\tLoss: 0.251330\n",
            "Train Epoch: 2 [2720/3978 (68%)]\tLoss: 0.087932\n",
            "Train Epoch: 2 [2725/3978 (68%)]\tLoss: 0.076595\n",
            "Train Epoch: 2 [2730/3978 (69%)]\tLoss: 0.375049\n",
            "Train Epoch: 2 [2735/3978 (69%)]\tLoss: 0.130476\n",
            "Train Epoch: 2 [2740/3978 (69%)]\tLoss: 0.158117\n",
            "Train Epoch: 2 [2745/3978 (69%)]\tLoss: 0.137690\n",
            "Train Epoch: 2 [2750/3978 (69%)]\tLoss: 0.238404\n",
            "Train Epoch: 2 [2755/3978 (69%)]\tLoss: 0.179746\n",
            "Train Epoch: 2 [2760/3978 (69%)]\tLoss: 0.316389\n",
            "Train Epoch: 2 [2765/3978 (69%)]\tLoss: 0.813740\n",
            "Train Epoch: 2 [2770/3978 (70%)]\tLoss: 0.478004\n",
            "Train Epoch: 2 [2775/3978 (70%)]\tLoss: 0.108762\n",
            "Train Epoch: 2 [2780/3978 (70%)]\tLoss: 0.104356\n",
            "Train Epoch: 2 [2785/3978 (70%)]\tLoss: 0.096562\n",
            "Train Epoch: 2 [2790/3978 (70%)]\tLoss: 0.240054\n",
            "Train Epoch: 2 [2795/3978 (70%)]\tLoss: 0.085067\n",
            "Train Epoch: 2 [2800/3978 (70%)]\tLoss: 0.481478\n",
            "Train Epoch: 2 [2805/3978 (70%)]\tLoss: 0.091826\n",
            "Train Epoch: 2 [2810/3978 (71%)]\tLoss: 0.084364\n",
            "Train Epoch: 2 [2815/3978 (71%)]\tLoss: 0.253461\n",
            "Train Epoch: 2 [2820/3978 (71%)]\tLoss: 0.248823\n",
            "Train Epoch: 2 [2825/3978 (71%)]\tLoss: 0.153410\n",
            "Train Epoch: 2 [2830/3978 (71%)]\tLoss: 0.079005\n",
            "Train Epoch: 2 [2835/3978 (71%)]\tLoss: 0.071498\n",
            "Train Epoch: 2 [2840/3978 (71%)]\tLoss: 0.548053\n",
            "Train Epoch: 2 [2845/3978 (71%)]\tLoss: 0.027666\n",
            "Train Epoch: 2 [2850/3978 (72%)]\tLoss: 0.422938\n",
            "Train Epoch: 2 [2855/3978 (72%)]\tLoss: 0.371669\n",
            "Train Epoch: 2 [2860/3978 (72%)]\tLoss: 0.353874\n",
            "Train Epoch: 2 [2865/3978 (72%)]\tLoss: 0.073878\n",
            "Train Epoch: 2 [2870/3978 (72%)]\tLoss: 0.164374\n",
            "Train Epoch: 2 [2875/3978 (72%)]\tLoss: 0.251884\n",
            "Train Epoch: 2 [2880/3978 (72%)]\tLoss: 0.185403\n",
            "Train Epoch: 2 [2885/3978 (72%)]\tLoss: 0.238510\n",
            "Train Epoch: 2 [2890/3978 (73%)]\tLoss: 0.109186\n",
            "Train Epoch: 2 [2895/3978 (73%)]\tLoss: 0.435310\n",
            "Train Epoch: 2 [2900/3978 (73%)]\tLoss: 0.274217\n",
            "Train Epoch: 2 [2905/3978 (73%)]\tLoss: 0.255271\n",
            "Train Epoch: 2 [2910/3978 (73%)]\tLoss: 0.091703\n",
            "Train Epoch: 2 [2915/3978 (73%)]\tLoss: 0.094739\n",
            "Train Epoch: 2 [2920/3978 (73%)]\tLoss: 0.148922\n",
            "Train Epoch: 2 [2925/3978 (73%)]\tLoss: 0.206562\n",
            "Train Epoch: 2 [2930/3978 (74%)]\tLoss: 0.247678\n",
            "Train Epoch: 2 [2935/3978 (74%)]\tLoss: 0.083182\n",
            "Train Epoch: 2 [2940/3978 (74%)]\tLoss: 0.315174\n",
            "Train Epoch: 2 [2945/3978 (74%)]\tLoss: 0.223666\n",
            "Train Epoch: 2 [2950/3978 (74%)]\tLoss: 0.236355\n",
            "Train Epoch: 2 [2955/3978 (74%)]\tLoss: 0.347915\n",
            "Train Epoch: 2 [2960/3978 (74%)]\tLoss: 0.287222\n",
            "Train Epoch: 2 [2965/3978 (74%)]\tLoss: 0.333853\n",
            "Train Epoch: 2 [2970/3978 (75%)]\tLoss: 0.487084\n",
            "Train Epoch: 2 [2975/3978 (75%)]\tLoss: 0.465159\n",
            "Train Epoch: 2 [2980/3978 (75%)]\tLoss: 0.578432\n",
            "Train Epoch: 2 [2985/3978 (75%)]\tLoss: 0.419055\n",
            "Train Epoch: 2 [2990/3978 (75%)]\tLoss: 0.178163\n",
            "Train Epoch: 2 [2995/3978 (75%)]\tLoss: 0.246063\n",
            "Train Epoch: 2 [3000/3978 (75%)]\tLoss: 0.119316\n",
            "Train Epoch: 2 [3005/3978 (76%)]\tLoss: 0.160316\n",
            "Train Epoch: 2 [3010/3978 (76%)]\tLoss: 0.104339\n",
            "Train Epoch: 2 [3015/3978 (76%)]\tLoss: 0.165469\n",
            "Train Epoch: 2 [3020/3978 (76%)]\tLoss: 0.187932\n",
            "Train Epoch: 2 [3025/3978 (76%)]\tLoss: 0.318412\n",
            "Train Epoch: 2 [3030/3978 (76%)]\tLoss: 0.313571\n",
            "Train Epoch: 2 [3035/3978 (76%)]\tLoss: 0.161401\n",
            "Train Epoch: 2 [3040/3978 (76%)]\tLoss: 0.118597\n",
            "Train Epoch: 2 [3045/3978 (77%)]\tLoss: 0.264079\n",
            "Train Epoch: 2 [3050/3978 (77%)]\tLoss: 0.464257\n",
            "Train Epoch: 2 [3055/3978 (77%)]\tLoss: 0.222506\n",
            "Train Epoch: 2 [3060/3978 (77%)]\tLoss: 0.406583\n",
            "Train Epoch: 2 [3065/3978 (77%)]\tLoss: 0.359595\n",
            "Train Epoch: 2 [3070/3978 (77%)]\tLoss: 0.078626\n",
            "Train Epoch: 2 [3075/3978 (77%)]\tLoss: 0.176955\n",
            "Train Epoch: 2 [3080/3978 (77%)]\tLoss: 0.390937\n",
            "Train Epoch: 2 [3085/3978 (78%)]\tLoss: 0.251376\n",
            "Train Epoch: 2 [3090/3978 (78%)]\tLoss: 0.088134\n",
            "Train Epoch: 2 [3095/3978 (78%)]\tLoss: 0.580121\n",
            "Train Epoch: 2 [3100/3978 (78%)]\tLoss: 0.091958\n",
            "Train Epoch: 2 [3105/3978 (78%)]\tLoss: 0.109275\n",
            "Train Epoch: 2 [3110/3978 (78%)]\tLoss: 0.103179\n",
            "Train Epoch: 2 [3115/3978 (78%)]\tLoss: 0.281357\n",
            "Train Epoch: 2 [3120/3978 (78%)]\tLoss: 0.249018\n",
            "Train Epoch: 2 [3125/3978 (79%)]\tLoss: 0.154474\n",
            "Train Epoch: 2 [3130/3978 (79%)]\tLoss: 0.276673\n",
            "Train Epoch: 2 [3135/3978 (79%)]\tLoss: 0.551113\n",
            "Train Epoch: 2 [3140/3978 (79%)]\tLoss: 0.183147\n",
            "Train Epoch: 2 [3145/3978 (79%)]\tLoss: 0.603001\n",
            "Train Epoch: 2 [3150/3978 (79%)]\tLoss: 0.214024\n",
            "Train Epoch: 2 [3155/3978 (79%)]\tLoss: 0.285071\n",
            "Train Epoch: 2 [3160/3978 (79%)]\tLoss: 0.078654\n",
            "Train Epoch: 2 [3165/3978 (80%)]\tLoss: 0.119165\n",
            "Train Epoch: 2 [3170/3978 (80%)]\tLoss: 0.118215\n",
            "Train Epoch: 2 [3175/3978 (80%)]\tLoss: 0.137242\n",
            "Train Epoch: 2 [3180/3978 (80%)]\tLoss: 0.180387\n",
            "Train Epoch: 2 [3185/3978 (80%)]\tLoss: 0.065185\n",
            "Train Epoch: 2 [3190/3978 (80%)]\tLoss: 0.231751\n",
            "Train Epoch: 2 [3195/3978 (80%)]\tLoss: 0.606180\n",
            "Train Epoch: 2 [3200/3978 (80%)]\tLoss: 0.219153\n",
            "Train Epoch: 2 [3205/3978 (81%)]\tLoss: 0.458774\n",
            "Train Epoch: 2 [3210/3978 (81%)]\tLoss: 0.099688\n",
            "Train Epoch: 2 [3215/3978 (81%)]\tLoss: 0.240759\n",
            "Train Epoch: 2 [3220/3978 (81%)]\tLoss: 0.424987\n",
            "Train Epoch: 2 [3225/3978 (81%)]\tLoss: 0.187345\n",
            "Train Epoch: 2 [3230/3978 (81%)]\tLoss: 0.188328\n",
            "Train Epoch: 2 [3235/3978 (81%)]\tLoss: 0.091595\n",
            "Train Epoch: 2 [3240/3978 (81%)]\tLoss: 0.080895\n",
            "Train Epoch: 2 [3245/3978 (82%)]\tLoss: 0.212755\n",
            "Train Epoch: 2 [3250/3978 (82%)]\tLoss: 0.374671\n",
            "Train Epoch: 2 [3255/3978 (82%)]\tLoss: 0.085417\n",
            "Train Epoch: 2 [3260/3978 (82%)]\tLoss: 0.180612\n",
            "Train Epoch: 2 [3265/3978 (82%)]\tLoss: 0.511534\n",
            "Train Epoch: 2 [3270/3978 (82%)]\tLoss: 0.195479\n",
            "Train Epoch: 2 [3275/3978 (82%)]\tLoss: 0.319849\n",
            "Train Epoch: 2 [3280/3978 (82%)]\tLoss: 0.480100\n",
            "Train Epoch: 2 [3285/3978 (83%)]\tLoss: 0.263097\n",
            "Train Epoch: 2 [3290/3978 (83%)]\tLoss: 0.384724\n",
            "Train Epoch: 2 [3295/3978 (83%)]\tLoss: 0.251112\n",
            "Train Epoch: 2 [3300/3978 (83%)]\tLoss: 0.421255\n",
            "Train Epoch: 2 [3305/3978 (83%)]\tLoss: 0.193016\n",
            "Train Epoch: 2 [3310/3978 (83%)]\tLoss: 0.342861\n",
            "Train Epoch: 2 [3315/3978 (83%)]\tLoss: 0.170146\n",
            "Train Epoch: 2 [3320/3978 (83%)]\tLoss: 0.229618\n",
            "Train Epoch: 2 [3325/3978 (84%)]\tLoss: 0.247599\n",
            "Train Epoch: 2 [3330/3978 (84%)]\tLoss: 0.172315\n",
            "Train Epoch: 2 [3335/3978 (84%)]\tLoss: 0.224776\n",
            "Train Epoch: 2 [3340/3978 (84%)]\tLoss: 0.240116\n",
            "Train Epoch: 2 [3345/3978 (84%)]\tLoss: 0.269972\n",
            "Train Epoch: 2 [3350/3978 (84%)]\tLoss: 0.347419\n",
            "Train Epoch: 2 [3355/3978 (84%)]\tLoss: 0.208050\n",
            "Train Epoch: 2 [3360/3978 (84%)]\tLoss: 0.355569\n",
            "Train Epoch: 2 [3365/3978 (85%)]\tLoss: 0.073720\n",
            "Train Epoch: 2 [3370/3978 (85%)]\tLoss: 0.266518\n",
            "Train Epoch: 2 [3375/3978 (85%)]\tLoss: 0.119314\n",
            "Train Epoch: 2 [3380/3978 (85%)]\tLoss: 0.159403\n",
            "Train Epoch: 2 [3385/3978 (85%)]\tLoss: 0.410976\n",
            "Train Epoch: 2 [3390/3978 (85%)]\tLoss: 0.347738\n",
            "Train Epoch: 2 [3395/3978 (85%)]\tLoss: 0.205662\n",
            "Train Epoch: 2 [3400/3978 (85%)]\tLoss: 0.170710\n",
            "Train Epoch: 2 [3405/3978 (86%)]\tLoss: 0.109939\n",
            "Train Epoch: 2 [3410/3978 (86%)]\tLoss: 0.234155\n",
            "Train Epoch: 2 [3415/3978 (86%)]\tLoss: 0.092864\n",
            "Train Epoch: 2 [3420/3978 (86%)]\tLoss: 0.095235\n",
            "Train Epoch: 2 [3425/3978 (86%)]\tLoss: 0.079222\n",
            "Train Epoch: 2 [3430/3978 (86%)]\tLoss: 0.372127\n",
            "Train Epoch: 2 [3435/3978 (86%)]\tLoss: 0.178301\n",
            "Train Epoch: 2 [3440/3978 (86%)]\tLoss: 0.458823\n",
            "Train Epoch: 2 [3445/3978 (87%)]\tLoss: 0.217789\n",
            "Train Epoch: 2 [3450/3978 (87%)]\tLoss: 0.083975\n",
            "Train Epoch: 2 [3455/3978 (87%)]\tLoss: 0.452360\n",
            "Train Epoch: 2 [3460/3978 (87%)]\tLoss: 0.143923\n",
            "Train Epoch: 2 [3465/3978 (87%)]\tLoss: 0.225219\n",
            "Train Epoch: 2 [3470/3978 (87%)]\tLoss: 0.311458\n",
            "Train Epoch: 2 [3475/3978 (87%)]\tLoss: 0.044297\n",
            "Train Epoch: 2 [3480/3978 (87%)]\tLoss: 0.061622\n",
            "Train Epoch: 2 [3485/3978 (88%)]\tLoss: 0.141659\n",
            "Train Epoch: 2 [3490/3978 (88%)]\tLoss: 0.207086\n",
            "Train Epoch: 2 [3495/3978 (88%)]\tLoss: 0.366635\n",
            "Train Epoch: 2 [3500/3978 (88%)]\tLoss: 0.204292\n",
            "Train Epoch: 2 [3505/3978 (88%)]\tLoss: 0.227049\n",
            "Train Epoch: 2 [3510/3978 (88%)]\tLoss: 0.278097\n",
            "Train Epoch: 2 [3515/3978 (88%)]\tLoss: 0.177432\n",
            "Train Epoch: 2 [3520/3978 (88%)]\tLoss: 0.183221\n",
            "Train Epoch: 2 [3525/3978 (89%)]\tLoss: 0.200269\n",
            "Train Epoch: 2 [3530/3978 (89%)]\tLoss: 0.202202\n",
            "Train Epoch: 2 [3535/3978 (89%)]\tLoss: 0.221962\n",
            "Train Epoch: 2 [3540/3978 (89%)]\tLoss: 0.161589\n",
            "Train Epoch: 2 [3545/3978 (89%)]\tLoss: 0.196131\n",
            "Train Epoch: 2 [3550/3978 (89%)]\tLoss: 0.571615\n",
            "Train Epoch: 2 [3555/3978 (89%)]\tLoss: 0.523774\n",
            "Train Epoch: 2 [3560/3978 (89%)]\tLoss: 0.162642\n",
            "Train Epoch: 2 [3565/3978 (90%)]\tLoss: 0.068384\n",
            "Train Epoch: 2 [3570/3978 (90%)]\tLoss: 0.412672\n",
            "Train Epoch: 2 [3575/3978 (90%)]\tLoss: 0.253565\n",
            "Train Epoch: 2 [3580/3978 (90%)]\tLoss: 0.591945\n",
            "Train Epoch: 2 [3585/3978 (90%)]\tLoss: 0.099238\n",
            "Train Epoch: 2 [3590/3978 (90%)]\tLoss: 0.101979\n",
            "Train Epoch: 2 [3595/3978 (90%)]\tLoss: 0.130889\n",
            "Train Epoch: 2 [3600/3978 (90%)]\tLoss: 0.159516\n",
            "Train Epoch: 2 [3605/3978 (91%)]\tLoss: 0.207794\n",
            "Train Epoch: 2 [3610/3978 (91%)]\tLoss: 0.152976\n",
            "Train Epoch: 2 [3615/3978 (91%)]\tLoss: 0.100029\n",
            "Train Epoch: 2 [3620/3978 (91%)]\tLoss: 0.214762\n",
            "Train Epoch: 2 [3625/3978 (91%)]\tLoss: 0.456477\n",
            "Train Epoch: 2 [3630/3978 (91%)]\tLoss: 0.158914\n",
            "Train Epoch: 2 [3635/3978 (91%)]\tLoss: 0.048734\n",
            "Train Epoch: 2 [3640/3978 (91%)]\tLoss: 0.377780\n",
            "Train Epoch: 2 [3645/3978 (92%)]\tLoss: 0.207262\n",
            "Train Epoch: 2 [3650/3978 (92%)]\tLoss: 0.041882\n",
            "Train Epoch: 2 [3655/3978 (92%)]\tLoss: 0.464926\n",
            "Train Epoch: 2 [3660/3978 (92%)]\tLoss: 0.405873\n",
            "Train Epoch: 2 [3665/3978 (92%)]\tLoss: 0.213928\n",
            "Train Epoch: 2 [3670/3978 (92%)]\tLoss: 0.313671\n",
            "Train Epoch: 2 [3675/3978 (92%)]\tLoss: 0.181665\n",
            "Train Epoch: 2 [3680/3978 (92%)]\tLoss: 0.078816\n",
            "Train Epoch: 2 [3685/3978 (93%)]\tLoss: 0.238281\n",
            "Train Epoch: 2 [3690/3978 (93%)]\tLoss: 0.350206\n",
            "Train Epoch: 2 [3695/3978 (93%)]\tLoss: 0.614928\n",
            "Train Epoch: 2 [3700/3978 (93%)]\tLoss: 0.081306\n",
            "Train Epoch: 2 [3705/3978 (93%)]\tLoss: 0.206749\n",
            "Train Epoch: 2 [3710/3978 (93%)]\tLoss: 0.176668\n",
            "Train Epoch: 2 [3715/3978 (93%)]\tLoss: 0.215687\n",
            "Train Epoch: 2 [3720/3978 (93%)]\tLoss: 0.282524\n",
            "Train Epoch: 2 [3725/3978 (94%)]\tLoss: 0.284589\n",
            "Train Epoch: 2 [3730/3978 (94%)]\tLoss: 0.125812\n",
            "Train Epoch: 2 [3735/3978 (94%)]\tLoss: 0.092230\n",
            "Train Epoch: 2 [3740/3978 (94%)]\tLoss: 0.255701\n",
            "Train Epoch: 2 [3745/3978 (94%)]\tLoss: 0.159833\n",
            "Train Epoch: 2 [3750/3978 (94%)]\tLoss: 0.119220\n",
            "Train Epoch: 2 [3755/3978 (94%)]\tLoss: 0.108713\n",
            "Train Epoch: 2 [3760/3978 (94%)]\tLoss: 0.178220\n",
            "Train Epoch: 2 [3765/3978 (95%)]\tLoss: 0.350756\n",
            "Train Epoch: 2 [3770/3978 (95%)]\tLoss: 0.081129\n",
            "Train Epoch: 2 [3775/3978 (95%)]\tLoss: 0.218242\n",
            "Train Epoch: 2 [3780/3978 (95%)]\tLoss: 0.097186\n",
            "Train Epoch: 2 [3785/3978 (95%)]\tLoss: 0.182499\n",
            "Train Epoch: 2 [3790/3978 (95%)]\tLoss: 0.066553\n",
            "Train Epoch: 2 [3795/3978 (95%)]\tLoss: 0.398460\n",
            "Train Epoch: 2 [3800/3978 (95%)]\tLoss: 0.061178\n",
            "Train Epoch: 2 [3805/3978 (96%)]\tLoss: 0.243965\n",
            "Train Epoch: 2 [3810/3978 (96%)]\tLoss: 0.149094\n",
            "Train Epoch: 2 [3815/3978 (96%)]\tLoss: 0.059345\n",
            "Train Epoch: 2 [3820/3978 (96%)]\tLoss: 0.197296\n",
            "Train Epoch: 2 [3825/3978 (96%)]\tLoss: 0.069562\n",
            "Train Epoch: 2 [3830/3978 (96%)]\tLoss: 0.248370\n",
            "Train Epoch: 2 [3835/3978 (96%)]\tLoss: 0.071812\n",
            "Train Epoch: 2 [3840/3978 (96%)]\tLoss: 0.059836\n",
            "Train Epoch: 2 [3845/3978 (97%)]\tLoss: 0.226359\n",
            "Train Epoch: 2 [3850/3978 (97%)]\tLoss: 0.271537\n",
            "Train Epoch: 2 [3855/3978 (97%)]\tLoss: 0.424171\n",
            "Train Epoch: 2 [3860/3978 (97%)]\tLoss: 0.331791\n",
            "Train Epoch: 2 [3865/3978 (97%)]\tLoss: 0.305910\n",
            "Train Epoch: 2 [3870/3978 (97%)]\tLoss: 0.294498\n",
            "Train Epoch: 2 [3875/3978 (97%)]\tLoss: 0.328951\n",
            "Train Epoch: 2 [3880/3978 (97%)]\tLoss: 0.075970\n",
            "Train Epoch: 2 [3885/3978 (98%)]\tLoss: 0.496931\n",
            "Train Epoch: 2 [3890/3978 (98%)]\tLoss: 0.191388\n",
            "Train Epoch: 2 [3895/3978 (98%)]\tLoss: 0.064769\n",
            "Train Epoch: 2 [3900/3978 (98%)]\tLoss: 0.101188\n",
            "Train Epoch: 2 [3905/3978 (98%)]\tLoss: 0.151648\n",
            "Train Epoch: 2 [3910/3978 (98%)]\tLoss: 0.339143\n",
            "Train Epoch: 2 [3915/3978 (98%)]\tLoss: 0.244888\n",
            "Train Epoch: 2 [3920/3978 (98%)]\tLoss: 0.088816\n",
            "Train Epoch: 2 [3925/3978 (99%)]\tLoss: 0.292002\n",
            "Train Epoch: 2 [3930/3978 (99%)]\tLoss: 0.319973\n",
            "Train Epoch: 2 [3935/3978 (99%)]\tLoss: 0.331457\n",
            "Train Epoch: 2 [3940/3978 (99%)]\tLoss: 0.298291\n",
            "Train Epoch: 2 [3945/3978 (99%)]\tLoss: 0.287751\n",
            "Train Epoch: 2 [3950/3978 (99%)]\tLoss: 0.306778\n",
            "Train Epoch: 2 [3955/3978 (99%)]\tLoss: 0.217210\n",
            "Train Epoch: 2 [3960/3978 (99%)]\tLoss: 0.140745\n",
            "Train Epoch: 2 [3965/3978 (100%)]\tLoss: 0.071878\n",
            "Train Epoch: 2 [3970/3978 (100%)]\tLoss: 0.244806\n",
            "Train Epoch: 2 [2385/3978 (100%)]\tLoss: 0.122236\n",
            "Epoch\n",
            "train/train_loss: 0.12223642319440842\n",
            "\n",
            "Train Loss: 0.122, Valid Loss: 0.306015, Accuracy: 0.35\n",
            "Train Epoch: 3 [0/3978 (0%)]\tLoss: 0.392387\n",
            "Train Epoch: 3 [5/3978 (0%)]\tLoss: 0.155293\n",
            "Train Epoch: 3 [10/3978 (0%)]\tLoss: 0.238241\n",
            "Train Epoch: 3 [15/3978 (0%)]\tLoss: 0.472784\n",
            "Train Epoch: 3 [20/3978 (1%)]\tLoss: 0.064365\n",
            "Train Epoch: 3 [25/3978 (1%)]\tLoss: 0.308306\n",
            "Train Epoch: 3 [30/3978 (1%)]\tLoss: 0.233192\n",
            "Train Epoch: 3 [35/3978 (1%)]\tLoss: 0.241817\n",
            "Train Epoch: 3 [40/3978 (1%)]\tLoss: 0.255004\n",
            "Train Epoch: 3 [45/3978 (1%)]\tLoss: 0.070917\n",
            "Train Epoch: 3 [50/3978 (1%)]\tLoss: 0.440534\n",
            "Train Epoch: 3 [55/3978 (1%)]\tLoss: 0.106237\n",
            "Train Epoch: 3 [60/3978 (2%)]\tLoss: 0.174264\n",
            "Train Epoch: 3 [65/3978 (2%)]\tLoss: 0.427262\n",
            "Train Epoch: 3 [70/3978 (2%)]\tLoss: 0.075260\n",
            "Train Epoch: 3 [75/3978 (2%)]\tLoss: 0.180232\n",
            "Train Epoch: 3 [80/3978 (2%)]\tLoss: 0.484746\n",
            "Train Epoch: 3 [85/3978 (2%)]\tLoss: 0.174761\n",
            "Train Epoch: 3 [90/3978 (2%)]\tLoss: 0.212399\n",
            "Train Epoch: 3 [95/3978 (2%)]\tLoss: 0.636063\n",
            "Train Epoch: 3 [100/3978 (3%)]\tLoss: 0.224585\n",
            "Train Epoch: 3 [105/3978 (3%)]\tLoss: 0.111042\n",
            "Train Epoch: 3 [110/3978 (3%)]\tLoss: 0.112381\n",
            "Train Epoch: 3 [115/3978 (3%)]\tLoss: 0.291900\n",
            "Train Epoch: 3 [120/3978 (3%)]\tLoss: 0.100792\n",
            "Train Epoch: 3 [125/3978 (3%)]\tLoss: 0.078781\n",
            "Train Epoch: 3 [130/3978 (3%)]\tLoss: 0.312181\n",
            "Train Epoch: 3 [135/3978 (3%)]\tLoss: 0.142828\n",
            "Train Epoch: 3 [140/3978 (4%)]\tLoss: 0.272667\n",
            "Train Epoch: 3 [145/3978 (4%)]\tLoss: 0.072620\n",
            "Train Epoch: 3 [150/3978 (4%)]\tLoss: 0.090689\n",
            "Train Epoch: 3 [155/3978 (4%)]\tLoss: 0.385112\n",
            "Train Epoch: 3 [160/3978 (4%)]\tLoss: 0.122398\n",
            "Train Epoch: 3 [165/3978 (4%)]\tLoss: 0.087674\n",
            "Train Epoch: 3 [170/3978 (4%)]\tLoss: 0.344422\n",
            "Train Epoch: 3 [175/3978 (4%)]\tLoss: 0.291343\n",
            "Train Epoch: 3 [180/3978 (5%)]\tLoss: 0.088391\n",
            "Train Epoch: 3 [185/3978 (5%)]\tLoss: 0.271009\n",
            "Train Epoch: 3 [190/3978 (5%)]\tLoss: 0.088390\n",
            "Train Epoch: 3 [195/3978 (5%)]\tLoss: 0.291626\n",
            "Train Epoch: 3 [200/3978 (5%)]\tLoss: 0.797432\n",
            "Train Epoch: 3 [205/3978 (5%)]\tLoss: 0.088421\n",
            "Train Epoch: 3 [210/3978 (5%)]\tLoss: 0.189158\n",
            "Train Epoch: 3 [215/3978 (5%)]\tLoss: 0.399743\n",
            "Train Epoch: 3 [220/3978 (6%)]\tLoss: 0.075288\n",
            "Train Epoch: 3 [225/3978 (6%)]\tLoss: 0.182924\n",
            "Train Epoch: 3 [230/3978 (6%)]\tLoss: 0.311349\n",
            "Train Epoch: 3 [235/3978 (6%)]\tLoss: 0.202346\n",
            "Train Epoch: 3 [240/3978 (6%)]\tLoss: 0.272564\n",
            "Train Epoch: 3 [245/3978 (6%)]\tLoss: 0.128195\n",
            "Train Epoch: 3 [250/3978 (6%)]\tLoss: 0.094565\n",
            "Train Epoch: 3 [255/3978 (6%)]\tLoss: 0.100250\n",
            "Train Epoch: 3 [260/3978 (7%)]\tLoss: 0.216464\n",
            "Train Epoch: 3 [265/3978 (7%)]\tLoss: 0.150796\n",
            "Train Epoch: 3 [270/3978 (7%)]\tLoss: 0.291094\n",
            "Train Epoch: 3 [275/3978 (7%)]\tLoss: 0.339104\n",
            "Train Epoch: 3 [280/3978 (7%)]\tLoss: 0.080487\n",
            "Train Epoch: 3 [285/3978 (7%)]\tLoss: 0.333841\n",
            "Train Epoch: 3 [290/3978 (7%)]\tLoss: 0.148907\n",
            "Train Epoch: 3 [295/3978 (7%)]\tLoss: 0.330518\n",
            "Train Epoch: 3 [300/3978 (8%)]\tLoss: 0.296631\n",
            "Train Epoch: 3 [305/3978 (8%)]\tLoss: 0.283016\n",
            "Train Epoch: 3 [310/3978 (8%)]\tLoss: 0.038601\n",
            "Train Epoch: 3 [315/3978 (8%)]\tLoss: 0.150674\n",
            "Train Epoch: 3 [320/3978 (8%)]\tLoss: 0.258817\n",
            "Train Epoch: 3 [325/3978 (8%)]\tLoss: 0.266125\n",
            "Train Epoch: 3 [330/3978 (8%)]\tLoss: 0.256467\n",
            "Train Epoch: 3 [335/3978 (8%)]\tLoss: 0.064822\n",
            "Train Epoch: 3 [340/3978 (9%)]\tLoss: 0.135880\n",
            "Train Epoch: 3 [345/3978 (9%)]\tLoss: 0.337057\n",
            "Train Epoch: 3 [350/3978 (9%)]\tLoss: 0.319992\n",
            "Train Epoch: 3 [355/3978 (9%)]\tLoss: 0.112333\n",
            "Train Epoch: 3 [360/3978 (9%)]\tLoss: 0.077155\n",
            "Train Epoch: 3 [365/3978 (9%)]\tLoss: 0.335944\n",
            "Train Epoch: 3 [370/3978 (9%)]\tLoss: 0.233765\n",
            "Train Epoch: 3 [375/3978 (9%)]\tLoss: 0.195402\n",
            "Train Epoch: 3 [380/3978 (10%)]\tLoss: 0.100490\n",
            "Train Epoch: 3 [385/3978 (10%)]\tLoss: 0.348715\n",
            "Train Epoch: 3 [390/3978 (10%)]\tLoss: 0.019988\n",
            "Train Epoch: 3 [395/3978 (10%)]\tLoss: 0.264486\n",
            "Train Epoch: 3 [400/3978 (10%)]\tLoss: 0.079528\n",
            "Train Epoch: 3 [405/3978 (10%)]\tLoss: 0.702995\n",
            "Train Epoch: 3 [410/3978 (10%)]\tLoss: 0.117834\n",
            "Train Epoch: 3 [415/3978 (10%)]\tLoss: 0.258661\n",
            "Train Epoch: 3 [420/3978 (11%)]\tLoss: 0.182730\n",
            "Train Epoch: 3 [425/3978 (11%)]\tLoss: 0.180218\n",
            "Train Epoch: 3 [430/3978 (11%)]\tLoss: 0.397317\n",
            "Train Epoch: 3 [435/3978 (11%)]\tLoss: 0.215703\n",
            "Train Epoch: 3 [440/3978 (11%)]\tLoss: 0.055042\n",
            "Train Epoch: 3 [445/3978 (11%)]\tLoss: 0.083852\n",
            "Train Epoch: 3 [450/3978 (11%)]\tLoss: 0.238447\n",
            "Train Epoch: 3 [455/3978 (11%)]\tLoss: 0.488682\n",
            "Train Epoch: 3 [460/3978 (12%)]\tLoss: 0.262875\n",
            "Train Epoch: 3 [465/3978 (12%)]\tLoss: 0.206368\n",
            "Train Epoch: 3 [470/3978 (12%)]\tLoss: 0.094142\n",
            "Train Epoch: 3 [475/3978 (12%)]\tLoss: 0.180138\n",
            "Train Epoch: 3 [480/3978 (12%)]\tLoss: 0.373178\n",
            "Train Epoch: 3 [485/3978 (12%)]\tLoss: 0.099083\n",
            "Train Epoch: 3 [490/3978 (12%)]\tLoss: 0.447078\n",
            "Train Epoch: 3 [495/3978 (12%)]\tLoss: 0.473371\n",
            "Train Epoch: 3 [500/3978 (13%)]\tLoss: 0.084660\n",
            "Train Epoch: 3 [505/3978 (13%)]\tLoss: 0.177779\n",
            "Train Epoch: 3 [510/3978 (13%)]\tLoss: 0.093189\n",
            "Train Epoch: 3 [515/3978 (13%)]\tLoss: 0.301030\n",
            "Train Epoch: 3 [520/3978 (13%)]\tLoss: 0.065942\n",
            "Train Epoch: 3 [525/3978 (13%)]\tLoss: 0.284148\n",
            "Train Epoch: 3 [530/3978 (13%)]\tLoss: 0.363114\n",
            "Train Epoch: 3 [535/3978 (13%)]\tLoss: 0.100741\n",
            "Train Epoch: 3 [540/3978 (14%)]\tLoss: 0.312858\n",
            "Train Epoch: 3 [545/3978 (14%)]\tLoss: 0.103752\n",
            "Train Epoch: 3 [550/3978 (14%)]\tLoss: 0.191186\n",
            "Train Epoch: 3 [555/3978 (14%)]\tLoss: 0.200510\n",
            "Train Epoch: 3 [560/3978 (14%)]\tLoss: 0.430299\n",
            "Train Epoch: 3 [565/3978 (14%)]\tLoss: 0.106128\n",
            "Train Epoch: 3 [570/3978 (14%)]\tLoss: 0.473540\n",
            "Train Epoch: 3 [575/3978 (14%)]\tLoss: 0.109808\n",
            "Train Epoch: 3 [580/3978 (15%)]\tLoss: 0.351515\n",
            "Train Epoch: 3 [585/3978 (15%)]\tLoss: 0.177941\n",
            "Train Epoch: 3 [590/3978 (15%)]\tLoss: 0.068046\n",
            "Train Epoch: 3 [595/3978 (15%)]\tLoss: 0.325206\n",
            "Train Epoch: 3 [600/3978 (15%)]\tLoss: 0.078242\n",
            "Train Epoch: 3 [605/3978 (15%)]\tLoss: 0.198112\n",
            "Train Epoch: 3 [610/3978 (15%)]\tLoss: 0.188516\n",
            "Train Epoch: 3 [615/3978 (15%)]\tLoss: 0.330053\n",
            "Train Epoch: 3 [620/3978 (16%)]\tLoss: 0.186595\n",
            "Train Epoch: 3 [625/3978 (16%)]\tLoss: 0.297294\n",
            "Train Epoch: 3 [630/3978 (16%)]\tLoss: 0.405776\n",
            "Train Epoch: 3 [635/3978 (16%)]\tLoss: 0.285270\n",
            "Train Epoch: 3 [640/3978 (16%)]\tLoss: 0.161927\n",
            "Train Epoch: 3 [645/3978 (16%)]\tLoss: 0.107467\n",
            "Train Epoch: 3 [650/3978 (16%)]\tLoss: 0.107002\n",
            "Train Epoch: 3 [655/3978 (16%)]\tLoss: 0.327107\n",
            "Train Epoch: 3 [660/3978 (17%)]\tLoss: 0.228923\n",
            "Train Epoch: 3 [665/3978 (17%)]\tLoss: 0.118408\n",
            "Train Epoch: 3 [670/3978 (17%)]\tLoss: 0.097289\n",
            "Train Epoch: 3 [675/3978 (17%)]\tLoss: 0.122511\n",
            "Train Epoch: 3 [680/3978 (17%)]\tLoss: 0.077448\n",
            "Train Epoch: 3 [685/3978 (17%)]\tLoss: 0.554211\n",
            "Train Epoch: 3 [690/3978 (17%)]\tLoss: 0.349128\n",
            "Train Epoch: 3 [695/3978 (17%)]\tLoss: 0.188703\n",
            "Train Epoch: 3 [700/3978 (18%)]\tLoss: 0.363786\n",
            "Train Epoch: 3 [705/3978 (18%)]\tLoss: 0.470156\n",
            "Train Epoch: 3 [710/3978 (18%)]\tLoss: 0.173691\n",
            "Train Epoch: 3 [715/3978 (18%)]\tLoss: 0.179148\n",
            "Train Epoch: 3 [720/3978 (18%)]\tLoss: 0.162019\n",
            "Train Epoch: 3 [725/3978 (18%)]\tLoss: 0.211565\n",
            "Train Epoch: 3 [730/3978 (18%)]\tLoss: 0.584021\n",
            "Train Epoch: 3 [735/3978 (18%)]\tLoss: 0.075259\n",
            "Train Epoch: 3 [740/3978 (19%)]\tLoss: 0.299818\n",
            "Train Epoch: 3 [745/3978 (19%)]\tLoss: 0.264764\n",
            "Train Epoch: 3 [750/3978 (19%)]\tLoss: 0.200715\n",
            "Train Epoch: 3 [755/3978 (19%)]\tLoss: 0.292613\n",
            "Train Epoch: 3 [760/3978 (19%)]\tLoss: 0.099277\n",
            "Train Epoch: 3 [765/3978 (19%)]\tLoss: 0.117544\n",
            "Train Epoch: 3 [770/3978 (19%)]\tLoss: 0.211018\n",
            "Train Epoch: 3 [775/3978 (19%)]\tLoss: 0.750662\n",
            "Train Epoch: 3 [780/3978 (20%)]\tLoss: 0.288160\n",
            "Train Epoch: 3 [785/3978 (20%)]\tLoss: 0.699617\n",
            "Train Epoch: 3 [790/3978 (20%)]\tLoss: 0.290518\n",
            "Train Epoch: 3 [795/3978 (20%)]\tLoss: 0.302966\n",
            "Train Epoch: 3 [800/3978 (20%)]\tLoss: 0.094809\n",
            "Train Epoch: 3 [805/3978 (20%)]\tLoss: 0.093028\n",
            "Train Epoch: 3 [810/3978 (20%)]\tLoss: 0.646773\n",
            "Train Epoch: 3 [815/3978 (20%)]\tLoss: 0.189548\n",
            "Train Epoch: 3 [820/3978 (21%)]\tLoss: 0.117147\n",
            "Train Epoch: 3 [825/3978 (21%)]\tLoss: 0.356343\n",
            "Train Epoch: 3 [830/3978 (21%)]\tLoss: 0.174521\n",
            "Train Epoch: 3 [835/3978 (21%)]\tLoss: 0.029367\n",
            "Train Epoch: 3 [840/3978 (21%)]\tLoss: 0.305750\n",
            "Train Epoch: 3 [845/3978 (21%)]\tLoss: 0.086172\n",
            "Train Epoch: 3 [850/3978 (21%)]\tLoss: 0.321507\n",
            "Train Epoch: 3 [855/3978 (21%)]\tLoss: 0.112793\n",
            "Train Epoch: 3 [860/3978 (22%)]\tLoss: 0.476494\n",
            "Train Epoch: 3 [865/3978 (22%)]\tLoss: 0.088025\n",
            "Train Epoch: 3 [870/3978 (22%)]\tLoss: 0.217167\n",
            "Train Epoch: 3 [875/3978 (22%)]\tLoss: 0.107804\n",
            "Train Epoch: 3 [880/3978 (22%)]\tLoss: 0.106977\n",
            "Train Epoch: 3 [885/3978 (22%)]\tLoss: 0.168667\n",
            "Train Epoch: 3 [890/3978 (22%)]\tLoss: 0.219040\n",
            "Train Epoch: 3 [895/3978 (22%)]\tLoss: 0.301106\n",
            "Train Epoch: 3 [900/3978 (23%)]\tLoss: 0.353040\n",
            "Train Epoch: 3 [905/3978 (23%)]\tLoss: 0.070815\n",
            "Train Epoch: 3 [910/3978 (23%)]\tLoss: 0.481093\n",
            "Train Epoch: 3 [915/3978 (23%)]\tLoss: 0.388000\n",
            "Train Epoch: 3 [920/3978 (23%)]\tLoss: 0.261281\n",
            "Train Epoch: 3 [925/3978 (23%)]\tLoss: 0.063095\n",
            "Train Epoch: 3 [930/3978 (23%)]\tLoss: 0.084698\n",
            "Train Epoch: 3 [935/3978 (23%)]\tLoss: 0.240167\n",
            "Train Epoch: 3 [940/3978 (24%)]\tLoss: 0.424537\n",
            "Train Epoch: 3 [945/3978 (24%)]\tLoss: 0.580909\n",
            "Train Epoch: 3 [950/3978 (24%)]\tLoss: 0.085797\n",
            "Train Epoch: 3 [955/3978 (24%)]\tLoss: 0.251285\n",
            "Train Epoch: 3 [960/3978 (24%)]\tLoss: 0.271453\n",
            "Train Epoch: 3 [965/3978 (24%)]\tLoss: 0.174019\n",
            "Train Epoch: 3 [970/3978 (24%)]\tLoss: 0.100520\n",
            "Train Epoch: 3 [975/3978 (24%)]\tLoss: 0.395333\n",
            "Train Epoch: 3 [980/3978 (25%)]\tLoss: 0.237982\n",
            "Train Epoch: 3 [985/3978 (25%)]\tLoss: 0.295026\n",
            "Train Epoch: 3 [990/3978 (25%)]\tLoss: 0.121791\n",
            "Train Epoch: 3 [995/3978 (25%)]\tLoss: 0.163263\n",
            "Train Epoch: 3 [1000/3978 (25%)]\tLoss: 0.350549\n",
            "Train Epoch: 3 [1005/3978 (25%)]\tLoss: 0.273592\n",
            "Train Epoch: 3 [1010/3978 (25%)]\tLoss: 0.279464\n",
            "Train Epoch: 3 [1015/3978 (26%)]\tLoss: 0.480523\n",
            "Train Epoch: 3 [1020/3978 (26%)]\tLoss: 0.253792\n",
            "Train Epoch: 3 [1025/3978 (26%)]\tLoss: 0.208333\n",
            "Train Epoch: 3 [1030/3978 (26%)]\tLoss: 0.109840\n",
            "Train Epoch: 3 [1035/3978 (26%)]\tLoss: 0.295871\n",
            "Train Epoch: 3 [1040/3978 (26%)]\tLoss: 0.371834\n",
            "Train Epoch: 3 [1045/3978 (26%)]\tLoss: 0.117238\n",
            "Train Epoch: 3 [1050/3978 (26%)]\tLoss: 0.121727\n",
            "Train Epoch: 3 [1055/3978 (27%)]\tLoss: 0.369212\n",
            "Train Epoch: 3 [1060/3978 (27%)]\tLoss: 0.244018\n",
            "Train Epoch: 3 [1065/3978 (27%)]\tLoss: 0.280746\n",
            "Train Epoch: 3 [1070/3978 (27%)]\tLoss: 0.324362\n",
            "Train Epoch: 3 [1075/3978 (27%)]\tLoss: 0.256899\n",
            "Train Epoch: 3 [1080/3978 (27%)]\tLoss: 0.533192\n",
            "Train Epoch: 3 [1085/3978 (27%)]\tLoss: 0.191577\n",
            "Train Epoch: 3 [1090/3978 (27%)]\tLoss: 0.156131\n",
            "Train Epoch: 3 [1095/3978 (28%)]\tLoss: 0.549138\n",
            "Train Epoch: 3 [1100/3978 (28%)]\tLoss: 0.238249\n",
            "Train Epoch: 3 [1105/3978 (28%)]\tLoss: 0.313588\n",
            "Train Epoch: 3 [1110/3978 (28%)]\tLoss: 0.311742\n",
            "Train Epoch: 3 [1115/3978 (28%)]\tLoss: 0.284190\n",
            "Train Epoch: 3 [1120/3978 (28%)]\tLoss: 0.222724\n",
            "Train Epoch: 3 [1125/3978 (28%)]\tLoss: 0.359887\n",
            "Train Epoch: 3 [1130/3978 (28%)]\tLoss: 0.186510\n",
            "Train Epoch: 3 [1135/3978 (29%)]\tLoss: 0.198845\n",
            "Train Epoch: 3 [1140/3978 (29%)]\tLoss: 0.344683\n",
            "Train Epoch: 3 [1145/3978 (29%)]\tLoss: 0.259946\n",
            "Train Epoch: 3 [1150/3978 (29%)]\tLoss: 0.219203\n",
            "Train Epoch: 3 [1155/3978 (29%)]\tLoss: 0.526810\n",
            "Train Epoch: 3 [1160/3978 (29%)]\tLoss: 0.200459\n",
            "Train Epoch: 3 [1165/3978 (29%)]\tLoss: 0.253459\n",
            "Train Epoch: 3 [1170/3978 (29%)]\tLoss: 0.271163\n",
            "Train Epoch: 3 [1175/3978 (30%)]\tLoss: 0.336405\n",
            "Train Epoch: 3 [1180/3978 (30%)]\tLoss: 0.115735\n",
            "Train Epoch: 3 [1185/3978 (30%)]\tLoss: 0.253339\n",
            "Train Epoch: 3 [1190/3978 (30%)]\tLoss: 0.370546\n",
            "Train Epoch: 3 [1195/3978 (30%)]\tLoss: 0.288004\n",
            "Train Epoch: 3 [1200/3978 (30%)]\tLoss: 0.137004\n",
            "Train Epoch: 3 [1205/3978 (30%)]\tLoss: 0.113206\n",
            "Train Epoch: 3 [1210/3978 (30%)]\tLoss: 0.240878\n",
            "Train Epoch: 3 [1215/3978 (31%)]\tLoss: 0.074790\n",
            "Train Epoch: 3 [1220/3978 (31%)]\tLoss: 0.343092\n",
            "Train Epoch: 3 [1225/3978 (31%)]\tLoss: 0.062903\n",
            "Train Epoch: 3 [1230/3978 (31%)]\tLoss: 0.199776\n",
            "Train Epoch: 3 [1235/3978 (31%)]\tLoss: 0.325847\n",
            "Train Epoch: 3 [1240/3978 (31%)]\tLoss: 0.214612\n",
            "Train Epoch: 3 [1245/3978 (31%)]\tLoss: 0.184212\n",
            "Train Epoch: 3 [1250/3978 (31%)]\tLoss: 0.290470\n",
            "Train Epoch: 3 [1255/3978 (32%)]\tLoss: 0.173510\n",
            "Train Epoch: 3 [1260/3978 (32%)]\tLoss: 0.229981\n",
            "Train Epoch: 3 [1265/3978 (32%)]\tLoss: 0.281938\n",
            "Train Epoch: 3 [1270/3978 (32%)]\tLoss: 0.058114\n",
            "Train Epoch: 3 [1275/3978 (32%)]\tLoss: 0.104114\n",
            "Train Epoch: 3 [1280/3978 (32%)]\tLoss: 0.498803\n",
            "Train Epoch: 3 [1285/3978 (32%)]\tLoss: 0.050141\n",
            "Train Epoch: 3 [1290/3978 (32%)]\tLoss: 0.146115\n",
            "Train Epoch: 3 [1295/3978 (33%)]\tLoss: 0.265940\n",
            "Train Epoch: 3 [1300/3978 (33%)]\tLoss: 0.329690\n",
            "Train Epoch: 3 [1305/3978 (33%)]\tLoss: 0.686360\n",
            "Train Epoch: 3 [1310/3978 (33%)]\tLoss: 0.064717\n",
            "Train Epoch: 3 [1315/3978 (33%)]\tLoss: 0.460933\n",
            "Train Epoch: 3 [1320/3978 (33%)]\tLoss: 0.167298\n",
            "Train Epoch: 3 [1325/3978 (33%)]\tLoss: 0.172583\n",
            "Train Epoch: 3 [1330/3978 (33%)]\tLoss: 0.285584\n",
            "Train Epoch: 3 [1335/3978 (34%)]\tLoss: 0.400316\n",
            "Train Epoch: 3 [1340/3978 (34%)]\tLoss: 0.461415\n",
            "Train Epoch: 3 [1345/3978 (34%)]\tLoss: 0.258380\n",
            "Train Epoch: 3 [1350/3978 (34%)]\tLoss: 0.181372\n",
            "Train Epoch: 3 [1355/3978 (34%)]\tLoss: 0.099410\n",
            "Train Epoch: 3 [1360/3978 (34%)]\tLoss: 0.110525\n",
            "Train Epoch: 3 [1365/3978 (34%)]\tLoss: 0.117732\n",
            "Train Epoch: 3 [1370/3978 (34%)]\tLoss: 0.291714\n",
            "Train Epoch: 3 [1375/3978 (35%)]\tLoss: 0.372454\n",
            "Train Epoch: 3 [1380/3978 (35%)]\tLoss: 0.437088\n",
            "Train Epoch: 3 [1385/3978 (35%)]\tLoss: 0.241736\n",
            "Train Epoch: 3 [1390/3978 (35%)]\tLoss: 0.184610\n",
            "Train Epoch: 3 [1395/3978 (35%)]\tLoss: 0.242862\n",
            "Train Epoch: 3 [1400/3978 (35%)]\tLoss: 0.118566\n",
            "Train Epoch: 3 [1405/3978 (35%)]\tLoss: 0.115823\n",
            "Train Epoch: 3 [1410/3978 (35%)]\tLoss: 0.166077\n",
            "Train Epoch: 3 [1415/3978 (36%)]\tLoss: 0.072672\n",
            "Train Epoch: 3 [1420/3978 (36%)]\tLoss: 0.130188\n",
            "Train Epoch: 3 [1425/3978 (36%)]\tLoss: 0.054942\n",
            "Train Epoch: 3 [1430/3978 (36%)]\tLoss: 0.060150\n",
            "Train Epoch: 3 [1435/3978 (36%)]\tLoss: 0.273626\n",
            "Train Epoch: 3 [1440/3978 (36%)]\tLoss: 0.559848\n",
            "Train Epoch: 3 [1445/3978 (36%)]\tLoss: 0.048821\n",
            "Train Epoch: 3 [1450/3978 (36%)]\tLoss: 0.095770\n",
            "Train Epoch: 3 [1455/3978 (37%)]\tLoss: 0.028216\n",
            "Train Epoch: 3 [1460/3978 (37%)]\tLoss: 0.066068\n",
            "Train Epoch: 3 [1465/3978 (37%)]\tLoss: 0.027858\n",
            "Train Epoch: 3 [1470/3978 (37%)]\tLoss: 0.507396\n",
            "Train Epoch: 3 [1475/3978 (37%)]\tLoss: 0.182992\n",
            "Train Epoch: 3 [1480/3978 (37%)]\tLoss: 0.063174\n",
            "Train Epoch: 3 [1485/3978 (37%)]\tLoss: 0.064508\n",
            "Train Epoch: 3 [1490/3978 (37%)]\tLoss: 0.298325\n",
            "Train Epoch: 3 [1495/3978 (38%)]\tLoss: 0.286060\n",
            "Train Epoch: 3 [1500/3978 (38%)]\tLoss: 0.199827\n",
            "Train Epoch: 3 [1505/3978 (38%)]\tLoss: 0.162681\n",
            "Train Epoch: 3 [1510/3978 (38%)]\tLoss: 0.607604\n",
            "Train Epoch: 3 [1515/3978 (38%)]\tLoss: 0.217134\n",
            "Train Epoch: 3 [1520/3978 (38%)]\tLoss: 0.584304\n",
            "Train Epoch: 3 [1525/3978 (38%)]\tLoss: 0.069982\n",
            "Train Epoch: 3 [1530/3978 (38%)]\tLoss: 0.509341\n",
            "Train Epoch: 3 [1535/3978 (39%)]\tLoss: 0.322647\n",
            "Train Epoch: 3 [1540/3978 (39%)]\tLoss: 0.089747\n",
            "Train Epoch: 3 [1545/3978 (39%)]\tLoss: 0.826764\n",
            "Train Epoch: 3 [1550/3978 (39%)]\tLoss: 0.145305\n",
            "Train Epoch: 3 [1555/3978 (39%)]\tLoss: 0.257910\n",
            "Train Epoch: 3 [1560/3978 (39%)]\tLoss: 0.170319\n",
            "Train Epoch: 3 [1565/3978 (39%)]\tLoss: 0.198635\n",
            "Train Epoch: 3 [1570/3978 (39%)]\tLoss: 0.113048\n",
            "Train Epoch: 3 [1575/3978 (40%)]\tLoss: 0.157423\n",
            "Train Epoch: 3 [1580/3978 (40%)]\tLoss: 0.127266\n",
            "Train Epoch: 3 [1585/3978 (40%)]\tLoss: 0.157685\n",
            "Train Epoch: 3 [1590/3978 (40%)]\tLoss: 0.384059\n",
            "Train Epoch: 3 [1595/3978 (40%)]\tLoss: 0.297708\n",
            "Train Epoch: 3 [1600/3978 (40%)]\tLoss: 0.252823\n",
            "Train Epoch: 3 [1605/3978 (40%)]\tLoss: 0.080890\n",
            "Train Epoch: 3 [1610/3978 (40%)]\tLoss: 0.220301\n",
            "Train Epoch: 3 [1615/3978 (41%)]\tLoss: 0.274979\n",
            "Train Epoch: 3 [1620/3978 (41%)]\tLoss: 0.077548\n",
            "Train Epoch: 3 [1625/3978 (41%)]\tLoss: 0.313985\n",
            "Train Epoch: 3 [1630/3978 (41%)]\tLoss: 0.072358\n",
            "Train Epoch: 3 [1635/3978 (41%)]\tLoss: 0.175931\n",
            "Train Epoch: 3 [1640/3978 (41%)]\tLoss: 0.294170\n",
            "Train Epoch: 3 [1645/3978 (41%)]\tLoss: 0.288026\n",
            "Train Epoch: 3 [1650/3978 (41%)]\tLoss: 0.240089\n",
            "Train Epoch: 3 [1655/3978 (42%)]\tLoss: 0.069155\n",
            "Train Epoch: 3 [1660/3978 (42%)]\tLoss: 0.210730\n",
            "Train Epoch: 3 [1665/3978 (42%)]\tLoss: 0.060693\n",
            "Train Epoch: 3 [1670/3978 (42%)]\tLoss: 0.169065\n",
            "Train Epoch: 3 [1675/3978 (42%)]\tLoss: 0.639633\n",
            "Train Epoch: 3 [1680/3978 (42%)]\tLoss: 0.043078\n",
            "Train Epoch: 3 [1685/3978 (42%)]\tLoss: 0.327470\n",
            "Train Epoch: 3 [1690/3978 (42%)]\tLoss: 0.532030\n",
            "Train Epoch: 3 [1695/3978 (43%)]\tLoss: 0.337783\n",
            "Train Epoch: 3 [1700/3978 (43%)]\tLoss: 0.053169\n",
            "Train Epoch: 3 [1705/3978 (43%)]\tLoss: 0.195030\n",
            "Train Epoch: 3 [1710/3978 (43%)]\tLoss: 0.114394\n",
            "Train Epoch: 3 [1715/3978 (43%)]\tLoss: 0.092717\n",
            "Train Epoch: 3 [1720/3978 (43%)]\tLoss: 0.139153\n",
            "Train Epoch: 3 [1725/3978 (43%)]\tLoss: 0.170440\n",
            "Train Epoch: 3 [1730/3978 (43%)]\tLoss: 0.116480\n",
            "Train Epoch: 3 [1735/3978 (44%)]\tLoss: 0.167491\n",
            "Train Epoch: 3 [1740/3978 (44%)]\tLoss: 0.285064\n",
            "Train Epoch: 3 [1745/3978 (44%)]\tLoss: 0.136690\n",
            "Train Epoch: 3 [1750/3978 (44%)]\tLoss: 0.197821\n",
            "Train Epoch: 3 [1755/3978 (44%)]\tLoss: 0.159112\n",
            "Train Epoch: 3 [1760/3978 (44%)]\tLoss: 0.209554\n",
            "Train Epoch: 3 [1765/3978 (44%)]\tLoss: 0.345224\n",
            "Train Epoch: 3 [1770/3978 (44%)]\tLoss: 0.335621\n",
            "Train Epoch: 3 [1775/3978 (45%)]\tLoss: 0.090952\n",
            "Train Epoch: 3 [1780/3978 (45%)]\tLoss: 0.227019\n",
            "Train Epoch: 3 [1785/3978 (45%)]\tLoss: 0.318339\n",
            "Train Epoch: 3 [1790/3978 (45%)]\tLoss: 0.340574\n",
            "Train Epoch: 3 [1795/3978 (45%)]\tLoss: 0.380587\n",
            "Train Epoch: 3 [1800/3978 (45%)]\tLoss: 0.274795\n",
            "Train Epoch: 3 [1805/3978 (45%)]\tLoss: 0.074519\n",
            "Train Epoch: 3 [1810/3978 (45%)]\tLoss: 0.318164\n",
            "Train Epoch: 3 [1815/3978 (46%)]\tLoss: 0.274712\n",
            "Train Epoch: 3 [1820/3978 (46%)]\tLoss: 0.198991\n",
            "Train Epoch: 3 [1825/3978 (46%)]\tLoss: 0.461900\n",
            "Train Epoch: 3 [1830/3978 (46%)]\tLoss: 0.307005\n",
            "Train Epoch: 3 [1835/3978 (46%)]\tLoss: 0.312772\n",
            "Train Epoch: 3 [1840/3978 (46%)]\tLoss: 0.250499\n",
            "Train Epoch: 3 [1845/3978 (46%)]\tLoss: 0.232987\n",
            "Train Epoch: 3 [1850/3978 (46%)]\tLoss: 0.263175\n",
            "Train Epoch: 3 [1855/3978 (47%)]\tLoss: 0.315867\n",
            "Train Epoch: 3 [1860/3978 (47%)]\tLoss: 0.336752\n",
            "Train Epoch: 3 [1865/3978 (47%)]\tLoss: 0.273107\n",
            "Train Epoch: 3 [1870/3978 (47%)]\tLoss: 0.123112\n",
            "Train Epoch: 3 [1875/3978 (47%)]\tLoss: 0.132226\n",
            "Train Epoch: 3 [1880/3978 (47%)]\tLoss: 0.327471\n",
            "Train Epoch: 3 [1885/3978 (47%)]\tLoss: 0.426202\n",
            "Train Epoch: 3 [1890/3978 (47%)]\tLoss: 0.332616\n",
            "Train Epoch: 3 [1895/3978 (48%)]\tLoss: 0.161086\n",
            "Train Epoch: 3 [1900/3978 (48%)]\tLoss: 0.354978\n",
            "Train Epoch: 3 [1905/3978 (48%)]\tLoss: 0.063972\n",
            "Train Epoch: 3 [1910/3978 (48%)]\tLoss: 0.124056\n",
            "Train Epoch: 3 [1915/3978 (48%)]\tLoss: 0.385860\n",
            "Train Epoch: 3 [1920/3978 (48%)]\tLoss: 0.106740\n",
            "Train Epoch: 3 [1925/3978 (48%)]\tLoss: 0.289864\n",
            "Train Epoch: 3 [1930/3978 (48%)]\tLoss: 0.546363\n",
            "Train Epoch: 3 [1935/3978 (49%)]\tLoss: 0.659134\n",
            "Train Epoch: 3 [1940/3978 (49%)]\tLoss: 0.521989\n",
            "Train Epoch: 3 [1945/3978 (49%)]\tLoss: 0.056818\n",
            "Train Epoch: 3 [1950/3978 (49%)]\tLoss: 0.192780\n",
            "Train Epoch: 3 [1955/3978 (49%)]\tLoss: 0.425290\n",
            "Train Epoch: 3 [1960/3978 (49%)]\tLoss: 0.133615\n",
            "Train Epoch: 3 [1965/3978 (49%)]\tLoss: 0.320233\n",
            "Train Epoch: 3 [1970/3978 (49%)]\tLoss: 0.197100\n",
            "Train Epoch: 3 [1975/3978 (50%)]\tLoss: 0.230590\n",
            "Train Epoch: 3 [1980/3978 (50%)]\tLoss: 0.228437\n",
            "Train Epoch: 3 [1985/3978 (50%)]\tLoss: 0.148442\n",
            "Train Epoch: 3 [1990/3978 (50%)]\tLoss: 0.180295\n",
            "Train Epoch: 3 [1995/3978 (50%)]\tLoss: 0.221774\n",
            "Train Epoch: 3 [2000/3978 (50%)]\tLoss: 0.148745\n",
            "Train Epoch: 3 [2005/3978 (50%)]\tLoss: 0.175575\n",
            "Train Epoch: 3 [2010/3978 (51%)]\tLoss: 0.120336\n",
            "Train Epoch: 3 [2015/3978 (51%)]\tLoss: 0.254545\n",
            "Train Epoch: 3 [2020/3978 (51%)]\tLoss: 0.254789\n",
            "Train Epoch: 3 [2025/3978 (51%)]\tLoss: 0.308131\n",
            "Train Epoch: 3 [2030/3978 (51%)]\tLoss: 0.167246\n",
            "Train Epoch: 3 [2035/3978 (51%)]\tLoss: 0.077312\n",
            "Train Epoch: 3 [2040/3978 (51%)]\tLoss: 0.073944\n",
            "Train Epoch: 3 [2045/3978 (51%)]\tLoss: 0.169886\n",
            "Train Epoch: 3 [2050/3978 (52%)]\tLoss: 0.321330\n",
            "Train Epoch: 3 [2055/3978 (52%)]\tLoss: 0.234164\n",
            "Train Epoch: 3 [2060/3978 (52%)]\tLoss: 0.361849\n",
            "Train Epoch: 3 [2065/3978 (52%)]\tLoss: 0.408054\n",
            "Train Epoch: 3 [2070/3978 (52%)]\tLoss: 0.071366\n",
            "Train Epoch: 3 [2075/3978 (52%)]\tLoss: 0.099805\n",
            "Train Epoch: 3 [2080/3978 (52%)]\tLoss: 0.062345\n",
            "Train Epoch: 3 [2085/3978 (52%)]\tLoss: 0.062077\n",
            "Train Epoch: 3 [2090/3978 (53%)]\tLoss: 0.075553\n",
            "Train Epoch: 3 [2095/3978 (53%)]\tLoss: 0.209413\n",
            "Train Epoch: 3 [2100/3978 (53%)]\tLoss: 0.062694\n",
            "Train Epoch: 3 [2105/3978 (53%)]\tLoss: 0.053932\n",
            "Train Epoch: 3 [2110/3978 (53%)]\tLoss: 0.074281\n",
            "Train Epoch: 3 [2115/3978 (53%)]\tLoss: 0.062350\n",
            "Train Epoch: 3 [2120/3978 (53%)]\tLoss: 0.062991\n",
            "Train Epoch: 3 [2125/3978 (53%)]\tLoss: 0.059157\n",
            "Train Epoch: 3 [2130/3978 (54%)]\tLoss: 0.075306\n",
            "Train Epoch: 3 [2135/3978 (54%)]\tLoss: 0.230786\n",
            "Train Epoch: 3 [2140/3978 (54%)]\tLoss: 0.466117\n",
            "Train Epoch: 3 [2145/3978 (54%)]\tLoss: 0.220095\n",
            "Train Epoch: 3 [2150/3978 (54%)]\tLoss: 0.181343\n",
            "Train Epoch: 3 [2155/3978 (54%)]\tLoss: 0.064595\n",
            "Train Epoch: 3 [2160/3978 (54%)]\tLoss: 0.362220\n",
            "Train Epoch: 3 [2165/3978 (54%)]\tLoss: 0.192633\n",
            "Train Epoch: 3 [2170/3978 (55%)]\tLoss: 0.192142\n",
            "Train Epoch: 3 [2175/3978 (55%)]\tLoss: 0.062420\n",
            "Train Epoch: 3 [2180/3978 (55%)]\tLoss: 0.148474\n",
            "Train Epoch: 3 [2185/3978 (55%)]\tLoss: 0.187605\n",
            "Train Epoch: 3 [2190/3978 (55%)]\tLoss: 0.066252\n",
            "Train Epoch: 3 [2195/3978 (55%)]\tLoss: 0.180894\n",
            "Train Epoch: 3 [2200/3978 (55%)]\tLoss: 0.108794\n",
            "Train Epoch: 3 [2205/3978 (55%)]\tLoss: 0.278874\n",
            "Train Epoch: 3 [2210/3978 (56%)]\tLoss: 0.207696\n",
            "Train Epoch: 3 [2215/3978 (56%)]\tLoss: 0.199671\n",
            "Train Epoch: 3 [2220/3978 (56%)]\tLoss: 0.517751\n",
            "Train Epoch: 3 [2225/3978 (56%)]\tLoss: 0.296164\n",
            "Train Epoch: 3 [2230/3978 (56%)]\tLoss: 0.095817\n",
            "Train Epoch: 3 [2235/3978 (56%)]\tLoss: 0.257249\n",
            "Train Epoch: 3 [2240/3978 (56%)]\tLoss: 0.237036\n",
            "Train Epoch: 3 [2245/3978 (56%)]\tLoss: 0.157390\n",
            "Train Epoch: 3 [2250/3978 (57%)]\tLoss: 0.813014\n",
            "Train Epoch: 3 [2255/3978 (57%)]\tLoss: 0.200843\n",
            "Train Epoch: 3 [2260/3978 (57%)]\tLoss: 0.173902\n",
            "Train Epoch: 3 [2265/3978 (57%)]\tLoss: 0.076796\n",
            "Train Epoch: 3 [2270/3978 (57%)]\tLoss: 0.336600\n",
            "Train Epoch: 3 [2275/3978 (57%)]\tLoss: 0.385893\n",
            "Train Epoch: 3 [2280/3978 (57%)]\tLoss: 0.322200\n",
            "Train Epoch: 3 [2285/3978 (57%)]\tLoss: 0.181074\n",
            "Train Epoch: 3 [2290/3978 (58%)]\tLoss: 0.196397\n",
            "Train Epoch: 3 [2295/3978 (58%)]\tLoss: 0.446303\n",
            "Train Epoch: 3 [2300/3978 (58%)]\tLoss: 0.111526\n",
            "Train Epoch: 3 [2305/3978 (58%)]\tLoss: 0.307830\n",
            "Train Epoch: 3 [2310/3978 (58%)]\tLoss: 0.193310\n",
            "Train Epoch: 3 [2315/3978 (58%)]\tLoss: 0.235891\n",
            "Train Epoch: 3 [2320/3978 (58%)]\tLoss: 0.304829\n",
            "Train Epoch: 3 [2325/3978 (58%)]\tLoss: 0.231296\n",
            "Train Epoch: 3 [2330/3978 (59%)]\tLoss: 0.223396\n",
            "Train Epoch: 3 [2335/3978 (59%)]\tLoss: 0.397842\n",
            "Train Epoch: 3 [2340/3978 (59%)]\tLoss: 0.099968\n",
            "Train Epoch: 3 [2345/3978 (59%)]\tLoss: 0.410461\n",
            "Train Epoch: 3 [2350/3978 (59%)]\tLoss: 0.103098\n",
            "Train Epoch: 3 [2355/3978 (59%)]\tLoss: 0.190746\n",
            "Train Epoch: 3 [2360/3978 (59%)]\tLoss: 0.329452\n",
            "Train Epoch: 3 [2365/3978 (59%)]\tLoss: 0.281900\n",
            "Train Epoch: 3 [2370/3978 (60%)]\tLoss: 0.387061\n",
            "Train Epoch: 3 [2375/3978 (60%)]\tLoss: 0.531508\n",
            "Train Epoch: 3 [2380/3978 (60%)]\tLoss: 0.101937\n",
            "Train Epoch: 3 [2385/3978 (60%)]\tLoss: 0.156877\n",
            "Train Epoch: 3 [2390/3978 (60%)]\tLoss: 0.097533\n",
            "Train Epoch: 3 [2395/3978 (60%)]\tLoss: 0.292244\n",
            "Train Epoch: 3 [2400/3978 (60%)]\tLoss: 0.307323\n",
            "Train Epoch: 3 [2405/3978 (60%)]\tLoss: 0.540177\n",
            "Train Epoch: 3 [2410/3978 (61%)]\tLoss: 0.390848\n",
            "Train Epoch: 3 [2415/3978 (61%)]\tLoss: 0.267293\n",
            "Train Epoch: 3 [2420/3978 (61%)]\tLoss: 0.272156\n",
            "Train Epoch: 3 [2425/3978 (61%)]\tLoss: 0.266243\n",
            "Train Epoch: 3 [2430/3978 (61%)]\tLoss: 0.287982\n",
            "Train Epoch: 3 [2435/3978 (61%)]\tLoss: 0.147399\n",
            "Train Epoch: 3 [2440/3978 (61%)]\tLoss: 0.756105\n",
            "Train Epoch: 3 [2445/3978 (61%)]\tLoss: 0.249963\n",
            "Train Epoch: 3 [2450/3978 (62%)]\tLoss: 0.236538\n",
            "Train Epoch: 3 [2455/3978 (62%)]\tLoss: 0.097946\n",
            "Train Epoch: 3 [2460/3978 (62%)]\tLoss: 0.214800\n",
            "Train Epoch: 3 [2465/3978 (62%)]\tLoss: 0.396373\n",
            "Train Epoch: 3 [2470/3978 (62%)]\tLoss: 0.095963\n",
            "Train Epoch: 3 [2475/3978 (62%)]\tLoss: 0.240350\n",
            "Train Epoch: 3 [2480/3978 (62%)]\tLoss: 0.131721\n",
            "Train Epoch: 3 [2485/3978 (62%)]\tLoss: 0.357368\n",
            "Train Epoch: 3 [2490/3978 (63%)]\tLoss: 0.488369\n",
            "Train Epoch: 3 [2495/3978 (63%)]\tLoss: 0.173946\n",
            "Train Epoch: 3 [2500/3978 (63%)]\tLoss: 0.206180\n",
            "Train Epoch: 3 [2505/3978 (63%)]\tLoss: 0.087134\n",
            "Train Epoch: 3 [2510/3978 (63%)]\tLoss: 0.068719\n",
            "Train Epoch: 3 [2515/3978 (63%)]\tLoss: 0.153062\n",
            "Train Epoch: 3 [2520/3978 (63%)]\tLoss: 0.269587\n",
            "Train Epoch: 3 [2525/3978 (63%)]\tLoss: 0.281435\n",
            "Train Epoch: 3 [2530/3978 (64%)]\tLoss: 0.100263\n",
            "Train Epoch: 3 [2535/3978 (64%)]\tLoss: 0.195874\n",
            "Train Epoch: 3 [2540/3978 (64%)]\tLoss: 0.076895\n",
            "Train Epoch: 3 [2545/3978 (64%)]\tLoss: 0.076821\n",
            "Train Epoch: 3 [2550/3978 (64%)]\tLoss: 0.077016\n",
            "Train Epoch: 3 [2555/3978 (64%)]\tLoss: 0.078853\n",
            "Train Epoch: 3 [2560/3978 (64%)]\tLoss: 0.536471\n",
            "Train Epoch: 3 [2565/3978 (64%)]\tLoss: 0.229643\n",
            "Train Epoch: 3 [2570/3978 (65%)]\tLoss: 0.168788\n",
            "Train Epoch: 3 [2575/3978 (65%)]\tLoss: 0.171610\n",
            "Train Epoch: 3 [2580/3978 (65%)]\tLoss: 0.255653\n",
            "Train Epoch: 3 [2585/3978 (65%)]\tLoss: 0.277102\n",
            "Train Epoch: 3 [2590/3978 (65%)]\tLoss: 0.365039\n",
            "Train Epoch: 3 [2595/3978 (65%)]\tLoss: 0.152534\n",
            "Train Epoch: 3 [2600/3978 (65%)]\tLoss: 0.055519\n",
            "Train Epoch: 3 [2605/3978 (65%)]\tLoss: 0.134888\n",
            "Train Epoch: 3 [2610/3978 (66%)]\tLoss: 0.529747\n",
            "Train Epoch: 3 [2615/3978 (66%)]\tLoss: 0.188021\n",
            "Train Epoch: 3 [2620/3978 (66%)]\tLoss: 0.195214\n",
            "Train Epoch: 3 [2625/3978 (66%)]\tLoss: 0.315517\n",
            "Train Epoch: 3 [2630/3978 (66%)]\tLoss: 0.266313\n",
            "Train Epoch: 3 [2635/3978 (66%)]\tLoss: 0.080665\n",
            "Train Epoch: 3 [2640/3978 (66%)]\tLoss: 0.186931\n",
            "Train Epoch: 3 [2645/3978 (66%)]\tLoss: 0.518063\n",
            "Train Epoch: 3 [2650/3978 (67%)]\tLoss: 0.059531\n",
            "Train Epoch: 3 [2655/3978 (67%)]\tLoss: 0.710615\n",
            "Train Epoch: 3 [2660/3978 (67%)]\tLoss: 0.111584\n",
            "Train Epoch: 3 [2665/3978 (67%)]\tLoss: 0.547480\n",
            "Train Epoch: 3 [2670/3978 (67%)]\tLoss: 0.198336\n",
            "Train Epoch: 3 [2675/3978 (67%)]\tLoss: 0.559232\n",
            "Train Epoch: 3 [2680/3978 (67%)]\tLoss: 0.164473\n",
            "Train Epoch: 3 [2685/3978 (67%)]\tLoss: 0.103808\n",
            "Train Epoch: 3 [2690/3978 (68%)]\tLoss: 0.211220\n",
            "Train Epoch: 3 [2695/3978 (68%)]\tLoss: 0.115637\n",
            "Train Epoch: 3 [2700/3978 (68%)]\tLoss: 0.099593\n",
            "Train Epoch: 3 [2705/3978 (68%)]\tLoss: 0.270768\n",
            "Train Epoch: 3 [2710/3978 (68%)]\tLoss: 0.053523\n",
            "Train Epoch: 3 [2715/3978 (68%)]\tLoss: 0.172997\n",
            "Train Epoch: 3 [2720/3978 (68%)]\tLoss: 0.224839\n",
            "Train Epoch: 3 [2725/3978 (68%)]\tLoss: 0.212319\n",
            "Train Epoch: 3 [2730/3978 (69%)]\tLoss: 0.262924\n",
            "Train Epoch: 3 [2735/3978 (69%)]\tLoss: 0.163958\n",
            "Train Epoch: 3 [2740/3978 (69%)]\tLoss: 0.152027\n",
            "Train Epoch: 3 [2745/3978 (69%)]\tLoss: 0.109022\n",
            "Train Epoch: 3 [2750/3978 (69%)]\tLoss: 0.105225\n",
            "Train Epoch: 3 [2755/3978 (69%)]\tLoss: 0.395948\n",
            "Train Epoch: 3 [2760/3978 (69%)]\tLoss: 0.078293\n",
            "Train Epoch: 3 [2765/3978 (69%)]\tLoss: 0.259244\n",
            "Train Epoch: 3 [2770/3978 (70%)]\tLoss: 0.179836\n",
            "Train Epoch: 3 [2775/3978 (70%)]\tLoss: 0.298152\n",
            "Train Epoch: 3 [2780/3978 (70%)]\tLoss: 0.375504\n",
            "Train Epoch: 3 [2785/3978 (70%)]\tLoss: 0.704605\n",
            "Train Epoch: 3 [2790/3978 (70%)]\tLoss: 0.279967\n",
            "Train Epoch: 3 [2795/3978 (70%)]\tLoss: 0.591049\n",
            "Train Epoch: 3 [2800/3978 (70%)]\tLoss: 0.467366\n",
            "Train Epoch: 3 [2805/3978 (70%)]\tLoss: 0.084789\n",
            "Train Epoch: 3 [2810/3978 (71%)]\tLoss: 0.100014\n",
            "Train Epoch: 3 [2815/3978 (71%)]\tLoss: 0.298653\n",
            "Train Epoch: 3 [2820/3978 (71%)]\tLoss: 0.218064\n",
            "Train Epoch: 3 [2825/3978 (71%)]\tLoss: 0.315426\n",
            "Train Epoch: 3 [2830/3978 (71%)]\tLoss: 0.251998\n",
            "Train Epoch: 3 [2835/3978 (71%)]\tLoss: 0.430911\n",
            "Train Epoch: 3 [2840/3978 (71%)]\tLoss: 0.481050\n",
            "Train Epoch: 3 [2845/3978 (71%)]\tLoss: 0.185063\n",
            "Train Epoch: 3 [2850/3978 (72%)]\tLoss: 0.305504\n",
            "Train Epoch: 3 [2855/3978 (72%)]\tLoss: 0.165642\n",
            "Train Epoch: 3 [2860/3978 (72%)]\tLoss: 0.175456\n",
            "Train Epoch: 3 [2865/3978 (72%)]\tLoss: 0.226833\n",
            "Train Epoch: 3 [2870/3978 (72%)]\tLoss: 0.513416\n",
            "Train Epoch: 3 [2875/3978 (72%)]\tLoss: 0.134080\n",
            "Train Epoch: 3 [2880/3978 (72%)]\tLoss: 0.153135\n",
            "Train Epoch: 3 [2885/3978 (72%)]\tLoss: 0.576717\n",
            "Train Epoch: 3 [2890/3978 (73%)]\tLoss: 0.312474\n",
            "Train Epoch: 3 [2895/3978 (73%)]\tLoss: 0.130220\n",
            "Train Epoch: 3 [2900/3978 (73%)]\tLoss: 0.068081\n",
            "Train Epoch: 3 [2905/3978 (73%)]\tLoss: 0.197612\n",
            "Train Epoch: 3 [2910/3978 (73%)]\tLoss: 0.584270\n",
            "Train Epoch: 3 [2915/3978 (73%)]\tLoss: 0.374918\n",
            "Train Epoch: 3 [2920/3978 (73%)]\tLoss: 0.124969\n",
            "Train Epoch: 3 [2925/3978 (73%)]\tLoss: 0.181137\n",
            "Train Epoch: 3 [2930/3978 (74%)]\tLoss: 0.209695\n",
            "Train Epoch: 3 [2935/3978 (74%)]\tLoss: 0.420907\n",
            "Train Epoch: 3 [2940/3978 (74%)]\tLoss: 0.213950\n",
            "Train Epoch: 3 [2945/3978 (74%)]\tLoss: 0.169177\n",
            "Train Epoch: 3 [2950/3978 (74%)]\tLoss: 0.168122\n",
            "Train Epoch: 3 [2955/3978 (74%)]\tLoss: 0.828656\n",
            "Train Epoch: 3 [2960/3978 (74%)]\tLoss: 0.101702\n",
            "Train Epoch: 3 [2965/3978 (74%)]\tLoss: 0.073343\n",
            "Train Epoch: 3 [2970/3978 (75%)]\tLoss: 0.249214\n",
            "Train Epoch: 3 [2975/3978 (75%)]\tLoss: 0.139912\n",
            "Train Epoch: 3 [2980/3978 (75%)]\tLoss: 0.343718\n",
            "Train Epoch: 3 [2985/3978 (75%)]\tLoss: 0.420156\n",
            "Train Epoch: 3 [2990/3978 (75%)]\tLoss: 0.311575\n",
            "Train Epoch: 3 [2995/3978 (75%)]\tLoss: 0.150006\n",
            "Train Epoch: 3 [3000/3978 (75%)]\tLoss: 0.280457\n",
            "Train Epoch: 3 [3005/3978 (76%)]\tLoss: 0.251504\n",
            "Train Epoch: 3 [3010/3978 (76%)]\tLoss: 0.145027\n",
            "Train Epoch: 3 [3015/3978 (76%)]\tLoss: 0.231829\n",
            "Train Epoch: 3 [3020/3978 (76%)]\tLoss: 0.199424\n",
            "Train Epoch: 3 [3025/3978 (76%)]\tLoss: 0.277677\n",
            "Train Epoch: 3 [3030/3978 (76%)]\tLoss: 0.358271\n",
            "Train Epoch: 3 [3035/3978 (76%)]\tLoss: 0.128675\n",
            "Train Epoch: 3 [3040/3978 (76%)]\tLoss: 0.465821\n",
            "Train Epoch: 3 [3045/3978 (77%)]\tLoss: 0.711473\n",
            "Train Epoch: 3 [3050/3978 (77%)]\tLoss: 0.610851\n",
            "Train Epoch: 3 [3055/3978 (77%)]\tLoss: 0.120835\n",
            "Train Epoch: 3 [3060/3978 (77%)]\tLoss: 0.476935\n",
            "Train Epoch: 3 [3065/3978 (77%)]\tLoss: 0.298690\n",
            "Train Epoch: 3 [3070/3978 (77%)]\tLoss: 0.067018\n",
            "Train Epoch: 3 [3075/3978 (77%)]\tLoss: 0.092787\n",
            "Train Epoch: 3 [3080/3978 (77%)]\tLoss: 0.101718\n",
            "Train Epoch: 3 [3085/3978 (78%)]\tLoss: 0.372506\n",
            "Train Epoch: 3 [3090/3978 (78%)]\tLoss: 0.114439\n",
            "Train Epoch: 3 [3095/3978 (78%)]\tLoss: 0.109558\n",
            "Train Epoch: 3 [3100/3978 (78%)]\tLoss: 0.089795\n",
            "Train Epoch: 3 [3105/3978 (78%)]\tLoss: 0.654054\n",
            "Train Epoch: 3 [3110/3978 (78%)]\tLoss: 0.093024\n",
            "Train Epoch: 3 [3115/3978 (78%)]\tLoss: 0.090934\n",
            "Train Epoch: 3 [3120/3978 (78%)]\tLoss: 0.471198\n",
            "Train Epoch: 3 [3125/3978 (79%)]\tLoss: 0.099383\n",
            "Train Epoch: 3 [3130/3978 (79%)]\tLoss: 0.085324\n",
            "Train Epoch: 3 [3135/3978 (79%)]\tLoss: 0.076110\n",
            "Train Epoch: 3 [3140/3978 (79%)]\tLoss: 0.631055\n",
            "Train Epoch: 3 [3145/3978 (79%)]\tLoss: 0.077385\n",
            "Train Epoch: 3 [3150/3978 (79%)]\tLoss: 0.348106\n",
            "Train Epoch: 3 [3155/3978 (79%)]\tLoss: 0.222412\n",
            "Train Epoch: 3 [3160/3978 (79%)]\tLoss: 0.329338\n",
            "Train Epoch: 3 [3165/3978 (80%)]\tLoss: 0.067372\n",
            "Train Epoch: 3 [3170/3978 (80%)]\tLoss: 0.416631\n",
            "Train Epoch: 3 [3175/3978 (80%)]\tLoss: 0.331431\n",
            "Train Epoch: 3 [3180/3978 (80%)]\tLoss: 0.479784\n",
            "Train Epoch: 3 [3185/3978 (80%)]\tLoss: 0.075252\n",
            "Train Epoch: 3 [3190/3978 (80%)]\tLoss: 0.332371\n",
            "Train Epoch: 3 [3195/3978 (80%)]\tLoss: 0.108083\n",
            "Train Epoch: 3 [3200/3978 (80%)]\tLoss: 0.077503\n",
            "Train Epoch: 3 [3205/3978 (81%)]\tLoss: 0.352738\n",
            "Train Epoch: 3 [3210/3978 (81%)]\tLoss: 0.202922\n",
            "Train Epoch: 3 [3215/3978 (81%)]\tLoss: 0.125868\n",
            "Train Epoch: 3 [3220/3978 (81%)]\tLoss: 0.210048\n",
            "Train Epoch: 3 [3225/3978 (81%)]\tLoss: 0.095071\n",
            "Train Epoch: 3 [3230/3978 (81%)]\tLoss: 0.196591\n",
            "Train Epoch: 3 [3235/3978 (81%)]\tLoss: 0.221061\n",
            "Train Epoch: 3 [3240/3978 (81%)]\tLoss: 0.091166\n",
            "Train Epoch: 3 [3245/3978 (82%)]\tLoss: 0.082395\n",
            "Train Epoch: 3 [3250/3978 (82%)]\tLoss: 0.226814\n",
            "Train Epoch: 3 [3255/3978 (82%)]\tLoss: 0.531349\n",
            "Train Epoch: 3 [3260/3978 (82%)]\tLoss: 0.157374\n",
            "Train Epoch: 3 [3265/3978 (82%)]\tLoss: 0.322983\n",
            "Train Epoch: 3 [3270/3978 (82%)]\tLoss: 0.081811\n",
            "Train Epoch: 3 [3275/3978 (82%)]\tLoss: 0.336479\n",
            "Train Epoch: 3 [3280/3978 (82%)]\tLoss: 0.224652\n",
            "Train Epoch: 3 [3285/3978 (83%)]\tLoss: 0.484830\n",
            "Train Epoch: 3 [3290/3978 (83%)]\tLoss: 0.089192\n",
            "Train Epoch: 3 [3295/3978 (83%)]\tLoss: 0.339307\n",
            "Train Epoch: 3 [3300/3978 (83%)]\tLoss: 0.316014\n",
            "Train Epoch: 3 [3305/3978 (83%)]\tLoss: 0.210849\n",
            "Train Epoch: 3 [3310/3978 (83%)]\tLoss: 0.200031\n",
            "Train Epoch: 3 [3315/3978 (83%)]\tLoss: 0.114881\n",
            "Train Epoch: 3 [3320/3978 (83%)]\tLoss: 0.273372\n",
            "Train Epoch: 3 [3325/3978 (84%)]\tLoss: 0.308623\n",
            "Train Epoch: 3 [3330/3978 (84%)]\tLoss: 0.433815\n",
            "Train Epoch: 3 [3335/3978 (84%)]\tLoss: 0.161923\n",
            "Train Epoch: 3 [3340/3978 (84%)]\tLoss: 0.335206\n",
            "Train Epoch: 3 [3345/3978 (84%)]\tLoss: 0.150335\n",
            "Train Epoch: 3 [3350/3978 (84%)]\tLoss: 0.101514\n",
            "Train Epoch: 3 [3355/3978 (84%)]\tLoss: 0.201807\n",
            "Train Epoch: 3 [3360/3978 (84%)]\tLoss: 0.439629\n",
            "Train Epoch: 3 [3365/3978 (85%)]\tLoss: 0.229391\n",
            "Train Epoch: 3 [3370/3978 (85%)]\tLoss: 0.159701\n",
            "Train Epoch: 3 [3375/3978 (85%)]\tLoss: 0.259056\n",
            "Train Epoch: 3 [3380/3978 (85%)]\tLoss: 0.599480\n",
            "Train Epoch: 3 [3385/3978 (85%)]\tLoss: 0.245293\n",
            "Train Epoch: 3 [3390/3978 (85%)]\tLoss: 0.435362\n",
            "Train Epoch: 3 [3395/3978 (85%)]\tLoss: 0.220508\n",
            "Train Epoch: 3 [3400/3978 (85%)]\tLoss: 0.291314\n",
            "Train Epoch: 3 [3405/3978 (86%)]\tLoss: 0.102001\n",
            "Train Epoch: 3 [3410/3978 (86%)]\tLoss: 0.178443\n",
            "Train Epoch: 3 [3415/3978 (86%)]\tLoss: 0.212678\n",
            "Train Epoch: 3 [3420/3978 (86%)]\tLoss: 0.186302\n",
            "Train Epoch: 3 [3425/3978 (86%)]\tLoss: 0.440717\n",
            "Train Epoch: 3 [3430/3978 (86%)]\tLoss: 0.250996\n",
            "Train Epoch: 3 [3435/3978 (86%)]\tLoss: 0.340222\n",
            "Train Epoch: 3 [3440/3978 (86%)]\tLoss: 0.457417\n",
            "Train Epoch: 3 [3445/3978 (87%)]\tLoss: 0.432508\n",
            "Train Epoch: 3 [3450/3978 (87%)]\tLoss: 0.065269\n",
            "Train Epoch: 3 [3455/3978 (87%)]\tLoss: 0.366588\n",
            "Train Epoch: 3 [3460/3978 (87%)]\tLoss: 0.079376\n",
            "Train Epoch: 3 [3465/3978 (87%)]\tLoss: 0.301920\n",
            "Train Epoch: 3 [3470/3978 (87%)]\tLoss: 0.075644\n",
            "Train Epoch: 3 [3475/3978 (87%)]\tLoss: 0.376120\n",
            "Train Epoch: 3 [3480/3978 (87%)]\tLoss: 0.236282\n",
            "Train Epoch: 3 [3485/3978 (88%)]\tLoss: 0.241122\n",
            "Train Epoch: 3 [3490/3978 (88%)]\tLoss: 0.126436\n",
            "Train Epoch: 3 [3495/3978 (88%)]\tLoss: 0.154685\n",
            "Train Epoch: 3 [3500/3978 (88%)]\tLoss: 0.089577\n",
            "Train Epoch: 3 [3505/3978 (88%)]\tLoss: 0.080406\n",
            "Train Epoch: 3 [3510/3978 (88%)]\tLoss: 0.509646\n",
            "Train Epoch: 3 [3515/3978 (88%)]\tLoss: 0.239129\n",
            "Train Epoch: 3 [3520/3978 (88%)]\tLoss: 0.564096\n",
            "Train Epoch: 3 [3525/3978 (89%)]\tLoss: 0.203467\n",
            "Train Epoch: 3 [3530/3978 (89%)]\tLoss: 0.073531\n",
            "Train Epoch: 3 [3535/3978 (89%)]\tLoss: 0.336416\n",
            "Train Epoch: 3 [3540/3978 (89%)]\tLoss: 0.184149\n",
            "Train Epoch: 3 [3545/3978 (89%)]\tLoss: 0.647047\n",
            "Train Epoch: 3 [3550/3978 (89%)]\tLoss: 0.209867\n",
            "Train Epoch: 3 [3555/3978 (89%)]\tLoss: 0.188290\n",
            "Train Epoch: 3 [3560/3978 (89%)]\tLoss: 0.250173\n",
            "Train Epoch: 3 [3565/3978 (90%)]\tLoss: 0.235099\n",
            "Train Epoch: 3 [3570/3978 (90%)]\tLoss: 0.083778\n",
            "Train Epoch: 3 [3575/3978 (90%)]\tLoss: 0.125147\n",
            "Train Epoch: 3 [3580/3978 (90%)]\tLoss: 0.300421\n",
            "Train Epoch: 3 [3585/3978 (90%)]\tLoss: 0.181614\n",
            "Train Epoch: 3 [3590/3978 (90%)]\tLoss: 0.109345\n",
            "Train Epoch: 3 [3595/3978 (90%)]\tLoss: 0.253383\n",
            "Train Epoch: 3 [3600/3978 (90%)]\tLoss: 0.136345\n",
            "Train Epoch: 3 [3605/3978 (91%)]\tLoss: 0.224264\n",
            "Train Epoch: 3 [3610/3978 (91%)]\tLoss: 0.518427\n",
            "Train Epoch: 3 [3615/3978 (91%)]\tLoss: 0.186431\n",
            "Train Epoch: 3 [3620/3978 (91%)]\tLoss: 0.322010\n",
            "Train Epoch: 3 [3625/3978 (91%)]\tLoss: 0.086722\n",
            "Train Epoch: 3 [3630/3978 (91%)]\tLoss: 0.326904\n",
            "Train Epoch: 3 [3635/3978 (91%)]\tLoss: 0.189595\n",
            "Train Epoch: 3 [3640/3978 (91%)]\tLoss: 0.047954\n",
            "Train Epoch: 3 [3645/3978 (92%)]\tLoss: 0.131621\n",
            "Train Epoch: 3 [3650/3978 (92%)]\tLoss: 0.363263\n",
            "Train Epoch: 3 [3655/3978 (92%)]\tLoss: 0.484720\n",
            "Train Epoch: 3 [3660/3978 (92%)]\tLoss: 0.409359\n",
            "Train Epoch: 3 [3665/3978 (92%)]\tLoss: 0.095849\n",
            "Train Epoch: 3 [3670/3978 (92%)]\tLoss: 0.167808\n",
            "Train Epoch: 3 [3675/3978 (92%)]\tLoss: 0.094022\n",
            "Train Epoch: 3 [3680/3978 (92%)]\tLoss: 0.097156\n",
            "Train Epoch: 3 [3685/3978 (93%)]\tLoss: 0.152307\n",
            "Train Epoch: 3 [3690/3978 (93%)]\tLoss: 0.224686\n",
            "Train Epoch: 3 [3695/3978 (93%)]\tLoss: 0.169530\n",
            "Train Epoch: 3 [3700/3978 (93%)]\tLoss: 0.080140\n",
            "Train Epoch: 3 [3705/3978 (93%)]\tLoss: 0.208487\n",
            "Train Epoch: 3 [3710/3978 (93%)]\tLoss: 0.256442\n",
            "Train Epoch: 3 [3715/3978 (93%)]\tLoss: 0.071045\n",
            "Train Epoch: 3 [3720/3978 (93%)]\tLoss: 0.078055\n",
            "Train Epoch: 3 [3725/3978 (94%)]\tLoss: 0.069932\n",
            "Train Epoch: 3 [3730/3978 (94%)]\tLoss: 0.068768\n",
            "Train Epoch: 3 [3735/3978 (94%)]\tLoss: 0.647993\n",
            "Train Epoch: 3 [3740/3978 (94%)]\tLoss: 0.040354\n",
            "Train Epoch: 3 [3745/3978 (94%)]\tLoss: 0.147363\n",
            "Train Epoch: 3 [3750/3978 (94%)]\tLoss: 0.245848\n",
            "Train Epoch: 3 [3755/3978 (94%)]\tLoss: 0.239315\n",
            "Train Epoch: 3 [3760/3978 (94%)]\tLoss: 0.416433\n",
            "Train Epoch: 3 [3765/3978 (95%)]\tLoss: 0.256783\n",
            "Train Epoch: 3 [3770/3978 (95%)]\tLoss: 0.210871\n",
            "Train Epoch: 3 [3775/3978 (95%)]\tLoss: 0.096584\n",
            "Train Epoch: 3 [3780/3978 (95%)]\tLoss: 0.217123\n",
            "Train Epoch: 3 [3785/3978 (95%)]\tLoss: 0.201962\n",
            "Train Epoch: 3 [3790/3978 (95%)]\tLoss: 0.191593\n",
            "Train Epoch: 3 [3795/3978 (95%)]\tLoss: 0.209898\n",
            "Train Epoch: 3 [3800/3978 (95%)]\tLoss: 0.217968\n",
            "Train Epoch: 3 [3805/3978 (96%)]\tLoss: 0.538873\n",
            "Train Epoch: 3 [3810/3978 (96%)]\tLoss: 0.514876\n",
            "Train Epoch: 3 [3815/3978 (96%)]\tLoss: 0.080305\n",
            "Train Epoch: 3 [3820/3978 (96%)]\tLoss: 0.366856\n",
            "Train Epoch: 3 [3825/3978 (96%)]\tLoss: 0.186590\n",
            "Train Epoch: 3 [3830/3978 (96%)]\tLoss: 0.119377\n",
            "Train Epoch: 3 [3835/3978 (96%)]\tLoss: 0.194824\n",
            "Train Epoch: 3 [3840/3978 (96%)]\tLoss: 0.196191\n",
            "Train Epoch: 3 [3845/3978 (97%)]\tLoss: 0.509008\n",
            "Train Epoch: 3 [3850/3978 (97%)]\tLoss: 0.193828\n",
            "Train Epoch: 3 [3855/3978 (97%)]\tLoss: 0.135699\n",
            "Train Epoch: 3 [3860/3978 (97%)]\tLoss: 0.172362\n",
            "Train Epoch: 3 [3865/3978 (97%)]\tLoss: 0.178060\n",
            "Train Epoch: 3 [3870/3978 (97%)]\tLoss: 0.144466\n",
            "Train Epoch: 3 [3875/3978 (97%)]\tLoss: 0.300257\n",
            "Train Epoch: 3 [3880/3978 (97%)]\tLoss: 0.312283\n",
            "Train Epoch: 3 [3885/3978 (98%)]\tLoss: 0.202317\n",
            "Train Epoch: 3 [3890/3978 (98%)]\tLoss: 0.187273\n",
            "Train Epoch: 3 [3895/3978 (98%)]\tLoss: 0.363782\n",
            "Train Epoch: 3 [3900/3978 (98%)]\tLoss: 0.280878\n",
            "Train Epoch: 3 [3905/3978 (98%)]\tLoss: 0.080801\n",
            "Train Epoch: 3 [3910/3978 (98%)]\tLoss: 0.221163\n",
            "Train Epoch: 3 [3915/3978 (98%)]\tLoss: 0.052659\n",
            "Train Epoch: 3 [3920/3978 (98%)]\tLoss: 0.258635\n",
            "Train Epoch: 3 [3925/3978 (99%)]\tLoss: 0.211919\n",
            "Train Epoch: 3 [3930/3978 (99%)]\tLoss: 0.066760\n",
            "Train Epoch: 3 [3935/3978 (99%)]\tLoss: 0.243557\n",
            "Train Epoch: 3 [3940/3978 (99%)]\tLoss: 0.230396\n",
            "Train Epoch: 3 [3945/3978 (99%)]\tLoss: 0.048978\n",
            "Train Epoch: 3 [3950/3978 (99%)]\tLoss: 0.588928\n",
            "Train Epoch: 3 [3955/3978 (99%)]\tLoss: 0.082319\n",
            "Train Epoch: 3 [3960/3978 (99%)]\tLoss: 0.233185\n",
            "Train Epoch: 3 [3965/3978 (100%)]\tLoss: 0.230473\n",
            "Train Epoch: 3 [3970/3978 (100%)]\tLoss: 0.067896\n",
            "Train Epoch: 3 [2385/3978 (100%)]\tLoss: 0.081545\n",
            "Epoch\n",
            "train/train_loss: 0.08154479414224625\n",
            "\n",
            "Train Loss: 0.082, Valid Loss: 0.325533, Accuracy: 0.35\n",
            "Train Epoch: 4 [0/3978 (0%)]\tLoss: 0.276057\n",
            "Train Epoch: 4 [5/3978 (0%)]\tLoss: 0.274782\n",
            "Train Epoch: 4 [10/3978 (0%)]\tLoss: 0.275449\n",
            "Train Epoch: 4 [15/3978 (0%)]\tLoss: 0.408422\n",
            "Train Epoch: 4 [20/3978 (1%)]\tLoss: 0.088821\n",
            "Train Epoch: 4 [25/3978 (1%)]\tLoss: 0.205275\n",
            "Train Epoch: 4 [30/3978 (1%)]\tLoss: 0.108138\n",
            "Train Epoch: 4 [35/3978 (1%)]\tLoss: 0.089944\n",
            "Train Epoch: 4 [40/3978 (1%)]\tLoss: 0.139243\n",
            "Train Epoch: 4 [45/3978 (1%)]\tLoss: 0.245072\n",
            "Train Epoch: 4 [50/3978 (1%)]\tLoss: 0.760147\n",
            "Train Epoch: 4 [55/3978 (1%)]\tLoss: 0.071778\n",
            "Train Epoch: 4 [60/3978 (2%)]\tLoss: 0.194639\n",
            "Train Epoch: 4 [65/3978 (2%)]\tLoss: 0.176072\n",
            "Train Epoch: 4 [70/3978 (2%)]\tLoss: 0.173700\n",
            "Train Epoch: 4 [75/3978 (2%)]\tLoss: 0.138423\n",
            "Train Epoch: 4 [80/3978 (2%)]\tLoss: 0.350267\n",
            "Train Epoch: 4 [85/3978 (2%)]\tLoss: 0.161294\n",
            "Train Epoch: 4 [90/3978 (2%)]\tLoss: 0.073374\n",
            "Train Epoch: 4 [95/3978 (2%)]\tLoss: 0.363294\n",
            "Train Epoch: 4 [100/3978 (3%)]\tLoss: 0.251350\n",
            "Train Epoch: 4 [105/3978 (3%)]\tLoss: 0.243275\n",
            "Train Epoch: 4 [110/3978 (3%)]\tLoss: 0.264082\n",
            "Train Epoch: 4 [115/3978 (3%)]\tLoss: 0.097047\n",
            "Train Epoch: 4 [120/3978 (3%)]\tLoss: 0.262347\n",
            "Train Epoch: 4 [125/3978 (3%)]\tLoss: 0.485929\n",
            "Train Epoch: 4 [130/3978 (3%)]\tLoss: 0.260628\n",
            "Train Epoch: 4 [135/3978 (3%)]\tLoss: 0.349562\n",
            "Train Epoch: 4 [140/3978 (4%)]\tLoss: 0.237452\n",
            "Train Epoch: 4 [145/3978 (4%)]\tLoss: 0.394180\n",
            "Train Epoch: 4 [150/3978 (4%)]\tLoss: 0.108346\n",
            "Train Epoch: 4 [155/3978 (4%)]\tLoss: 0.192713\n",
            "Train Epoch: 4 [160/3978 (4%)]\tLoss: 0.376789\n",
            "Train Epoch: 4 [165/3978 (4%)]\tLoss: 0.087519\n",
            "Train Epoch: 4 [170/3978 (4%)]\tLoss: 0.049706\n",
            "Train Epoch: 4 [175/3978 (4%)]\tLoss: 0.437937\n",
            "Train Epoch: 4 [180/3978 (5%)]\tLoss: 0.124621\n",
            "Train Epoch: 4 [185/3978 (5%)]\tLoss: 0.075806\n",
            "Train Epoch: 4 [190/3978 (5%)]\tLoss: 0.374872\n",
            "Train Epoch: 4 [195/3978 (5%)]\tLoss: 0.551112\n",
            "Train Epoch: 4 [200/3978 (5%)]\tLoss: 0.182855\n",
            "Train Epoch: 4 [205/3978 (5%)]\tLoss: 0.187116\n",
            "Train Epoch: 4 [210/3978 (5%)]\tLoss: 0.424274\n",
            "Train Epoch: 4 [215/3978 (5%)]\tLoss: 0.115663\n",
            "Train Epoch: 4 [220/3978 (6%)]\tLoss: 0.115907\n",
            "Train Epoch: 4 [225/3978 (6%)]\tLoss: 0.109389\n",
            "Train Epoch: 4 [230/3978 (6%)]\tLoss: 0.203092\n",
            "Train Epoch: 4 [235/3978 (6%)]\tLoss: 0.190207\n",
            "Train Epoch: 4 [240/3978 (6%)]\tLoss: 0.209183\n",
            "Train Epoch: 4 [245/3978 (6%)]\tLoss: 0.176980\n",
            "Train Epoch: 4 [250/3978 (6%)]\tLoss: 0.067093\n",
            "Train Epoch: 4 [255/3978 (6%)]\tLoss: 0.079465\n",
            "Train Epoch: 4 [260/3978 (7%)]\tLoss: 0.061577\n",
            "Train Epoch: 4 [265/3978 (7%)]\tLoss: 0.185335\n",
            "Train Epoch: 4 [270/3978 (7%)]\tLoss: 0.070015\n",
            "Train Epoch: 4 [275/3978 (7%)]\tLoss: 0.017632\n",
            "Train Epoch: 4 [280/3978 (7%)]\tLoss: 0.101042\n",
            "Train Epoch: 4 [285/3978 (7%)]\tLoss: 0.403232\n",
            "Train Epoch: 4 [290/3978 (7%)]\tLoss: 0.066296\n",
            "Train Epoch: 4 [295/3978 (7%)]\tLoss: 0.059130\n",
            "Train Epoch: 4 [300/3978 (8%)]\tLoss: 0.148960\n",
            "Train Epoch: 4 [305/3978 (8%)]\tLoss: 0.035036\n",
            "Train Epoch: 4 [310/3978 (8%)]\tLoss: 0.028656\n",
            "Train Epoch: 4 [315/3978 (8%)]\tLoss: 0.365923\n",
            "Train Epoch: 4 [320/3978 (8%)]\tLoss: 0.059615\n",
            "Train Epoch: 4 [325/3978 (8%)]\tLoss: 0.098695\n",
            "Train Epoch: 4 [330/3978 (8%)]\tLoss: 0.207713\n",
            "Train Epoch: 4 [335/3978 (8%)]\tLoss: 0.454608\n",
            "Train Epoch: 4 [340/3978 (9%)]\tLoss: 0.071315\n",
            "Train Epoch: 4 [345/3978 (9%)]\tLoss: 0.058504\n",
            "Train Epoch: 4 [350/3978 (9%)]\tLoss: 0.405892\n",
            "Train Epoch: 4 [355/3978 (9%)]\tLoss: 0.224967\n",
            "Train Epoch: 4 [360/3978 (9%)]\tLoss: 0.778212\n",
            "Train Epoch: 4 [365/3978 (9%)]\tLoss: 0.200692\n",
            "Train Epoch: 4 [370/3978 (9%)]\tLoss: 0.437387\n",
            "Train Epoch: 4 [375/3978 (9%)]\tLoss: 0.655229\n",
            "Train Epoch: 4 [380/3978 (10%)]\tLoss: 0.165615\n",
            "Train Epoch: 4 [385/3978 (10%)]\tLoss: 0.094006\n",
            "Train Epoch: 4 [390/3978 (10%)]\tLoss: 0.119230\n",
            "Train Epoch: 4 [395/3978 (10%)]\tLoss: 0.302817\n",
            "Train Epoch: 4 [400/3978 (10%)]\tLoss: 0.123028\n",
            "Train Epoch: 4 [405/3978 (10%)]\tLoss: 0.128276\n",
            "Train Epoch: 4 [410/3978 (10%)]\tLoss: 0.158881\n",
            "Train Epoch: 4 [415/3978 (10%)]\tLoss: 0.361252\n",
            "Train Epoch: 4 [420/3978 (11%)]\tLoss: 0.377475\n",
            "Train Epoch: 4 [425/3978 (11%)]\tLoss: 0.163692\n",
            "Train Epoch: 4 [430/3978 (11%)]\tLoss: 0.144124\n",
            "Train Epoch: 4 [435/3978 (11%)]\tLoss: 0.218848\n",
            "Train Epoch: 4 [440/3978 (11%)]\tLoss: 0.140476\n",
            "Train Epoch: 4 [445/3978 (11%)]\tLoss: 0.137758\n",
            "Train Epoch: 4 [450/3978 (11%)]\tLoss: 0.058048\n",
            "Train Epoch: 4 [455/3978 (11%)]\tLoss: 0.081145\n",
            "Train Epoch: 4 [460/3978 (12%)]\tLoss: 0.171535\n",
            "Train Epoch: 4 [465/3978 (12%)]\tLoss: 0.041682\n",
            "Train Epoch: 4 [470/3978 (12%)]\tLoss: 0.150283\n",
            "Train Epoch: 4 [475/3978 (12%)]\tLoss: 0.058101\n",
            "Train Epoch: 4 [480/3978 (12%)]\tLoss: 0.192614\n",
            "Train Epoch: 4 [485/3978 (12%)]\tLoss: 0.059998\n",
            "Train Epoch: 4 [490/3978 (12%)]\tLoss: 0.463523\n",
            "Train Epoch: 4 [495/3978 (12%)]\tLoss: 0.259442\n",
            "Train Epoch: 4 [500/3978 (13%)]\tLoss: 0.181464\n",
            "Train Epoch: 4 [505/3978 (13%)]\tLoss: 0.173300\n",
            "Train Epoch: 4 [510/3978 (13%)]\tLoss: 0.482096\n",
            "Train Epoch: 4 [515/3978 (13%)]\tLoss: 0.291168\n",
            "Train Epoch: 4 [520/3978 (13%)]\tLoss: 0.450989\n",
            "Train Epoch: 4 [525/3978 (13%)]\tLoss: 0.398041\n",
            "Train Epoch: 4 [530/3978 (13%)]\tLoss: 0.198730\n",
            "Train Epoch: 4 [535/3978 (13%)]\tLoss: 0.204848\n",
            "Train Epoch: 4 [540/3978 (14%)]\tLoss: 0.349970\n",
            "Train Epoch: 4 [545/3978 (14%)]\tLoss: 0.073128\n",
            "Train Epoch: 4 [550/3978 (14%)]\tLoss: 0.101923\n",
            "Train Epoch: 4 [555/3978 (14%)]\tLoss: 0.091914\n",
            "Train Epoch: 4 [560/3978 (14%)]\tLoss: 0.475564\n",
            "Train Epoch: 4 [565/3978 (14%)]\tLoss: 0.707616\n",
            "Train Epoch: 4 [570/3978 (14%)]\tLoss: 0.154287\n",
            "Train Epoch: 4 [575/3978 (14%)]\tLoss: 0.190749\n",
            "Train Epoch: 4 [580/3978 (15%)]\tLoss: 0.115535\n",
            "Train Epoch: 4 [585/3978 (15%)]\tLoss: 0.120452\n",
            "Train Epoch: 4 [590/3978 (15%)]\tLoss: 0.439564\n",
            "Train Epoch: 4 [595/3978 (15%)]\tLoss: 0.131371\n",
            "Train Epoch: 4 [600/3978 (15%)]\tLoss: 0.369647\n",
            "Train Epoch: 4 [605/3978 (15%)]\tLoss: 0.117274\n",
            "Train Epoch: 4 [610/3978 (15%)]\tLoss: 0.190741\n",
            "Train Epoch: 4 [615/3978 (15%)]\tLoss: 0.102412\n",
            "Train Epoch: 4 [620/3978 (16%)]\tLoss: 0.247783\n",
            "Train Epoch: 4 [625/3978 (16%)]\tLoss: 0.439105\n",
            "Train Epoch: 4 [630/3978 (16%)]\tLoss: 0.305283\n",
            "Train Epoch: 4 [635/3978 (16%)]\tLoss: 0.211243\n",
            "Train Epoch: 4 [640/3978 (16%)]\tLoss: 0.089374\n",
            "Train Epoch: 4 [645/3978 (16%)]\tLoss: 0.462274\n",
            "Train Epoch: 4 [650/3978 (16%)]\tLoss: 0.471048\n",
            "Train Epoch: 4 [655/3978 (16%)]\tLoss: 0.263123\n",
            "Train Epoch: 4 [660/3978 (17%)]\tLoss: 0.103767\n",
            "Train Epoch: 4 [665/3978 (17%)]\tLoss: 0.058675\n",
            "Train Epoch: 4 [670/3978 (17%)]\tLoss: 0.640208\n",
            "Train Epoch: 4 [675/3978 (17%)]\tLoss: 0.097062\n",
            "Train Epoch: 4 [680/3978 (17%)]\tLoss: 0.366022\n",
            "Train Epoch: 4 [685/3978 (17%)]\tLoss: 0.097294\n",
            "Train Epoch: 4 [690/3978 (17%)]\tLoss: 0.446104\n",
            "Train Epoch: 4 [695/3978 (17%)]\tLoss: 0.196722\n",
            "Train Epoch: 4 [700/3978 (18%)]\tLoss: 0.091407\n",
            "Train Epoch: 4 [705/3978 (18%)]\tLoss: 0.426391\n",
            "Train Epoch: 4 [710/3978 (18%)]\tLoss: 0.143948\n",
            "Train Epoch: 4 [715/3978 (18%)]\tLoss: 0.121086\n",
            "Train Epoch: 4 [720/3978 (18%)]\tLoss: 0.320901\n",
            "Train Epoch: 4 [725/3978 (18%)]\tLoss: 0.349587\n",
            "Train Epoch: 4 [730/3978 (18%)]\tLoss: 0.089382\n",
            "Train Epoch: 4 [735/3978 (18%)]\tLoss: 0.078711\n",
            "Train Epoch: 4 [740/3978 (19%)]\tLoss: 0.126152\n",
            "Train Epoch: 4 [745/3978 (19%)]\tLoss: 0.342971\n",
            "Train Epoch: 4 [750/3978 (19%)]\tLoss: 0.075069\n",
            "Train Epoch: 4 [755/3978 (19%)]\tLoss: 0.159380\n",
            "Train Epoch: 4 [760/3978 (19%)]\tLoss: 0.201293\n",
            "Train Epoch: 4 [765/3978 (19%)]\tLoss: 0.191433\n",
            "Train Epoch: 4 [770/3978 (19%)]\tLoss: 0.107645\n",
            "Train Epoch: 4 [775/3978 (19%)]\tLoss: 0.071167\n",
            "Train Epoch: 4 [780/3978 (20%)]\tLoss: 0.069164\n",
            "Train Epoch: 4 [785/3978 (20%)]\tLoss: 0.185859\n",
            "Train Epoch: 4 [790/3978 (20%)]\tLoss: 0.272499\n",
            "Train Epoch: 4 [795/3978 (20%)]\tLoss: 0.077285\n",
            "Train Epoch: 4 [800/3978 (20%)]\tLoss: 0.081227\n",
            "Train Epoch: 4 [805/3978 (20%)]\tLoss: 0.176637\n",
            "Train Epoch: 4 [810/3978 (20%)]\tLoss: 0.075561\n",
            "Train Epoch: 4 [815/3978 (20%)]\tLoss: 0.253735\n",
            "Train Epoch: 4 [820/3978 (21%)]\tLoss: 0.432403\n",
            "Train Epoch: 4 [825/3978 (21%)]\tLoss: 0.167556\n",
            "Train Epoch: 4 [830/3978 (21%)]\tLoss: 0.065836\n",
            "Train Epoch: 4 [835/3978 (21%)]\tLoss: 0.248640\n",
            "Train Epoch: 4 [840/3978 (21%)]\tLoss: 0.094317\n",
            "Train Epoch: 4 [845/3978 (21%)]\tLoss: 0.376069\n",
            "Train Epoch: 4 [850/3978 (21%)]\tLoss: 0.699424\n",
            "Train Epoch: 4 [855/3978 (21%)]\tLoss: 0.273015\n",
            "Train Epoch: 4 [860/3978 (22%)]\tLoss: 0.272935\n",
            "Train Epoch: 4 [865/3978 (22%)]\tLoss: 0.063461\n",
            "Train Epoch: 4 [870/3978 (22%)]\tLoss: 0.072710\n",
            "Train Epoch: 4 [875/3978 (22%)]\tLoss: 0.128326\n",
            "Train Epoch: 4 [880/3978 (22%)]\tLoss: 0.371578\n",
            "Train Epoch: 4 [885/3978 (22%)]\tLoss: 0.196218\n",
            "Train Epoch: 4 [890/3978 (22%)]\tLoss: 0.279284\n",
            "Train Epoch: 4 [895/3978 (22%)]\tLoss: 0.181595\n",
            "Train Epoch: 4 [900/3978 (23%)]\tLoss: 0.459567\n",
            "Train Epoch: 4 [905/3978 (23%)]\tLoss: 0.269993\n",
            "Train Epoch: 4 [910/3978 (23%)]\tLoss: 0.302506\n",
            "Train Epoch: 4 [915/3978 (23%)]\tLoss: 0.108427\n",
            "Train Epoch: 4 [920/3978 (23%)]\tLoss: 0.194604\n",
            "Train Epoch: 4 [925/3978 (23%)]\tLoss: 0.093590\n",
            "Train Epoch: 4 [930/3978 (23%)]\tLoss: 0.373650\n",
            "Train Epoch: 4 [935/3978 (23%)]\tLoss: 0.201785\n",
            "Train Epoch: 4 [940/3978 (24%)]\tLoss: 0.088838\n",
            "Train Epoch: 4 [945/3978 (24%)]\tLoss: 0.213110\n",
            "Train Epoch: 4 [950/3978 (24%)]\tLoss: 0.220338\n",
            "Train Epoch: 4 [955/3978 (24%)]\tLoss: 0.286444\n",
            "Train Epoch: 4 [960/3978 (24%)]\tLoss: 0.175997\n",
            "Train Epoch: 4 [965/3978 (24%)]\tLoss: 0.354183\n",
            "Train Epoch: 4 [970/3978 (24%)]\tLoss: 0.232215\n",
            "Train Epoch: 4 [975/3978 (24%)]\tLoss: 0.492173\n",
            "Train Epoch: 4 [980/3978 (25%)]\tLoss: 0.192495\n",
            "Train Epoch: 4 [985/3978 (25%)]\tLoss: 0.077762\n",
            "Train Epoch: 4 [990/3978 (25%)]\tLoss: 0.357480\n",
            "Train Epoch: 4 [995/3978 (25%)]\tLoss: 0.079227\n",
            "Train Epoch: 4 [1000/3978 (25%)]\tLoss: 0.108913\n",
            "Train Epoch: 4 [1005/3978 (25%)]\tLoss: 0.096439\n",
            "Train Epoch: 4 [1010/3978 (25%)]\tLoss: 0.337192\n",
            "Train Epoch: 4 [1015/3978 (26%)]\tLoss: 0.175015\n",
            "Train Epoch: 4 [1020/3978 (26%)]\tLoss: 0.068748\n",
            "Train Epoch: 4 [1025/3978 (26%)]\tLoss: 0.060413\n",
            "Train Epoch: 4 [1030/3978 (26%)]\tLoss: 0.188845\n",
            "Train Epoch: 4 [1035/3978 (26%)]\tLoss: 0.474700\n",
            "Train Epoch: 4 [1040/3978 (26%)]\tLoss: 0.237656\n",
            "Train Epoch: 4 [1045/3978 (26%)]\tLoss: 0.247989\n",
            "Train Epoch: 4 [1050/3978 (26%)]\tLoss: 0.043955\n",
            "Train Epoch: 4 [1055/3978 (27%)]\tLoss: 0.161004\n",
            "Train Epoch: 4 [1060/3978 (27%)]\tLoss: 0.057931\n",
            "Train Epoch: 4 [1065/3978 (27%)]\tLoss: 0.213986\n",
            "Train Epoch: 4 [1070/3978 (27%)]\tLoss: 0.221768\n",
            "Train Epoch: 4 [1075/3978 (27%)]\tLoss: 0.056407\n",
            "Train Epoch: 4 [1080/3978 (27%)]\tLoss: 0.081199\n",
            "Train Epoch: 4 [1085/3978 (27%)]\tLoss: 0.115329\n",
            "Train Epoch: 4 [1090/3978 (27%)]\tLoss: 0.082165\n",
            "Train Epoch: 4 [1095/3978 (28%)]\tLoss: 0.488781\n",
            "Train Epoch: 4 [1100/3978 (28%)]\tLoss: 0.791112\n",
            "Train Epoch: 4 [1105/3978 (28%)]\tLoss: 0.312600\n",
            "Train Epoch: 4 [1110/3978 (28%)]\tLoss: 0.301979\n",
            "Train Epoch: 4 [1115/3978 (28%)]\tLoss: 0.472057\n",
            "Train Epoch: 4 [1120/3978 (28%)]\tLoss: 0.092074\n",
            "Train Epoch: 4 [1125/3978 (28%)]\tLoss: 0.233275\n",
            "Train Epoch: 4 [1130/3978 (28%)]\tLoss: 0.539568\n",
            "Train Epoch: 4 [1135/3978 (29%)]\tLoss: 0.449648\n",
            "Train Epoch: 4 [1140/3978 (29%)]\tLoss: 0.130011\n",
            "Train Epoch: 4 [1145/3978 (29%)]\tLoss: 0.124185\n",
            "Train Epoch: 4 [1150/3978 (29%)]\tLoss: 0.093214\n",
            "Train Epoch: 4 [1155/3978 (29%)]\tLoss: 0.086809\n",
            "Train Epoch: 4 [1160/3978 (29%)]\tLoss: 0.168855\n",
            "Train Epoch: 4 [1165/3978 (29%)]\tLoss: 0.630660\n",
            "Train Epoch: 4 [1170/3978 (29%)]\tLoss: 0.326951\n",
            "Train Epoch: 4 [1175/3978 (30%)]\tLoss: 0.173639\n",
            "Train Epoch: 4 [1180/3978 (30%)]\tLoss: 0.078036\n",
            "Train Epoch: 4 [1185/3978 (30%)]\tLoss: 0.441504\n",
            "Train Epoch: 4 [1190/3978 (30%)]\tLoss: 0.197334\n",
            "Train Epoch: 4 [1195/3978 (30%)]\tLoss: 0.214545\n",
            "Train Epoch: 4 [1200/3978 (30%)]\tLoss: 0.173952\n",
            "Train Epoch: 4 [1205/3978 (30%)]\tLoss: 0.112090\n",
            "Train Epoch: 4 [1210/3978 (30%)]\tLoss: 0.383298\n",
            "Train Epoch: 4 [1215/3978 (31%)]\tLoss: 0.224147\n",
            "Train Epoch: 4 [1220/3978 (31%)]\tLoss: 0.114638\n",
            "Train Epoch: 4 [1225/3978 (31%)]\tLoss: 0.604505\n",
            "Train Epoch: 4 [1230/3978 (31%)]\tLoss: 0.413298\n",
            "Train Epoch: 4 [1235/3978 (31%)]\tLoss: 0.118451\n",
            "Train Epoch: 4 [1240/3978 (31%)]\tLoss: 0.300717\n",
            "Train Epoch: 4 [1245/3978 (31%)]\tLoss: 0.109160\n",
            "Train Epoch: 4 [1250/3978 (31%)]\tLoss: 0.397388\n",
            "Train Epoch: 4 [1255/3978 (32%)]\tLoss: 0.303532\n",
            "Train Epoch: 4 [1260/3978 (32%)]\tLoss: 0.385970\n",
            "Train Epoch: 4 [1265/3978 (32%)]\tLoss: 0.289980\n",
            "Train Epoch: 4 [1270/3978 (32%)]\tLoss: 0.248174\n",
            "Train Epoch: 4 [1275/3978 (32%)]\tLoss: 0.393500\n",
            "Train Epoch: 4 [1280/3978 (32%)]\tLoss: 0.413934\n",
            "Train Epoch: 4 [1285/3978 (32%)]\tLoss: 0.110723\n",
            "Train Epoch: 4 [1290/3978 (32%)]\tLoss: 0.192778\n",
            "Train Epoch: 4 [1295/3978 (33%)]\tLoss: 0.199125\n",
            "Train Epoch: 4 [1300/3978 (33%)]\tLoss: 0.111949\n",
            "Train Epoch: 4 [1305/3978 (33%)]\tLoss: 0.101740\n",
            "Train Epoch: 4 [1310/3978 (33%)]\tLoss: 0.224581\n",
            "Train Epoch: 4 [1315/3978 (33%)]\tLoss: 0.076606\n",
            "Train Epoch: 4 [1320/3978 (33%)]\tLoss: 0.057274\n",
            "Train Epoch: 4 [1325/3978 (33%)]\tLoss: 0.132280\n",
            "Train Epoch: 4 [1330/3978 (33%)]\tLoss: 0.082224\n",
            "Train Epoch: 4 [1335/3978 (34%)]\tLoss: 0.069534\n",
            "Train Epoch: 4 [1340/3978 (34%)]\tLoss: 0.204276\n",
            "Train Epoch: 4 [1345/3978 (34%)]\tLoss: 0.239548\n",
            "Train Epoch: 4 [1350/3978 (34%)]\tLoss: 0.169847\n",
            "Train Epoch: 4 [1355/3978 (34%)]\tLoss: 0.784234\n",
            "Train Epoch: 4 [1360/3978 (34%)]\tLoss: 0.172148\n",
            "Train Epoch: 4 [1365/3978 (34%)]\tLoss: 0.155421\n",
            "Train Epoch: 4 [1370/3978 (34%)]\tLoss: 0.710437\n",
            "Train Epoch: 4 [1375/3978 (35%)]\tLoss: 0.645651\n",
            "Train Epoch: 4 [1380/3978 (35%)]\tLoss: 0.077764\n",
            "Train Epoch: 4 [1385/3978 (35%)]\tLoss: 0.378836\n",
            "Train Epoch: 4 [1390/3978 (35%)]\tLoss: 0.300581\n",
            "Train Epoch: 4 [1395/3978 (35%)]\tLoss: 0.266812\n",
            "Train Epoch: 4 [1400/3978 (35%)]\tLoss: 0.389817\n",
            "Train Epoch: 4 [1405/3978 (35%)]\tLoss: 0.152033\n",
            "Train Epoch: 4 [1410/3978 (35%)]\tLoss: 0.258115\n",
            "Train Epoch: 4 [1415/3978 (36%)]\tLoss: 0.263820\n",
            "Train Epoch: 4 [1420/3978 (36%)]\tLoss: 0.378665\n",
            "Train Epoch: 4 [1425/3978 (36%)]\tLoss: 0.333003\n",
            "Train Epoch: 4 [1430/3978 (36%)]\tLoss: 0.232742\n",
            "Train Epoch: 4 [1435/3978 (36%)]\tLoss: 0.150945\n",
            "Train Epoch: 4 [1440/3978 (36%)]\tLoss: 0.276349\n",
            "Train Epoch: 4 [1445/3978 (36%)]\tLoss: 0.417185\n",
            "Train Epoch: 4 [1450/3978 (36%)]\tLoss: 0.132107\n",
            "Train Epoch: 4 [1455/3978 (37%)]\tLoss: 0.130721\n",
            "Train Epoch: 4 [1460/3978 (37%)]\tLoss: 0.427018\n",
            "Train Epoch: 4 [1465/3978 (37%)]\tLoss: 0.238315\n",
            "Train Epoch: 4 [1470/3978 (37%)]\tLoss: 0.433559\n",
            "Train Epoch: 4 [1475/3978 (37%)]\tLoss: 0.393277\n",
            "Train Epoch: 4 [1480/3978 (37%)]\tLoss: 0.113782\n",
            "Train Epoch: 4 [1485/3978 (37%)]\tLoss: 0.088819\n",
            "Train Epoch: 4 [1490/3978 (37%)]\tLoss: 0.340924\n",
            "Train Epoch: 4 [1495/3978 (38%)]\tLoss: 0.116949\n",
            "Train Epoch: 4 [1500/3978 (38%)]\tLoss: 0.255650\n",
            "Train Epoch: 4 [1505/3978 (38%)]\tLoss: 0.089437\n",
            "Train Epoch: 4 [1510/3978 (38%)]\tLoss: 0.418458\n",
            "Train Epoch: 4 [1515/3978 (38%)]\tLoss: 0.221450\n",
            "Train Epoch: 4 [1520/3978 (38%)]\tLoss: 0.137773\n",
            "Train Epoch: 4 [1525/3978 (38%)]\tLoss: 0.100226\n",
            "Train Epoch: 4 [1530/3978 (38%)]\tLoss: 0.348051\n",
            "Train Epoch: 4 [1535/3978 (39%)]\tLoss: 0.048868\n",
            "Train Epoch: 4 [1540/3978 (39%)]\tLoss: 0.165220\n",
            "Train Epoch: 4 [1545/3978 (39%)]\tLoss: 0.072523\n",
            "Train Epoch: 4 [1550/3978 (39%)]\tLoss: 0.310557\n",
            "Train Epoch: 4 [1555/3978 (39%)]\tLoss: 0.614247\n",
            "Train Epoch: 4 [1560/3978 (39%)]\tLoss: 0.089228\n",
            "Train Epoch: 4 [1565/3978 (39%)]\tLoss: 0.552669\n",
            "Train Epoch: 4 [1570/3978 (39%)]\tLoss: 0.501615\n",
            "Train Epoch: 4 [1575/3978 (40%)]\tLoss: 0.037716\n",
            "Train Epoch: 4 [1580/3978 (40%)]\tLoss: 0.150164\n",
            "Train Epoch: 4 [1585/3978 (40%)]\tLoss: 0.466230\n",
            "Train Epoch: 4 [1590/3978 (40%)]\tLoss: 0.079810\n",
            "Train Epoch: 4 [1595/3978 (40%)]\tLoss: 0.072982\n",
            "Train Epoch: 4 [1600/3978 (40%)]\tLoss: 0.349549\n",
            "Train Epoch: 4 [1605/3978 (40%)]\tLoss: 0.338343\n",
            "Train Epoch: 4 [1610/3978 (40%)]\tLoss: 0.305917\n",
            "Train Epoch: 4 [1615/3978 (41%)]\tLoss: 0.487664\n",
            "Train Epoch: 4 [1620/3978 (41%)]\tLoss: 0.443870\n",
            "Train Epoch: 4 [1625/3978 (41%)]\tLoss: 0.333773\n",
            "Train Epoch: 4 [1630/3978 (41%)]\tLoss: 0.352576\n",
            "Train Epoch: 4 [1635/3978 (41%)]\tLoss: 0.565515\n",
            "Train Epoch: 4 [1640/3978 (41%)]\tLoss: 0.439777\n",
            "Train Epoch: 4 [1645/3978 (41%)]\tLoss: 0.212492\n",
            "Train Epoch: 4 [1650/3978 (41%)]\tLoss: 0.349289\n",
            "Train Epoch: 4 [1655/3978 (42%)]\tLoss: 0.206539\n",
            "Train Epoch: 4 [1660/3978 (42%)]\tLoss: 0.205387\n",
            "Train Epoch: 4 [1665/3978 (42%)]\tLoss: 0.195676\n",
            "Train Epoch: 4 [1670/3978 (42%)]\tLoss: 0.346927\n",
            "Train Epoch: 4 [1675/3978 (42%)]\tLoss: 0.270329\n",
            "Train Epoch: 4 [1680/3978 (42%)]\tLoss: 0.288596\n",
            "Train Epoch: 4 [1685/3978 (42%)]\tLoss: 0.224283\n",
            "Train Epoch: 4 [1690/3978 (42%)]\tLoss: 0.167371\n",
            "Train Epoch: 4 [1695/3978 (43%)]\tLoss: 0.210342\n",
            "Train Epoch: 4 [1700/3978 (43%)]\tLoss: 0.697148\n",
            "Train Epoch: 4 [1705/3978 (43%)]\tLoss: 0.085223\n",
            "Train Epoch: 4 [1710/3978 (43%)]\tLoss: 0.072256\n",
            "Train Epoch: 4 [1715/3978 (43%)]\tLoss: 0.553145\n",
            "Train Epoch: 4 [1720/3978 (43%)]\tLoss: 0.252106\n",
            "Train Epoch: 4 [1725/3978 (43%)]\tLoss: 0.623148\n",
            "Train Epoch: 4 [1730/3978 (43%)]\tLoss: 0.369159\n",
            "Train Epoch: 4 [1735/3978 (44%)]\tLoss: 0.074181\n",
            "Train Epoch: 4 [1740/3978 (44%)]\tLoss: 0.402785\n",
            "Train Epoch: 4 [1745/3978 (44%)]\tLoss: 0.133171\n",
            "Train Epoch: 4 [1750/3978 (44%)]\tLoss: 0.223280\n",
            "Train Epoch: 4 [1755/3978 (44%)]\tLoss: 0.211618\n",
            "Train Epoch: 4 [1760/3978 (44%)]\tLoss: 0.232958\n",
            "Train Epoch: 4 [1765/3978 (44%)]\tLoss: 0.246059\n",
            "Train Epoch: 4 [1770/3978 (44%)]\tLoss: 0.322043\n",
            "Train Epoch: 4 [1775/3978 (45%)]\tLoss: 0.081398\n",
            "Train Epoch: 4 [1780/3978 (45%)]\tLoss: 0.098722\n",
            "Train Epoch: 4 [1785/3978 (45%)]\tLoss: 0.092108\n",
            "Train Epoch: 4 [1790/3978 (45%)]\tLoss: 0.270641\n",
            "Train Epoch: 4 [1795/3978 (45%)]\tLoss: 0.380263\n",
            "Train Epoch: 4 [1800/3978 (45%)]\tLoss: 0.112867\n",
            "Train Epoch: 4 [1805/3978 (45%)]\tLoss: 0.327104\n",
            "Train Epoch: 4 [1810/3978 (45%)]\tLoss: 0.150147\n",
            "Train Epoch: 4 [1815/3978 (46%)]\tLoss: 0.252702\n",
            "Train Epoch: 4 [1820/3978 (46%)]\tLoss: 0.158698\n",
            "Train Epoch: 4 [1825/3978 (46%)]\tLoss: 0.242639\n",
            "Train Epoch: 4 [1830/3978 (46%)]\tLoss: 0.324796\n",
            "Train Epoch: 4 [1835/3978 (46%)]\tLoss: 0.124218\n",
            "Train Epoch: 4 [1840/3978 (46%)]\tLoss: 0.486177\n",
            "Train Epoch: 4 [1845/3978 (46%)]\tLoss: 0.397423\n",
            "Train Epoch: 4 [1850/3978 (46%)]\tLoss: 0.385618\n",
            "Train Epoch: 4 [1855/3978 (47%)]\tLoss: 0.214799\n",
            "Train Epoch: 4 [1860/3978 (47%)]\tLoss: 0.107974\n",
            "Train Epoch: 4 [1865/3978 (47%)]\tLoss: 0.264447\n",
            "Train Epoch: 4 [1870/3978 (47%)]\tLoss: 0.256751\n",
            "Train Epoch: 4 [1875/3978 (47%)]\tLoss: 0.114226\n",
            "Train Epoch: 4 [1880/3978 (47%)]\tLoss: 0.109954\n",
            "Train Epoch: 4 [1885/3978 (47%)]\tLoss: 0.120342\n",
            "Train Epoch: 4 [1890/3978 (47%)]\tLoss: 0.219735\n",
            "Train Epoch: 4 [1895/3978 (48%)]\tLoss: 0.190836\n",
            "Train Epoch: 4 [1900/3978 (48%)]\tLoss: 0.137964\n",
            "Train Epoch: 4 [1905/3978 (48%)]\tLoss: 0.330881\n",
            "Train Epoch: 4 [1910/3978 (48%)]\tLoss: 0.125288\n",
            "Train Epoch: 4 [1915/3978 (48%)]\tLoss: 0.272795\n",
            "Train Epoch: 4 [1920/3978 (48%)]\tLoss: 0.318483\n",
            "Train Epoch: 4 [1925/3978 (48%)]\tLoss: 0.213278\n",
            "Train Epoch: 4 [1930/3978 (48%)]\tLoss: 0.189528\n",
            "Train Epoch: 4 [1935/3978 (49%)]\tLoss: 0.259105\n",
            "Train Epoch: 4 [1940/3978 (49%)]\tLoss: 0.053771\n",
            "Train Epoch: 4 [1945/3978 (49%)]\tLoss: 0.105161\n",
            "Train Epoch: 4 [1950/3978 (49%)]\tLoss: 0.076011\n",
            "Train Epoch: 4 [1955/3978 (49%)]\tLoss: 0.611866\n",
            "Train Epoch: 4 [1960/3978 (49%)]\tLoss: 0.040638\n",
            "Train Epoch: 4 [1965/3978 (49%)]\tLoss: 0.422480\n",
            "Train Epoch: 4 [1970/3978 (49%)]\tLoss: 0.462301\n",
            "Train Epoch: 4 [1975/3978 (50%)]\tLoss: 0.074404\n",
            "Train Epoch: 4 [1980/3978 (50%)]\tLoss: 0.417903\n",
            "Train Epoch: 4 [1985/3978 (50%)]\tLoss: 0.168883\n",
            "Train Epoch: 4 [1990/3978 (50%)]\tLoss: 0.213483\n",
            "Train Epoch: 4 [1995/3978 (50%)]\tLoss: 0.085255\n",
            "Train Epoch: 4 [2000/3978 (50%)]\tLoss: 0.230220\n",
            "Train Epoch: 4 [2005/3978 (50%)]\tLoss: 0.355736\n",
            "Train Epoch: 4 [2010/3978 (51%)]\tLoss: 0.095166\n",
            "Train Epoch: 4 [2015/3978 (51%)]\tLoss: 0.250133\n",
            "Train Epoch: 4 [2020/3978 (51%)]\tLoss: 0.408595\n",
            "Train Epoch: 4 [2025/3978 (51%)]\tLoss: 0.395037\n",
            "Train Epoch: 4 [2030/3978 (51%)]\tLoss: 0.176418\n",
            "Train Epoch: 4 [2035/3978 (51%)]\tLoss: 0.088315\n",
            "Train Epoch: 4 [2040/3978 (51%)]\tLoss: 0.674906\n",
            "Train Epoch: 4 [2045/3978 (51%)]\tLoss: 0.088452\n",
            "Train Epoch: 4 [2050/3978 (52%)]\tLoss: 0.202488\n",
            "Train Epoch: 4 [2055/3978 (52%)]\tLoss: 0.236597\n",
            "Train Epoch: 4 [2060/3978 (52%)]\tLoss: 0.254011\n",
            "Train Epoch: 4 [2065/3978 (52%)]\tLoss: 0.248923\n",
            "Train Epoch: 4 [2070/3978 (52%)]\tLoss: 0.200832\n",
            "Train Epoch: 4 [2075/3978 (52%)]\tLoss: 0.105517\n",
            "Train Epoch: 4 [2080/3978 (52%)]\tLoss: 0.245180\n",
            "Train Epoch: 4 [2085/3978 (52%)]\tLoss: 0.224528\n",
            "Train Epoch: 4 [2090/3978 (53%)]\tLoss: 0.092878\n",
            "Train Epoch: 4 [2095/3978 (53%)]\tLoss: 0.105416\n",
            "Train Epoch: 4 [2100/3978 (53%)]\tLoss: 0.193234\n",
            "Train Epoch: 4 [2105/3978 (53%)]\tLoss: 0.106996\n",
            "Train Epoch: 4 [2110/3978 (53%)]\tLoss: 0.446242\n",
            "Train Epoch: 4 [2115/3978 (53%)]\tLoss: 0.228203\n",
            "Train Epoch: 4 [2120/3978 (53%)]\tLoss: 0.072869\n",
            "Train Epoch: 4 [2125/3978 (53%)]\tLoss: 0.554669\n",
            "Train Epoch: 4 [2130/3978 (54%)]\tLoss: 0.196023\n",
            "Train Epoch: 4 [2135/3978 (54%)]\tLoss: 0.197919\n",
            "Train Epoch: 4 [2140/3978 (54%)]\tLoss: 0.093582\n",
            "Train Epoch: 4 [2145/3978 (54%)]\tLoss: 0.239364\n",
            "Train Epoch: 4 [2150/3978 (54%)]\tLoss: 0.218788\n",
            "Train Epoch: 4 [2155/3978 (54%)]\tLoss: 0.381562\n",
            "Train Epoch: 4 [2160/3978 (54%)]\tLoss: 0.057925\n",
            "Train Epoch: 4 [2165/3978 (54%)]\tLoss: 0.474118\n",
            "Train Epoch: 4 [2170/3978 (55%)]\tLoss: 0.399275\n",
            "Train Epoch: 4 [2175/3978 (55%)]\tLoss: 0.073761\n",
            "Train Epoch: 4 [2180/3978 (55%)]\tLoss: 0.296788\n",
            "Train Epoch: 4 [2185/3978 (55%)]\tLoss: 0.260128\n",
            "Train Epoch: 4 [2190/3978 (55%)]\tLoss: 0.518657\n",
            "Train Epoch: 4 [2195/3978 (55%)]\tLoss: 0.217037\n",
            "Train Epoch: 4 [2200/3978 (55%)]\tLoss: 0.211300\n",
            "Train Epoch: 4 [2205/3978 (55%)]\tLoss: 0.098134\n",
            "Train Epoch: 4 [2210/3978 (56%)]\tLoss: 0.110777\n",
            "Train Epoch: 4 [2215/3978 (56%)]\tLoss: 0.103638\n",
            "Train Epoch: 4 [2220/3978 (56%)]\tLoss: 0.228340\n",
            "Train Epoch: 4 [2225/3978 (56%)]\tLoss: 0.115774\n",
            "Train Epoch: 4 [2230/3978 (56%)]\tLoss: 0.203321\n",
            "Train Epoch: 4 [2235/3978 (56%)]\tLoss: 0.104941\n",
            "Train Epoch: 4 [2240/3978 (56%)]\tLoss: 0.089198\n",
            "Train Epoch: 4 [2245/3978 (56%)]\tLoss: 0.086746\n",
            "Train Epoch: 4 [2250/3978 (57%)]\tLoss: 0.426041\n",
            "Train Epoch: 4 [2255/3978 (57%)]\tLoss: 0.235922\n",
            "Train Epoch: 4 [2260/3978 (57%)]\tLoss: 0.295962\n",
            "Train Epoch: 4 [2265/3978 (57%)]\tLoss: 0.238632\n",
            "Train Epoch: 4 [2270/3978 (57%)]\tLoss: 0.228134\n",
            "Train Epoch: 4 [2275/3978 (57%)]\tLoss: 0.281671\n",
            "Train Epoch: 4 [2280/3978 (57%)]\tLoss: 0.266064\n",
            "Train Epoch: 4 [2285/3978 (57%)]\tLoss: 0.215264\n",
            "Train Epoch: 4 [2290/3978 (58%)]\tLoss: 0.061342\n",
            "Train Epoch: 4 [2295/3978 (58%)]\tLoss: 0.195817\n",
            "Train Epoch: 4 [2300/3978 (58%)]\tLoss: 0.105792\n",
            "Train Epoch: 4 [2305/3978 (58%)]\tLoss: 0.074152\n",
            "Train Epoch: 4 [2310/3978 (58%)]\tLoss: 0.176279\n",
            "Train Epoch: 4 [2315/3978 (58%)]\tLoss: 0.404987\n",
            "Train Epoch: 4 [2320/3978 (58%)]\tLoss: 0.307485\n",
            "Train Epoch: 4 [2325/3978 (58%)]\tLoss: 0.202107\n",
            "Train Epoch: 4 [2330/3978 (59%)]\tLoss: 0.109608\n",
            "Train Epoch: 4 [2335/3978 (59%)]\tLoss: 0.218518\n",
            "Train Epoch: 4 [2340/3978 (59%)]\tLoss: 0.380969\n",
            "Train Epoch: 4 [2345/3978 (59%)]\tLoss: 0.056934\n",
            "Train Epoch: 4 [2350/3978 (59%)]\tLoss: 0.357913\n",
            "Train Epoch: 4 [2355/3978 (59%)]\tLoss: 0.188721\n",
            "Train Epoch: 4 [2360/3978 (59%)]\tLoss: 0.166447\n",
            "Train Epoch: 4 [2365/3978 (59%)]\tLoss: 0.404750\n",
            "Train Epoch: 4 [2370/3978 (60%)]\tLoss: 0.206750\n",
            "Train Epoch: 4 [2375/3978 (60%)]\tLoss: 0.163834\n",
            "Train Epoch: 4 [2380/3978 (60%)]\tLoss: 0.126770\n",
            "Train Epoch: 4 [2385/3978 (60%)]\tLoss: 0.141813\n",
            "Train Epoch: 4 [2390/3978 (60%)]\tLoss: 0.235898\n",
            "Train Epoch: 4 [2395/3978 (60%)]\tLoss: 0.130802\n",
            "Train Epoch: 4 [2400/3978 (60%)]\tLoss: 0.126143\n",
            "Train Epoch: 4 [2405/3978 (60%)]\tLoss: 0.203509\n",
            "Train Epoch: 4 [2410/3978 (61%)]\tLoss: 0.233035\n",
            "Train Epoch: 4 [2415/3978 (61%)]\tLoss: 0.351392\n",
            "Train Epoch: 4 [2420/3978 (61%)]\tLoss: 0.170693\n",
            "Train Epoch: 4 [2425/3978 (61%)]\tLoss: 0.096747\n",
            "Train Epoch: 4 [2430/3978 (61%)]\tLoss: 0.312109\n",
            "Train Epoch: 4 [2435/3978 (61%)]\tLoss: 0.608572\n",
            "Train Epoch: 4 [2440/3978 (61%)]\tLoss: 0.095081\n",
            "Train Epoch: 4 [2445/3978 (61%)]\tLoss: 0.129582\n",
            "Train Epoch: 4 [2450/3978 (62%)]\tLoss: 0.163375\n",
            "Train Epoch: 4 [2455/3978 (62%)]\tLoss: 0.522211\n",
            "Train Epoch: 4 [2460/3978 (62%)]\tLoss: 0.106349\n",
            "Train Epoch: 4 [2465/3978 (62%)]\tLoss: 0.234882\n",
            "Train Epoch: 4 [2470/3978 (62%)]\tLoss: 0.087092\n",
            "Train Epoch: 4 [2475/3978 (62%)]\tLoss: 0.530057\n",
            "Train Epoch: 4 [2480/3978 (62%)]\tLoss: 0.281963\n",
            "Train Epoch: 4 [2485/3978 (62%)]\tLoss: 0.292557\n",
            "Train Epoch: 4 [2490/3978 (63%)]\tLoss: 0.306357\n",
            "Train Epoch: 4 [2495/3978 (63%)]\tLoss: 0.151397\n",
            "Train Epoch: 4 [2500/3978 (63%)]\tLoss: 0.312773\n",
            "Train Epoch: 4 [2505/3978 (63%)]\tLoss: 0.308314\n",
            "Train Epoch: 4 [2510/3978 (63%)]\tLoss: 0.566647\n",
            "Train Epoch: 4 [2515/3978 (63%)]\tLoss: 0.309845\n",
            "Train Epoch: 4 [2520/3978 (63%)]\tLoss: 0.222285\n",
            "Train Epoch: 4 [2525/3978 (63%)]\tLoss: 0.127340\n",
            "Train Epoch: 4 [2530/3978 (64%)]\tLoss: 0.130285\n",
            "Train Epoch: 4 [2535/3978 (64%)]\tLoss: 0.099258\n",
            "Train Epoch: 4 [2540/3978 (64%)]\tLoss: 0.104819\n",
            "Train Epoch: 4 [2545/3978 (64%)]\tLoss: 0.147571\n",
            "Train Epoch: 4 [2550/3978 (64%)]\tLoss: 0.273815\n",
            "Train Epoch: 4 [2555/3978 (64%)]\tLoss: 0.348117\n",
            "Train Epoch: 4 [2560/3978 (64%)]\tLoss: 0.172965\n",
            "Train Epoch: 4 [2565/3978 (64%)]\tLoss: 0.082062\n",
            "Train Epoch: 4 [2570/3978 (65%)]\tLoss: 0.082223\n",
            "Train Epoch: 4 [2575/3978 (65%)]\tLoss: 0.193980\n",
            "Train Epoch: 4 [2580/3978 (65%)]\tLoss: 0.246972\n",
            "Train Epoch: 4 [2585/3978 (65%)]\tLoss: 0.141838\n",
            "Train Epoch: 4 [2590/3978 (65%)]\tLoss: 0.231797\n",
            "Train Epoch: 4 [2595/3978 (65%)]\tLoss: 0.239513\n",
            "Train Epoch: 4 [2600/3978 (65%)]\tLoss: 0.191567\n",
            "Train Epoch: 4 [2605/3978 (65%)]\tLoss: 0.319442\n",
            "Train Epoch: 4 [2610/3978 (66%)]\tLoss: 0.263772\n",
            "Train Epoch: 4 [2615/3978 (66%)]\tLoss: 0.189199\n",
            "Train Epoch: 4 [2620/3978 (66%)]\tLoss: 0.290646\n",
            "Train Epoch: 4 [2625/3978 (66%)]\tLoss: 0.087942\n",
            "Train Epoch: 4 [2630/3978 (66%)]\tLoss: 0.078991\n",
            "Train Epoch: 4 [2635/3978 (66%)]\tLoss: 0.600325\n",
            "Train Epoch: 4 [2640/3978 (66%)]\tLoss: 0.086920\n",
            "Train Epoch: 4 [2645/3978 (66%)]\tLoss: 0.068604\n",
            "Train Epoch: 4 [2650/3978 (67%)]\tLoss: 0.100293\n",
            "Train Epoch: 4 [2655/3978 (67%)]\tLoss: 0.241639\n",
            "Train Epoch: 4 [2660/3978 (67%)]\tLoss: 0.063908\n",
            "Train Epoch: 4 [2665/3978 (67%)]\tLoss: 0.644888\n",
            "Train Epoch: 4 [2670/3978 (67%)]\tLoss: 0.156631\n",
            "Train Epoch: 4 [2675/3978 (67%)]\tLoss: 0.410193\n",
            "Train Epoch: 4 [2680/3978 (67%)]\tLoss: 0.245932\n",
            "Train Epoch: 4 [2685/3978 (67%)]\tLoss: 0.532022\n",
            "Train Epoch: 4 [2690/3978 (68%)]\tLoss: 0.199045\n",
            "Train Epoch: 4 [2695/3978 (68%)]\tLoss: 0.081869\n",
            "Train Epoch: 4 [2700/3978 (68%)]\tLoss: 0.197850\n",
            "Train Epoch: 4 [2705/3978 (68%)]\tLoss: 0.159707\n",
            "Train Epoch: 4 [2710/3978 (68%)]\tLoss: 0.219912\n",
            "Train Epoch: 4 [2715/3978 (68%)]\tLoss: 0.310029\n",
            "Train Epoch: 4 [2720/3978 (68%)]\tLoss: 0.228283\n",
            "Train Epoch: 4 [2725/3978 (68%)]\tLoss: 0.321918\n",
            "Train Epoch: 4 [2730/3978 (69%)]\tLoss: 0.305539\n",
            "Train Epoch: 4 [2735/3978 (69%)]\tLoss: 0.225392\n",
            "Train Epoch: 4 [2740/3978 (69%)]\tLoss: 0.160139\n",
            "Train Epoch: 4 [2745/3978 (69%)]\tLoss: 0.805341\n",
            "Train Epoch: 4 [2750/3978 (69%)]\tLoss: 0.214244\n",
            "Train Epoch: 4 [2755/3978 (69%)]\tLoss: 0.524153\n",
            "Train Epoch: 4 [2760/3978 (69%)]\tLoss: 0.137515\n",
            "Train Epoch: 4 [2765/3978 (69%)]\tLoss: 0.263528\n",
            "Train Epoch: 4 [2770/3978 (70%)]\tLoss: 0.147240\n",
            "Train Epoch: 4 [2775/3978 (70%)]\tLoss: 0.142679\n",
            "Train Epoch: 4 [2780/3978 (70%)]\tLoss: 0.163713\n",
            "Train Epoch: 4 [2785/3978 (70%)]\tLoss: 0.206529\n",
            "Train Epoch: 4 [2790/3978 (70%)]\tLoss: 0.198148\n",
            "Train Epoch: 4 [2795/3978 (70%)]\tLoss: 0.121549\n",
            "Train Epoch: 4 [2800/3978 (70%)]\tLoss: 0.078880\n",
            "Train Epoch: 4 [2805/3978 (70%)]\tLoss: 0.094532\n",
            "Train Epoch: 4 [2810/3978 (71%)]\tLoss: 0.129006\n",
            "Train Epoch: 4 [2815/3978 (71%)]\tLoss: 0.176830\n",
            "Train Epoch: 4 [2820/3978 (71%)]\tLoss: 0.277301\n",
            "Train Epoch: 4 [2825/3978 (71%)]\tLoss: 0.226401\n",
            "Train Epoch: 4 [2830/3978 (71%)]\tLoss: 0.208538\n",
            "Train Epoch: 4 [2835/3978 (71%)]\tLoss: 0.399493\n",
            "Train Epoch: 4 [2840/3978 (71%)]\tLoss: 0.186196\n",
            "Train Epoch: 4 [2845/3978 (71%)]\tLoss: 0.281762\n",
            "Train Epoch: 4 [2850/3978 (72%)]\tLoss: 0.068662\n",
            "Train Epoch: 4 [2855/3978 (72%)]\tLoss: 0.063162\n",
            "Train Epoch: 4 [2860/3978 (72%)]\tLoss: 0.070400\n",
            "Train Epoch: 4 [2865/3978 (72%)]\tLoss: 0.229999\n",
            "Train Epoch: 4 [2870/3978 (72%)]\tLoss: 0.059395\n",
            "Train Epoch: 4 [2875/3978 (72%)]\tLoss: 0.100030\n",
            "Train Epoch: 4 [2880/3978 (72%)]\tLoss: 0.507981\n",
            "Train Epoch: 4 [2885/3978 (72%)]\tLoss: 0.359174\n",
            "Train Epoch: 4 [2890/3978 (73%)]\tLoss: 0.450253\n",
            "Train Epoch: 4 [2895/3978 (73%)]\tLoss: 0.317618\n",
            "Train Epoch: 4 [2900/3978 (73%)]\tLoss: 0.222992\n",
            "Train Epoch: 4 [2905/3978 (73%)]\tLoss: 0.063935\n",
            "Train Epoch: 4 [2910/3978 (73%)]\tLoss: 0.212628\n",
            "Train Epoch: 4 [2915/3978 (73%)]\tLoss: 0.311865\n",
            "Train Epoch: 4 [2920/3978 (73%)]\tLoss: 0.517587\n",
            "Train Epoch: 4 [2925/3978 (73%)]\tLoss: 0.133179\n",
            "Train Epoch: 4 [2930/3978 (74%)]\tLoss: 0.488334\n",
            "Train Epoch: 4 [2935/3978 (74%)]\tLoss: 0.233174\n",
            "Train Epoch: 4 [2940/3978 (74%)]\tLoss: 0.158566\n",
            "Train Epoch: 4 [2945/3978 (74%)]\tLoss: 0.243665\n",
            "Train Epoch: 4 [2950/3978 (74%)]\tLoss: 0.253200\n",
            "Train Epoch: 4 [2955/3978 (74%)]\tLoss: 0.129237\n",
            "Train Epoch: 4 [2960/3978 (74%)]\tLoss: 0.272539\n",
            "Train Epoch: 4 [2965/3978 (74%)]\tLoss: 0.097979\n",
            "Train Epoch: 4 [2970/3978 (75%)]\tLoss: 0.090330\n",
            "Train Epoch: 4 [2975/3978 (75%)]\tLoss: 0.210052\n",
            "Train Epoch: 4 [2980/3978 (75%)]\tLoss: 0.329326\n",
            "Train Epoch: 4 [2985/3978 (75%)]\tLoss: 0.209637\n",
            "Train Epoch: 4 [2990/3978 (75%)]\tLoss: 0.468237\n",
            "Train Epoch: 4 [2995/3978 (75%)]\tLoss: 0.109015\n",
            "Train Epoch: 4 [3000/3978 (75%)]\tLoss: 0.116013\n",
            "Train Epoch: 4 [3005/3978 (76%)]\tLoss: 0.307211\n",
            "Train Epoch: 4 [3010/3978 (76%)]\tLoss: 0.395671\n",
            "Train Epoch: 4 [3015/3978 (76%)]\tLoss: 0.068926\n",
            "Train Epoch: 4 [3020/3978 (76%)]\tLoss: 0.237962\n",
            "Train Epoch: 4 [3025/3978 (76%)]\tLoss: 0.223277\n",
            "Train Epoch: 4 [3030/3978 (76%)]\tLoss: 0.067061\n",
            "Train Epoch: 4 [3035/3978 (76%)]\tLoss: 0.191939\n",
            "Train Epoch: 4 [3040/3978 (76%)]\tLoss: 0.863188\n",
            "Train Epoch: 4 [3045/3978 (77%)]\tLoss: 0.219827\n",
            "Train Epoch: 4 [3050/3978 (77%)]\tLoss: 0.094689\n",
            "Train Epoch: 4 [3055/3978 (77%)]\tLoss: 0.255006\n",
            "Train Epoch: 4 [3060/3978 (77%)]\tLoss: 0.163237\n",
            "Train Epoch: 4 [3065/3978 (77%)]\tLoss: 0.235809\n",
            "Train Epoch: 4 [3070/3978 (77%)]\tLoss: 0.113293\n",
            "Train Epoch: 4 [3075/3978 (77%)]\tLoss: 0.222304\n",
            "Train Epoch: 4 [3080/3978 (77%)]\tLoss: 0.345182\n",
            "Train Epoch: 4 [3085/3978 (78%)]\tLoss: 0.104749\n",
            "Train Epoch: 4 [3090/3978 (78%)]\tLoss: 0.426165\n",
            "Train Epoch: 4 [3095/3978 (78%)]\tLoss: 0.169905\n",
            "Train Epoch: 4 [3100/3978 (78%)]\tLoss: 0.106341\n",
            "Train Epoch: 4 [3105/3978 (78%)]\tLoss: 0.347293\n",
            "Train Epoch: 4 [3110/3978 (78%)]\tLoss: 0.321741\n",
            "Train Epoch: 4 [3115/3978 (78%)]\tLoss: 0.361486\n",
            "Train Epoch: 4 [3120/3978 (78%)]\tLoss: 0.171513\n",
            "Train Epoch: 4 [3125/3978 (79%)]\tLoss: 0.175887\n",
            "Train Epoch: 4 [3130/3978 (79%)]\tLoss: 0.131065\n",
            "Train Epoch: 4 [3135/3978 (79%)]\tLoss: 0.124622\n",
            "Train Epoch: 4 [3140/3978 (79%)]\tLoss: 0.201498\n",
            "Train Epoch: 4 [3145/3978 (79%)]\tLoss: 0.082231\n",
            "Train Epoch: 4 [3150/3978 (79%)]\tLoss: 0.093744\n",
            "Train Epoch: 4 [3155/3978 (79%)]\tLoss: 0.211378\n",
            "Train Epoch: 4 [3160/3978 (79%)]\tLoss: 0.074526\n",
            "Train Epoch: 4 [3165/3978 (80%)]\tLoss: 0.072845\n",
            "Train Epoch: 4 [3170/3978 (80%)]\tLoss: 0.171078\n",
            "Train Epoch: 4 [3175/3978 (80%)]\tLoss: 0.093858\n",
            "Train Epoch: 4 [3180/3978 (80%)]\tLoss: 0.066352\n",
            "Train Epoch: 4 [3185/3978 (80%)]\tLoss: 0.067214\n",
            "Train Epoch: 4 [3190/3978 (80%)]\tLoss: 0.080741\n",
            "Train Epoch: 4 [3195/3978 (80%)]\tLoss: 0.106535\n",
            "Train Epoch: 4 [3200/3978 (80%)]\tLoss: 0.368116\n",
            "Train Epoch: 4 [3205/3978 (81%)]\tLoss: 0.072481\n",
            "Train Epoch: 4 [3210/3978 (81%)]\tLoss: 0.246033\n",
            "Train Epoch: 4 [3215/3978 (81%)]\tLoss: 0.173042\n",
            "Train Epoch: 4 [3220/3978 (81%)]\tLoss: 0.050406\n",
            "Train Epoch: 4 [3225/3978 (81%)]\tLoss: 0.058206\n",
            "Train Epoch: 4 [3230/3978 (81%)]\tLoss: 0.477579\n",
            "Train Epoch: 4 [3235/3978 (81%)]\tLoss: 0.159371\n",
            "Train Epoch: 4 [3240/3978 (81%)]\tLoss: 0.076263\n",
            "Train Epoch: 4 [3245/3978 (82%)]\tLoss: 0.249492\n",
            "Train Epoch: 4 [3250/3978 (82%)]\tLoss: 0.378403\n",
            "Train Epoch: 4 [3255/3978 (82%)]\tLoss: 0.538316\n",
            "Train Epoch: 4 [3260/3978 (82%)]\tLoss: 0.166086\n",
            "Train Epoch: 4 [3265/3978 (82%)]\tLoss: 0.067817\n",
            "Train Epoch: 4 [3270/3978 (82%)]\tLoss: 0.096471\n",
            "Train Epoch: 4 [3275/3978 (82%)]\tLoss: 0.436049\n",
            "Train Epoch: 4 [3280/3978 (82%)]\tLoss: 0.100795\n",
            "Train Epoch: 4 [3285/3978 (83%)]\tLoss: 0.100176\n",
            "Train Epoch: 4 [3290/3978 (83%)]\tLoss: 0.681944\n",
            "Train Epoch: 4 [3295/3978 (83%)]\tLoss: 0.298452\n",
            "Train Epoch: 4 [3300/3978 (83%)]\tLoss: 0.490814\n",
            "Train Epoch: 4 [3305/3978 (83%)]\tLoss: 0.443905\n",
            "Train Epoch: 4 [3310/3978 (83%)]\tLoss: 0.411613\n",
            "Train Epoch: 4 [3315/3978 (83%)]\tLoss: 0.233876\n",
            "Train Epoch: 4 [3320/3978 (83%)]\tLoss: 0.212299\n",
            "Train Epoch: 4 [3325/3978 (84%)]\tLoss: 0.195277\n",
            "Train Epoch: 4 [3330/3978 (84%)]\tLoss: 0.106219\n",
            "Train Epoch: 4 [3335/3978 (84%)]\tLoss: 0.242625\n",
            "Train Epoch: 4 [3340/3978 (84%)]\tLoss: 0.431855\n",
            "Train Epoch: 4 [3345/3978 (84%)]\tLoss: 0.294663\n",
            "Train Epoch: 4 [3350/3978 (84%)]\tLoss: 0.289076\n",
            "Train Epoch: 4 [3355/3978 (84%)]\tLoss: 0.242728\n",
            "Train Epoch: 4 [3360/3978 (84%)]\tLoss: 0.151426\n",
            "Train Epoch: 4 [3365/3978 (85%)]\tLoss: 0.574716\n",
            "Train Epoch: 4 [3370/3978 (85%)]\tLoss: 0.127549\n",
            "Train Epoch: 4 [3375/3978 (85%)]\tLoss: 0.556030\n",
            "Train Epoch: 4 [3380/3978 (85%)]\tLoss: 0.232152\n",
            "Train Epoch: 4 [3385/3978 (85%)]\tLoss: 0.460901\n",
            "Train Epoch: 4 [3390/3978 (85%)]\tLoss: 0.535623\n",
            "Train Epoch: 4 [3395/3978 (85%)]\tLoss: 0.193739\n",
            "Train Epoch: 4 [3400/3978 (85%)]\tLoss: 0.202961\n",
            "Train Epoch: 4 [3405/3978 (86%)]\tLoss: 0.304551\n",
            "Train Epoch: 4 [3410/3978 (86%)]\tLoss: 0.252114\n",
            "Train Epoch: 4 [3415/3978 (86%)]\tLoss: 0.356275\n",
            "Train Epoch: 4 [3420/3978 (86%)]\tLoss: 0.140072\n",
            "Train Epoch: 4 [3425/3978 (86%)]\tLoss: 0.200341\n",
            "Train Epoch: 4 [3430/3978 (86%)]\tLoss: 0.226528\n",
            "Train Epoch: 4 [3435/3978 (86%)]\tLoss: 0.445493\n",
            "Train Epoch: 4 [3440/3978 (86%)]\tLoss: 0.164178\n",
            "Train Epoch: 4 [3445/3978 (87%)]\tLoss: 0.377202\n",
            "Train Epoch: 4 [3450/3978 (87%)]\tLoss: 0.320457\n",
            "Train Epoch: 4 [3455/3978 (87%)]\tLoss: 0.181886\n",
            "Train Epoch: 4 [3460/3978 (87%)]\tLoss: 0.079554\n",
            "Train Epoch: 4 [3465/3978 (87%)]\tLoss: 0.536580\n",
            "Train Epoch: 4 [3470/3978 (87%)]\tLoss: 0.082555\n",
            "Train Epoch: 4 [3475/3978 (87%)]\tLoss: 0.182604\n",
            "Train Epoch: 4 [3480/3978 (87%)]\tLoss: 0.082220\n",
            "Train Epoch: 4 [3485/3978 (88%)]\tLoss: 0.551421\n",
            "Train Epoch: 4 [3490/3978 (88%)]\tLoss: 0.037018\n",
            "Train Epoch: 4 [3495/3978 (88%)]\tLoss: 0.351107\n",
            "Train Epoch: 4 [3500/3978 (88%)]\tLoss: 0.411930\n",
            "Train Epoch: 4 [3505/3978 (88%)]\tLoss: 0.075111\n",
            "Train Epoch: 4 [3510/3978 (88%)]\tLoss: 0.117750\n",
            "Train Epoch: 4 [3515/3978 (88%)]\tLoss: 0.188876\n",
            "Train Epoch: 4 [3520/3978 (88%)]\tLoss: 0.135761\n",
            "Train Epoch: 4 [3525/3978 (89%)]\tLoss: 0.081235\n",
            "Train Epoch: 4 [3530/3978 (89%)]\tLoss: 0.236822\n",
            "Train Epoch: 4 [3535/3978 (89%)]\tLoss: 0.259003\n",
            "Train Epoch: 4 [3540/3978 (89%)]\tLoss: 0.529135\n",
            "Train Epoch: 4 [3545/3978 (89%)]\tLoss: 0.104212\n",
            "Train Epoch: 4 [3550/3978 (89%)]\tLoss: 0.316338\n",
            "Train Epoch: 4 [3555/3978 (89%)]\tLoss: 0.185022\n",
            "Train Epoch: 4 [3560/3978 (89%)]\tLoss: 0.279793\n",
            "Train Epoch: 4 [3565/3978 (90%)]\tLoss: 0.126208\n",
            "Train Epoch: 4 [3570/3978 (90%)]\tLoss: 0.402848\n",
            "Train Epoch: 4 [3575/3978 (90%)]\tLoss: 0.107859\n",
            "Train Epoch: 4 [3580/3978 (90%)]\tLoss: 0.192356\n",
            "Train Epoch: 4 [3585/3978 (90%)]\tLoss: 0.185042\n",
            "Train Epoch: 4 [3590/3978 (90%)]\tLoss: 0.097140\n",
            "Train Epoch: 4 [3595/3978 (90%)]\tLoss: 0.405236\n",
            "Train Epoch: 4 [3600/3978 (90%)]\tLoss: 0.361830\n",
            "Train Epoch: 4 [3605/3978 (91%)]\tLoss: 0.092847\n",
            "Train Epoch: 4 [3610/3978 (91%)]\tLoss: 0.184282\n",
            "Train Epoch: 4 [3615/3978 (91%)]\tLoss: 0.063116\n",
            "Train Epoch: 4 [3620/3978 (91%)]\tLoss: 0.239654\n",
            "Train Epoch: 4 [3625/3978 (91%)]\tLoss: 0.130563\n",
            "Train Epoch: 4 [3630/3978 (91%)]\tLoss: 0.319968\n",
            "Train Epoch: 4 [3635/3978 (91%)]\tLoss: 0.305984\n",
            "Train Epoch: 4 [3640/3978 (91%)]\tLoss: 0.129245\n",
            "Train Epoch: 4 [3645/3978 (92%)]\tLoss: 0.136047\n",
            "Train Epoch: 4 [3650/3978 (92%)]\tLoss: 0.102167\n",
            "Train Epoch: 4 [3655/3978 (92%)]\tLoss: 0.182975\n",
            "Train Epoch: 4 [3660/3978 (92%)]\tLoss: 0.114325\n",
            "Train Epoch: 4 [3665/3978 (92%)]\tLoss: 0.314196\n",
            "Train Epoch: 4 [3670/3978 (92%)]\tLoss: 0.384700\n",
            "Train Epoch: 4 [3675/3978 (92%)]\tLoss: 0.082699\n",
            "Train Epoch: 4 [3680/3978 (92%)]\tLoss: 0.162759\n",
            "Train Epoch: 4 [3685/3978 (93%)]\tLoss: 0.288503\n",
            "Train Epoch: 4 [3690/3978 (93%)]\tLoss: 0.211830\n",
            "Train Epoch: 4 [3695/3978 (93%)]\tLoss: 0.088507\n",
            "Train Epoch: 4 [3700/3978 (93%)]\tLoss: 0.296523\n",
            "Train Epoch: 4 [3705/3978 (93%)]\tLoss: 0.106790\n",
            "Train Epoch: 4 [3710/3978 (93%)]\tLoss: 0.122338\n",
            "Train Epoch: 4 [3715/3978 (93%)]\tLoss: 0.513291\n",
            "Train Epoch: 4 [3720/3978 (93%)]\tLoss: 0.679274\n",
            "Train Epoch: 4 [3725/3978 (94%)]\tLoss: 0.086646\n",
            "Train Epoch: 4 [3730/3978 (94%)]\tLoss: 0.099551\n",
            "Train Epoch: 4 [3735/3978 (94%)]\tLoss: 0.221811\n",
            "Train Epoch: 4 [3740/3978 (94%)]\tLoss: 0.136489\n",
            "Train Epoch: 4 [3745/3978 (94%)]\tLoss: 0.317455\n",
            "Train Epoch: 4 [3750/3978 (94%)]\tLoss: 0.128301\n",
            "Train Epoch: 4 [3755/3978 (94%)]\tLoss: 0.347675\n",
            "Train Epoch: 4 [3760/3978 (94%)]\tLoss: 0.542781\n",
            "Train Epoch: 4 [3765/3978 (95%)]\tLoss: 0.084609\n",
            "Train Epoch: 4 [3770/3978 (95%)]\tLoss: 0.291107\n",
            "Train Epoch: 4 [3775/3978 (95%)]\tLoss: 0.201087\n",
            "Train Epoch: 4 [3780/3978 (95%)]\tLoss: 0.216915\n",
            "Train Epoch: 4 [3785/3978 (95%)]\tLoss: 0.221574\n",
            "Train Epoch: 4 [3790/3978 (95%)]\tLoss: 0.130579\n",
            "Train Epoch: 4 [3795/3978 (95%)]\tLoss: 0.184239\n",
            "Train Epoch: 4 [3800/3978 (95%)]\tLoss: 0.251790\n",
            "Train Epoch: 4 [3805/3978 (96%)]\tLoss: 0.389743\n",
            "Train Epoch: 4 [3810/3978 (96%)]\tLoss: 0.187001\n",
            "Train Epoch: 4 [3815/3978 (96%)]\tLoss: 0.098311\n",
            "Train Epoch: 4 [3820/3978 (96%)]\tLoss: 0.213908\n",
            "Train Epoch: 4 [3825/3978 (96%)]\tLoss: 0.257102\n",
            "Train Epoch: 4 [3830/3978 (96%)]\tLoss: 0.378033\n",
            "Train Epoch: 4 [3835/3978 (96%)]\tLoss: 0.098542\n",
            "Train Epoch: 4 [3840/3978 (96%)]\tLoss: 0.154037\n",
            "Train Epoch: 4 [3845/3978 (97%)]\tLoss: 0.252966\n",
            "Train Epoch: 4 [3850/3978 (97%)]\tLoss: 0.188086\n",
            "Train Epoch: 4 [3855/3978 (97%)]\tLoss: 0.287947\n",
            "Train Epoch: 4 [3860/3978 (97%)]\tLoss: 0.376363\n",
            "Train Epoch: 4 [3865/3978 (97%)]\tLoss: 0.262256\n",
            "Train Epoch: 4 [3870/3978 (97%)]\tLoss: 0.078470\n",
            "Train Epoch: 4 [3875/3978 (97%)]\tLoss: 0.343955\n",
            "Train Epoch: 4 [3880/3978 (97%)]\tLoss: 0.226041\n",
            "Train Epoch: 4 [3885/3978 (98%)]\tLoss: 0.377976\n",
            "Train Epoch: 4 [3890/3978 (98%)]\tLoss: 0.128210\n",
            "Train Epoch: 4 [3895/3978 (98%)]\tLoss: 0.181627\n",
            "Train Epoch: 4 [3900/3978 (98%)]\tLoss: 0.356754\n",
            "Train Epoch: 4 [3905/3978 (98%)]\tLoss: 0.358393\n",
            "Train Epoch: 4 [3910/3978 (98%)]\tLoss: 0.377421\n",
            "Train Epoch: 4 [3915/3978 (98%)]\tLoss: 0.392486\n",
            "Train Epoch: 4 [3920/3978 (98%)]\tLoss: 0.392721\n",
            "Train Epoch: 4 [3925/3978 (99%)]\tLoss: 0.106099\n",
            "Train Epoch: 4 [3930/3978 (99%)]\tLoss: 0.139155\n",
            "Train Epoch: 4 [3935/3978 (99%)]\tLoss: 0.093565\n",
            "Train Epoch: 4 [3940/3978 (99%)]\tLoss: 0.293910\n",
            "Train Epoch: 4 [3945/3978 (99%)]\tLoss: 0.527929\n",
            "Train Epoch: 4 [3950/3978 (99%)]\tLoss: 0.152955\n",
            "Train Epoch: 4 [3955/3978 (99%)]\tLoss: 0.049995\n",
            "Train Epoch: 4 [3960/3978 (99%)]\tLoss: 0.260681\n",
            "Train Epoch: 4 [3965/3978 (100%)]\tLoss: 0.235003\n",
            "Train Epoch: 4 [3970/3978 (100%)]\tLoss: 0.047568\n",
            "Train Epoch: 4 [2385/3978 (100%)]\tLoss: 0.233682\n",
            "Epoch\n",
            "train/train_loss: 0.2336820811033249\n",
            "\n",
            "Train Loss: 0.234, Valid Loss: 0.319636, Accuracy: 0.35\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='270.643 MB of 270.835 MB uploaded\\r'), FloatProgress(value=0.9992924486711368, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc3766f0d55e4cecb2e8100ba40c7014"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train/loss</td><td>▂▂▄▁▁▁▃▇▃▂▄▂▃▂▁▃▅▂▃▃▂▂▁▂▄▂▄▃▅▃▆▇▂▂█▁▄▁▅▄</td></tr><tr><td>validation/accuracy</td><td>██▁▁▁</td></tr><tr><td>validation/loss</td><td>▁▃▂█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/loss</td><td>0.23368</td></tr><tr><td>validation/accuracy</td><td>0.3456</td></tr><tr><td>validation/loss</td><td>0.31964</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dry-sweep-4</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/usll2fd7' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/usll2fd7</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240829_185733-usll2fd7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mwj2226b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240829_192547-mwj2226b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/mwj2226b' target=\"_blank\">olive-sweep-5</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/sweeps/fa5dcf96</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/mwj2226b' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/mwj2226b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/3978 (0%)]\tLoss: 0.521895\n",
            "Train Epoch: 0 [5/3978 (0%)]\tLoss: 0.585990\n",
            "Train Epoch: 0 [10/3978 (0%)]\tLoss: 1.679535\n",
            "Train Epoch: 0 [15/3978 (0%)]\tLoss: 0.232715\n",
            "Train Epoch: 0 [20/3978 (1%)]\tLoss: 0.881926\n",
            "Train Epoch: 0 [25/3978 (1%)]\tLoss: 0.484596\n",
            "Train Epoch: 0 [30/3978 (1%)]\tLoss: 1.905495\n",
            "Train Epoch: 0 [35/3978 (1%)]\tLoss: 0.353120\n",
            "Train Epoch: 0 [40/3978 (1%)]\tLoss: 1.041607\n",
            "Train Epoch: 0 [45/3978 (1%)]\tLoss: 0.487729\n",
            "Train Epoch: 0 [50/3978 (1%)]\tLoss: 0.081807\n",
            "Train Epoch: 0 [55/3978 (1%)]\tLoss: 0.431842\n",
            "Train Epoch: 0 [60/3978 (2%)]\tLoss: 0.658449\n",
            "Train Epoch: 0 [65/3978 (2%)]\tLoss: 1.324799\n",
            "Train Epoch: 0 [70/3978 (2%)]\tLoss: 0.021372\n",
            "Train Epoch: 0 [75/3978 (2%)]\tLoss: 0.593655\n",
            "Train Epoch: 0 [80/3978 (2%)]\tLoss: 0.359335\n",
            "Train Epoch: 0 [85/3978 (2%)]\tLoss: 0.648013\n",
            "Train Epoch: 0 [90/3978 (2%)]\tLoss: 0.116720\n",
            "Train Epoch: 0 [95/3978 (2%)]\tLoss: 1.003506\n",
            "Train Epoch: 0 [100/3978 (3%)]\tLoss: 2.060476\n",
            "Train Epoch: 0 [105/3978 (3%)]\tLoss: 0.158759\n",
            "Train Epoch: 0 [110/3978 (3%)]\tLoss: 0.180430\n",
            "Train Epoch: 0 [115/3978 (3%)]\tLoss: 0.061155\n",
            "Train Epoch: 0 [120/3978 (3%)]\tLoss: 1.023427\n",
            "Train Epoch: 0 [125/3978 (3%)]\tLoss: 1.367587\n",
            "Train Epoch: 0 [130/3978 (3%)]\tLoss: 0.102409\n",
            "Train Epoch: 0 [135/3978 (3%)]\tLoss: 0.325815\n",
            "Train Epoch: 0 [140/3978 (4%)]\tLoss: 1.170528\n",
            "Train Epoch: 0 [145/3978 (4%)]\tLoss: 1.154723\n",
            "Train Epoch: 0 [150/3978 (4%)]\tLoss: 0.295515\n",
            "Train Epoch: 0 [155/3978 (4%)]\tLoss: 0.409698\n",
            "Train Epoch: 0 [160/3978 (4%)]\tLoss: 0.385618\n",
            "Train Epoch: 0 [165/3978 (4%)]\tLoss: 0.490224\n",
            "Train Epoch: 0 [170/3978 (4%)]\tLoss: 0.100651\n",
            "Train Epoch: 0 [175/3978 (4%)]\tLoss: 0.229248\n",
            "Train Epoch: 0 [180/3978 (5%)]\tLoss: 2.454494\n",
            "Train Epoch: 0 [185/3978 (5%)]\tLoss: 0.041226\n",
            "Train Epoch: 0 [190/3978 (5%)]\tLoss: 0.778971\n",
            "Train Epoch: 0 [195/3978 (5%)]\tLoss: 0.061167\n",
            "Train Epoch: 0 [200/3978 (5%)]\tLoss: 0.549420\n",
            "Train Epoch: 0 [205/3978 (5%)]\tLoss: 0.041526\n",
            "Train Epoch: 0 [210/3978 (5%)]\tLoss: 0.043091\n",
            "Train Epoch: 0 [215/3978 (5%)]\tLoss: 0.838603\n",
            "Train Epoch: 0 [220/3978 (6%)]\tLoss: 0.006035\n",
            "Train Epoch: 0 [225/3978 (6%)]\tLoss: 0.052944\n",
            "Train Epoch: 0 [230/3978 (6%)]\tLoss: 1.407568\n",
            "Train Epoch: 0 [235/3978 (6%)]\tLoss: 1.104519\n",
            "Train Epoch: 0 [240/3978 (6%)]\tLoss: 0.112267\n",
            "Train Epoch: 0 [245/3978 (6%)]\tLoss: 0.192809\n",
            "Train Epoch: 0 [250/3978 (6%)]\tLoss: 0.049314\n",
            "Train Epoch: 0 [255/3978 (6%)]\tLoss: 0.262797\n",
            "Train Epoch: 0 [260/3978 (7%)]\tLoss: 0.906375\n",
            "Train Epoch: 0 [265/3978 (7%)]\tLoss: 1.116742\n",
            "Train Epoch: 0 [270/3978 (7%)]\tLoss: 0.569877\n",
            "Train Epoch: 0 [275/3978 (7%)]\tLoss: 0.189241\n",
            "Train Epoch: 0 [280/3978 (7%)]\tLoss: 0.372978\n",
            "Train Epoch: 0 [285/3978 (7%)]\tLoss: 0.071369\n",
            "Train Epoch: 0 [290/3978 (7%)]\tLoss: 0.609906\n",
            "Train Epoch: 0 [295/3978 (7%)]\tLoss: 0.309258\n",
            "Train Epoch: 0 [300/3978 (8%)]\tLoss: 0.261585\n",
            "Train Epoch: 0 [305/3978 (8%)]\tLoss: 0.311813\n",
            "Train Epoch: 0 [310/3978 (8%)]\tLoss: 0.333882\n",
            "Train Epoch: 0 [315/3978 (8%)]\tLoss: 0.064564\n",
            "Train Epoch: 0 [320/3978 (8%)]\tLoss: 0.068762\n",
            "Train Epoch: 0 [325/3978 (8%)]\tLoss: 0.028959\n",
            "Train Epoch: 0 [330/3978 (8%)]\tLoss: 0.130197\n",
            "Train Epoch: 0 [335/3978 (8%)]\tLoss: 0.893783\n",
            "Train Epoch: 0 [340/3978 (9%)]\tLoss: 0.982025\n",
            "Train Epoch: 0 [345/3978 (9%)]\tLoss: 0.071936\n",
            "Train Epoch: 0 [350/3978 (9%)]\tLoss: 0.125972\n",
            "Train Epoch: 0 [355/3978 (9%)]\tLoss: 0.375681\n",
            "Train Epoch: 0 [360/3978 (9%)]\tLoss: 0.591588\n",
            "Train Epoch: 0 [365/3978 (9%)]\tLoss: 0.661783\n",
            "Train Epoch: 0 [370/3978 (9%)]\tLoss: 0.014111\n",
            "Train Epoch: 0 [375/3978 (9%)]\tLoss: 0.096016\n",
            "Train Epoch: 0 [380/3978 (10%)]\tLoss: 0.787543\n",
            "Train Epoch: 0 [385/3978 (10%)]\tLoss: 0.341046\n",
            "Train Epoch: 0 [390/3978 (10%)]\tLoss: 0.136283\n",
            "Train Epoch: 0 [395/3978 (10%)]\tLoss: 0.341064\n",
            "Train Epoch: 0 [400/3978 (10%)]\tLoss: 0.211790\n",
            "Train Epoch: 0 [405/3978 (10%)]\tLoss: 0.375254\n",
            "Train Epoch: 0 [410/3978 (10%)]\tLoss: 0.172658\n",
            "Train Epoch: 0 [415/3978 (10%)]\tLoss: 0.318196\n",
            "Train Epoch: 0 [420/3978 (11%)]\tLoss: 0.481327\n",
            "Train Epoch: 0 [425/3978 (11%)]\tLoss: 0.832228\n",
            "Train Epoch: 0 [430/3978 (11%)]\tLoss: 0.399197\n",
            "Train Epoch: 0 [435/3978 (11%)]\tLoss: 0.061897\n",
            "Train Epoch: 0 [440/3978 (11%)]\tLoss: 1.025434\n",
            "Train Epoch: 0 [445/3978 (11%)]\tLoss: 0.316806\n",
            "Train Epoch: 0 [450/3978 (11%)]\tLoss: 0.271249\n",
            "Train Epoch: 0 [455/3978 (11%)]\tLoss: 0.339318\n",
            "Train Epoch: 0 [460/3978 (12%)]\tLoss: 0.267844\n",
            "Train Epoch: 0 [465/3978 (12%)]\tLoss: 0.467919\n",
            "Train Epoch: 0 [470/3978 (12%)]\tLoss: 1.136834\n",
            "Train Epoch: 0 [475/3978 (12%)]\tLoss: 1.170246\n",
            "Train Epoch: 0 [480/3978 (12%)]\tLoss: 0.778000\n",
            "Train Epoch: 0 [485/3978 (12%)]\tLoss: 0.674369\n",
            "Train Epoch: 0 [490/3978 (12%)]\tLoss: 0.589528\n",
            "Train Epoch: 0 [495/3978 (12%)]\tLoss: 0.887112\n",
            "Train Epoch: 0 [500/3978 (13%)]\tLoss: 0.660227\n",
            "Train Epoch: 0 [505/3978 (13%)]\tLoss: 0.397446\n",
            "Train Epoch: 0 [510/3978 (13%)]\tLoss: 0.672676\n",
            "Train Epoch: 0 [515/3978 (13%)]\tLoss: 0.240953\n",
            "Train Epoch: 0 [520/3978 (13%)]\tLoss: 0.258421\n",
            "Train Epoch: 0 [525/3978 (13%)]\tLoss: 0.147828\n",
            "Train Epoch: 0 [530/3978 (13%)]\tLoss: 0.641101\n",
            "Train Epoch: 0 [535/3978 (13%)]\tLoss: 0.030714\n",
            "Train Epoch: 0 [540/3978 (14%)]\tLoss: 0.898402\n",
            "Train Epoch: 0 [545/3978 (14%)]\tLoss: 0.253500\n",
            "Train Epoch: 0 [550/3978 (14%)]\tLoss: 0.470504\n",
            "Train Epoch: 0 [555/3978 (14%)]\tLoss: 0.097337\n",
            "Train Epoch: 0 [560/3978 (14%)]\tLoss: 0.334180\n",
            "Train Epoch: 0 [565/3978 (14%)]\tLoss: 0.861316\n",
            "Train Epoch: 0 [570/3978 (14%)]\tLoss: 0.806173\n",
            "Train Epoch: 0 [575/3978 (14%)]\tLoss: 0.761080\n",
            "Train Epoch: 0 [580/3978 (15%)]\tLoss: 0.127744\n",
            "Train Epoch: 0 [585/3978 (15%)]\tLoss: 0.083780\n",
            "Train Epoch: 0 [590/3978 (15%)]\tLoss: 0.092635\n",
            "Train Epoch: 0 [595/3978 (15%)]\tLoss: 0.113218\n",
            "Train Epoch: 0 [600/3978 (15%)]\tLoss: 0.048137\n",
            "Train Epoch: 0 [605/3978 (15%)]\tLoss: 0.065244\n",
            "Train Epoch: 0 [610/3978 (15%)]\tLoss: 0.284497\n",
            "Train Epoch: 0 [615/3978 (15%)]\tLoss: 0.565620\n",
            "Train Epoch: 0 [620/3978 (16%)]\tLoss: 0.242092\n",
            "Train Epoch: 0 [625/3978 (16%)]\tLoss: 1.039140\n",
            "Train Epoch: 0 [630/3978 (16%)]\tLoss: 0.643126\n",
            "Train Epoch: 0 [635/3978 (16%)]\tLoss: 0.273833\n",
            "Train Epoch: 0 [640/3978 (16%)]\tLoss: 1.211130\n",
            "Train Epoch: 0 [645/3978 (16%)]\tLoss: 0.080056\n",
            "Train Epoch: 0 [650/3978 (16%)]\tLoss: 0.803223\n",
            "Train Epoch: 0 [655/3978 (16%)]\tLoss: 1.429469\n",
            "Train Epoch: 0 [660/3978 (17%)]\tLoss: 0.413998\n",
            "Train Epoch: 0 [665/3978 (17%)]\tLoss: 0.774594\n",
            "Train Epoch: 0 [670/3978 (17%)]\tLoss: 0.231450\n",
            "Train Epoch: 0 [675/3978 (17%)]\tLoss: 0.577405\n",
            "Train Epoch: 0 [680/3978 (17%)]\tLoss: 0.610998\n",
            "Train Epoch: 0 [685/3978 (17%)]\tLoss: 1.013094\n",
            "Train Epoch: 0 [690/3978 (17%)]\tLoss: 0.384762\n",
            "Train Epoch: 0 [695/3978 (17%)]\tLoss: 0.379323\n",
            "Train Epoch: 0 [700/3978 (18%)]\tLoss: 0.174764\n",
            "Train Epoch: 0 [705/3978 (18%)]\tLoss: 0.139305\n",
            "Train Epoch: 0 [710/3978 (18%)]\tLoss: 0.669127\n",
            "Train Epoch: 0 [715/3978 (18%)]\tLoss: 0.077936\n",
            "Train Epoch: 0 [720/3978 (18%)]\tLoss: 0.170750\n",
            "Train Epoch: 0 [725/3978 (18%)]\tLoss: 0.163004\n",
            "Train Epoch: 0 [730/3978 (18%)]\tLoss: 0.704262\n",
            "Train Epoch: 0 [735/3978 (18%)]\tLoss: 0.066413\n",
            "Train Epoch: 0 [740/3978 (19%)]\tLoss: 1.001716\n",
            "Train Epoch: 0 [745/3978 (19%)]\tLoss: 1.118438\n",
            "Train Epoch: 0 [750/3978 (19%)]\tLoss: 1.228421\n",
            "Train Epoch: 0 [755/3978 (19%)]\tLoss: 0.580290\n",
            "Train Epoch: 0 [760/3978 (19%)]\tLoss: 1.185828\n",
            "Train Epoch: 0 [765/3978 (19%)]\tLoss: 0.127186\n",
            "Train Epoch: 0 [770/3978 (19%)]\tLoss: 1.069013\n",
            "Train Epoch: 0 [775/3978 (19%)]\tLoss: 0.622597\n",
            "Train Epoch: 0 [780/3978 (20%)]\tLoss: 0.888130\n",
            "Train Epoch: 0 [785/3978 (20%)]\tLoss: 1.022428\n",
            "Train Epoch: 0 [790/3978 (20%)]\tLoss: 0.334762\n",
            "Train Epoch: 0 [795/3978 (20%)]\tLoss: 0.074065\n",
            "Train Epoch: 0 [800/3978 (20%)]\tLoss: 1.121017\n",
            "Train Epoch: 0 [805/3978 (20%)]\tLoss: 0.552200\n",
            "Train Epoch: 0 [810/3978 (20%)]\tLoss: 0.690607\n",
            "Train Epoch: 0 [815/3978 (20%)]\tLoss: 0.497508\n",
            "Train Epoch: 0 [820/3978 (21%)]\tLoss: 0.555331\n",
            "Train Epoch: 0 [825/3978 (21%)]\tLoss: 0.182805\n",
            "Train Epoch: 0 [830/3978 (21%)]\tLoss: 0.309335\n",
            "Train Epoch: 0 [835/3978 (21%)]\tLoss: 0.093636\n",
            "Train Epoch: 0 [840/3978 (21%)]\tLoss: 1.547743\n",
            "Train Epoch: 0 [845/3978 (21%)]\tLoss: 0.044685\n",
            "Train Epoch: 0 [850/3978 (21%)]\tLoss: 0.319815\n",
            "Train Epoch: 0 [855/3978 (21%)]\tLoss: 0.687645\n",
            "Train Epoch: 0 [860/3978 (22%)]\tLoss: 0.484547\n",
            "Train Epoch: 0 [865/3978 (22%)]\tLoss: 0.414504\n",
            "Train Epoch: 0 [870/3978 (22%)]\tLoss: 1.589367\n",
            "Train Epoch: 0 [875/3978 (22%)]\tLoss: 0.580980\n",
            "Train Epoch: 0 [880/3978 (22%)]\tLoss: 0.367467\n",
            "Train Epoch: 0 [885/3978 (22%)]\tLoss: 0.437737\n",
            "Train Epoch: 0 [890/3978 (22%)]\tLoss: 0.199544\n",
            "Train Epoch: 0 [895/3978 (22%)]\tLoss: 0.086450\n",
            "Train Epoch: 0 [900/3978 (23%)]\tLoss: 1.608215\n",
            "Train Epoch: 0 [905/3978 (23%)]\tLoss: 0.627528\n",
            "Train Epoch: 0 [910/3978 (23%)]\tLoss: 0.207036\n",
            "Train Epoch: 0 [915/3978 (23%)]\tLoss: 0.391968\n",
            "Train Epoch: 0 [920/3978 (23%)]\tLoss: 0.397569\n",
            "Train Epoch: 0 [925/3978 (23%)]\tLoss: 0.881156\n",
            "Train Epoch: 0 [930/3978 (23%)]\tLoss: 0.355370\n",
            "Train Epoch: 0 [935/3978 (23%)]\tLoss: 0.528275\n",
            "Train Epoch: 0 [940/3978 (24%)]\tLoss: 0.473633\n",
            "Train Epoch: 0 [945/3978 (24%)]\tLoss: 0.158960\n",
            "Train Epoch: 0 [950/3978 (24%)]\tLoss: 0.401870\n",
            "Train Epoch: 0 [955/3978 (24%)]\tLoss: 1.328604\n",
            "Train Epoch: 0 [960/3978 (24%)]\tLoss: 0.086029\n",
            "Train Epoch: 0 [965/3978 (24%)]\tLoss: 0.899532\n",
            "Train Epoch: 0 [970/3978 (24%)]\tLoss: 0.722455\n",
            "Train Epoch: 0 [975/3978 (24%)]\tLoss: 0.356763\n",
            "Train Epoch: 0 [980/3978 (25%)]\tLoss: 0.185450\n",
            "Train Epoch: 0 [985/3978 (25%)]\tLoss: 0.131254\n",
            "Train Epoch: 0 [990/3978 (25%)]\tLoss: 0.386645\n",
            "Train Epoch: 0 [995/3978 (25%)]\tLoss: 0.081233\n",
            "Train Epoch: 0 [1000/3978 (25%)]\tLoss: 0.538246\n",
            "Train Epoch: 0 [1005/3978 (25%)]\tLoss: 0.655168\n",
            "Train Epoch: 0 [1010/3978 (25%)]\tLoss: 0.188307\n",
            "Train Epoch: 0 [1015/3978 (26%)]\tLoss: 0.306636\n",
            "Train Epoch: 0 [1020/3978 (26%)]\tLoss: 0.472742\n",
            "Train Epoch: 0 [1025/3978 (26%)]\tLoss: 0.170995\n",
            "Train Epoch: 0 [1030/3978 (26%)]\tLoss: 0.197674\n",
            "Train Epoch: 0 [1035/3978 (26%)]\tLoss: 0.335023\n",
            "Train Epoch: 0 [1040/3978 (26%)]\tLoss: 0.091967\n",
            "Train Epoch: 0 [1045/3978 (26%)]\tLoss: 0.302792\n",
            "Train Epoch: 0 [1050/3978 (26%)]\tLoss: 0.996535\n",
            "Train Epoch: 0 [1055/3978 (27%)]\tLoss: 0.789388\n",
            "Train Epoch: 0 [1060/3978 (27%)]\tLoss: 0.319213\n",
            "Train Epoch: 0 [1065/3978 (27%)]\tLoss: 0.079796\n",
            "Train Epoch: 0 [1070/3978 (27%)]\tLoss: 0.812831\n",
            "Train Epoch: 0 [1075/3978 (27%)]\tLoss: 0.134048\n",
            "Train Epoch: 0 [1080/3978 (27%)]\tLoss: 0.438015\n",
            "Train Epoch: 0 [1085/3978 (27%)]\tLoss: 0.868024\n",
            "Train Epoch: 0 [1090/3978 (27%)]\tLoss: 0.287629\n",
            "Train Epoch: 0 [1095/3978 (28%)]\tLoss: 0.196133\n",
            "Train Epoch: 0 [1100/3978 (28%)]\tLoss: 0.472666\n",
            "Train Epoch: 0 [1105/3978 (28%)]\tLoss: 0.386031\n",
            "Train Epoch: 0 [1110/3978 (28%)]\tLoss: 0.160453\n",
            "Train Epoch: 0 [1115/3978 (28%)]\tLoss: 0.339561\n",
            "Train Epoch: 0 [1120/3978 (28%)]\tLoss: 0.334716\n",
            "Train Epoch: 0 [1125/3978 (28%)]\tLoss: 0.170051\n",
            "Train Epoch: 0 [1130/3978 (28%)]\tLoss: 0.153678\n",
            "Train Epoch: 0 [1135/3978 (29%)]\tLoss: 0.260898\n",
            "Train Epoch: 0 [1140/3978 (29%)]\tLoss: 0.253279\n",
            "Train Epoch: 0 [1145/3978 (29%)]\tLoss: 1.739985\n",
            "Train Epoch: 0 [1150/3978 (29%)]\tLoss: 0.150452\n",
            "Train Epoch: 0 [1155/3978 (29%)]\tLoss: 0.325702\n",
            "Train Epoch: 0 [1160/3978 (29%)]\tLoss: 0.937131\n",
            "Train Epoch: 0 [1165/3978 (29%)]\tLoss: 0.397458\n",
            "Train Epoch: 0 [1170/3978 (29%)]\tLoss: 0.316454\n",
            "Train Epoch: 0 [1175/3978 (30%)]\tLoss: 0.142279\n",
            "Train Epoch: 0 [1180/3978 (30%)]\tLoss: 0.503620\n",
            "Train Epoch: 0 [1185/3978 (30%)]\tLoss: 0.416124\n",
            "Train Epoch: 0 [1190/3978 (30%)]\tLoss: 0.812368\n",
            "Train Epoch: 0 [1195/3978 (30%)]\tLoss: 0.733244\n",
            "Train Epoch: 0 [1200/3978 (30%)]\tLoss: 0.601061\n",
            "Train Epoch: 0 [1205/3978 (30%)]\tLoss: 0.351251\n",
            "Train Epoch: 0 [1210/3978 (30%)]\tLoss: 0.477086\n",
            "Train Epoch: 0 [1215/3978 (31%)]\tLoss: 0.327211\n",
            "Train Epoch: 0 [1220/3978 (31%)]\tLoss: 0.138720\n",
            "Train Epoch: 0 [1225/3978 (31%)]\tLoss: 0.234738\n",
            "Train Epoch: 0 [1230/3978 (31%)]\tLoss: 0.194811\n",
            "Train Epoch: 0 [1235/3978 (31%)]\tLoss: 0.312855\n",
            "Train Epoch: 0 [1240/3978 (31%)]\tLoss: 1.224858\n",
            "Train Epoch: 0 [1245/3978 (31%)]\tLoss: 0.381244\n",
            "Train Epoch: 0 [1250/3978 (31%)]\tLoss: 0.404098\n",
            "Train Epoch: 0 [1255/3978 (32%)]\tLoss: 0.539705\n",
            "Train Epoch: 0 [1260/3978 (32%)]\tLoss: 0.481299\n",
            "Train Epoch: 0 [1265/3978 (32%)]\tLoss: 1.270763\n",
            "Train Epoch: 0 [1270/3978 (32%)]\tLoss: 0.196201\n",
            "Train Epoch: 0 [1275/3978 (32%)]\tLoss: 0.170518\n",
            "Train Epoch: 0 [1280/3978 (32%)]\tLoss: 1.396467\n",
            "Train Epoch: 0 [1285/3978 (32%)]\tLoss: 0.311325\n",
            "Train Epoch: 0 [1290/3978 (32%)]\tLoss: 0.552507\n",
            "Train Epoch: 0 [1295/3978 (33%)]\tLoss: 1.019798\n",
            "Train Epoch: 0 [1300/3978 (33%)]\tLoss: 0.427114\n",
            "Train Epoch: 0 [1305/3978 (33%)]\tLoss: 0.171070\n",
            "Train Epoch: 0 [1310/3978 (33%)]\tLoss: 0.435839\n",
            "Train Epoch: 0 [1315/3978 (33%)]\tLoss: 0.396930\n",
            "Train Epoch: 0 [1320/3978 (33%)]\tLoss: 0.234029\n",
            "Train Epoch: 0 [1325/3978 (33%)]\tLoss: 0.136087\n",
            "Train Epoch: 0 [1330/3978 (33%)]\tLoss: 0.176899\n",
            "Train Epoch: 0 [1335/3978 (34%)]\tLoss: 0.128467\n",
            "Train Epoch: 0 [1340/3978 (34%)]\tLoss: 1.089806\n",
            "Train Epoch: 0 [1345/3978 (34%)]\tLoss: 1.076376\n",
            "Train Epoch: 0 [1350/3978 (34%)]\tLoss: 0.205124\n",
            "Train Epoch: 0 [1355/3978 (34%)]\tLoss: 0.061119\n",
            "Train Epoch: 0 [1360/3978 (34%)]\tLoss: 0.012831\n",
            "Train Epoch: 0 [1365/3978 (34%)]\tLoss: 0.215773\n",
            "Train Epoch: 0 [1370/3978 (34%)]\tLoss: 0.689403\n",
            "Train Epoch: 0 [1375/3978 (35%)]\tLoss: 0.077074\n",
            "Train Epoch: 0 [1380/3978 (35%)]\tLoss: 1.233554\n",
            "Train Epoch: 0 [1385/3978 (35%)]\tLoss: 0.296529\n",
            "Train Epoch: 0 [1390/3978 (35%)]\tLoss: 0.363934\n",
            "Train Epoch: 0 [1395/3978 (35%)]\tLoss: 0.037324\n",
            "Train Epoch: 0 [1400/3978 (35%)]\tLoss: 0.169849\n",
            "Train Epoch: 0 [1405/3978 (35%)]\tLoss: 0.168610\n",
            "Train Epoch: 0 [1410/3978 (35%)]\tLoss: 0.746036\n",
            "Train Epoch: 0 [1415/3978 (36%)]\tLoss: 0.410246\n",
            "Train Epoch: 0 [1420/3978 (36%)]\tLoss: 0.336470\n",
            "Train Epoch: 0 [1425/3978 (36%)]\tLoss: 0.924245\n",
            "Train Epoch: 0 [1430/3978 (36%)]\tLoss: 0.163836\n",
            "Train Epoch: 0 [1435/3978 (36%)]\tLoss: 0.816312\n",
            "Train Epoch: 0 [1440/3978 (36%)]\tLoss: 2.421916\n",
            "Train Epoch: 0 [1445/3978 (36%)]\tLoss: 0.315791\n",
            "Train Epoch: 0 [1450/3978 (36%)]\tLoss: 0.351464\n",
            "Train Epoch: 0 [1455/3978 (37%)]\tLoss: 0.744507\n",
            "Train Epoch: 0 [1460/3978 (37%)]\tLoss: 0.848781\n",
            "Train Epoch: 0 [1465/3978 (37%)]\tLoss: 0.420378\n",
            "Train Epoch: 0 [1470/3978 (37%)]\tLoss: 0.354990\n",
            "Train Epoch: 0 [1475/3978 (37%)]\tLoss: 0.248853\n",
            "Train Epoch: 0 [1480/3978 (37%)]\tLoss: 0.312828\n",
            "Train Epoch: 0 [1485/3978 (37%)]\tLoss: 1.126111\n",
            "Train Epoch: 0 [1490/3978 (37%)]\tLoss: 0.808971\n",
            "Train Epoch: 0 [1495/3978 (38%)]\tLoss: 0.002964\n",
            "Train Epoch: 0 [1500/3978 (38%)]\tLoss: 0.817379\n",
            "Train Epoch: 0 [1505/3978 (38%)]\tLoss: 1.211452\n",
            "Train Epoch: 0 [1510/3978 (38%)]\tLoss: 0.775063\n",
            "Train Epoch: 0 [1515/3978 (38%)]\tLoss: 0.247781\n",
            "Train Epoch: 0 [1520/3978 (38%)]\tLoss: 1.325646\n",
            "Train Epoch: 0 [1525/3978 (38%)]\tLoss: 0.432935\n",
            "Train Epoch: 0 [1530/3978 (38%)]\tLoss: 0.675985\n",
            "Train Epoch: 0 [1535/3978 (39%)]\tLoss: 0.405695\n",
            "Train Epoch: 0 [1540/3978 (39%)]\tLoss: 0.270108\n",
            "Train Epoch: 0 [1545/3978 (39%)]\tLoss: 0.156226\n",
            "Train Epoch: 0 [1550/3978 (39%)]\tLoss: 0.969909\n",
            "Train Epoch: 0 [1555/3978 (39%)]\tLoss: 0.837379\n",
            "Train Epoch: 0 [1560/3978 (39%)]\tLoss: 0.094907\n",
            "Train Epoch: 0 [1565/3978 (39%)]\tLoss: 0.077359\n",
            "Train Epoch: 0 [1570/3978 (39%)]\tLoss: 0.355413\n",
            "Train Epoch: 0 [1575/3978 (40%)]\tLoss: 0.087863\n",
            "Train Epoch: 0 [1580/3978 (40%)]\tLoss: 0.193575\n",
            "Train Epoch: 0 [1585/3978 (40%)]\tLoss: 1.214922\n",
            "Train Epoch: 0 [1590/3978 (40%)]\tLoss: 0.971383\n",
            "Train Epoch: 0 [1595/3978 (40%)]\tLoss: 0.149872\n",
            "Train Epoch: 0 [1600/3978 (40%)]\tLoss: 0.218428\n",
            "Train Epoch: 0 [1605/3978 (40%)]\tLoss: 0.672580\n",
            "Train Epoch: 0 [1610/3978 (40%)]\tLoss: 0.820556\n",
            "Train Epoch: 0 [1615/3978 (41%)]\tLoss: 0.355197\n",
            "Train Epoch: 0 [1620/3978 (41%)]\tLoss: 0.471324\n",
            "Train Epoch: 0 [1625/3978 (41%)]\tLoss: 1.327661\n",
            "Train Epoch: 0 [1630/3978 (41%)]\tLoss: 0.264538\n",
            "Train Epoch: 0 [1635/3978 (41%)]\tLoss: 0.027407\n",
            "Train Epoch: 0 [1640/3978 (41%)]\tLoss: 0.961143\n",
            "Train Epoch: 0 [1645/3978 (41%)]\tLoss: 1.205078\n",
            "Train Epoch: 0 [1650/3978 (41%)]\tLoss: 0.086133\n",
            "Train Epoch: 0 [1655/3978 (42%)]\tLoss: 0.213533\n",
            "Train Epoch: 0 [1660/3978 (42%)]\tLoss: 0.603741\n",
            "Train Epoch: 0 [1665/3978 (42%)]\tLoss: 0.099387\n",
            "Train Epoch: 0 [1670/3978 (42%)]\tLoss: 0.108980\n",
            "Train Epoch: 0 [1675/3978 (42%)]\tLoss: 1.027347\n",
            "Train Epoch: 0 [1680/3978 (42%)]\tLoss: 0.610396\n",
            "Train Epoch: 0 [1685/3978 (42%)]\tLoss: 0.680168\n",
            "Train Epoch: 0 [1690/3978 (42%)]\tLoss: 0.112027\n",
            "Train Epoch: 0 [1695/3978 (43%)]\tLoss: 0.206165\n",
            "Train Epoch: 0 [1700/3978 (43%)]\tLoss: 0.078636\n",
            "Train Epoch: 0 [1705/3978 (43%)]\tLoss: 0.082653\n",
            "Train Epoch: 0 [1710/3978 (43%)]\tLoss: 0.110346\n",
            "Train Epoch: 0 [1715/3978 (43%)]\tLoss: 0.264996\n",
            "Train Epoch: 0 [1720/3978 (43%)]\tLoss: 1.117182\n",
            "Train Epoch: 0 [1725/3978 (43%)]\tLoss: 0.642478\n",
            "Train Epoch: 0 [1730/3978 (43%)]\tLoss: 0.395165\n",
            "Train Epoch: 0 [1735/3978 (44%)]\tLoss: 0.575185\n",
            "Train Epoch: 0 [1740/3978 (44%)]\tLoss: 0.279687\n",
            "Train Epoch: 0 [1745/3978 (44%)]\tLoss: 1.160779\n",
            "Train Epoch: 0 [1750/3978 (44%)]\tLoss: 0.349339\n",
            "Train Epoch: 0 [1755/3978 (44%)]\tLoss: 0.234439\n",
            "Train Epoch: 0 [1760/3978 (44%)]\tLoss: 0.624426\n",
            "Train Epoch: 0 [1765/3978 (44%)]\tLoss: 0.357706\n",
            "Train Epoch: 0 [1770/3978 (44%)]\tLoss: 0.236340\n",
            "Train Epoch: 0 [1775/3978 (45%)]\tLoss: 0.553117\n",
            "Train Epoch: 0 [1780/3978 (45%)]\tLoss: 0.812939\n",
            "Train Epoch: 0 [1785/3978 (45%)]\tLoss: 0.140003\n",
            "Train Epoch: 0 [1790/3978 (45%)]\tLoss: 0.127984\n",
            "Train Epoch: 0 [1795/3978 (45%)]\tLoss: 0.059280\n",
            "Train Epoch: 0 [1800/3978 (45%)]\tLoss: 0.364802\n",
            "Train Epoch: 0 [1805/3978 (45%)]\tLoss: 1.276304\n",
            "Train Epoch: 0 [1810/3978 (45%)]\tLoss: 0.041039\n",
            "Train Epoch: 0 [1815/3978 (46%)]\tLoss: 0.526426\n",
            "Train Epoch: 0 [1820/3978 (46%)]\tLoss: 0.269180\n",
            "Train Epoch: 0 [1825/3978 (46%)]\tLoss: 0.053674\n",
            "Train Epoch: 0 [1830/3978 (46%)]\tLoss: 0.987913\n",
            "Train Epoch: 0 [1835/3978 (46%)]\tLoss: 0.405087\n",
            "Train Epoch: 0 [1840/3978 (46%)]\tLoss: 1.113144\n",
            "Train Epoch: 0 [1845/3978 (46%)]\tLoss: 0.166043\n",
            "Train Epoch: 0 [1850/3978 (46%)]\tLoss: 0.232952\n",
            "Train Epoch: 0 [1855/3978 (47%)]\tLoss: 0.380826\n",
            "Train Epoch: 0 [1860/3978 (47%)]\tLoss: 1.193719\n",
            "Train Epoch: 0 [1865/3978 (47%)]\tLoss: 0.759293\n",
            "Train Epoch: 0 [1870/3978 (47%)]\tLoss: 0.144344\n",
            "Train Epoch: 0 [1875/3978 (47%)]\tLoss: 0.213081\n",
            "Train Epoch: 0 [1880/3978 (47%)]\tLoss: 0.244245\n",
            "Train Epoch: 0 [1885/3978 (47%)]\tLoss: 0.229446\n",
            "Train Epoch: 0 [1890/3978 (47%)]\tLoss: 0.139270\n",
            "Train Epoch: 0 [1895/3978 (48%)]\tLoss: 0.524929\n",
            "Train Epoch: 0 [1900/3978 (48%)]\tLoss: 0.100710\n",
            "Train Epoch: 0 [1905/3978 (48%)]\tLoss: 0.512640\n",
            "Train Epoch: 0 [1910/3978 (48%)]\tLoss: 0.615405\n",
            "Train Epoch: 0 [1915/3978 (48%)]\tLoss: 0.140050\n",
            "Train Epoch: 0 [1920/3978 (48%)]\tLoss: 0.179342\n",
            "Train Epoch: 0 [1925/3978 (48%)]\tLoss: 0.198158\n",
            "Train Epoch: 0 [1930/3978 (48%)]\tLoss: 0.213104\n",
            "Train Epoch: 0 [1935/3978 (49%)]\tLoss: 0.300137\n",
            "Train Epoch: 0 [1940/3978 (49%)]\tLoss: 0.516943\n",
            "Train Epoch: 0 [1945/3978 (49%)]\tLoss: 1.092958\n",
            "Train Epoch: 0 [1950/3978 (49%)]\tLoss: 1.109320\n",
            "Train Epoch: 0 [1955/3978 (49%)]\tLoss: 0.581395\n",
            "Train Epoch: 0 [1960/3978 (49%)]\tLoss: 0.291144\n",
            "Train Epoch: 0 [1965/3978 (49%)]\tLoss: 0.498601\n",
            "Train Epoch: 0 [1970/3978 (49%)]\tLoss: 0.391641\n",
            "Train Epoch: 0 [1975/3978 (50%)]\tLoss: 0.233238\n",
            "Train Epoch: 0 [1980/3978 (50%)]\tLoss: 0.323735\n",
            "Train Epoch: 0 [1985/3978 (50%)]\tLoss: 0.319557\n",
            "Train Epoch: 0 [1990/3978 (50%)]\tLoss: 0.061743\n",
            "Train Epoch: 0 [1995/3978 (50%)]\tLoss: 0.421709\n",
            "Train Epoch: 0 [2000/3978 (50%)]\tLoss: 0.725671\n",
            "Train Epoch: 0 [2005/3978 (50%)]\tLoss: 1.008790\n",
            "Train Epoch: 0 [2010/3978 (51%)]\tLoss: 0.714074\n",
            "Train Epoch: 0 [2015/3978 (51%)]\tLoss: 0.273821\n",
            "Train Epoch: 0 [2020/3978 (51%)]\tLoss: 0.216623\n",
            "Train Epoch: 0 [2025/3978 (51%)]\tLoss: 0.218549\n",
            "Train Epoch: 0 [2030/3978 (51%)]\tLoss: 0.147269\n",
            "Train Epoch: 0 [2035/3978 (51%)]\tLoss: 0.079626\n",
            "Train Epoch: 0 [2040/3978 (51%)]\tLoss: 0.510662\n",
            "Train Epoch: 0 [2045/3978 (51%)]\tLoss: 0.483249\n",
            "Train Epoch: 0 [2050/3978 (52%)]\tLoss: 0.354040\n",
            "Train Epoch: 0 [2055/3978 (52%)]\tLoss: 0.133400\n",
            "Train Epoch: 0 [2060/3978 (52%)]\tLoss: 0.270684\n",
            "Train Epoch: 0 [2065/3978 (52%)]\tLoss: 0.964685\n",
            "Train Epoch: 0 [2070/3978 (52%)]\tLoss: 1.329428\n",
            "Train Epoch: 0 [2075/3978 (52%)]\tLoss: 0.837010\n",
            "Train Epoch: 0 [2080/3978 (52%)]\tLoss: 0.192933\n",
            "Train Epoch: 0 [2085/3978 (52%)]\tLoss: 0.635391\n",
            "Train Epoch: 0 [2090/3978 (53%)]\tLoss: 0.368648\n",
            "Train Epoch: 0 [2095/3978 (53%)]\tLoss: 0.913524\n",
            "Train Epoch: 0 [2100/3978 (53%)]\tLoss: 0.513880\n",
            "Train Epoch: 0 [2105/3978 (53%)]\tLoss: 0.304343\n",
            "Train Epoch: 0 [2110/3978 (53%)]\tLoss: 0.258738\n",
            "Train Epoch: 0 [2115/3978 (53%)]\tLoss: 0.153793\n",
            "Train Epoch: 0 [2120/3978 (53%)]\tLoss: 0.339663\n",
            "Train Epoch: 0 [2125/3978 (53%)]\tLoss: 0.581229\n",
            "Train Epoch: 0 [2130/3978 (54%)]\tLoss: 0.318457\n",
            "Train Epoch: 0 [2135/3978 (54%)]\tLoss: 0.309472\n",
            "Train Epoch: 0 [2140/3978 (54%)]\tLoss: 0.813293\n",
            "Train Epoch: 0 [2145/3978 (54%)]\tLoss: 0.453013\n",
            "Train Epoch: 0 [2150/3978 (54%)]\tLoss: 0.853320\n",
            "Train Epoch: 0 [2155/3978 (54%)]\tLoss: 0.024600\n",
            "Train Epoch: 0 [2160/3978 (54%)]\tLoss: 0.494945\n",
            "Train Epoch: 0 [2165/3978 (54%)]\tLoss: 0.455086\n",
            "Train Epoch: 0 [2170/3978 (55%)]\tLoss: 1.071061\n",
            "Train Epoch: 0 [2175/3978 (55%)]\tLoss: 0.087960\n",
            "Train Epoch: 0 [2180/3978 (55%)]\tLoss: 0.345584\n",
            "Train Epoch: 0 [2185/3978 (55%)]\tLoss: 0.444894\n",
            "Train Epoch: 0 [2190/3978 (55%)]\tLoss: 1.148759\n",
            "Train Epoch: 0 [2195/3978 (55%)]\tLoss: 0.187294\n",
            "Train Epoch: 0 [2200/3978 (55%)]\tLoss: 0.263847\n",
            "Train Epoch: 0 [2205/3978 (55%)]\tLoss: 0.645286\n",
            "Train Epoch: 0 [2210/3978 (56%)]\tLoss: 0.755370\n",
            "Train Epoch: 0 [2215/3978 (56%)]\tLoss: 0.355661\n",
            "Train Epoch: 0 [2220/3978 (56%)]\tLoss: 0.607835\n",
            "Train Epoch: 0 [2225/3978 (56%)]\tLoss: 0.595116\n",
            "Train Epoch: 0 [2230/3978 (56%)]\tLoss: 0.217341\n",
            "Train Epoch: 0 [2235/3978 (56%)]\tLoss: 0.625423\n",
            "Train Epoch: 0 [2240/3978 (56%)]\tLoss: 0.307364\n",
            "Train Epoch: 0 [2245/3978 (56%)]\tLoss: 1.114517\n",
            "Train Epoch: 0 [2250/3978 (57%)]\tLoss: 0.417481\n",
            "Train Epoch: 0 [2255/3978 (57%)]\tLoss: 0.213363\n",
            "Train Epoch: 0 [2260/3978 (57%)]\tLoss: 0.369478\n",
            "Train Epoch: 0 [2265/3978 (57%)]\tLoss: 0.881362\n",
            "Train Epoch: 0 [2270/3978 (57%)]\tLoss: 0.184007\n",
            "Train Epoch: 0 [2275/3978 (57%)]\tLoss: 0.104113\n",
            "Train Epoch: 0 [2280/3978 (57%)]\tLoss: 0.036029\n",
            "Train Epoch: 0 [2285/3978 (57%)]\tLoss: 0.388892\n",
            "Train Epoch: 0 [2290/3978 (58%)]\tLoss: 0.439735\n",
            "Train Epoch: 0 [2295/3978 (58%)]\tLoss: 0.315531\n",
            "Train Epoch: 0 [2300/3978 (58%)]\tLoss: 0.068472\n",
            "Train Epoch: 0 [2305/3978 (58%)]\tLoss: 0.429781\n",
            "Train Epoch: 0 [2310/3978 (58%)]\tLoss: 0.072255\n",
            "Train Epoch: 0 [2315/3978 (58%)]\tLoss: 0.324994\n",
            "Train Epoch: 0 [2320/3978 (58%)]\tLoss: 0.102079\n",
            "Train Epoch: 0 [2325/3978 (58%)]\tLoss: 0.218360\n",
            "Train Epoch: 0 [2330/3978 (59%)]\tLoss: 0.098657\n",
            "Train Epoch: 0 [2335/3978 (59%)]\tLoss: 0.407621\n",
            "Train Epoch: 0 [2340/3978 (59%)]\tLoss: 0.216303\n",
            "Train Epoch: 0 [2345/3978 (59%)]\tLoss: 0.070546\n",
            "Train Epoch: 0 [2350/3978 (59%)]\tLoss: 0.355117\n",
            "Train Epoch: 0 [2355/3978 (59%)]\tLoss: 0.111239\n",
            "Train Epoch: 0 [2360/3978 (59%)]\tLoss: 1.968050\n",
            "Train Epoch: 0 [2365/3978 (59%)]\tLoss: 0.046688\n",
            "Train Epoch: 0 [2370/3978 (60%)]\tLoss: 0.205513\n",
            "Train Epoch: 0 [2375/3978 (60%)]\tLoss: 0.672149\n",
            "Train Epoch: 0 [2380/3978 (60%)]\tLoss: 0.161195\n",
            "Train Epoch: 0 [2385/3978 (60%)]\tLoss: 0.061960\n",
            "Train Epoch: 0 [2390/3978 (60%)]\tLoss: 0.262184\n",
            "Train Epoch: 0 [2395/3978 (60%)]\tLoss: 0.774429\n",
            "Train Epoch: 0 [2400/3978 (60%)]\tLoss: 0.354448\n",
            "Train Epoch: 0 [2405/3978 (60%)]\tLoss: 0.067679\n",
            "Train Epoch: 0 [2410/3978 (61%)]\tLoss: 0.282454\n",
            "Train Epoch: 0 [2415/3978 (61%)]\tLoss: 0.036069\n",
            "Train Epoch: 0 [2420/3978 (61%)]\tLoss: 0.619935\n",
            "Train Epoch: 0 [2425/3978 (61%)]\tLoss: 0.512082\n",
            "Train Epoch: 0 [2430/3978 (61%)]\tLoss: 0.005209\n",
            "Train Epoch: 0 [2435/3978 (61%)]\tLoss: 0.207766\n",
            "Train Epoch: 0 [2440/3978 (61%)]\tLoss: 0.525490\n",
            "Train Epoch: 0 [2445/3978 (61%)]\tLoss: 0.101997\n",
            "Train Epoch: 0 [2450/3978 (62%)]\tLoss: 0.377307\n",
            "Train Epoch: 0 [2455/3978 (62%)]\tLoss: 0.212695\n",
            "Train Epoch: 0 [2460/3978 (62%)]\tLoss: 0.338229\n",
            "Train Epoch: 0 [2465/3978 (62%)]\tLoss: 0.353054\n",
            "Train Epoch: 0 [2470/3978 (62%)]\tLoss: 0.154266\n",
            "Train Epoch: 0 [2475/3978 (62%)]\tLoss: 0.111723\n",
            "Train Epoch: 0 [2480/3978 (62%)]\tLoss: 0.032157\n",
            "Train Epoch: 0 [2485/3978 (62%)]\tLoss: 0.876527\n",
            "Train Epoch: 0 [2490/3978 (63%)]\tLoss: 0.487990\n",
            "Train Epoch: 0 [2495/3978 (63%)]\tLoss: 1.017924\n",
            "Train Epoch: 0 [2500/3978 (63%)]\tLoss: 0.125202\n",
            "Train Epoch: 0 [2505/3978 (63%)]\tLoss: 0.053925\n",
            "Train Epoch: 0 [2510/3978 (63%)]\tLoss: 0.413051\n",
            "Train Epoch: 0 [2515/3978 (63%)]\tLoss: 0.032938\n",
            "Train Epoch: 0 [2520/3978 (63%)]\tLoss: 0.638069\n",
            "Train Epoch: 0 [2525/3978 (63%)]\tLoss: 0.309589\n",
            "Train Epoch: 0 [2530/3978 (64%)]\tLoss: 0.913472\n",
            "Train Epoch: 0 [2535/3978 (64%)]\tLoss: 0.438081\n",
            "Train Epoch: 0 [2540/3978 (64%)]\tLoss: 0.129684\n",
            "Train Epoch: 0 [2545/3978 (64%)]\tLoss: 0.272437\n",
            "Train Epoch: 0 [2550/3978 (64%)]\tLoss: 0.049790\n",
            "Train Epoch: 0 [2555/3978 (64%)]\tLoss: 0.040746\n",
            "Train Epoch: 0 [2560/3978 (64%)]\tLoss: 0.027099\n",
            "Train Epoch: 0 [2565/3978 (64%)]\tLoss: 0.044392\n",
            "Train Epoch: 0 [2570/3978 (65%)]\tLoss: 0.099183\n",
            "Train Epoch: 0 [2575/3978 (65%)]\tLoss: 1.712939\n",
            "Train Epoch: 0 [2580/3978 (65%)]\tLoss: 0.249330\n",
            "Train Epoch: 0 [2585/3978 (65%)]\tLoss: 2.008594\n",
            "Train Epoch: 0 [2590/3978 (65%)]\tLoss: 0.328063\n",
            "Train Epoch: 0 [2595/3978 (65%)]\tLoss: 0.211173\n",
            "Train Epoch: 0 [2600/3978 (65%)]\tLoss: 0.207046\n",
            "Train Epoch: 0 [2605/3978 (65%)]\tLoss: 0.282038\n",
            "Train Epoch: 0 [2610/3978 (66%)]\tLoss: 0.328178\n",
            "Train Epoch: 0 [2615/3978 (66%)]\tLoss: 0.373563\n",
            "Train Epoch: 0 [2620/3978 (66%)]\tLoss: 0.884299\n",
            "Train Epoch: 0 [2625/3978 (66%)]\tLoss: 0.134933\n",
            "Train Epoch: 0 [2630/3978 (66%)]\tLoss: 0.044789\n",
            "Train Epoch: 0 [2635/3978 (66%)]\tLoss: 0.269854\n",
            "Train Epoch: 0 [2640/3978 (66%)]\tLoss: 0.238047\n",
            "Train Epoch: 0 [2645/3978 (66%)]\tLoss: 0.608551\n",
            "Train Epoch: 0 [2650/3978 (67%)]\tLoss: 0.714597\n",
            "Train Epoch: 0 [2655/3978 (67%)]\tLoss: 0.104520\n",
            "Train Epoch: 0 [2660/3978 (67%)]\tLoss: 0.108851\n",
            "Train Epoch: 0 [2665/3978 (67%)]\tLoss: 1.894666\n",
            "Train Epoch: 0 [2670/3978 (67%)]\tLoss: 0.637730\n",
            "Train Epoch: 0 [2675/3978 (67%)]\tLoss: 1.220125\n",
            "Train Epoch: 0 [2680/3978 (67%)]\tLoss: 0.041254\n",
            "Train Epoch: 0 [2685/3978 (67%)]\tLoss: 0.499091\n",
            "Train Epoch: 0 [2690/3978 (68%)]\tLoss: 0.295058\n",
            "Train Epoch: 0 [2695/3978 (68%)]\tLoss: 0.403687\n",
            "Train Epoch: 0 [2700/3978 (68%)]\tLoss: 0.225941\n",
            "Train Epoch: 0 [2705/3978 (68%)]\tLoss: 0.194228\n",
            "Train Epoch: 0 [2710/3978 (68%)]\tLoss: 0.604778\n",
            "Train Epoch: 0 [2715/3978 (68%)]\tLoss: 0.343695\n",
            "Train Epoch: 0 [2720/3978 (68%)]\tLoss: 1.052633\n",
            "Train Epoch: 0 [2725/3978 (68%)]\tLoss: 0.236473\n",
            "Train Epoch: 0 [2730/3978 (69%)]\tLoss: 0.053516\n",
            "Train Epoch: 0 [2735/3978 (69%)]\tLoss: 0.669506\n",
            "Train Epoch: 0 [2740/3978 (69%)]\tLoss: 0.603571\n",
            "Train Epoch: 0 [2745/3978 (69%)]\tLoss: 0.207440\n",
            "Train Epoch: 0 [2750/3978 (69%)]\tLoss: 0.194532\n",
            "Train Epoch: 0 [2755/3978 (69%)]\tLoss: 0.499127\n",
            "Train Epoch: 0 [2760/3978 (69%)]\tLoss: 0.232842\n",
            "Train Epoch: 0 [2765/3978 (69%)]\tLoss: 0.583232\n",
            "Train Epoch: 0 [2770/3978 (70%)]\tLoss: 0.392634\n",
            "Train Epoch: 0 [2775/3978 (70%)]\tLoss: 0.257243\n",
            "Train Epoch: 0 [2780/3978 (70%)]\tLoss: 0.853269\n",
            "Train Epoch: 0 [2785/3978 (70%)]\tLoss: 0.029741\n",
            "Train Epoch: 0 [2790/3978 (70%)]\tLoss: 0.221013\n",
            "Train Epoch: 0 [2795/3978 (70%)]\tLoss: 0.819332\n",
            "Train Epoch: 0 [2800/3978 (70%)]\tLoss: 0.413252\n",
            "Train Epoch: 0 [2805/3978 (70%)]\tLoss: 0.100207\n",
            "Train Epoch: 0 [2810/3978 (71%)]\tLoss: 0.184374\n",
            "Train Epoch: 0 [2815/3978 (71%)]\tLoss: 0.701956\n",
            "Train Epoch: 0 [2820/3978 (71%)]\tLoss: 1.110717\n",
            "Train Epoch: 0 [2825/3978 (71%)]\tLoss: 0.723183\n",
            "Train Epoch: 0 [2830/3978 (71%)]\tLoss: 0.176804\n",
            "Train Epoch: 0 [2835/3978 (71%)]\tLoss: 0.142786\n",
            "Train Epoch: 0 [2840/3978 (71%)]\tLoss: 0.674121\n",
            "Train Epoch: 0 [2845/3978 (71%)]\tLoss: 0.348034\n",
            "Train Epoch: 0 [2850/3978 (72%)]\tLoss: 1.610954\n",
            "Train Epoch: 0 [2855/3978 (72%)]\tLoss: 0.000427\n",
            "Train Epoch: 0 [2860/3978 (72%)]\tLoss: 0.914832\n",
            "Train Epoch: 0 [2865/3978 (72%)]\tLoss: 0.340199\n",
            "Train Epoch: 0 [2870/3978 (72%)]\tLoss: 0.477958\n",
            "Train Epoch: 0 [2875/3978 (72%)]\tLoss: 0.696533\n",
            "Train Epoch: 0 [2880/3978 (72%)]\tLoss: 0.189732\n",
            "Train Epoch: 0 [2885/3978 (72%)]\tLoss: 0.481491\n",
            "Train Epoch: 0 [2890/3978 (73%)]\tLoss: 0.123576\n",
            "Train Epoch: 0 [2895/3978 (73%)]\tLoss: 0.268990\n",
            "Train Epoch: 0 [2900/3978 (73%)]\tLoss: 0.410898\n",
            "Train Epoch: 0 [2905/3978 (73%)]\tLoss: 0.343328\n",
            "Train Epoch: 0 [2910/3978 (73%)]\tLoss: 0.245533\n",
            "Train Epoch: 0 [2915/3978 (73%)]\tLoss: 0.415039\n",
            "Train Epoch: 0 [2920/3978 (73%)]\tLoss: 0.740823\n",
            "Train Epoch: 0 [2925/3978 (73%)]\tLoss: 0.289650\n",
            "Train Epoch: 0 [2930/3978 (74%)]\tLoss: 0.492129\n",
            "Train Epoch: 0 [2935/3978 (74%)]\tLoss: 0.220379\n",
            "Train Epoch: 0 [2940/3978 (74%)]\tLoss: 0.592932\n",
            "Train Epoch: 0 [2945/3978 (74%)]\tLoss: 0.803134\n",
            "Train Epoch: 0 [2950/3978 (74%)]\tLoss: 0.227650\n",
            "Train Epoch: 0 [2955/3978 (74%)]\tLoss: 0.327344\n",
            "Train Epoch: 0 [2960/3978 (74%)]\tLoss: 0.387502\n",
            "Train Epoch: 0 [2965/3978 (74%)]\tLoss: 0.166361\n",
            "Train Epoch: 0 [2970/3978 (75%)]\tLoss: 0.995918\n",
            "Train Epoch: 0 [2975/3978 (75%)]\tLoss: 0.402728\n",
            "Train Epoch: 0 [2980/3978 (75%)]\tLoss: 0.732059\n",
            "Train Epoch: 0 [2985/3978 (75%)]\tLoss: 0.639710\n",
            "Train Epoch: 0 [2990/3978 (75%)]\tLoss: 0.787793\n",
            "Train Epoch: 0 [2995/3978 (75%)]\tLoss: 0.481872\n",
            "Train Epoch: 0 [3000/3978 (75%)]\tLoss: 0.525192\n",
            "Train Epoch: 0 [3005/3978 (76%)]\tLoss: 0.371484\n",
            "Train Epoch: 0 [3010/3978 (76%)]\tLoss: 0.349047\n",
            "Train Epoch: 0 [3015/3978 (76%)]\tLoss: 0.980975\n",
            "Train Epoch: 0 [3020/3978 (76%)]\tLoss: 0.534947\n",
            "Train Epoch: 0 [3025/3978 (76%)]\tLoss: 0.371515\n",
            "Train Epoch: 0 [3030/3978 (76%)]\tLoss: 1.200778\n",
            "Train Epoch: 0 [3035/3978 (76%)]\tLoss: 0.287081\n",
            "Train Epoch: 0 [3040/3978 (76%)]\tLoss: 0.849710\n",
            "Train Epoch: 0 [3045/3978 (77%)]\tLoss: 0.628680\n",
            "Train Epoch: 0 [3050/3978 (77%)]\tLoss: 0.591298\n",
            "Train Epoch: 0 [3055/3978 (77%)]\tLoss: 0.458948\n",
            "Train Epoch: 0 [3060/3978 (77%)]\tLoss: 0.259559\n",
            "Train Epoch: 0 [3065/3978 (77%)]\tLoss: 0.480694\n",
            "Train Epoch: 0 [3070/3978 (77%)]\tLoss: 0.554509\n",
            "Train Epoch: 0 [3075/3978 (77%)]\tLoss: 0.019315\n",
            "Train Epoch: 0 [3080/3978 (77%)]\tLoss: 0.057277\n",
            "Train Epoch: 0 [3085/3978 (78%)]\tLoss: 1.461059\n",
            "Train Epoch: 0 [3090/3978 (78%)]\tLoss: 0.455278\n",
            "Train Epoch: 0 [3095/3978 (78%)]\tLoss: 1.069366\n",
            "Train Epoch: 0 [3100/3978 (78%)]\tLoss: 0.357528\n",
            "Train Epoch: 0 [3105/3978 (78%)]\tLoss: 0.115777\n",
            "Train Epoch: 0 [3110/3978 (78%)]\tLoss: 0.761332\n",
            "Train Epoch: 0 [3115/3978 (78%)]\tLoss: 1.289635\n",
            "Train Epoch: 0 [3120/3978 (78%)]\tLoss: 1.436518\n",
            "Train Epoch: 0 [3125/3978 (79%)]\tLoss: 1.681205\n",
            "Train Epoch: 0 [3130/3978 (79%)]\tLoss: 0.633152\n",
            "Train Epoch: 0 [3135/3978 (79%)]\tLoss: 0.491987\n",
            "Train Epoch: 0 [3140/3978 (79%)]\tLoss: 0.477514\n",
            "Train Epoch: 0 [3145/3978 (79%)]\tLoss: 0.801405\n",
            "Train Epoch: 0 [3150/3978 (79%)]\tLoss: 1.287078\n",
            "Train Epoch: 0 [3155/3978 (79%)]\tLoss: 1.494259\n",
            "Train Epoch: 0 [3160/3978 (79%)]\tLoss: 1.520471\n",
            "Train Epoch: 0 [3165/3978 (80%)]\tLoss: 1.192681\n",
            "Train Epoch: 0 [3170/3978 (80%)]\tLoss: 1.288234\n",
            "Train Epoch: 0 [3175/3978 (80%)]\tLoss: 0.760027\n",
            "Train Epoch: 0 [3180/3978 (80%)]\tLoss: 0.283176\n",
            "Train Epoch: 0 [3185/3978 (80%)]\tLoss: 0.082915\n",
            "Train Epoch: 0 [3190/3978 (80%)]\tLoss: 0.227515\n",
            "Train Epoch: 0 [3195/3978 (80%)]\tLoss: 0.784800\n",
            "Train Epoch: 0 [3200/3978 (80%)]\tLoss: 0.144110\n",
            "Train Epoch: 0 [3205/3978 (81%)]\tLoss: 0.338343\n",
            "Train Epoch: 0 [3210/3978 (81%)]\tLoss: 0.200985\n",
            "Train Epoch: 0 [3215/3978 (81%)]\tLoss: 1.011641\n",
            "Train Epoch: 0 [3220/3978 (81%)]\tLoss: 1.290640\n",
            "Train Epoch: 0 [3225/3978 (81%)]\tLoss: 0.186919\n",
            "Train Epoch: 0 [3230/3978 (81%)]\tLoss: 0.420504\n",
            "Train Epoch: 0 [3235/3978 (81%)]\tLoss: 0.287668\n",
            "Train Epoch: 0 [3240/3978 (81%)]\tLoss: 0.330344\n",
            "Train Epoch: 0 [3245/3978 (82%)]\tLoss: 0.084331\n",
            "Train Epoch: 0 [3250/3978 (82%)]\tLoss: 0.093823\n",
            "Train Epoch: 0 [3255/3978 (82%)]\tLoss: 0.396122\n",
            "Train Epoch: 0 [3260/3978 (82%)]\tLoss: 0.411025\n",
            "Train Epoch: 0 [3265/3978 (82%)]\tLoss: 0.675590\n",
            "Train Epoch: 0 [3270/3978 (82%)]\tLoss: 0.595129\n",
            "Train Epoch: 0 [3275/3978 (82%)]\tLoss: 0.142936\n",
            "Train Epoch: 0 [3280/3978 (82%)]\tLoss: 0.092406\n",
            "Train Epoch: 0 [3285/3978 (83%)]\tLoss: 0.499109\n",
            "Train Epoch: 0 [3290/3978 (83%)]\tLoss: 0.299449\n",
            "Train Epoch: 0 [3295/3978 (83%)]\tLoss: 1.034517\n",
            "Train Epoch: 0 [3300/3978 (83%)]\tLoss: 0.178780\n",
            "Train Epoch: 0 [3305/3978 (83%)]\tLoss: 0.309168\n",
            "Train Epoch: 0 [3310/3978 (83%)]\tLoss: 0.218474\n",
            "Train Epoch: 0 [3315/3978 (83%)]\tLoss: 0.276880\n",
            "Train Epoch: 0 [3320/3978 (83%)]\tLoss: 0.298402\n",
            "Train Epoch: 0 [3325/3978 (84%)]\tLoss: 0.079851\n",
            "Train Epoch: 0 [3330/3978 (84%)]\tLoss: 0.458905\n",
            "Train Epoch: 0 [3335/3978 (84%)]\tLoss: 0.033049\n",
            "Train Epoch: 0 [3340/3978 (84%)]\tLoss: 0.061622\n",
            "Train Epoch: 0 [3345/3978 (84%)]\tLoss: 0.600764\n",
            "Train Epoch: 0 [3350/3978 (84%)]\tLoss: 0.829518\n",
            "Train Epoch: 0 [3355/3978 (84%)]\tLoss: 0.786577\n",
            "Train Epoch: 0 [3360/3978 (84%)]\tLoss: 0.709034\n",
            "Train Epoch: 0 [3365/3978 (85%)]\tLoss: 0.069610\n",
            "Train Epoch: 0 [3370/3978 (85%)]\tLoss: 1.701161\n",
            "Train Epoch: 0 [3375/3978 (85%)]\tLoss: 1.085573\n",
            "Train Epoch: 0 [3380/3978 (85%)]\tLoss: 0.658334\n",
            "Train Epoch: 0 [3385/3978 (85%)]\tLoss: 0.421524\n",
            "Train Epoch: 0 [3390/3978 (85%)]\tLoss: 0.217244\n",
            "Train Epoch: 0 [3395/3978 (85%)]\tLoss: 0.477012\n",
            "Train Epoch: 0 [3400/3978 (85%)]\tLoss: 0.136130\n",
            "Train Epoch: 0 [3405/3978 (86%)]\tLoss: 0.621810\n",
            "Train Epoch: 0 [3410/3978 (86%)]\tLoss: 0.347674\n",
            "Train Epoch: 0 [3415/3978 (86%)]\tLoss: 0.082738\n",
            "Train Epoch: 0 [3420/3978 (86%)]\tLoss: 0.286739\n",
            "Train Epoch: 0 [3425/3978 (86%)]\tLoss: 0.250808\n",
            "Train Epoch: 0 [3430/3978 (86%)]\tLoss: 0.234637\n",
            "Train Epoch: 0 [3435/3978 (86%)]\tLoss: 0.227454\n",
            "Train Epoch: 0 [3440/3978 (86%)]\tLoss: 0.074531\n",
            "Train Epoch: 0 [3445/3978 (87%)]\tLoss: 0.547826\n",
            "Train Epoch: 0 [3450/3978 (87%)]\tLoss: 0.473150\n",
            "Train Epoch: 0 [3455/3978 (87%)]\tLoss: 0.570806\n",
            "Train Epoch: 0 [3460/3978 (87%)]\tLoss: 0.057117\n",
            "Train Epoch: 0 [3465/3978 (87%)]\tLoss: 0.260842\n",
            "Train Epoch: 0 [3470/3978 (87%)]\tLoss: 0.040579\n",
            "Train Epoch: 0 [3475/3978 (87%)]\tLoss: 0.909276\n",
            "Train Epoch: 0 [3480/3978 (87%)]\tLoss: 0.058105\n",
            "Train Epoch: 0 [3485/3978 (88%)]\tLoss: 0.131033\n",
            "Train Epoch: 0 [3490/3978 (88%)]\tLoss: 0.860270\n",
            "Train Epoch: 0 [3495/3978 (88%)]\tLoss: 0.469293\n",
            "Train Epoch: 0 [3500/3978 (88%)]\tLoss: 1.087173\n",
            "Train Epoch: 0 [3505/3978 (88%)]\tLoss: 2.373487\n",
            "Train Epoch: 0 [3510/3978 (88%)]\tLoss: 0.224627\n",
            "Train Epoch: 0 [3515/3978 (88%)]\tLoss: 0.149112\n",
            "Train Epoch: 0 [3520/3978 (88%)]\tLoss: 1.253351\n",
            "Train Epoch: 0 [3525/3978 (89%)]\tLoss: 0.133240\n",
            "Train Epoch: 0 [3530/3978 (89%)]\tLoss: 0.043204\n",
            "Train Epoch: 0 [3535/3978 (89%)]\tLoss: 0.641801\n",
            "Train Epoch: 0 [3540/3978 (89%)]\tLoss: 0.037563\n",
            "Train Epoch: 0 [3545/3978 (89%)]\tLoss: 1.340377\n",
            "Train Epoch: 0 [3550/3978 (89%)]\tLoss: 1.560609\n",
            "Train Epoch: 0 [3555/3978 (89%)]\tLoss: 0.390541\n",
            "Train Epoch: 0 [3560/3978 (89%)]\tLoss: 0.093450\n",
            "Train Epoch: 0 [3565/3978 (90%)]\tLoss: 0.045282\n",
            "Train Epoch: 0 [3570/3978 (90%)]\tLoss: 0.106306\n",
            "Train Epoch: 0 [3575/3978 (90%)]\tLoss: 0.344775\n",
            "Train Epoch: 0 [3580/3978 (90%)]\tLoss: 0.451112\n",
            "Train Epoch: 0 [3585/3978 (90%)]\tLoss: 0.303540\n",
            "Train Epoch: 0 [3590/3978 (90%)]\tLoss: 1.250414\n",
            "Train Epoch: 0 [3595/3978 (90%)]\tLoss: 0.165173\n",
            "Train Epoch: 0 [3600/3978 (90%)]\tLoss: 0.396296\n",
            "Train Epoch: 0 [3605/3978 (91%)]\tLoss: 0.169731\n",
            "Train Epoch: 0 [3610/3978 (91%)]\tLoss: 0.728761\n",
            "Train Epoch: 0 [3615/3978 (91%)]\tLoss: 0.287610\n",
            "Train Epoch: 0 [3620/3978 (91%)]\tLoss: 0.526412\n",
            "Train Epoch: 0 [3625/3978 (91%)]\tLoss: 0.127491\n",
            "Train Epoch: 0 [3630/3978 (91%)]\tLoss: 0.637012\n",
            "Train Epoch: 0 [3635/3978 (91%)]\tLoss: 0.208614\n",
            "Train Epoch: 0 [3640/3978 (91%)]\tLoss: 0.770855\n",
            "Train Epoch: 0 [3645/3978 (92%)]\tLoss: 0.214784\n",
            "Train Epoch: 0 [3650/3978 (92%)]\tLoss: 0.014080\n",
            "Train Epoch: 0 [3655/3978 (92%)]\tLoss: 0.174149\n",
            "Train Epoch: 0 [3660/3978 (92%)]\tLoss: 1.143335\n",
            "Train Epoch: 0 [3665/3978 (92%)]\tLoss: 0.403718\n",
            "Train Epoch: 0 [3670/3978 (92%)]\tLoss: 0.366188\n",
            "Train Epoch: 0 [3675/3978 (92%)]\tLoss: 0.415115\n",
            "Train Epoch: 0 [3680/3978 (92%)]\tLoss: 0.437828\n",
            "Train Epoch: 0 [3685/3978 (93%)]\tLoss: 0.719788\n",
            "Train Epoch: 0 [3690/3978 (93%)]\tLoss: 0.609807\n",
            "Train Epoch: 0 [3695/3978 (93%)]\tLoss: 0.287044\n",
            "Train Epoch: 0 [3700/3978 (93%)]\tLoss: 0.682886\n",
            "Train Epoch: 0 [3705/3978 (93%)]\tLoss: 0.372822\n",
            "Train Epoch: 0 [3710/3978 (93%)]\tLoss: 1.113466\n",
            "Train Epoch: 0 [3715/3978 (93%)]\tLoss: 0.149641\n",
            "Train Epoch: 0 [3720/3978 (93%)]\tLoss: 0.448825\n",
            "Train Epoch: 0 [3725/3978 (94%)]\tLoss: 0.498709\n",
            "Train Epoch: 0 [3730/3978 (94%)]\tLoss: 0.126137\n",
            "Train Epoch: 0 [3735/3978 (94%)]\tLoss: 0.046416\n",
            "Train Epoch: 0 [3740/3978 (94%)]\tLoss: 1.209273\n",
            "Train Epoch: 0 [3745/3978 (94%)]\tLoss: 1.596403\n",
            "Train Epoch: 0 [3750/3978 (94%)]\tLoss: 0.365407\n",
            "Train Epoch: 0 [3755/3978 (94%)]\tLoss: 0.061382\n",
            "Train Epoch: 0 [3760/3978 (94%)]\tLoss: 0.092308\n",
            "Train Epoch: 0 [3765/3978 (95%)]\tLoss: 0.088696\n",
            "Train Epoch: 0 [3770/3978 (95%)]\tLoss: 0.132844\n",
            "Train Epoch: 0 [3775/3978 (95%)]\tLoss: 0.650112\n",
            "Train Epoch: 0 [3780/3978 (95%)]\tLoss: 1.020293\n",
            "Train Epoch: 0 [3785/3978 (95%)]\tLoss: 0.083805\n",
            "Train Epoch: 0 [3790/3978 (95%)]\tLoss: 0.483546\n",
            "Train Epoch: 0 [3795/3978 (95%)]\tLoss: 0.295792\n",
            "Train Epoch: 0 [3800/3978 (95%)]\tLoss: 0.181736\n",
            "Train Epoch: 0 [3805/3978 (96%)]\tLoss: 0.169076\n",
            "Train Epoch: 0 [3810/3978 (96%)]\tLoss: 0.302420\n",
            "Train Epoch: 0 [3815/3978 (96%)]\tLoss: 0.564359\n",
            "Train Epoch: 0 [3820/3978 (96%)]\tLoss: 0.019575\n",
            "Train Epoch: 0 [3825/3978 (96%)]\tLoss: 0.481810\n",
            "Train Epoch: 0 [3830/3978 (96%)]\tLoss: 0.107570\n",
            "Train Epoch: 0 [3835/3978 (96%)]\tLoss: 0.201402\n",
            "Train Epoch: 0 [3840/3978 (96%)]\tLoss: 0.385972\n",
            "Train Epoch: 0 [3845/3978 (97%)]\tLoss: 0.505043\n",
            "Train Epoch: 0 [3850/3978 (97%)]\tLoss: 0.082404\n",
            "Train Epoch: 0 [3855/3978 (97%)]\tLoss: 0.050858\n",
            "Train Epoch: 0 [3860/3978 (97%)]\tLoss: 0.444484\n",
            "Train Epoch: 0 [3865/3978 (97%)]\tLoss: 0.277359\n",
            "Train Epoch: 0 [3870/3978 (97%)]\tLoss: 0.577834\n",
            "Train Epoch: 0 [3875/3978 (97%)]\tLoss: 0.064839\n",
            "Train Epoch: 0 [3880/3978 (97%)]\tLoss: 0.732810\n",
            "Train Epoch: 0 [3885/3978 (98%)]\tLoss: 0.669449\n",
            "Train Epoch: 0 [3890/3978 (98%)]\tLoss: 0.589350\n",
            "Train Epoch: 0 [3895/3978 (98%)]\tLoss: 0.536400\n",
            "Train Epoch: 0 [3900/3978 (98%)]\tLoss: 0.562226\n",
            "Train Epoch: 0 [3905/3978 (98%)]\tLoss: 0.692098\n",
            "Train Epoch: 0 [3910/3978 (98%)]\tLoss: 0.384433\n",
            "Train Epoch: 0 [3915/3978 (98%)]\tLoss: 0.371469\n",
            "Train Epoch: 0 [3920/3978 (98%)]\tLoss: 0.589384\n",
            "Train Epoch: 0 [3925/3978 (99%)]\tLoss: 0.388030\n",
            "Train Epoch: 0 [3930/3978 (99%)]\tLoss: 0.617179\n",
            "Train Epoch: 0 [3935/3978 (99%)]\tLoss: 0.321474\n",
            "Train Epoch: 0 [3940/3978 (99%)]\tLoss: 0.062161\n",
            "Train Epoch: 0 [3945/3978 (99%)]\tLoss: 0.405341\n",
            "Train Epoch: 0 [3950/3978 (99%)]\tLoss: 0.413383\n",
            "Train Epoch: 0 [3955/3978 (99%)]\tLoss: 0.055849\n",
            "Train Epoch: 0 [3960/3978 (99%)]\tLoss: 0.502371\n",
            "Train Epoch: 0 [3965/3978 (100%)]\tLoss: 0.688783\n",
            "Train Epoch: 0 [3970/3978 (100%)]\tLoss: 0.588160\n",
            "Train Epoch: 0 [2385/3978 (100%)]\tLoss: 0.463845\n",
            "Epoch\n",
            "train/train_loss: 0.4638449251651764\n",
            "\n",
            "Train Loss: 0.464, Valid Loss: 0.538482, Accuracy: 0.35\n",
            "Train Epoch: 1 [0/3978 (0%)]\tLoss: 0.078236\n",
            "Train Epoch: 1 [5/3978 (0%)]\tLoss: 0.235416\n",
            "Train Epoch: 1 [10/3978 (0%)]\tLoss: 1.568539\n",
            "Train Epoch: 1 [15/3978 (0%)]\tLoss: 0.431982\n",
            "Train Epoch: 1 [20/3978 (1%)]\tLoss: 0.963887\n",
            "Train Epoch: 1 [25/3978 (1%)]\tLoss: 0.344960\n",
            "Train Epoch: 1 [30/3978 (1%)]\tLoss: 1.316128\n",
            "Train Epoch: 1 [35/3978 (1%)]\tLoss: 0.190522\n",
            "Train Epoch: 1 [40/3978 (1%)]\tLoss: 0.496502\n",
            "Train Epoch: 1 [45/3978 (1%)]\tLoss: 0.286575\n",
            "Train Epoch: 1 [50/3978 (1%)]\tLoss: 0.040032\n",
            "Train Epoch: 1 [55/3978 (1%)]\tLoss: 0.062421\n",
            "Train Epoch: 1 [60/3978 (2%)]\tLoss: 1.366074\n",
            "Train Epoch: 1 [65/3978 (2%)]\tLoss: 0.317770\n",
            "Train Epoch: 1 [70/3978 (2%)]\tLoss: 0.270192\n",
            "Train Epoch: 1 [75/3978 (2%)]\tLoss: 0.403183\n",
            "Train Epoch: 1 [80/3978 (2%)]\tLoss: 0.032277\n",
            "Train Epoch: 1 [85/3978 (2%)]\tLoss: 0.098001\n",
            "Train Epoch: 1 [90/3978 (2%)]\tLoss: 0.078679\n",
            "Train Epoch: 1 [95/3978 (2%)]\tLoss: 0.712806\n",
            "Train Epoch: 1 [100/3978 (3%)]\tLoss: 0.881910\n",
            "Train Epoch: 1 [105/3978 (3%)]\tLoss: 0.520105\n",
            "Train Epoch: 1 [110/3978 (3%)]\tLoss: 1.323383\n",
            "Train Epoch: 1 [115/3978 (3%)]\tLoss: 0.281819\n",
            "Train Epoch: 1 [120/3978 (3%)]\tLoss: 0.451535\n",
            "Train Epoch: 1 [125/3978 (3%)]\tLoss: 0.836090\n",
            "Train Epoch: 1 [130/3978 (3%)]\tLoss: 0.340829\n",
            "Train Epoch: 1 [135/3978 (3%)]\tLoss: 0.200484\n",
            "Train Epoch: 1 [140/3978 (4%)]\tLoss: 0.711314\n",
            "Train Epoch: 1 [145/3978 (4%)]\tLoss: 0.709901\n",
            "Train Epoch: 1 [150/3978 (4%)]\tLoss: 0.039001\n",
            "Train Epoch: 1 [155/3978 (4%)]\tLoss: 0.629091\n",
            "Train Epoch: 1 [160/3978 (4%)]\tLoss: 0.082388\n",
            "Train Epoch: 1 [165/3978 (4%)]\tLoss: 0.819189\n",
            "Train Epoch: 1 [170/3978 (4%)]\tLoss: 0.381284\n",
            "Train Epoch: 1 [175/3978 (4%)]\tLoss: 0.575607\n",
            "Train Epoch: 1 [180/3978 (5%)]\tLoss: 0.099454\n",
            "Train Epoch: 1 [185/3978 (5%)]\tLoss: 0.121474\n",
            "Train Epoch: 1 [190/3978 (5%)]\tLoss: 0.540051\n",
            "Train Epoch: 1 [195/3978 (5%)]\tLoss: 0.072505\n",
            "Train Epoch: 1 [200/3978 (5%)]\tLoss: 0.586572\n",
            "Train Epoch: 1 [205/3978 (5%)]\tLoss: 0.347110\n",
            "Train Epoch: 1 [210/3978 (5%)]\tLoss: 0.907318\n",
            "Train Epoch: 1 [215/3978 (5%)]\tLoss: 0.543963\n",
            "Train Epoch: 1 [220/3978 (6%)]\tLoss: 0.214853\n",
            "Train Epoch: 1 [225/3978 (6%)]\tLoss: 0.088185\n",
            "Train Epoch: 1 [230/3978 (6%)]\tLoss: 0.278320\n",
            "Train Epoch: 1 [235/3978 (6%)]\tLoss: 1.191722\n",
            "Train Epoch: 1 [240/3978 (6%)]\tLoss: 0.706293\n",
            "Train Epoch: 1 [245/3978 (6%)]\tLoss: 0.286561\n",
            "Train Epoch: 1 [250/3978 (6%)]\tLoss: 0.830818\n",
            "Train Epoch: 1 [255/3978 (6%)]\tLoss: 0.507946\n",
            "Train Epoch: 1 [260/3978 (7%)]\tLoss: 0.680355\n",
            "Train Epoch: 1 [265/3978 (7%)]\tLoss: 1.535961\n",
            "Train Epoch: 1 [270/3978 (7%)]\tLoss: 0.320637\n",
            "Train Epoch: 1 [275/3978 (7%)]\tLoss: 0.262282\n",
            "Train Epoch: 1 [280/3978 (7%)]\tLoss: 0.053890\n",
            "Train Epoch: 1 [285/3978 (7%)]\tLoss: 0.847468\n",
            "Train Epoch: 1 [290/3978 (7%)]\tLoss: 2.167943\n",
            "Train Epoch: 1 [295/3978 (7%)]\tLoss: 0.880676\n",
            "Train Epoch: 1 [300/3978 (8%)]\tLoss: 1.357691\n",
            "Train Epoch: 1 [305/3978 (8%)]\tLoss: 0.273668\n",
            "Train Epoch: 1 [310/3978 (8%)]\tLoss: 0.207852\n",
            "Train Epoch: 1 [315/3978 (8%)]\tLoss: 0.239874\n",
            "Train Epoch: 1 [320/3978 (8%)]\tLoss: 0.760391\n",
            "Train Epoch: 1 [325/3978 (8%)]\tLoss: 1.001371\n",
            "Train Epoch: 1 [330/3978 (8%)]\tLoss: 1.268065\n",
            "Train Epoch: 1 [335/3978 (8%)]\tLoss: 0.461081\n",
            "Train Epoch: 1 [340/3978 (9%)]\tLoss: 0.379305\n",
            "Train Epoch: 1 [345/3978 (9%)]\tLoss: 0.182873\n",
            "Train Epoch: 1 [350/3978 (9%)]\tLoss: 1.159604\n",
            "Train Epoch: 1 [355/3978 (9%)]\tLoss: 0.682776\n",
            "Train Epoch: 1 [360/3978 (9%)]\tLoss: 0.115270\n",
            "Train Epoch: 1 [365/3978 (9%)]\tLoss: 0.643706\n",
            "Train Epoch: 1 [370/3978 (9%)]\tLoss: 0.474611\n",
            "Train Epoch: 1 [375/3978 (9%)]\tLoss: 0.657414\n",
            "Train Epoch: 1 [380/3978 (10%)]\tLoss: 0.136564\n",
            "Train Epoch: 1 [385/3978 (10%)]\tLoss: 0.602628\n",
            "Train Epoch: 1 [390/3978 (10%)]\tLoss: 0.597688\n",
            "Train Epoch: 1 [395/3978 (10%)]\tLoss: 0.255430\n",
            "Train Epoch: 1 [400/3978 (10%)]\tLoss: 0.190827\n",
            "Train Epoch: 1 [405/3978 (10%)]\tLoss: 0.078625\n",
            "Train Epoch: 1 [410/3978 (10%)]\tLoss: 0.252821\n",
            "Train Epoch: 1 [415/3978 (10%)]\tLoss: 0.310593\n",
            "Train Epoch: 1 [420/3978 (11%)]\tLoss: 0.083426\n",
            "Train Epoch: 1 [425/3978 (11%)]\tLoss: 0.179170\n",
            "Train Epoch: 1 [430/3978 (11%)]\tLoss: 0.429304\n",
            "Train Epoch: 1 [435/3978 (11%)]\tLoss: 0.254963\n",
            "Train Epoch: 1 [440/3978 (11%)]\tLoss: 0.260575\n",
            "Train Epoch: 1 [445/3978 (11%)]\tLoss: 0.442213\n",
            "Train Epoch: 1 [450/3978 (11%)]\tLoss: 0.462660\n",
            "Train Epoch: 1 [455/3978 (11%)]\tLoss: 0.571857\n",
            "Train Epoch: 1 [460/3978 (12%)]\tLoss: 0.082280\n",
            "Train Epoch: 1 [465/3978 (12%)]\tLoss: 0.114760\n",
            "Train Epoch: 1 [470/3978 (12%)]\tLoss: 1.299607\n",
            "Train Epoch: 1 [475/3978 (12%)]\tLoss: 0.566029\n",
            "Train Epoch: 1 [480/3978 (12%)]\tLoss: 0.097141\n",
            "Train Epoch: 1 [485/3978 (12%)]\tLoss: 0.448622\n",
            "Train Epoch: 1 [490/3978 (12%)]\tLoss: 0.705922\n",
            "Train Epoch: 1 [495/3978 (12%)]\tLoss: 0.270486\n",
            "Train Epoch: 1 [500/3978 (13%)]\tLoss: 0.100488\n",
            "Train Epoch: 1 [505/3978 (13%)]\tLoss: 0.053997\n",
            "Train Epoch: 1 [510/3978 (13%)]\tLoss: 0.049440\n",
            "Train Epoch: 1 [515/3978 (13%)]\tLoss: 0.445731\n",
            "Train Epoch: 1 [520/3978 (13%)]\tLoss: 0.751027\n",
            "Train Epoch: 1 [525/3978 (13%)]\tLoss: 0.937202\n",
            "Train Epoch: 1 [530/3978 (13%)]\tLoss: 0.807052\n",
            "Train Epoch: 1 [535/3978 (13%)]\tLoss: 0.042726\n",
            "Train Epoch: 1 [540/3978 (14%)]\tLoss: 0.248640\n",
            "Train Epoch: 1 [545/3978 (14%)]\tLoss: 0.822336\n",
            "Train Epoch: 1 [550/3978 (14%)]\tLoss: 0.495704\n",
            "Train Epoch: 1 [555/3978 (14%)]\tLoss: 0.235965\n",
            "Train Epoch: 1 [560/3978 (14%)]\tLoss: 0.286914\n",
            "Train Epoch: 1 [565/3978 (14%)]\tLoss: 0.551531\n",
            "Train Epoch: 1 [570/3978 (14%)]\tLoss: 0.557113\n",
            "Train Epoch: 1 [575/3978 (14%)]\tLoss: 0.403350\n",
            "Train Epoch: 1 [580/3978 (15%)]\tLoss: 0.550254\n",
            "Train Epoch: 1 [585/3978 (15%)]\tLoss: 0.479698\n",
            "Train Epoch: 1 [590/3978 (15%)]\tLoss: 0.628419\n",
            "Train Epoch: 1 [595/3978 (15%)]\tLoss: 0.138609\n",
            "Train Epoch: 1 [600/3978 (15%)]\tLoss: 0.067959\n",
            "Train Epoch: 1 [605/3978 (15%)]\tLoss: 0.763370\n",
            "Train Epoch: 1 [610/3978 (15%)]\tLoss: 0.454954\n",
            "Train Epoch: 1 [615/3978 (15%)]\tLoss: 0.835355\n",
            "Train Epoch: 1 [620/3978 (16%)]\tLoss: 0.713974\n",
            "Train Epoch: 1 [625/3978 (16%)]\tLoss: 0.301407\n",
            "Train Epoch: 1 [630/3978 (16%)]\tLoss: 0.646009\n",
            "Train Epoch: 1 [635/3978 (16%)]\tLoss: 0.339743\n",
            "Train Epoch: 1 [640/3978 (16%)]\tLoss: 0.073729\n",
            "Train Epoch: 1 [645/3978 (16%)]\tLoss: 0.389900\n",
            "Train Epoch: 1 [650/3978 (16%)]\tLoss: 0.350289\n",
            "Train Epoch: 1 [655/3978 (16%)]\tLoss: 1.425741\n",
            "Train Epoch: 1 [660/3978 (17%)]\tLoss: 0.523901\n",
            "Train Epoch: 1 [665/3978 (17%)]\tLoss: 0.942187\n",
            "Train Epoch: 1 [670/3978 (17%)]\tLoss: 0.571649\n",
            "Train Epoch: 1 [675/3978 (17%)]\tLoss: 0.349472\n",
            "Train Epoch: 1 [680/3978 (17%)]\tLoss: 0.309123\n",
            "Train Epoch: 1 [685/3978 (17%)]\tLoss: 0.671931\n",
            "Train Epoch: 1 [690/3978 (17%)]\tLoss: 0.708921\n",
            "Train Epoch: 1 [695/3978 (17%)]\tLoss: 0.572920\n",
            "Train Epoch: 1 [700/3978 (18%)]\tLoss: 0.849335\n",
            "Train Epoch: 1 [705/3978 (18%)]\tLoss: 0.688433\n",
            "Train Epoch: 1 [710/3978 (18%)]\tLoss: 0.139957\n",
            "Train Epoch: 1 [715/3978 (18%)]\tLoss: 0.689562\n",
            "Train Epoch: 1 [720/3978 (18%)]\tLoss: 0.469147\n",
            "Train Epoch: 1 [725/3978 (18%)]\tLoss: 0.705600\n",
            "Train Epoch: 1 [730/3978 (18%)]\tLoss: 0.183809\n",
            "Train Epoch: 1 [735/3978 (18%)]\tLoss: 0.202799\n",
            "Train Epoch: 1 [740/3978 (19%)]\tLoss: 0.097059\n",
            "Train Epoch: 1 [745/3978 (19%)]\tLoss: 1.037512\n",
            "Train Epoch: 1 [750/3978 (19%)]\tLoss: 0.426203\n",
            "Train Epoch: 1 [755/3978 (19%)]\tLoss: 0.378827\n",
            "Train Epoch: 1 [760/3978 (19%)]\tLoss: 1.274693\n",
            "Train Epoch: 1 [765/3978 (19%)]\tLoss: 0.113358\n",
            "Train Epoch: 1 [770/3978 (19%)]\tLoss: 0.411525\n",
            "Train Epoch: 1 [775/3978 (19%)]\tLoss: 0.376119\n",
            "Train Epoch: 1 [780/3978 (20%)]\tLoss: 1.247316\n",
            "Train Epoch: 1 [785/3978 (20%)]\tLoss: 0.292131\n",
            "Train Epoch: 1 [790/3978 (20%)]\tLoss: 0.198098\n",
            "Train Epoch: 1 [795/3978 (20%)]\tLoss: 0.740051\n",
            "Train Epoch: 1 [800/3978 (20%)]\tLoss: 0.044878\n",
            "Train Epoch: 1 [805/3978 (20%)]\tLoss: 1.794043\n",
            "Train Epoch: 1 [810/3978 (20%)]\tLoss: 0.460793\n",
            "Train Epoch: 1 [815/3978 (20%)]\tLoss: 1.101340\n",
            "Train Epoch: 1 [820/3978 (21%)]\tLoss: 1.243788\n",
            "Train Epoch: 1 [825/3978 (21%)]\tLoss: 0.262578\n",
            "Train Epoch: 1 [830/3978 (21%)]\tLoss: 0.251670\n",
            "Train Epoch: 1 [835/3978 (21%)]\tLoss: 0.600521\n",
            "Train Epoch: 1 [840/3978 (21%)]\tLoss: 0.415522\n",
            "Train Epoch: 1 [845/3978 (21%)]\tLoss: 0.480350\n",
            "Train Epoch: 1 [850/3978 (21%)]\tLoss: 0.285319\n",
            "Train Epoch: 1 [855/3978 (21%)]\tLoss: 0.150706\n",
            "Train Epoch: 1 [860/3978 (22%)]\tLoss: 0.618896\n",
            "Train Epoch: 1 [865/3978 (22%)]\tLoss: 0.228397\n",
            "Train Epoch: 1 [870/3978 (22%)]\tLoss: 0.144405\n",
            "Train Epoch: 1 [875/3978 (22%)]\tLoss: 0.569404\n",
            "Train Epoch: 1 [880/3978 (22%)]\tLoss: 0.604687\n",
            "Train Epoch: 1 [885/3978 (22%)]\tLoss: 0.583104\n",
            "Train Epoch: 1 [890/3978 (22%)]\tLoss: 0.856103\n",
            "Train Epoch: 1 [895/3978 (22%)]\tLoss: 0.307383\n",
            "Train Epoch: 1 [900/3978 (23%)]\tLoss: 0.348733\n",
            "Train Epoch: 1 [905/3978 (23%)]\tLoss: 1.250982\n",
            "Train Epoch: 1 [910/3978 (23%)]\tLoss: 0.224538\n",
            "Train Epoch: 1 [915/3978 (23%)]\tLoss: 0.050090\n",
            "Train Epoch: 1 [920/3978 (23%)]\tLoss: 0.131596\n",
            "Train Epoch: 1 [925/3978 (23%)]\tLoss: 1.177303\n",
            "Train Epoch: 1 [930/3978 (23%)]\tLoss: 0.366097\n",
            "Train Epoch: 1 [935/3978 (23%)]\tLoss: 1.041879\n",
            "Train Epoch: 1 [940/3978 (24%)]\tLoss: 0.108569\n",
            "Train Epoch: 1 [945/3978 (24%)]\tLoss: 0.843896\n",
            "Train Epoch: 1 [950/3978 (24%)]\tLoss: 0.246666\n",
            "Train Epoch: 1 [955/3978 (24%)]\tLoss: 0.847839\n",
            "Train Epoch: 1 [960/3978 (24%)]\tLoss: 0.581129\n",
            "Train Epoch: 1 [965/3978 (24%)]\tLoss: 0.257019\n",
            "Train Epoch: 1 [970/3978 (24%)]\tLoss: 0.903673\n",
            "Train Epoch: 1 [975/3978 (24%)]\tLoss: 0.417743\n",
            "Train Epoch: 1 [980/3978 (25%)]\tLoss: 0.061472\n",
            "Train Epoch: 1 [985/3978 (25%)]\tLoss: 0.499332\n",
            "Train Epoch: 1 [990/3978 (25%)]\tLoss: 0.531076\n",
            "Train Epoch: 1 [995/3978 (25%)]\tLoss: 0.105474\n",
            "Train Epoch: 1 [1000/3978 (25%)]\tLoss: 0.027766\n",
            "Train Epoch: 1 [1005/3978 (25%)]\tLoss: 0.636629\n",
            "Train Epoch: 1 [1010/3978 (25%)]\tLoss: 0.552035\n",
            "Train Epoch: 1 [1015/3978 (26%)]\tLoss: 0.850947\n",
            "Train Epoch: 1 [1020/3978 (26%)]\tLoss: 0.551367\n",
            "Train Epoch: 1 [1025/3978 (26%)]\tLoss: 0.546754\n",
            "Train Epoch: 1 [1030/3978 (26%)]\tLoss: 0.749586\n",
            "Train Epoch: 1 [1035/3978 (26%)]\tLoss: 0.247590\n",
            "Train Epoch: 1 [1040/3978 (26%)]\tLoss: 0.459837\n",
            "Train Epoch: 1 [1045/3978 (26%)]\tLoss: 0.646586\n",
            "Train Epoch: 1 [1050/3978 (26%)]\tLoss: 1.487535\n",
            "Train Epoch: 1 [1055/3978 (27%)]\tLoss: 0.412773\n",
            "Train Epoch: 1 [1060/3978 (27%)]\tLoss: 0.050006\n",
            "Train Epoch: 1 [1065/3978 (27%)]\tLoss: 0.831789\n",
            "Train Epoch: 1 [1070/3978 (27%)]\tLoss: 0.330371\n",
            "Train Epoch: 1 [1075/3978 (27%)]\tLoss: 0.554517\n",
            "Train Epoch: 1 [1080/3978 (27%)]\tLoss: 0.407149\n",
            "Train Epoch: 1 [1085/3978 (27%)]\tLoss: 0.717302\n",
            "Train Epoch: 1 [1090/3978 (27%)]\tLoss: 1.335062\n",
            "Train Epoch: 1 [1095/3978 (28%)]\tLoss: 0.956205\n",
            "Train Epoch: 1 [1100/3978 (28%)]\tLoss: 0.339871\n",
            "Train Epoch: 1 [1105/3978 (28%)]\tLoss: 0.166563\n",
            "Train Epoch: 1 [1110/3978 (28%)]\tLoss: 0.554056\n",
            "Train Epoch: 1 [1115/3978 (28%)]\tLoss: 0.621488\n",
            "Train Epoch: 1 [1120/3978 (28%)]\tLoss: 0.087697\n",
            "Train Epoch: 1 [1125/3978 (28%)]\tLoss: 0.454509\n",
            "Train Epoch: 1 [1130/3978 (28%)]\tLoss: 0.206452\n",
            "Train Epoch: 1 [1135/3978 (29%)]\tLoss: 0.486856\n",
            "Train Epoch: 1 [1140/3978 (29%)]\tLoss: 1.451237\n",
            "Train Epoch: 1 [1145/3978 (29%)]\tLoss: 0.515029\n",
            "Train Epoch: 1 [1150/3978 (29%)]\tLoss: 0.239339\n",
            "Train Epoch: 1 [1155/3978 (29%)]\tLoss: 0.177915\n",
            "Train Epoch: 1 [1160/3978 (29%)]\tLoss: 0.280830\n",
            "Train Epoch: 1 [1165/3978 (29%)]\tLoss: 0.660645\n",
            "Train Epoch: 1 [1170/3978 (29%)]\tLoss: 0.372725\n",
            "Train Epoch: 1 [1175/3978 (30%)]\tLoss: 0.164640\n",
            "Train Epoch: 1 [1180/3978 (30%)]\tLoss: 0.133203\n",
            "Train Epoch: 1 [1185/3978 (30%)]\tLoss: 0.451509\n",
            "Train Epoch: 1 [1190/3978 (30%)]\tLoss: 0.691790\n",
            "Train Epoch: 1 [1195/3978 (30%)]\tLoss: 0.227687\n",
            "Train Epoch: 1 [1200/3978 (30%)]\tLoss: 0.900906\n",
            "Train Epoch: 1 [1205/3978 (30%)]\tLoss: 0.056459\n",
            "Train Epoch: 1 [1210/3978 (30%)]\tLoss: 0.929951\n",
            "Train Epoch: 1 [1215/3978 (31%)]\tLoss: 0.736211\n",
            "Train Epoch: 1 [1220/3978 (31%)]\tLoss: 0.313957\n",
            "Train Epoch: 1 [1225/3978 (31%)]\tLoss: 0.150584\n",
            "Train Epoch: 1 [1230/3978 (31%)]\tLoss: 0.299573\n",
            "Train Epoch: 1 [1235/3978 (31%)]\tLoss: 0.886842\n",
            "Train Epoch: 1 [1240/3978 (31%)]\tLoss: 0.892320\n",
            "Train Epoch: 1 [1245/3978 (31%)]\tLoss: 0.684280\n",
            "Train Epoch: 1 [1250/3978 (31%)]\tLoss: 0.030839\n",
            "Train Epoch: 1 [1255/3978 (32%)]\tLoss: 0.386821\n",
            "Train Epoch: 1 [1260/3978 (32%)]\tLoss: 0.317087\n",
            "Train Epoch: 1 [1265/3978 (32%)]\tLoss: 0.141712\n",
            "Train Epoch: 1 [1270/3978 (32%)]\tLoss: 0.284213\n",
            "Train Epoch: 1 [1275/3978 (32%)]\tLoss: 0.695404\n",
            "Train Epoch: 1 [1280/3978 (32%)]\tLoss: 0.291976\n",
            "Train Epoch: 1 [1285/3978 (32%)]\tLoss: 0.103865\n",
            "Train Epoch: 1 [1290/3978 (32%)]\tLoss: 0.349791\n",
            "Train Epoch: 1 [1295/3978 (33%)]\tLoss: 0.051598\n",
            "Train Epoch: 1 [1300/3978 (33%)]\tLoss: 0.452716\n",
            "Train Epoch: 1 [1305/3978 (33%)]\tLoss: 0.343085\n",
            "Train Epoch: 1 [1310/3978 (33%)]\tLoss: 0.197773\n",
            "Train Epoch: 1 [1315/3978 (33%)]\tLoss: 0.644152\n",
            "Train Epoch: 1 [1320/3978 (33%)]\tLoss: 0.124558\n",
            "Train Epoch: 1 [1325/3978 (33%)]\tLoss: 0.232685\n",
            "Train Epoch: 1 [1330/3978 (33%)]\tLoss: 0.527436\n",
            "Train Epoch: 1 [1335/3978 (34%)]\tLoss: 0.547513\n",
            "Train Epoch: 1 [1340/3978 (34%)]\tLoss: 0.230640\n",
            "Train Epoch: 1 [1345/3978 (34%)]\tLoss: 1.254837\n",
            "Train Epoch: 1 [1350/3978 (34%)]\tLoss: 0.091063\n",
            "Train Epoch: 1 [1355/3978 (34%)]\tLoss: 0.511785\n",
            "Train Epoch: 1 [1360/3978 (34%)]\tLoss: 0.253244\n",
            "Train Epoch: 1 [1365/3978 (34%)]\tLoss: 0.235179\n",
            "Train Epoch: 1 [1370/3978 (34%)]\tLoss: 0.269318\n",
            "Train Epoch: 1 [1375/3978 (35%)]\tLoss: 0.527836\n",
            "Train Epoch: 1 [1380/3978 (35%)]\tLoss: 0.388199\n",
            "Train Epoch: 1 [1385/3978 (35%)]\tLoss: 0.303955\n",
            "Train Epoch: 1 [1390/3978 (35%)]\tLoss: 0.819816\n",
            "Train Epoch: 1 [1395/3978 (35%)]\tLoss: 1.052030\n",
            "Train Epoch: 1 [1400/3978 (35%)]\tLoss: 0.699735\n",
            "Train Epoch: 1 [1405/3978 (35%)]\tLoss: 0.148700\n",
            "Train Epoch: 1 [1410/3978 (35%)]\tLoss: 0.285294\n",
            "Train Epoch: 1 [1415/3978 (36%)]\tLoss: 0.082099\n",
            "Train Epoch: 1 [1420/3978 (36%)]\tLoss: 0.056188\n",
            "Train Epoch: 1 [1425/3978 (36%)]\tLoss: 0.034069\n",
            "Train Epoch: 1 [1430/3978 (36%)]\tLoss: 0.050002\n",
            "Train Epoch: 1 [1435/3978 (36%)]\tLoss: 0.521957\n",
            "Train Epoch: 1 [1440/3978 (36%)]\tLoss: 1.265287\n",
            "Train Epoch: 1 [1445/3978 (36%)]\tLoss: 0.147129\n",
            "Train Epoch: 1 [1450/3978 (36%)]\tLoss: 0.557889\n",
            "Train Epoch: 1 [1455/3978 (37%)]\tLoss: 0.580704\n",
            "Train Epoch: 1 [1460/3978 (37%)]\tLoss: 0.291435\n",
            "Train Epoch: 1 [1465/3978 (37%)]\tLoss: 0.489333\n",
            "Train Epoch: 1 [1470/3978 (37%)]\tLoss: 0.123757\n",
            "Train Epoch: 1 [1475/3978 (37%)]\tLoss: 0.512162\n",
            "Train Epoch: 1 [1480/3978 (37%)]\tLoss: 0.765812\n",
            "Train Epoch: 1 [1485/3978 (37%)]\tLoss: 0.077307\n",
            "Train Epoch: 1 [1490/3978 (37%)]\tLoss: 0.286823\n",
            "Train Epoch: 1 [1495/3978 (38%)]\tLoss: 0.636585\n",
            "Train Epoch: 1 [1500/3978 (38%)]\tLoss: 0.656481\n",
            "Train Epoch: 1 [1505/3978 (38%)]\tLoss: 0.093545\n",
            "Train Epoch: 1 [1510/3978 (38%)]\tLoss: 1.014647\n",
            "Train Epoch: 1 [1515/3978 (38%)]\tLoss: 0.178339\n",
            "Train Epoch: 1 [1520/3978 (38%)]\tLoss: 0.862983\n",
            "Train Epoch: 1 [1525/3978 (38%)]\tLoss: 0.085595\n",
            "Train Epoch: 1 [1530/3978 (38%)]\tLoss: 0.158774\n",
            "Train Epoch: 1 [1535/3978 (39%)]\tLoss: 0.427344\n",
            "Train Epoch: 1 [1540/3978 (39%)]\tLoss: 0.142669\n",
            "Train Epoch: 1 [1545/3978 (39%)]\tLoss: 0.519070\n",
            "Train Epoch: 1 [1550/3978 (39%)]\tLoss: 0.589908\n",
            "Train Epoch: 1 [1555/3978 (39%)]\tLoss: 0.177517\n",
            "Train Epoch: 1 [1560/3978 (39%)]\tLoss: 0.708965\n",
            "Train Epoch: 1 [1565/3978 (39%)]\tLoss: 0.612568\n",
            "Train Epoch: 1 [1570/3978 (39%)]\tLoss: 1.114583\n",
            "Train Epoch: 1 [1575/3978 (40%)]\tLoss: 0.169317\n",
            "Train Epoch: 1 [1580/3978 (40%)]\tLoss: 0.167350\n",
            "Train Epoch: 1 [1585/3978 (40%)]\tLoss: 0.142326\n",
            "Train Epoch: 1 [1590/3978 (40%)]\tLoss: 0.271086\n",
            "Train Epoch: 1 [1595/3978 (40%)]\tLoss: 0.602264\n",
            "Train Epoch: 1 [1600/3978 (40%)]\tLoss: 0.079575\n",
            "Train Epoch: 1 [1605/3978 (40%)]\tLoss: 0.043164\n",
            "Train Epoch: 1 [1610/3978 (40%)]\tLoss: 0.594747\n",
            "Train Epoch: 1 [1615/3978 (41%)]\tLoss: 0.277604\n",
            "Train Epoch: 1 [1620/3978 (41%)]\tLoss: 0.240252\n",
            "Train Epoch: 1 [1625/3978 (41%)]\tLoss: 0.188358\n",
            "Train Epoch: 1 [1630/3978 (41%)]\tLoss: 0.230215\n",
            "Train Epoch: 1 [1635/3978 (41%)]\tLoss: 0.912199\n",
            "Train Epoch: 1 [1640/3978 (41%)]\tLoss: 0.050415\n",
            "Train Epoch: 1 [1645/3978 (41%)]\tLoss: 0.446456\n",
            "Train Epoch: 1 [1650/3978 (41%)]\tLoss: 0.068602\n",
            "Train Epoch: 1 [1655/3978 (42%)]\tLoss: 0.555620\n",
            "Train Epoch: 1 [1660/3978 (42%)]\tLoss: 0.845369\n",
            "Train Epoch: 1 [1665/3978 (42%)]\tLoss: 0.554829\n",
            "Train Epoch: 1 [1670/3978 (42%)]\tLoss: 0.288385\n",
            "Train Epoch: 1 [1675/3978 (42%)]\tLoss: 0.314838\n",
            "Train Epoch: 1 [1680/3978 (42%)]\tLoss: 0.139195\n",
            "Train Epoch: 1 [1685/3978 (42%)]\tLoss: 0.130654\n",
            "Train Epoch: 1 [1690/3978 (42%)]\tLoss: 0.066576\n",
            "Train Epoch: 1 [1695/3978 (43%)]\tLoss: 0.469968\n",
            "Train Epoch: 1 [1700/3978 (43%)]\tLoss: 0.319026\n",
            "Train Epoch: 1 [1705/3978 (43%)]\tLoss: 0.354659\n",
            "Train Epoch: 1 [1710/3978 (43%)]\tLoss: 0.225396\n",
            "Train Epoch: 1 [1715/3978 (43%)]\tLoss: 0.321279\n",
            "Train Epoch: 1 [1720/3978 (43%)]\tLoss: 0.503825\n",
            "Train Epoch: 1 [1725/3978 (43%)]\tLoss: 0.085718\n",
            "Train Epoch: 1 [1730/3978 (43%)]\tLoss: 0.036175\n",
            "Train Epoch: 1 [1735/3978 (44%)]\tLoss: 0.140149\n",
            "Train Epoch: 1 [1740/3978 (44%)]\tLoss: 0.116214\n",
            "Train Epoch: 1 [1745/3978 (44%)]\tLoss: 0.079316\n",
            "Train Epoch: 1 [1750/3978 (44%)]\tLoss: 0.897647\n",
            "Train Epoch: 1 [1755/3978 (44%)]\tLoss: 0.508299\n",
            "Train Epoch: 1 [1760/3978 (44%)]\tLoss: 0.203743\n",
            "Train Epoch: 1 [1765/3978 (44%)]\tLoss: 0.181814\n",
            "Train Epoch: 1 [1770/3978 (44%)]\tLoss: 0.709587\n",
            "Train Epoch: 1 [1775/3978 (45%)]\tLoss: 0.112822\n",
            "Train Epoch: 1 [1780/3978 (45%)]\tLoss: 0.098157\n",
            "Train Epoch: 1 [1785/3978 (45%)]\tLoss: 0.626287\n",
            "Train Epoch: 1 [1790/3978 (45%)]\tLoss: 0.420910\n",
            "Train Epoch: 1 [1795/3978 (45%)]\tLoss: 0.016544\n",
            "Train Epoch: 1 [1800/3978 (45%)]\tLoss: 0.219177\n",
            "Train Epoch: 1 [1805/3978 (45%)]\tLoss: 1.642267\n",
            "Train Epoch: 1 [1810/3978 (45%)]\tLoss: 0.505347\n",
            "Train Epoch: 1 [1815/3978 (46%)]\tLoss: 0.086274\n",
            "Train Epoch: 1 [1820/3978 (46%)]\tLoss: 0.034055\n",
            "Train Epoch: 1 [1825/3978 (46%)]\tLoss: 1.175960\n",
            "Train Epoch: 1 [1830/3978 (46%)]\tLoss: 0.275912\n",
            "Train Epoch: 1 [1835/3978 (46%)]\tLoss: 0.098567\n",
            "Train Epoch: 1 [1840/3978 (46%)]\tLoss: 0.133425\n",
            "Train Epoch: 1 [1845/3978 (46%)]\tLoss: 0.505064\n",
            "Train Epoch: 1 [1850/3978 (46%)]\tLoss: 0.110041\n",
            "Train Epoch: 1 [1855/3978 (47%)]\tLoss: 0.404630\n",
            "Train Epoch: 1 [1860/3978 (47%)]\tLoss: 0.346097\n",
            "Train Epoch: 1 [1865/3978 (47%)]\tLoss: 0.223855\n",
            "Train Epoch: 1 [1870/3978 (47%)]\tLoss: 1.069217\n",
            "Train Epoch: 1 [1875/3978 (47%)]\tLoss: 0.207704\n",
            "Train Epoch: 1 [1880/3978 (47%)]\tLoss: 0.141924\n",
            "Train Epoch: 1 [1885/3978 (47%)]\tLoss: 0.339375\n",
            "Train Epoch: 1 [1890/3978 (47%)]\tLoss: 0.053682\n",
            "Train Epoch: 1 [1895/3978 (48%)]\tLoss: 1.936269\n",
            "Train Epoch: 1 [1900/3978 (48%)]\tLoss: 0.469045\n",
            "Train Epoch: 1 [1905/3978 (48%)]\tLoss: 1.200125\n",
            "Train Epoch: 1 [1910/3978 (48%)]\tLoss: 0.430907\n",
            "Train Epoch: 1 [1915/3978 (48%)]\tLoss: 0.097625\n",
            "Train Epoch: 1 [1920/3978 (48%)]\tLoss: 0.704979\n",
            "Train Epoch: 1 [1925/3978 (48%)]\tLoss: 0.275902\n",
            "Train Epoch: 1 [1930/3978 (48%)]\tLoss: 0.324055\n",
            "Train Epoch: 1 [1935/3978 (49%)]\tLoss: 0.262008\n",
            "Train Epoch: 1 [1940/3978 (49%)]\tLoss: 0.488584\n",
            "Train Epoch: 1 [1945/3978 (49%)]\tLoss: 0.280659\n",
            "Train Epoch: 1 [1950/3978 (49%)]\tLoss: 0.402220\n",
            "Train Epoch: 1 [1955/3978 (49%)]\tLoss: 0.669835\n",
            "Train Epoch: 1 [1960/3978 (49%)]\tLoss: 0.174925\n",
            "Train Epoch: 1 [1965/3978 (49%)]\tLoss: 0.727133\n",
            "Train Epoch: 1 [1970/3978 (49%)]\tLoss: 0.584648\n",
            "Train Epoch: 1 [1975/3978 (50%)]\tLoss: 0.693553\n",
            "Train Epoch: 1 [1980/3978 (50%)]\tLoss: 0.591943\n",
            "Train Epoch: 1 [1985/3978 (50%)]\tLoss: 0.433170\n",
            "Train Epoch: 1 [1990/3978 (50%)]\tLoss: 0.345449\n",
            "Train Epoch: 1 [1995/3978 (50%)]\tLoss: 0.130652\n",
            "Train Epoch: 1 [2000/3978 (50%)]\tLoss: 0.117508\n",
            "Train Epoch: 1 [2005/3978 (50%)]\tLoss: 0.589952\n",
            "Train Epoch: 1 [2010/3978 (51%)]\tLoss: 0.530344\n",
            "Train Epoch: 1 [2015/3978 (51%)]\tLoss: 0.237273\n",
            "Train Epoch: 1 [2020/3978 (51%)]\tLoss: 0.424758\n",
            "Train Epoch: 1 [2025/3978 (51%)]\tLoss: 0.134322\n",
            "Train Epoch: 1 [2030/3978 (51%)]\tLoss: 0.703223\n",
            "Train Epoch: 1 [2035/3978 (51%)]\tLoss: 1.169843\n",
            "Train Epoch: 1 [2040/3978 (51%)]\tLoss: 0.428853\n",
            "Train Epoch: 1 [2045/3978 (51%)]\tLoss: 0.370949\n",
            "Train Epoch: 1 [2050/3978 (52%)]\tLoss: 0.500165\n",
            "Train Epoch: 1 [2055/3978 (52%)]\tLoss: 0.667676\n",
            "Train Epoch: 1 [2060/3978 (52%)]\tLoss: 0.442878\n",
            "Train Epoch: 1 [2065/3978 (52%)]\tLoss: 0.551048\n",
            "Train Epoch: 1 [2070/3978 (52%)]\tLoss: 0.455799\n",
            "Train Epoch: 1 [2075/3978 (52%)]\tLoss: 0.377363\n",
            "Train Epoch: 1 [2080/3978 (52%)]\tLoss: 0.197234\n",
            "Train Epoch: 1 [2085/3978 (52%)]\tLoss: 0.167864\n",
            "Train Epoch: 1 [2090/3978 (53%)]\tLoss: 0.459852\n",
            "Train Epoch: 1 [2095/3978 (53%)]\tLoss: 0.455822\n",
            "Train Epoch: 1 [2100/3978 (53%)]\tLoss: 0.433166\n",
            "Train Epoch: 1 [2105/3978 (53%)]\tLoss: 0.455783\n",
            "Train Epoch: 1 [2110/3978 (53%)]\tLoss: 1.077218\n",
            "Train Epoch: 1 [2115/3978 (53%)]\tLoss: 0.219399\n",
            "Train Epoch: 1 [2120/3978 (53%)]\tLoss: 0.195699\n",
            "Train Epoch: 1 [2125/3978 (53%)]\tLoss: 0.350670\n",
            "Train Epoch: 1 [2130/3978 (54%)]\tLoss: 0.587498\n",
            "Train Epoch: 1 [2135/3978 (54%)]\tLoss: 0.487607\n",
            "Train Epoch: 1 [2140/3978 (54%)]\tLoss: 0.140761\n",
            "Train Epoch: 1 [2145/3978 (54%)]\tLoss: 0.142917\n",
            "Train Epoch: 1 [2150/3978 (54%)]\tLoss: 0.548058\n",
            "Train Epoch: 1 [2155/3978 (54%)]\tLoss: 0.025829\n",
            "Train Epoch: 1 [2160/3978 (54%)]\tLoss: 0.227135\n",
            "Train Epoch: 1 [2165/3978 (54%)]\tLoss: 0.303893\n",
            "Train Epoch: 1 [2170/3978 (55%)]\tLoss: 0.289831\n",
            "Train Epoch: 1 [2175/3978 (55%)]\tLoss: 0.027378\n",
            "Train Epoch: 1 [2180/3978 (55%)]\tLoss: 1.089217\n",
            "Train Epoch: 1 [2185/3978 (55%)]\tLoss: 0.021722\n",
            "Train Epoch: 1 [2190/3978 (55%)]\tLoss: 0.331215\n",
            "Train Epoch: 1 [2195/3978 (55%)]\tLoss: 0.318782\n",
            "Train Epoch: 1 [2200/3978 (55%)]\tLoss: 0.339465\n",
            "Train Epoch: 1 [2205/3978 (55%)]\tLoss: 0.723869\n",
            "Train Epoch: 1 [2210/3978 (56%)]\tLoss: 0.042272\n",
            "Train Epoch: 1 [2215/3978 (56%)]\tLoss: 0.907687\n",
            "Train Epoch: 1 [2220/3978 (56%)]\tLoss: 0.629377\n",
            "Train Epoch: 1 [2225/3978 (56%)]\tLoss: 0.201158\n",
            "Train Epoch: 1 [2230/3978 (56%)]\tLoss: 0.439873\n",
            "Train Epoch: 1 [2235/3978 (56%)]\tLoss: 0.217080\n",
            "Train Epoch: 1 [2240/3978 (56%)]\tLoss: 0.150349\n",
            "Train Epoch: 1 [2245/3978 (56%)]\tLoss: 0.139453\n",
            "Train Epoch: 1 [2250/3978 (57%)]\tLoss: 0.646275\n",
            "Train Epoch: 1 [2255/3978 (57%)]\tLoss: 0.178465\n",
            "Train Epoch: 1 [2260/3978 (57%)]\tLoss: 0.612841\n",
            "Train Epoch: 1 [2265/3978 (57%)]\tLoss: 0.817409\n",
            "Train Epoch: 1 [2270/3978 (57%)]\tLoss: 0.138305\n",
            "Train Epoch: 1 [2275/3978 (57%)]\tLoss: 0.576752\n",
            "Train Epoch: 1 [2280/3978 (57%)]\tLoss: 0.112471\n",
            "Train Epoch: 1 [2285/3978 (57%)]\tLoss: 0.999132\n",
            "Train Epoch: 1 [2290/3978 (58%)]\tLoss: 0.624113\n",
            "Train Epoch: 1 [2295/3978 (58%)]\tLoss: 0.466354\n",
            "Train Epoch: 1 [2300/3978 (58%)]\tLoss: 0.465653\n",
            "Train Epoch: 1 [2305/3978 (58%)]\tLoss: 0.026633\n",
            "Train Epoch: 1 [2310/3978 (58%)]\tLoss: 0.595327\n",
            "Train Epoch: 1 [2315/3978 (58%)]\tLoss: 0.811096\n",
            "Train Epoch: 1 [2320/3978 (58%)]\tLoss: 0.085040\n",
            "Train Epoch: 1 [2325/3978 (58%)]\tLoss: 0.261099\n",
            "Train Epoch: 1 [2330/3978 (59%)]\tLoss: 0.086966\n",
            "Train Epoch: 1 [2335/3978 (59%)]\tLoss: 0.179005\n",
            "Train Epoch: 1 [2340/3978 (59%)]\tLoss: 0.269395\n",
            "Train Epoch: 1 [2345/3978 (59%)]\tLoss: 0.266068\n",
            "Train Epoch: 1 [2350/3978 (59%)]\tLoss: 0.757437\n",
            "Train Epoch: 1 [2355/3978 (59%)]\tLoss: 0.423187\n",
            "Train Epoch: 1 [2360/3978 (59%)]\tLoss: 0.146517\n",
            "Train Epoch: 1 [2365/3978 (59%)]\tLoss: 0.262765\n",
            "Train Epoch: 1 [2370/3978 (60%)]\tLoss: 0.197531\n",
            "Train Epoch: 1 [2375/3978 (60%)]\tLoss: 0.487100\n",
            "Train Epoch: 1 [2380/3978 (60%)]\tLoss: 0.887536\n",
            "Train Epoch: 1 [2385/3978 (60%)]\tLoss: 0.647648\n",
            "Train Epoch: 1 [2390/3978 (60%)]\tLoss: 0.069920\n",
            "Train Epoch: 1 [2395/3978 (60%)]\tLoss: 0.983466\n",
            "Train Epoch: 1 [2400/3978 (60%)]\tLoss: 0.400472\n",
            "Train Epoch: 1 [2405/3978 (60%)]\tLoss: 0.166870\n",
            "Train Epoch: 1 [2410/3978 (61%)]\tLoss: 0.056908\n",
            "Train Epoch: 1 [2415/3978 (61%)]\tLoss: 0.067915\n",
            "Train Epoch: 1 [2420/3978 (61%)]\tLoss: 0.534255\n",
            "Train Epoch: 1 [2425/3978 (61%)]\tLoss: 0.763007\n",
            "Train Epoch: 1 [2430/3978 (61%)]\tLoss: 0.119857\n",
            "Train Epoch: 1 [2435/3978 (61%)]\tLoss: 0.340603\n",
            "Train Epoch: 1 [2440/3978 (61%)]\tLoss: 0.053440\n",
            "Train Epoch: 1 [2445/3978 (61%)]\tLoss: 0.067290\n",
            "Train Epoch: 1 [2450/3978 (62%)]\tLoss: 0.324717\n",
            "Train Epoch: 1 [2455/3978 (62%)]\tLoss: 0.213379\n",
            "Train Epoch: 1 [2460/3978 (62%)]\tLoss: 0.129509\n",
            "Train Epoch: 1 [2465/3978 (62%)]\tLoss: 0.380159\n",
            "Train Epoch: 1 [2470/3978 (62%)]\tLoss: 0.060297\n",
            "Train Epoch: 1 [2475/3978 (62%)]\tLoss: 0.682127\n",
            "Train Epoch: 1 [2480/3978 (62%)]\tLoss: 0.781840\n",
            "Train Epoch: 1 [2485/3978 (62%)]\tLoss: 0.417987\n",
            "Train Epoch: 1 [2490/3978 (63%)]\tLoss: 0.446272\n",
            "Train Epoch: 1 [2495/3978 (63%)]\tLoss: 0.133937\n",
            "Train Epoch: 1 [2500/3978 (63%)]\tLoss: 0.145666\n",
            "Train Epoch: 1 [2505/3978 (63%)]\tLoss: 0.504994\n",
            "Train Epoch: 1 [2510/3978 (63%)]\tLoss: 0.409969\n",
            "Train Epoch: 1 [2515/3978 (63%)]\tLoss: 0.542286\n",
            "Train Epoch: 1 [2520/3978 (63%)]\tLoss: 0.109445\n",
            "Train Epoch: 1 [2525/3978 (63%)]\tLoss: 0.188841\n",
            "Train Epoch: 1 [2530/3978 (64%)]\tLoss: 0.318465\n",
            "Train Epoch: 1 [2535/3978 (64%)]\tLoss: 0.213554\n",
            "Train Epoch: 1 [2540/3978 (64%)]\tLoss: 0.117180\n",
            "Train Epoch: 1 [2545/3978 (64%)]\tLoss: 0.236692\n",
            "Train Epoch: 1 [2550/3978 (64%)]\tLoss: 0.660111\n",
            "Train Epoch: 1 [2555/3978 (64%)]\tLoss: 0.119611\n",
            "Train Epoch: 1 [2560/3978 (64%)]\tLoss: 0.112889\n",
            "Train Epoch: 1 [2565/3978 (64%)]\tLoss: 0.062061\n",
            "Train Epoch: 1 [2570/3978 (65%)]\tLoss: 0.247963\n",
            "Train Epoch: 1 [2575/3978 (65%)]\tLoss: 0.283347\n",
            "Train Epoch: 1 [2580/3978 (65%)]\tLoss: 0.414907\n",
            "Train Epoch: 1 [2585/3978 (65%)]\tLoss: 0.261040\n",
            "Train Epoch: 1 [2590/3978 (65%)]\tLoss: 0.096463\n",
            "Train Epoch: 1 [2595/3978 (65%)]\tLoss: 0.279049\n",
            "Train Epoch: 1 [2600/3978 (65%)]\tLoss: 0.528597\n",
            "Train Epoch: 1 [2605/3978 (65%)]\tLoss: 0.091830\n",
            "Train Epoch: 1 [2610/3978 (66%)]\tLoss: 0.110011\n",
            "Train Epoch: 1 [2615/3978 (66%)]\tLoss: 0.093171\n",
            "Train Epoch: 1 [2620/3978 (66%)]\tLoss: 0.116510\n",
            "Train Epoch: 1 [2625/3978 (66%)]\tLoss: 0.584985\n",
            "Train Epoch: 1 [2630/3978 (66%)]\tLoss: 0.692845\n",
            "Train Epoch: 1 [2635/3978 (66%)]\tLoss: 0.522668\n",
            "Train Epoch: 1 [2640/3978 (66%)]\tLoss: 0.010330\n",
            "Train Epoch: 1 [2645/3978 (66%)]\tLoss: 0.664307\n",
            "Train Epoch: 1 [2650/3978 (67%)]\tLoss: 0.647673\n",
            "Train Epoch: 1 [2655/3978 (67%)]\tLoss: 0.717462\n",
            "Train Epoch: 1 [2660/3978 (67%)]\tLoss: 0.722578\n",
            "Train Epoch: 1 [2665/3978 (67%)]\tLoss: 0.454277\n",
            "Train Epoch: 1 [2670/3978 (67%)]\tLoss: 0.088995\n",
            "Train Epoch: 1 [2675/3978 (67%)]\tLoss: 0.574965\n",
            "Train Epoch: 1 [2680/3978 (67%)]\tLoss: 0.071420\n",
            "Train Epoch: 1 [2685/3978 (67%)]\tLoss: 0.509383\n",
            "Train Epoch: 1 [2690/3978 (68%)]\tLoss: 0.347641\n",
            "Train Epoch: 1 [2695/3978 (68%)]\tLoss: 0.342740\n",
            "Train Epoch: 1 [2700/3978 (68%)]\tLoss: 0.813143\n",
            "Train Epoch: 1 [2705/3978 (68%)]\tLoss: 0.172601\n",
            "Train Epoch: 1 [2710/3978 (68%)]\tLoss: 0.196399\n",
            "Train Epoch: 1 [2715/3978 (68%)]\tLoss: 0.557068\n",
            "Train Epoch: 1 [2720/3978 (68%)]\tLoss: 0.186803\n",
            "Train Epoch: 1 [2725/3978 (68%)]\tLoss: 0.254911\n",
            "Train Epoch: 1 [2730/3978 (69%)]\tLoss: 0.577501\n",
            "Train Epoch: 1 [2735/3978 (69%)]\tLoss: 0.249557\n",
            "Train Epoch: 1 [2740/3978 (69%)]\tLoss: 0.223770\n",
            "Train Epoch: 1 [2745/3978 (69%)]\tLoss: 0.443313\n",
            "Train Epoch: 1 [2750/3978 (69%)]\tLoss: 0.379330\n",
            "Train Epoch: 1 [2755/3978 (69%)]\tLoss: 0.452818\n",
            "Train Epoch: 1 [2760/3978 (69%)]\tLoss: 0.395806\n",
            "Train Epoch: 1 [2765/3978 (69%)]\tLoss: 0.081810\n",
            "Train Epoch: 1 [2770/3978 (70%)]\tLoss: 0.184735\n",
            "Train Epoch: 1 [2775/3978 (70%)]\tLoss: 0.280663\n",
            "Train Epoch: 1 [2780/3978 (70%)]\tLoss: 0.345679\n",
            "Train Epoch: 1 [2785/3978 (70%)]\tLoss: 0.327167\n",
            "Train Epoch: 1 [2790/3978 (70%)]\tLoss: 0.035187\n",
            "Train Epoch: 1 [2795/3978 (70%)]\tLoss: 0.141621\n",
            "Train Epoch: 1 [2800/3978 (70%)]\tLoss: 0.341733\n",
            "Train Epoch: 1 [2805/3978 (70%)]\tLoss: 0.316136\n",
            "Train Epoch: 1 [2810/3978 (71%)]\tLoss: 0.640322\n",
            "Train Epoch: 1 [2815/3978 (71%)]\tLoss: 0.286801\n",
            "Train Epoch: 1 [2820/3978 (71%)]\tLoss: 0.320334\n",
            "Train Epoch: 1 [2825/3978 (71%)]\tLoss: 0.375017\n",
            "Train Epoch: 1 [2830/3978 (71%)]\tLoss: 0.608263\n",
            "Train Epoch: 1 [2835/3978 (71%)]\tLoss: 0.777706\n",
            "Train Epoch: 1 [2840/3978 (71%)]\tLoss: 0.172470\n",
            "Train Epoch: 1 [2845/3978 (71%)]\tLoss: 0.299756\n",
            "Train Epoch: 1 [2850/3978 (72%)]\tLoss: 0.519194\n",
            "Train Epoch: 1 [2855/3978 (72%)]\tLoss: 0.183161\n",
            "Train Epoch: 1 [2860/3978 (72%)]\tLoss: 0.271434\n",
            "Train Epoch: 1 [2865/3978 (72%)]\tLoss: 0.449145\n",
            "Train Epoch: 1 [2870/3978 (72%)]\tLoss: 0.679795\n",
            "Train Epoch: 1 [2875/3978 (72%)]\tLoss: 0.084565\n",
            "Train Epoch: 1 [2880/3978 (72%)]\tLoss: 1.096402\n",
            "Train Epoch: 1 [2885/3978 (72%)]\tLoss: 0.334894\n",
            "Train Epoch: 1 [2890/3978 (73%)]\tLoss: 0.836895\n",
            "Train Epoch: 1 [2895/3978 (73%)]\tLoss: 0.661290\n",
            "Train Epoch: 1 [2900/3978 (73%)]\tLoss: 0.180273\n",
            "Train Epoch: 1 [2905/3978 (73%)]\tLoss: 0.217847\n",
            "Train Epoch: 1 [2910/3978 (73%)]\tLoss: 0.064963\n",
            "Train Epoch: 1 [2915/3978 (73%)]\tLoss: 0.241585\n",
            "Train Epoch: 1 [2920/3978 (73%)]\tLoss: 0.059264\n",
            "Train Epoch: 1 [2925/3978 (73%)]\tLoss: 0.373221\n",
            "Train Epoch: 1 [2930/3978 (74%)]\tLoss: 0.373530\n",
            "Train Epoch: 1 [2935/3978 (74%)]\tLoss: 0.292648\n",
            "Train Epoch: 1 [2940/3978 (74%)]\tLoss: 0.385083\n",
            "Train Epoch: 1 [2945/3978 (74%)]\tLoss: 0.064173\n",
            "Train Epoch: 1 [2950/3978 (74%)]\tLoss: 0.448334\n",
            "Train Epoch: 1 [2955/3978 (74%)]\tLoss: 0.489349\n",
            "Train Epoch: 1 [2960/3978 (74%)]\tLoss: 0.533874\n",
            "Train Epoch: 1 [2965/3978 (74%)]\tLoss: 0.822366\n",
            "Train Epoch: 1 [2970/3978 (75%)]\tLoss: 0.640200\n",
            "Train Epoch: 1 [2975/3978 (75%)]\tLoss: 0.190436\n",
            "Train Epoch: 1 [2980/3978 (75%)]\tLoss: 0.221601\n",
            "Train Epoch: 1 [2985/3978 (75%)]\tLoss: 0.999167\n",
            "Train Epoch: 1 [2990/3978 (75%)]\tLoss: 0.164461\n",
            "Train Epoch: 1 [2995/3978 (75%)]\tLoss: 0.485846\n",
            "Train Epoch: 1 [3000/3978 (75%)]\tLoss: 0.231636\n",
            "Train Epoch: 1 [3005/3978 (76%)]\tLoss: 0.457969\n",
            "Train Epoch: 1 [3010/3978 (76%)]\tLoss: 0.154480\n",
            "Train Epoch: 1 [3015/3978 (76%)]\tLoss: 0.577643\n",
            "Train Epoch: 1 [3020/3978 (76%)]\tLoss: 0.274127\n",
            "Train Epoch: 1 [3025/3978 (76%)]\tLoss: 0.138340\n",
            "Train Epoch: 1 [3030/3978 (76%)]\tLoss: 0.366787\n",
            "Train Epoch: 1 [3035/3978 (76%)]\tLoss: 0.221599\n",
            "Train Epoch: 1 [3040/3978 (76%)]\tLoss: 0.113450\n",
            "Train Epoch: 1 [3045/3978 (77%)]\tLoss: 0.433590\n",
            "Train Epoch: 1 [3050/3978 (77%)]\tLoss: 0.136872\n",
            "Train Epoch: 1 [3055/3978 (77%)]\tLoss: 0.468540\n",
            "Train Epoch: 1 [3060/3978 (77%)]\tLoss: 0.200103\n",
            "Train Epoch: 1 [3065/3978 (77%)]\tLoss: 0.110970\n",
            "Train Epoch: 1 [3070/3978 (77%)]\tLoss: 0.094227\n",
            "Train Epoch: 1 [3075/3978 (77%)]\tLoss: 0.119575\n",
            "Train Epoch: 1 [3080/3978 (77%)]\tLoss: 0.177605\n",
            "Train Epoch: 1 [3085/3978 (78%)]\tLoss: 0.119965\n",
            "Train Epoch: 1 [3090/3978 (78%)]\tLoss: 0.062950\n",
            "Train Epoch: 1 [3095/3978 (78%)]\tLoss: 0.376901\n",
            "Train Epoch: 1 [3100/3978 (78%)]\tLoss: 0.229026\n",
            "Train Epoch: 1 [3105/3978 (78%)]\tLoss: 0.047451\n",
            "Train Epoch: 1 [3110/3978 (78%)]\tLoss: 0.825788\n",
            "Train Epoch: 1 [3115/3978 (78%)]\tLoss: 0.434828\n",
            "Train Epoch: 1 [3120/3978 (78%)]\tLoss: 0.210353\n",
            "Train Epoch: 1 [3125/3978 (79%)]\tLoss: 0.598982\n",
            "Train Epoch: 1 [3130/3978 (79%)]\tLoss: 0.911683\n",
            "Train Epoch: 1 [3135/3978 (79%)]\tLoss: 0.202056\n",
            "Train Epoch: 1 [3140/3978 (79%)]\tLoss: 0.270363\n",
            "Train Epoch: 1 [3145/3978 (79%)]\tLoss: 0.154444\n",
            "Train Epoch: 1 [3150/3978 (79%)]\tLoss: 0.586546\n",
            "Train Epoch: 1 [3155/3978 (79%)]\tLoss: 0.096444\n",
            "Train Epoch: 1 [3160/3978 (79%)]\tLoss: 0.447407\n",
            "Train Epoch: 1 [3165/3978 (80%)]\tLoss: 0.267910\n",
            "Train Epoch: 1 [3170/3978 (80%)]\tLoss: 0.783684\n",
            "Train Epoch: 1 [3175/3978 (80%)]\tLoss: 0.239526\n",
            "Train Epoch: 1 [3180/3978 (80%)]\tLoss: 0.322927\n",
            "Train Epoch: 1 [3185/3978 (80%)]\tLoss: 0.427739\n",
            "Train Epoch: 1 [3190/3978 (80%)]\tLoss: 0.551669\n",
            "Train Epoch: 1 [3195/3978 (80%)]\tLoss: 0.212400\n",
            "Train Epoch: 1 [3200/3978 (80%)]\tLoss: 0.279817\n",
            "Train Epoch: 1 [3205/3978 (81%)]\tLoss: 0.184329\n",
            "Train Epoch: 1 [3210/3978 (81%)]\tLoss: 0.343249\n",
            "Train Epoch: 1 [3215/3978 (81%)]\tLoss: 0.299084\n",
            "Train Epoch: 1 [3220/3978 (81%)]\tLoss: 0.097038\n",
            "Train Epoch: 1 [3225/3978 (81%)]\tLoss: 0.648620\n",
            "Train Epoch: 1 [3230/3978 (81%)]\tLoss: 0.465436\n",
            "Train Epoch: 1 [3235/3978 (81%)]\tLoss: 0.149609\n",
            "Train Epoch: 1 [3240/3978 (81%)]\tLoss: 0.449398\n",
            "Train Epoch: 1 [3245/3978 (82%)]\tLoss: 0.383135\n",
            "Train Epoch: 1 [3250/3978 (82%)]\tLoss: 0.157966\n",
            "Train Epoch: 1 [3255/3978 (82%)]\tLoss: 0.312365\n",
            "Train Epoch: 1 [3260/3978 (82%)]\tLoss: 0.360602\n",
            "Train Epoch: 1 [3265/3978 (82%)]\tLoss: 0.495486\n",
            "Train Epoch: 1 [3270/3978 (82%)]\tLoss: 0.180890\n",
            "Train Epoch: 1 [3275/3978 (82%)]\tLoss: 0.603695\n",
            "Train Epoch: 1 [3280/3978 (82%)]\tLoss: 0.303385\n",
            "Train Epoch: 1 [3285/3978 (83%)]\tLoss: 0.713896\n",
            "Train Epoch: 1 [3290/3978 (83%)]\tLoss: 0.688918\n",
            "Train Epoch: 1 [3295/3978 (83%)]\tLoss: 0.311519\n",
            "Train Epoch: 1 [3300/3978 (83%)]\tLoss: 0.063861\n",
            "Train Epoch: 1 [3305/3978 (83%)]\tLoss: 0.926025\n",
            "Train Epoch: 1 [3310/3978 (83%)]\tLoss: 0.508141\n",
            "Train Epoch: 1 [3315/3978 (83%)]\tLoss: 0.211562\n",
            "Train Epoch: 1 [3320/3978 (83%)]\tLoss: 0.328941\n",
            "Train Epoch: 1 [3325/3978 (84%)]\tLoss: 0.456287\n",
            "Train Epoch: 1 [3330/3978 (84%)]\tLoss: 0.402413\n",
            "Train Epoch: 1 [3335/3978 (84%)]\tLoss: 0.217418\n",
            "Train Epoch: 1 [3340/3978 (84%)]\tLoss: 0.121274\n",
            "Train Epoch: 1 [3345/3978 (84%)]\tLoss: 0.156449\n",
            "Train Epoch: 1 [3350/3978 (84%)]\tLoss: 0.209459\n",
            "Train Epoch: 1 [3355/3978 (84%)]\tLoss: 0.276051\n",
            "Train Epoch: 1 [3360/3978 (84%)]\tLoss: 0.057440\n",
            "Train Epoch: 1 [3365/3978 (85%)]\tLoss: 0.508220\n",
            "Train Epoch: 1 [3370/3978 (85%)]\tLoss: 0.097522\n",
            "Train Epoch: 1 [3375/3978 (85%)]\tLoss: 0.427102\n",
            "Train Epoch: 1 [3380/3978 (85%)]\tLoss: 0.433163\n",
            "Train Epoch: 1 [3385/3978 (85%)]\tLoss: 0.400330\n",
            "Train Epoch: 1 [3390/3978 (85%)]\tLoss: 0.284287\n",
            "Train Epoch: 1 [3395/3978 (85%)]\tLoss: 1.046996\n",
            "Train Epoch: 1 [3400/3978 (85%)]\tLoss: 0.672759\n",
            "Train Epoch: 1 [3405/3978 (86%)]\tLoss: 0.182115\n",
            "Train Epoch: 1 [3410/3978 (86%)]\tLoss: 0.118698\n",
            "Train Epoch: 1 [3415/3978 (86%)]\tLoss: 0.582066\n",
            "Train Epoch: 1 [3420/3978 (86%)]\tLoss: 0.134525\n",
            "Train Epoch: 1 [3425/3978 (86%)]\tLoss: 0.664499\n",
            "Train Epoch: 1 [3430/3978 (86%)]\tLoss: 0.127562\n",
            "Train Epoch: 1 [3435/3978 (86%)]\tLoss: 0.309551\n",
            "Train Epoch: 1 [3440/3978 (86%)]\tLoss: 0.572107\n",
            "Train Epoch: 1 [3445/3978 (87%)]\tLoss: 0.119281\n",
            "Train Epoch: 1 [3450/3978 (87%)]\tLoss: 0.399206\n",
            "Train Epoch: 1 [3455/3978 (87%)]\tLoss: 0.584369\n",
            "Train Epoch: 1 [3460/3978 (87%)]\tLoss: 0.399950\n",
            "Train Epoch: 1 [3465/3978 (87%)]\tLoss: 0.972820\n",
            "Train Epoch: 1 [3470/3978 (87%)]\tLoss: 0.286052\n",
            "Train Epoch: 1 [3475/3978 (87%)]\tLoss: 0.233548\n",
            "Train Epoch: 1 [3480/3978 (87%)]\tLoss: 0.701616\n",
            "Train Epoch: 1 [3485/3978 (88%)]\tLoss: 0.026449\n",
            "Train Epoch: 1 [3490/3978 (88%)]\tLoss: 0.432424\n",
            "Train Epoch: 1 [3495/3978 (88%)]\tLoss: 0.731697\n",
            "Train Epoch: 1 [3500/3978 (88%)]\tLoss: 0.723329\n",
            "Train Epoch: 1 [3505/3978 (88%)]\tLoss: 0.119022\n",
            "Train Epoch: 1 [3510/3978 (88%)]\tLoss: 0.194582\n",
            "Train Epoch: 1 [3515/3978 (88%)]\tLoss: 1.056934\n",
            "Train Epoch: 1 [3520/3978 (88%)]\tLoss: 0.139549\n",
            "Train Epoch: 1 [3525/3978 (89%)]\tLoss: 0.836031\n",
            "Train Epoch: 1 [3530/3978 (89%)]\tLoss: 0.144411\n",
            "Train Epoch: 1 [3535/3978 (89%)]\tLoss: 0.370180\n",
            "Train Epoch: 1 [3540/3978 (89%)]\tLoss: 0.301802\n",
            "Train Epoch: 1 [3545/3978 (89%)]\tLoss: 0.156240\n",
            "Train Epoch: 1 [3550/3978 (89%)]\tLoss: 0.410736\n",
            "Train Epoch: 1 [3555/3978 (89%)]\tLoss: 0.374674\n",
            "Train Epoch: 1 [3560/3978 (89%)]\tLoss: 0.236052\n",
            "Train Epoch: 1 [3565/3978 (90%)]\tLoss: 0.860560\n",
            "Train Epoch: 1 [3570/3978 (90%)]\tLoss: 0.136472\n",
            "Train Epoch: 1 [3575/3978 (90%)]\tLoss: 0.082388\n",
            "Train Epoch: 1 [3580/3978 (90%)]\tLoss: 0.894455\n",
            "Train Epoch: 1 [3585/3978 (90%)]\tLoss: 0.217161\n",
            "Train Epoch: 1 [3590/3978 (90%)]\tLoss: 0.097986\n",
            "Train Epoch: 1 [3595/3978 (90%)]\tLoss: 0.181473\n",
            "Train Epoch: 1 [3600/3978 (90%)]\tLoss: 0.384053\n",
            "Train Epoch: 1 [3605/3978 (91%)]\tLoss: 0.091660\n",
            "Train Epoch: 1 [3610/3978 (91%)]\tLoss: 0.099236\n",
            "Train Epoch: 1 [3615/3978 (91%)]\tLoss: 0.119792\n",
            "Train Epoch: 1 [3620/3978 (91%)]\tLoss: 0.303216\n",
            "Train Epoch: 1 [3625/3978 (91%)]\tLoss: 0.129083\n",
            "Train Epoch: 1 [3630/3978 (91%)]\tLoss: 0.141237\n",
            "Train Epoch: 1 [3635/3978 (91%)]\tLoss: 0.120811\n",
            "Train Epoch: 1 [3640/3978 (91%)]\tLoss: 0.138524\n",
            "Train Epoch: 1 [3645/3978 (92%)]\tLoss: 0.415830\n",
            "Train Epoch: 1 [3650/3978 (92%)]\tLoss: 0.337272\n",
            "Train Epoch: 1 [3655/3978 (92%)]\tLoss: 0.053376\n",
            "Train Epoch: 1 [3660/3978 (92%)]\tLoss: 0.638689\n",
            "Train Epoch: 1 [3665/3978 (92%)]\tLoss: 0.545517\n",
            "Train Epoch: 1 [3670/3978 (92%)]\tLoss: 0.846868\n",
            "Train Epoch: 1 [3675/3978 (92%)]\tLoss: 0.165128\n",
            "Train Epoch: 1 [3680/3978 (92%)]\tLoss: 0.368197\n",
            "Train Epoch: 1 [3685/3978 (93%)]\tLoss: 0.064790\n",
            "Train Epoch: 1 [3690/3978 (93%)]\tLoss: 0.045037\n",
            "Train Epoch: 1 [3695/3978 (93%)]\tLoss: 0.200623\n",
            "Train Epoch: 1 [3700/3978 (93%)]\tLoss: 0.106678\n",
            "Train Epoch: 1 [3705/3978 (93%)]\tLoss: 0.253291\n",
            "Train Epoch: 1 [3710/3978 (93%)]\tLoss: 0.046845\n",
            "Train Epoch: 1 [3715/3978 (93%)]\tLoss: 0.481828\n",
            "Train Epoch: 1 [3720/3978 (93%)]\tLoss: 0.296279\n",
            "Train Epoch: 1 [3725/3978 (94%)]\tLoss: 0.151513\n",
            "Train Epoch: 1 [3730/3978 (94%)]\tLoss: 0.095403\n",
            "Train Epoch: 1 [3735/3978 (94%)]\tLoss: 0.753242\n",
            "Train Epoch: 1 [3740/3978 (94%)]\tLoss: 0.216608\n",
            "Train Epoch: 1 [3745/3978 (94%)]\tLoss: 0.462973\n",
            "Train Epoch: 1 [3750/3978 (94%)]\tLoss: 1.176835\n",
            "Train Epoch: 1 [3755/3978 (94%)]\tLoss: 0.246952\n",
            "Train Epoch: 1 [3760/3978 (94%)]\tLoss: 0.279220\n",
            "Train Epoch: 1 [3765/3978 (95%)]\tLoss: 0.259775\n",
            "Train Epoch: 1 [3770/3978 (95%)]\tLoss: 0.486044\n",
            "Train Epoch: 1 [3775/3978 (95%)]\tLoss: 0.257859\n",
            "Train Epoch: 1 [3780/3978 (95%)]\tLoss: 1.108817\n",
            "Train Epoch: 1 [3785/3978 (95%)]\tLoss: 0.248860\n",
            "Train Epoch: 1 [3790/3978 (95%)]\tLoss: 0.175698\n",
            "Train Epoch: 1 [3795/3978 (95%)]\tLoss: 0.535024\n",
            "Train Epoch: 1 [3800/3978 (95%)]\tLoss: 0.107830\n",
            "Train Epoch: 1 [3805/3978 (96%)]\tLoss: 0.205818\n",
            "Train Epoch: 1 [3810/3978 (96%)]\tLoss: 0.142016\n",
            "Train Epoch: 1 [3815/3978 (96%)]\tLoss: 0.395118\n",
            "Train Epoch: 1 [3820/3978 (96%)]\tLoss: 0.178983\n",
            "Train Epoch: 1 [3825/3978 (96%)]\tLoss: 0.353775\n",
            "Train Epoch: 1 [3830/3978 (96%)]\tLoss: 0.514831\n",
            "Train Epoch: 1 [3835/3978 (96%)]\tLoss: 0.078756\n",
            "Train Epoch: 1 [3840/3978 (96%)]\tLoss: 0.061407\n",
            "Train Epoch: 1 [3845/3978 (97%)]\tLoss: 0.149559\n",
            "Train Epoch: 1 [3850/3978 (97%)]\tLoss: 0.670115\n",
            "Train Epoch: 1 [3855/3978 (97%)]\tLoss: 0.145195\n",
            "Train Epoch: 1 [3860/3978 (97%)]\tLoss: 0.243632\n",
            "Train Epoch: 1 [3865/3978 (97%)]\tLoss: 0.405031\n",
            "Train Epoch: 1 [3870/3978 (97%)]\tLoss: 0.875215\n",
            "Train Epoch: 1 [3875/3978 (97%)]\tLoss: 0.082157\n",
            "Train Epoch: 1 [3880/3978 (97%)]\tLoss: 0.144411\n",
            "Train Epoch: 1 [3885/3978 (98%)]\tLoss: 0.074220\n",
            "Train Epoch: 1 [3890/3978 (98%)]\tLoss: 0.714760\n",
            "Train Epoch: 1 [3895/3978 (98%)]\tLoss: 0.334420\n",
            "Train Epoch: 1 [3900/3978 (98%)]\tLoss: 0.244518\n",
            "Train Epoch: 1 [3905/3978 (98%)]\tLoss: 0.178420\n",
            "Train Epoch: 1 [3910/3978 (98%)]\tLoss: 0.018174\n",
            "Train Epoch: 1 [3915/3978 (98%)]\tLoss: 0.314404\n",
            "Train Epoch: 1 [3920/3978 (98%)]\tLoss: 0.745093\n",
            "Train Epoch: 1 [3925/3978 (99%)]\tLoss: 0.355469\n",
            "Train Epoch: 1 [3930/3978 (99%)]\tLoss: 0.254510\n",
            "Train Epoch: 1 [3935/3978 (99%)]\tLoss: 0.440547\n",
            "Train Epoch: 1 [3940/3978 (99%)]\tLoss: 0.570300\n",
            "Train Epoch: 1 [3945/3978 (99%)]\tLoss: 0.558357\n",
            "Train Epoch: 1 [3950/3978 (99%)]\tLoss: 0.598846\n",
            "Train Epoch: 1 [3955/3978 (99%)]\tLoss: 0.326358\n",
            "Train Epoch: 1 [3960/3978 (99%)]\tLoss: 0.134661\n",
            "Train Epoch: 1 [3965/3978 (100%)]\tLoss: 0.073309\n",
            "Train Epoch: 1 [3970/3978 (100%)]\tLoss: 0.076165\n",
            "Train Epoch: 1 [2385/3978 (100%)]\tLoss: 0.039848\n",
            "Epoch\n",
            "train/train_loss: 0.0398484505712986\n",
            "\n",
            "Train Loss: 0.040, Valid Loss: 0.428167, Accuracy: 0.36\n",
            "Train Epoch: 2 [0/3978 (0%)]\tLoss: 0.096144\n",
            "Train Epoch: 2 [5/3978 (0%)]\tLoss: 0.335027\n",
            "Train Epoch: 2 [10/3978 (0%)]\tLoss: 0.231516\n",
            "Train Epoch: 2 [15/3978 (0%)]\tLoss: 0.210794\n",
            "Train Epoch: 2 [20/3978 (1%)]\tLoss: 0.628205\n",
            "Train Epoch: 2 [25/3978 (1%)]\tLoss: 0.316929\n",
            "Train Epoch: 2 [30/3978 (1%)]\tLoss: 0.320161\n",
            "Train Epoch: 2 [35/3978 (1%)]\tLoss: 0.273234\n",
            "Train Epoch: 2 [40/3978 (1%)]\tLoss: 0.762748\n",
            "Train Epoch: 2 [45/3978 (1%)]\tLoss: 1.070231\n",
            "Train Epoch: 2 [50/3978 (1%)]\tLoss: 0.076548\n",
            "Train Epoch: 2 [55/3978 (1%)]\tLoss: 0.152513\n",
            "Train Epoch: 2 [60/3978 (2%)]\tLoss: 0.096413\n",
            "Train Epoch: 2 [65/3978 (2%)]\tLoss: 0.108943\n",
            "Train Epoch: 2 [70/3978 (2%)]\tLoss: 0.062257\n",
            "Train Epoch: 2 [75/3978 (2%)]\tLoss: 0.439948\n",
            "Train Epoch: 2 [80/3978 (2%)]\tLoss: 0.350589\n",
            "Train Epoch: 2 [85/3978 (2%)]\tLoss: 0.111841\n",
            "Train Epoch: 2 [90/3978 (2%)]\tLoss: 0.237160\n",
            "Train Epoch: 2 [95/3978 (2%)]\tLoss: 0.449754\n",
            "Train Epoch: 2 [100/3978 (3%)]\tLoss: 0.446930\n",
            "Train Epoch: 2 [105/3978 (3%)]\tLoss: 0.314334\n",
            "Train Epoch: 2 [110/3978 (3%)]\tLoss: 0.189153\n",
            "Train Epoch: 2 [115/3978 (3%)]\tLoss: 0.167481\n",
            "Train Epoch: 2 [120/3978 (3%)]\tLoss: 0.583781\n",
            "Train Epoch: 2 [125/3978 (3%)]\tLoss: 0.853924\n",
            "Train Epoch: 2 [130/3978 (3%)]\tLoss: 0.432235\n",
            "Train Epoch: 2 [135/3978 (3%)]\tLoss: 0.086900\n",
            "Train Epoch: 2 [140/3978 (4%)]\tLoss: 0.169115\n",
            "Train Epoch: 2 [145/3978 (4%)]\tLoss: 0.240418\n",
            "Train Epoch: 2 [150/3978 (4%)]\tLoss: 0.137349\n",
            "Train Epoch: 2 [155/3978 (4%)]\tLoss: 0.245791\n",
            "Train Epoch: 2 [160/3978 (4%)]\tLoss: 0.073372\n",
            "Train Epoch: 2 [165/3978 (4%)]\tLoss: 0.907268\n",
            "Train Epoch: 2 [170/3978 (4%)]\tLoss: 0.390908\n",
            "Train Epoch: 2 [175/3978 (4%)]\tLoss: 0.916749\n",
            "Train Epoch: 2 [180/3978 (5%)]\tLoss: 0.314938\n",
            "Train Epoch: 2 [185/3978 (5%)]\tLoss: 0.481700\n",
            "Train Epoch: 2 [190/3978 (5%)]\tLoss: 0.260831\n",
            "Train Epoch: 2 [195/3978 (5%)]\tLoss: 0.219472\n",
            "Train Epoch: 2 [200/3978 (5%)]\tLoss: 0.010247\n",
            "Train Epoch: 2 [205/3978 (5%)]\tLoss: 0.086671\n",
            "Train Epoch: 2 [210/3978 (5%)]\tLoss: 0.174465\n",
            "Train Epoch: 2 [215/3978 (5%)]\tLoss: 0.132357\n",
            "Train Epoch: 2 [220/3978 (6%)]\tLoss: 0.439114\n",
            "Train Epoch: 2 [225/3978 (6%)]\tLoss: 0.330320\n",
            "Train Epoch: 2 [230/3978 (6%)]\tLoss: 0.158208\n",
            "Train Epoch: 2 [235/3978 (6%)]\tLoss: 0.408341\n",
            "Train Epoch: 2 [240/3978 (6%)]\tLoss: 0.115919\n",
            "Train Epoch: 2 [245/3978 (6%)]\tLoss: 0.156462\n",
            "Train Epoch: 2 [250/3978 (6%)]\tLoss: 0.279704\n",
            "Train Epoch: 2 [255/3978 (6%)]\tLoss: 0.239221\n",
            "Train Epoch: 2 [260/3978 (7%)]\tLoss: 0.261789\n",
            "Train Epoch: 2 [265/3978 (7%)]\tLoss: 0.707873\n",
            "Train Epoch: 2 [270/3978 (7%)]\tLoss: 0.075092\n",
            "Train Epoch: 2 [275/3978 (7%)]\tLoss: 0.298518\n",
            "Train Epoch: 2 [280/3978 (7%)]\tLoss: 0.563735\n",
            "Train Epoch: 2 [285/3978 (7%)]\tLoss: 0.107675\n",
            "Train Epoch: 2 [290/3978 (7%)]\tLoss: 0.057729\n",
            "Train Epoch: 2 [295/3978 (7%)]\tLoss: 0.310748\n",
            "Train Epoch: 2 [300/3978 (8%)]\tLoss: 0.672458\n",
            "Train Epoch: 2 [305/3978 (8%)]\tLoss: 0.305761\n",
            "Train Epoch: 2 [310/3978 (8%)]\tLoss: 1.339449\n",
            "Train Epoch: 2 [315/3978 (8%)]\tLoss: 0.269965\n",
            "Train Epoch: 2 [320/3978 (8%)]\tLoss: 0.604383\n",
            "Train Epoch: 2 [325/3978 (8%)]\tLoss: 0.237383\n",
            "Train Epoch: 2 [330/3978 (8%)]\tLoss: 0.092585\n",
            "Train Epoch: 2 [335/3978 (8%)]\tLoss: 0.079307\n",
            "Train Epoch: 2 [340/3978 (9%)]\tLoss: 0.409959\n",
            "Train Epoch: 2 [345/3978 (9%)]\tLoss: 0.276597\n",
            "Train Epoch: 2 [350/3978 (9%)]\tLoss: 0.336667\n",
            "Train Epoch: 2 [355/3978 (9%)]\tLoss: 0.421811\n",
            "Train Epoch: 2 [360/3978 (9%)]\tLoss: 0.517653\n",
            "Train Epoch: 2 [365/3978 (9%)]\tLoss: 0.268966\n",
            "Train Epoch: 2 [370/3978 (9%)]\tLoss: 0.190164\n",
            "Train Epoch: 2 [375/3978 (9%)]\tLoss: 0.198513\n",
            "Train Epoch: 2 [380/3978 (10%)]\tLoss: 0.097647\n",
            "Train Epoch: 2 [385/3978 (10%)]\tLoss: 0.173876\n",
            "Train Epoch: 2 [390/3978 (10%)]\tLoss: 0.458177\n",
            "Train Epoch: 2 [395/3978 (10%)]\tLoss: 0.319773\n",
            "Train Epoch: 2 [400/3978 (10%)]\tLoss: 0.381825\n",
            "Train Epoch: 2 [405/3978 (10%)]\tLoss: 0.443129\n",
            "Train Epoch: 2 [410/3978 (10%)]\tLoss: 0.305287\n",
            "Train Epoch: 2 [415/3978 (10%)]\tLoss: 0.396241\n",
            "Train Epoch: 2 [420/3978 (11%)]\tLoss: 0.127892\n",
            "Train Epoch: 2 [425/3978 (11%)]\tLoss: 0.566577\n",
            "Train Epoch: 2 [430/3978 (11%)]\tLoss: 0.467775\n",
            "Train Epoch: 2 [435/3978 (11%)]\tLoss: 0.309744\n",
            "Train Epoch: 2 [440/3978 (11%)]\tLoss: 0.770746\n",
            "Train Epoch: 2 [445/3978 (11%)]\tLoss: 0.818144\n",
            "Train Epoch: 2 [450/3978 (11%)]\tLoss: 0.091620\n",
            "Train Epoch: 2 [455/3978 (11%)]\tLoss: 0.115958\n",
            "Train Epoch: 2 [460/3978 (12%)]\tLoss: 0.262554\n",
            "Train Epoch: 2 [465/3978 (12%)]\tLoss: 0.420688\n",
            "Train Epoch: 2 [470/3978 (12%)]\tLoss: 0.391149\n",
            "Train Epoch: 2 [475/3978 (12%)]\tLoss: 0.230588\n",
            "Train Epoch: 2 [480/3978 (12%)]\tLoss: 0.374619\n",
            "Train Epoch: 2 [485/3978 (12%)]\tLoss: 0.780176\n",
            "Train Epoch: 2 [490/3978 (12%)]\tLoss: 0.549164\n",
            "Train Epoch: 2 [495/3978 (12%)]\tLoss: 0.132560\n",
            "Train Epoch: 2 [500/3978 (13%)]\tLoss: 0.130067\n",
            "Train Epoch: 2 [505/3978 (13%)]\tLoss: 0.397589\n",
            "Train Epoch: 2 [510/3978 (13%)]\tLoss: 0.379924\n",
            "Train Epoch: 2 [515/3978 (13%)]\tLoss: 0.473670\n",
            "Train Epoch: 2 [520/3978 (13%)]\tLoss: 0.293696\n",
            "Train Epoch: 2 [525/3978 (13%)]\tLoss: 0.678591\n",
            "Train Epoch: 2 [530/3978 (13%)]\tLoss: 0.526953\n",
            "Train Epoch: 2 [535/3978 (13%)]\tLoss: 0.211636\n",
            "Train Epoch: 2 [540/3978 (14%)]\tLoss: 0.523052\n",
            "Train Epoch: 2 [545/3978 (14%)]\tLoss: 0.267051\n",
            "Train Epoch: 2 [550/3978 (14%)]\tLoss: 1.243628\n",
            "Train Epoch: 2 [555/3978 (14%)]\tLoss: 1.127971\n",
            "Train Epoch: 2 [560/3978 (14%)]\tLoss: 0.338776\n",
            "Train Epoch: 2 [565/3978 (14%)]\tLoss: 0.126583\n",
            "Train Epoch: 2 [570/3978 (14%)]\tLoss: 0.143682\n",
            "Train Epoch: 2 [575/3978 (14%)]\tLoss: 0.319546\n",
            "Train Epoch: 2 [580/3978 (15%)]\tLoss: 0.177117\n",
            "Train Epoch: 2 [585/3978 (15%)]\tLoss: 0.615722\n",
            "Train Epoch: 2 [590/3978 (15%)]\tLoss: 0.202141\n",
            "Train Epoch: 2 [595/3978 (15%)]\tLoss: 1.153197\n",
            "Train Epoch: 2 [600/3978 (15%)]\tLoss: 0.175754\n",
            "Train Epoch: 2 [605/3978 (15%)]\tLoss: 0.321438\n",
            "Train Epoch: 2 [610/3978 (15%)]\tLoss: 0.262805\n",
            "Train Epoch: 2 [615/3978 (15%)]\tLoss: 0.365367\n",
            "Train Epoch: 2 [620/3978 (16%)]\tLoss: 0.445868\n",
            "Train Epoch: 2 [625/3978 (16%)]\tLoss: 0.196263\n",
            "Train Epoch: 2 [630/3978 (16%)]\tLoss: 0.562762\n",
            "Train Epoch: 2 [635/3978 (16%)]\tLoss: 0.647330\n",
            "Train Epoch: 2 [640/3978 (16%)]\tLoss: 0.337728\n",
            "Train Epoch: 2 [645/3978 (16%)]\tLoss: 0.534831\n",
            "Train Epoch: 2 [650/3978 (16%)]\tLoss: 0.076889\n",
            "Train Epoch: 2 [655/3978 (16%)]\tLoss: 0.094381\n",
            "Train Epoch: 2 [660/3978 (17%)]\tLoss: 0.229256\n",
            "Train Epoch: 2 [665/3978 (17%)]\tLoss: 0.176760\n",
            "Train Epoch: 2 [670/3978 (17%)]\tLoss: 0.199161\n",
            "Train Epoch: 2 [675/3978 (17%)]\tLoss: 1.236625\n",
            "Train Epoch: 2 [680/3978 (17%)]\tLoss: 0.206076\n",
            "Train Epoch: 2 [685/3978 (17%)]\tLoss: 0.298544\n",
            "Train Epoch: 2 [690/3978 (17%)]\tLoss: 0.373439\n",
            "Train Epoch: 2 [695/3978 (17%)]\tLoss: 0.096389\n",
            "Train Epoch: 2 [700/3978 (18%)]\tLoss: 0.080890\n",
            "Train Epoch: 2 [705/3978 (18%)]\tLoss: 1.263622\n",
            "Train Epoch: 2 [710/3978 (18%)]\tLoss: 0.773880\n",
            "Train Epoch: 2 [715/3978 (18%)]\tLoss: 0.327643\n",
            "Train Epoch: 2 [720/3978 (18%)]\tLoss: 0.418091\n",
            "Train Epoch: 2 [725/3978 (18%)]\tLoss: 0.321638\n",
            "Train Epoch: 2 [730/3978 (18%)]\tLoss: 1.148528\n",
            "Train Epoch: 2 [735/3978 (18%)]\tLoss: 0.932021\n",
            "Train Epoch: 2 [740/3978 (19%)]\tLoss: 0.292112\n",
            "Train Epoch: 2 [745/3978 (19%)]\tLoss: 0.054611\n",
            "Train Epoch: 2 [750/3978 (19%)]\tLoss: 0.670331\n",
            "Train Epoch: 2 [755/3978 (19%)]\tLoss: 0.330253\n",
            "Train Epoch: 2 [760/3978 (19%)]\tLoss: 0.463003\n",
            "Train Epoch: 2 [765/3978 (19%)]\tLoss: 0.522275\n",
            "Train Epoch: 2 [770/3978 (19%)]\tLoss: 0.198728\n",
            "Train Epoch: 2 [775/3978 (19%)]\tLoss: 0.207798\n",
            "Train Epoch: 2 [780/3978 (20%)]\tLoss: 0.726071\n",
            "Train Epoch: 2 [785/3978 (20%)]\tLoss: 0.925797\n",
            "Train Epoch: 2 [790/3978 (20%)]\tLoss: 0.304612\n",
            "Train Epoch: 2 [795/3978 (20%)]\tLoss: 0.300796\n",
            "Train Epoch: 2 [800/3978 (20%)]\tLoss: 0.163078\n",
            "Train Epoch: 2 [805/3978 (20%)]\tLoss: 0.082256\n",
            "Train Epoch: 2 [810/3978 (20%)]\tLoss: 0.347851\n",
            "Train Epoch: 2 [815/3978 (20%)]\tLoss: 0.670342\n",
            "Train Epoch: 2 [820/3978 (21%)]\tLoss: 0.446638\n",
            "Train Epoch: 2 [825/3978 (21%)]\tLoss: 0.688772\n",
            "Train Epoch: 2 [830/3978 (21%)]\tLoss: 0.849906\n",
            "Train Epoch: 2 [835/3978 (21%)]\tLoss: 0.249310\n",
            "Train Epoch: 2 [840/3978 (21%)]\tLoss: 0.650817\n",
            "Train Epoch: 2 [845/3978 (21%)]\tLoss: 0.387675\n",
            "Train Epoch: 2 [850/3978 (21%)]\tLoss: 0.187602\n",
            "Train Epoch: 2 [855/3978 (21%)]\tLoss: 0.500454\n",
            "Train Epoch: 2 [860/3978 (22%)]\tLoss: 0.607269\n",
            "Train Epoch: 2 [865/3978 (22%)]\tLoss: 0.740531\n",
            "Train Epoch: 2 [870/3978 (22%)]\tLoss: 0.053205\n",
            "Train Epoch: 2 [875/3978 (22%)]\tLoss: 0.442177\n",
            "Train Epoch: 2 [880/3978 (22%)]\tLoss: 0.290620\n",
            "Train Epoch: 2 [885/3978 (22%)]\tLoss: 0.070918\n",
            "Train Epoch: 2 [890/3978 (22%)]\tLoss: 0.112086\n",
            "Train Epoch: 2 [895/3978 (22%)]\tLoss: 0.373945\n",
            "Train Epoch: 2 [900/3978 (23%)]\tLoss: 0.031351\n",
            "Train Epoch: 2 [905/3978 (23%)]\tLoss: 0.352920\n",
            "Train Epoch: 2 [910/3978 (23%)]\tLoss: 0.144056\n",
            "Train Epoch: 2 [915/3978 (23%)]\tLoss: 0.453775\n",
            "Train Epoch: 2 [920/3978 (23%)]\tLoss: 0.049500\n",
            "Train Epoch: 2 [925/3978 (23%)]\tLoss: 0.671644\n",
            "Train Epoch: 2 [930/3978 (23%)]\tLoss: 0.567572\n",
            "Train Epoch: 2 [935/3978 (23%)]\tLoss: 0.547058\n",
            "Train Epoch: 2 [940/3978 (24%)]\tLoss: 0.567082\n",
            "Train Epoch: 2 [945/3978 (24%)]\tLoss: 0.274974\n",
            "Train Epoch: 2 [950/3978 (24%)]\tLoss: 0.466919\n",
            "Train Epoch: 2 [955/3978 (24%)]\tLoss: 0.195705\n",
            "Train Epoch: 2 [960/3978 (24%)]\tLoss: 0.442348\n",
            "Train Epoch: 2 [965/3978 (24%)]\tLoss: 0.334453\n",
            "Train Epoch: 2 [970/3978 (24%)]\tLoss: 0.931199\n",
            "Train Epoch: 2 [975/3978 (24%)]\tLoss: 0.427666\n",
            "Train Epoch: 2 [980/3978 (25%)]\tLoss: 0.246467\n",
            "Train Epoch: 2 [985/3978 (25%)]\tLoss: 0.540074\n",
            "Train Epoch: 2 [990/3978 (25%)]\tLoss: 0.416843\n",
            "Train Epoch: 2 [995/3978 (25%)]\tLoss: 0.627060\n",
            "Train Epoch: 2 [1000/3978 (25%)]\tLoss: 0.845634\n",
            "Train Epoch: 2 [1005/3978 (25%)]\tLoss: 0.434126\n",
            "Train Epoch: 2 [1010/3978 (25%)]\tLoss: 1.337090\n",
            "Train Epoch: 2 [1015/3978 (26%)]\tLoss: 0.736339\n",
            "Train Epoch: 2 [1020/3978 (26%)]\tLoss: 0.299170\n",
            "Train Epoch: 2 [1025/3978 (26%)]\tLoss: 0.775688\n",
            "Train Epoch: 2 [1030/3978 (26%)]\tLoss: 0.501274\n",
            "Train Epoch: 2 [1035/3978 (26%)]\tLoss: 0.488655\n",
            "Train Epoch: 2 [1040/3978 (26%)]\tLoss: 0.204704\n",
            "Train Epoch: 2 [1045/3978 (26%)]\tLoss: 0.277231\n",
            "Train Epoch: 2 [1050/3978 (26%)]\tLoss: 0.679441\n",
            "Train Epoch: 2 [1055/3978 (27%)]\tLoss: 0.377889\n",
            "Train Epoch: 2 [1060/3978 (27%)]\tLoss: 0.867529\n",
            "Train Epoch: 2 [1065/3978 (27%)]\tLoss: 0.581130\n",
            "Train Epoch: 2 [1070/3978 (27%)]\tLoss: 0.575160\n",
            "Train Epoch: 2 [1075/3978 (27%)]\tLoss: 0.487632\n",
            "Train Epoch: 2 [1080/3978 (27%)]\tLoss: 0.745062\n",
            "Train Epoch: 2 [1085/3978 (27%)]\tLoss: 0.130923\n",
            "Train Epoch: 2 [1090/3978 (27%)]\tLoss: 0.285579\n",
            "Train Epoch: 2 [1095/3978 (28%)]\tLoss: 0.685287\n",
            "Train Epoch: 2 [1100/3978 (28%)]\tLoss: 0.266104\n",
            "Train Epoch: 2 [1105/3978 (28%)]\tLoss: 0.149711\n",
            "Train Epoch: 2 [1110/3978 (28%)]\tLoss: 0.319658\n",
            "Train Epoch: 2 [1115/3978 (28%)]\tLoss: 0.215338\n",
            "Train Epoch: 2 [1120/3978 (28%)]\tLoss: 0.433858\n",
            "Train Epoch: 2 [1125/3978 (28%)]\tLoss: 0.416427\n",
            "Train Epoch: 2 [1130/3978 (28%)]\tLoss: 0.060518\n",
            "Train Epoch: 2 [1135/3978 (29%)]\tLoss: 0.034728\n",
            "Train Epoch: 2 [1140/3978 (29%)]\tLoss: 0.360607\n",
            "Train Epoch: 2 [1145/3978 (29%)]\tLoss: 0.245793\n",
            "Train Epoch: 2 [1150/3978 (29%)]\tLoss: 0.139819\n",
            "Train Epoch: 2 [1155/3978 (29%)]\tLoss: 0.135964\n",
            "Train Epoch: 2 [1160/3978 (29%)]\tLoss: 0.591293\n",
            "Train Epoch: 2 [1165/3978 (29%)]\tLoss: 0.097176\n",
            "Train Epoch: 2 [1170/3978 (29%)]\tLoss: 0.594401\n",
            "Train Epoch: 2 [1175/3978 (30%)]\tLoss: 0.276175\n",
            "Train Epoch: 2 [1180/3978 (30%)]\tLoss: 0.146854\n",
            "Train Epoch: 2 [1185/3978 (30%)]\tLoss: 0.552560\n",
            "Train Epoch: 2 [1190/3978 (30%)]\tLoss: 0.605908\n",
            "Train Epoch: 2 [1195/3978 (30%)]\tLoss: 0.123514\n",
            "Train Epoch: 2 [1200/3978 (30%)]\tLoss: 0.162835\n",
            "Train Epoch: 2 [1205/3978 (30%)]\tLoss: 0.082881\n",
            "Train Epoch: 2 [1210/3978 (30%)]\tLoss: 0.742804\n",
            "Train Epoch: 2 [1215/3978 (31%)]\tLoss: 0.298546\n",
            "Train Epoch: 2 [1220/3978 (31%)]\tLoss: 0.023256\n",
            "Train Epoch: 2 [1225/3978 (31%)]\tLoss: 0.335483\n",
            "Train Epoch: 2 [1230/3978 (31%)]\tLoss: 0.385596\n",
            "Train Epoch: 2 [1235/3978 (31%)]\tLoss: 0.103581\n",
            "Train Epoch: 2 [1240/3978 (31%)]\tLoss: 0.230841\n",
            "Train Epoch: 2 [1245/3978 (31%)]\tLoss: 0.088223\n",
            "Train Epoch: 2 [1250/3978 (31%)]\tLoss: 0.018367\n",
            "Train Epoch: 2 [1255/3978 (32%)]\tLoss: 0.206120\n",
            "Train Epoch: 2 [1260/3978 (32%)]\tLoss: 0.346763\n",
            "Train Epoch: 2 [1265/3978 (32%)]\tLoss: 0.095476\n",
            "Train Epoch: 2 [1270/3978 (32%)]\tLoss: 0.166962\n",
            "Train Epoch: 2 [1275/3978 (32%)]\tLoss: 0.145732\n",
            "Train Epoch: 2 [1280/3978 (32%)]\tLoss: 0.227674\n",
            "Train Epoch: 2 [1285/3978 (32%)]\tLoss: 0.101323\n",
            "Train Epoch: 2 [1290/3978 (32%)]\tLoss: 0.085166\n",
            "Train Epoch: 2 [1295/3978 (33%)]\tLoss: 0.046120\n",
            "Train Epoch: 2 [1300/3978 (33%)]\tLoss: 0.811613\n",
            "Train Epoch: 2 [1305/3978 (33%)]\tLoss: 0.591637\n",
            "Train Epoch: 2 [1310/3978 (33%)]\tLoss: 0.165991\n",
            "Train Epoch: 2 [1315/3978 (33%)]\tLoss: 0.159467\n",
            "Train Epoch: 2 [1320/3978 (33%)]\tLoss: 0.183812\n",
            "Train Epoch: 2 [1325/3978 (33%)]\tLoss: 0.100875\n",
            "Train Epoch: 2 [1330/3978 (33%)]\tLoss: 0.330443\n",
            "Train Epoch: 2 [1335/3978 (34%)]\tLoss: 0.021683\n",
            "Train Epoch: 2 [1340/3978 (34%)]\tLoss: 0.389499\n",
            "Train Epoch: 2 [1345/3978 (34%)]\tLoss: 0.060459\n",
            "Train Epoch: 2 [1350/3978 (34%)]\tLoss: 0.380967\n",
            "Train Epoch: 2 [1355/3978 (34%)]\tLoss: 0.355575\n",
            "Train Epoch: 2 [1360/3978 (34%)]\tLoss: 0.434280\n",
            "Train Epoch: 2 [1365/3978 (34%)]\tLoss: 0.477144\n",
            "Train Epoch: 2 [1370/3978 (34%)]\tLoss: 0.408817\n",
            "Train Epoch: 2 [1375/3978 (35%)]\tLoss: 0.185554\n",
            "Train Epoch: 2 [1380/3978 (35%)]\tLoss: 0.319617\n",
            "Train Epoch: 2 [1385/3978 (35%)]\tLoss: 0.312084\n",
            "Train Epoch: 2 [1390/3978 (35%)]\tLoss: 0.321706\n",
            "Train Epoch: 2 [1395/3978 (35%)]\tLoss: 0.460166\n",
            "Train Epoch: 2 [1400/3978 (35%)]\tLoss: 0.111829\n",
            "Train Epoch: 2 [1405/3978 (35%)]\tLoss: 0.222875\n",
            "Train Epoch: 2 [1410/3978 (35%)]\tLoss: 0.324928\n",
            "Train Epoch: 2 [1415/3978 (36%)]\tLoss: 0.288919\n",
            "Train Epoch: 2 [1420/3978 (36%)]\tLoss: 0.218720\n",
            "Train Epoch: 2 [1425/3978 (36%)]\tLoss: 0.127120\n",
            "Train Epoch: 2 [1430/3978 (36%)]\tLoss: 0.224024\n",
            "Train Epoch: 2 [1435/3978 (36%)]\tLoss: 0.226849\n",
            "Train Epoch: 2 [1440/3978 (36%)]\tLoss: 0.124134\n",
            "Train Epoch: 2 [1445/3978 (36%)]\tLoss: 0.367555\n",
            "Train Epoch: 2 [1450/3978 (36%)]\tLoss: 0.408188\n",
            "Train Epoch: 2 [1455/3978 (37%)]\tLoss: 0.129200\n",
            "Train Epoch: 2 [1460/3978 (37%)]\tLoss: 0.722242\n",
            "Train Epoch: 2 [1465/3978 (37%)]\tLoss: 0.047771\n",
            "Train Epoch: 2 [1470/3978 (37%)]\tLoss: 0.078188\n",
            "Train Epoch: 2 [1475/3978 (37%)]\tLoss: 0.261671\n",
            "Train Epoch: 2 [1480/3978 (37%)]\tLoss: 0.152262\n",
            "Train Epoch: 2 [1485/3978 (37%)]\tLoss: 0.324825\n",
            "Train Epoch: 2 [1490/3978 (37%)]\tLoss: 0.690552\n",
            "Train Epoch: 2 [1495/3978 (38%)]\tLoss: 0.036386\n",
            "Train Epoch: 2 [1500/3978 (38%)]\tLoss: 0.287872\n",
            "Train Epoch: 2 [1505/3978 (38%)]\tLoss: 0.511533\n",
            "Train Epoch: 2 [1510/3978 (38%)]\tLoss: 0.354429\n",
            "Train Epoch: 2 [1515/3978 (38%)]\tLoss: 0.295141\n",
            "Train Epoch: 2 [1520/3978 (38%)]\tLoss: 0.277794\n",
            "Train Epoch: 2 [1525/3978 (38%)]\tLoss: 0.090317\n",
            "Train Epoch: 2 [1530/3978 (38%)]\tLoss: 0.108603\n",
            "Train Epoch: 2 [1535/3978 (39%)]\tLoss: 0.142507\n",
            "Train Epoch: 2 [1540/3978 (39%)]\tLoss: 0.784798\n",
            "Train Epoch: 2 [1545/3978 (39%)]\tLoss: 0.052268\n",
            "Train Epoch: 2 [1550/3978 (39%)]\tLoss: 0.063065\n",
            "Train Epoch: 2 [1555/3978 (39%)]\tLoss: 0.035367\n",
            "Train Epoch: 2 [1560/3978 (39%)]\tLoss: 0.284012\n",
            "Train Epoch: 2 [1565/3978 (39%)]\tLoss: 0.334402\n",
            "Train Epoch: 2 [1570/3978 (39%)]\tLoss: 0.494410\n",
            "Train Epoch: 2 [1575/3978 (40%)]\tLoss: 0.240278\n",
            "Train Epoch: 2 [1580/3978 (40%)]\tLoss: 0.105678\n",
            "Train Epoch: 2 [1585/3978 (40%)]\tLoss: 0.184538\n",
            "Train Epoch: 2 [1590/3978 (40%)]\tLoss: 0.356157\n",
            "Train Epoch: 2 [1595/3978 (40%)]\tLoss: 0.423071\n",
            "Train Epoch: 2 [1600/3978 (40%)]\tLoss: 0.190640\n",
            "Train Epoch: 2 [1605/3978 (40%)]\tLoss: 0.306964\n",
            "Train Epoch: 2 [1610/3978 (40%)]\tLoss: 0.304154\n",
            "Train Epoch: 2 [1615/3978 (41%)]\tLoss: 0.284235\n",
            "Train Epoch: 2 [1620/3978 (41%)]\tLoss: 0.125369\n",
            "Train Epoch: 2 [1625/3978 (41%)]\tLoss: 0.061828\n",
            "Train Epoch: 2 [1630/3978 (41%)]\tLoss: 0.744977\n",
            "Train Epoch: 2 [1635/3978 (41%)]\tLoss: 0.380459\n",
            "Train Epoch: 2 [1640/3978 (41%)]\tLoss: 1.006427\n",
            "Train Epoch: 2 [1645/3978 (41%)]\tLoss: 0.387681\n",
            "Train Epoch: 2 [1650/3978 (41%)]\tLoss: 0.108587\n",
            "Train Epoch: 2 [1655/3978 (42%)]\tLoss: 0.089564\n",
            "Train Epoch: 2 [1660/3978 (42%)]\tLoss: 0.074753\n",
            "Train Epoch: 2 [1665/3978 (42%)]\tLoss: 0.238327\n",
            "Train Epoch: 2 [1670/3978 (42%)]\tLoss: 0.610736\n",
            "Train Epoch: 2 [1675/3978 (42%)]\tLoss: 0.534082\n",
            "Train Epoch: 2 [1680/3978 (42%)]\tLoss: 0.192165\n",
            "Train Epoch: 2 [1685/3978 (42%)]\tLoss: 0.236171\n",
            "Train Epoch: 2 [1690/3978 (42%)]\tLoss: 0.452010\n",
            "Train Epoch: 2 [1695/3978 (43%)]\tLoss: 0.447793\n",
            "Train Epoch: 2 [1700/3978 (43%)]\tLoss: 0.114783\n",
            "Train Epoch: 2 [1705/3978 (43%)]\tLoss: 0.211492\n",
            "Train Epoch: 2 [1710/3978 (43%)]\tLoss: 0.260260\n",
            "Train Epoch: 2 [1715/3978 (43%)]\tLoss: 0.151239\n",
            "Train Epoch: 2 [1720/3978 (43%)]\tLoss: 0.145737\n",
            "Train Epoch: 2 [1725/3978 (43%)]\tLoss: 0.453414\n",
            "Train Epoch: 2 [1730/3978 (43%)]\tLoss: 0.135629\n",
            "Train Epoch: 2 [1735/3978 (44%)]\tLoss: 0.162533\n",
            "Train Epoch: 2 [1740/3978 (44%)]\tLoss: 0.105325\n",
            "Train Epoch: 2 [1745/3978 (44%)]\tLoss: 0.230510\n",
            "Train Epoch: 2 [1750/3978 (44%)]\tLoss: 0.245630\n",
            "Train Epoch: 2 [1755/3978 (44%)]\tLoss: 0.280597\n",
            "Train Epoch: 2 [1760/3978 (44%)]\tLoss: 0.156893\n",
            "Train Epoch: 2 [1765/3978 (44%)]\tLoss: 0.097129\n",
            "Train Epoch: 2 [1770/3978 (44%)]\tLoss: 0.089849\n",
            "Train Epoch: 2 [1775/3978 (45%)]\tLoss: 0.107940\n",
            "Train Epoch: 2 [1780/3978 (45%)]\tLoss: 0.368979\n",
            "Train Epoch: 2 [1785/3978 (45%)]\tLoss: 0.262766\n",
            "Train Epoch: 2 [1790/3978 (45%)]\tLoss: 0.079509\n",
            "Train Epoch: 2 [1795/3978 (45%)]\tLoss: 0.080157\n",
            "Train Epoch: 2 [1800/3978 (45%)]\tLoss: 0.326277\n",
            "Train Epoch: 2 [1805/3978 (45%)]\tLoss: 0.257533\n",
            "Train Epoch: 2 [1810/3978 (45%)]\tLoss: 0.422082\n",
            "Train Epoch: 2 [1815/3978 (46%)]\tLoss: 0.249129\n",
            "Train Epoch: 2 [1820/3978 (46%)]\tLoss: 0.216826\n",
            "Train Epoch: 2 [1825/3978 (46%)]\tLoss: 0.092933\n",
            "Train Epoch: 2 [1830/3978 (46%)]\tLoss: 0.048858\n",
            "Train Epoch: 2 [1835/3978 (46%)]\tLoss: 0.191702\n",
            "Train Epoch: 2 [1840/3978 (46%)]\tLoss: 0.167821\n",
            "Train Epoch: 2 [1845/3978 (46%)]\tLoss: 0.735598\n",
            "Train Epoch: 2 [1850/3978 (46%)]\tLoss: 0.090131\n",
            "Train Epoch: 2 [1855/3978 (47%)]\tLoss: 0.167214\n",
            "Train Epoch: 2 [1860/3978 (47%)]\tLoss: 0.253905\n",
            "Train Epoch: 2 [1865/3978 (47%)]\tLoss: 0.025595\n",
            "Train Epoch: 2 [1870/3978 (47%)]\tLoss: 0.610825\n",
            "Train Epoch: 2 [1875/3978 (47%)]\tLoss: 0.067514\n",
            "Train Epoch: 2 [1880/3978 (47%)]\tLoss: 0.411954\n",
            "Train Epoch: 2 [1885/3978 (47%)]\tLoss: 0.521519\n",
            "Train Epoch: 2 [1890/3978 (47%)]\tLoss: 0.494108\n",
            "Train Epoch: 2 [1895/3978 (48%)]\tLoss: 0.074687\n",
            "Train Epoch: 2 [1900/3978 (48%)]\tLoss: 0.232207\n",
            "Train Epoch: 2 [1905/3978 (48%)]\tLoss: 0.074445\n",
            "Train Epoch: 2 [1910/3978 (48%)]\tLoss: 0.213632\n",
            "Train Epoch: 2 [1915/3978 (48%)]\tLoss: 0.297728\n",
            "Train Epoch: 2 [1920/3978 (48%)]\tLoss: 0.385286\n",
            "Train Epoch: 2 [1925/3978 (48%)]\tLoss: 0.352627\n",
            "Train Epoch: 2 [1930/3978 (48%)]\tLoss: 0.264825\n",
            "Train Epoch: 2 [1935/3978 (49%)]\tLoss: 0.229732\n",
            "Train Epoch: 2 [1940/3978 (49%)]\tLoss: 0.199255\n",
            "Train Epoch: 2 [1945/3978 (49%)]\tLoss: 0.251969\n",
            "Train Epoch: 2 [1950/3978 (49%)]\tLoss: 0.447054\n",
            "Train Epoch: 2 [1955/3978 (49%)]\tLoss: 0.234699\n",
            "Train Epoch: 2 [1960/3978 (49%)]\tLoss: 0.216370\n",
            "Train Epoch: 2 [1965/3978 (49%)]\tLoss: 0.341872\n",
            "Train Epoch: 2 [1970/3978 (49%)]\tLoss: 0.224296\n",
            "Train Epoch: 2 [1975/3978 (50%)]\tLoss: 0.293270\n",
            "Train Epoch: 2 [1980/3978 (50%)]\tLoss: 0.092128\n",
            "Train Epoch: 2 [1985/3978 (50%)]\tLoss: 0.141331\n",
            "Train Epoch: 2 [1990/3978 (50%)]\tLoss: 0.331080\n",
            "Train Epoch: 2 [1995/3978 (50%)]\tLoss: 0.386903\n",
            "Train Epoch: 2 [2000/3978 (50%)]\tLoss: 0.057736\n",
            "Train Epoch: 2 [2005/3978 (50%)]\tLoss: 0.315539\n",
            "Train Epoch: 2 [2010/3978 (51%)]\tLoss: 0.047137\n",
            "Train Epoch: 2 [2015/3978 (51%)]\tLoss: 0.059474\n",
            "Train Epoch: 2 [2020/3978 (51%)]\tLoss: 0.273191\n",
            "Train Epoch: 2 [2025/3978 (51%)]\tLoss: 0.141673\n",
            "Train Epoch: 2 [2030/3978 (51%)]\tLoss: 0.121048\n",
            "Train Epoch: 2 [2035/3978 (51%)]\tLoss: 0.234359\n",
            "Train Epoch: 2 [2040/3978 (51%)]\tLoss: 0.399924\n",
            "Train Epoch: 2 [2045/3978 (51%)]\tLoss: 0.234073\n",
            "Train Epoch: 2 [2050/3978 (52%)]\tLoss: 0.224033\n",
            "Train Epoch: 2 [2055/3978 (52%)]\tLoss: 0.259717\n",
            "Train Epoch: 2 [2060/3978 (52%)]\tLoss: 0.344504\n",
            "Train Epoch: 2 [2065/3978 (52%)]\tLoss: 0.310105\n",
            "Train Epoch: 2 [2070/3978 (52%)]\tLoss: 0.604825\n",
            "Train Epoch: 2 [2075/3978 (52%)]\tLoss: 0.165385\n",
            "Train Epoch: 2 [2080/3978 (52%)]\tLoss: 0.305530\n",
            "Train Epoch: 2 [2085/3978 (52%)]\tLoss: 0.443315\n",
            "Train Epoch: 2 [2090/3978 (53%)]\tLoss: 0.390267\n",
            "Train Epoch: 2 [2095/3978 (53%)]\tLoss: 0.351138\n",
            "Train Epoch: 2 [2100/3978 (53%)]\tLoss: 0.160470\n",
            "Train Epoch: 2 [2105/3978 (53%)]\tLoss: 0.471834\n",
            "Train Epoch: 2 [2110/3978 (53%)]\tLoss: 0.209297\n",
            "Train Epoch: 2 [2115/3978 (53%)]\tLoss: 0.313662\n",
            "Train Epoch: 2 [2120/3978 (53%)]\tLoss: 0.320801\n",
            "Train Epoch: 2 [2125/3978 (53%)]\tLoss: 0.298929\n",
            "Train Epoch: 2 [2130/3978 (54%)]\tLoss: 0.042677\n",
            "Train Epoch: 2 [2135/3978 (54%)]\tLoss: 0.208877\n",
            "Train Epoch: 2 [2140/3978 (54%)]\tLoss: 0.296132\n",
            "Train Epoch: 2 [2145/3978 (54%)]\tLoss: 0.727444\n",
            "Train Epoch: 2 [2150/3978 (54%)]\tLoss: 0.353025\n",
            "Train Epoch: 2 [2155/3978 (54%)]\tLoss: 0.247141\n",
            "Train Epoch: 2 [2160/3978 (54%)]\tLoss: 0.282397\n",
            "Train Epoch: 2 [2165/3978 (54%)]\tLoss: 0.062362\n",
            "Train Epoch: 2 [2170/3978 (55%)]\tLoss: 0.541130\n",
            "Train Epoch: 2 [2175/3978 (55%)]\tLoss: 0.483693\n",
            "Train Epoch: 2 [2180/3978 (55%)]\tLoss: 0.356342\n",
            "Train Epoch: 2 [2185/3978 (55%)]\tLoss: 0.439829\n",
            "Train Epoch: 2 [2190/3978 (55%)]\tLoss: 0.162446\n",
            "Train Epoch: 2 [2195/3978 (55%)]\tLoss: 0.195285\n",
            "Train Epoch: 2 [2200/3978 (55%)]\tLoss: 0.184016\n",
            "Train Epoch: 2 [2205/3978 (55%)]\tLoss: 0.258934\n",
            "Train Epoch: 2 [2210/3978 (56%)]\tLoss: 0.385728\n",
            "Train Epoch: 2 [2215/3978 (56%)]\tLoss: 0.308542\n",
            "Train Epoch: 2 [2220/3978 (56%)]\tLoss: 0.304688\n",
            "Train Epoch: 2 [2225/3978 (56%)]\tLoss: 0.324004\n",
            "Train Epoch: 2 [2230/3978 (56%)]\tLoss: 0.294595\n",
            "Train Epoch: 2 [2235/3978 (56%)]\tLoss: 0.798535\n",
            "Train Epoch: 2 [2240/3978 (56%)]\tLoss: 0.372976\n",
            "Train Epoch: 2 [2245/3978 (56%)]\tLoss: 0.258677\n",
            "Train Epoch: 2 [2250/3978 (57%)]\tLoss: 0.177589\n",
            "Train Epoch: 2 [2255/3978 (57%)]\tLoss: 0.309326\n",
            "Train Epoch: 2 [2260/3978 (57%)]\tLoss: 0.462795\n",
            "Train Epoch: 2 [2265/3978 (57%)]\tLoss: 0.274230\n",
            "Train Epoch: 2 [2270/3978 (57%)]\tLoss: 0.095573\n",
            "Train Epoch: 2 [2275/3978 (57%)]\tLoss: 0.200705\n",
            "Train Epoch: 2 [2280/3978 (57%)]\tLoss: 0.215359\n",
            "Train Epoch: 2 [2285/3978 (57%)]\tLoss: 0.355842\n",
            "Train Epoch: 2 [2290/3978 (58%)]\tLoss: 0.183017\n",
            "Train Epoch: 2 [2295/3978 (58%)]\tLoss: 0.109443\n",
            "Train Epoch: 2 [2300/3978 (58%)]\tLoss: 0.221214\n",
            "Train Epoch: 2 [2305/3978 (58%)]\tLoss: 0.113031\n",
            "Train Epoch: 2 [2310/3978 (58%)]\tLoss: 0.073045\n",
            "Train Epoch: 2 [2315/3978 (58%)]\tLoss: 0.289218\n",
            "Train Epoch: 2 [2320/3978 (58%)]\tLoss: 0.219904\n",
            "Train Epoch: 2 [2325/3978 (58%)]\tLoss: 0.429916\n",
            "Train Epoch: 2 [2330/3978 (59%)]\tLoss: 0.440239\n",
            "Train Epoch: 2 [2335/3978 (59%)]\tLoss: 0.278418\n",
            "Train Epoch: 2 [2340/3978 (59%)]\tLoss: 0.249585\n",
            "Train Epoch: 2 [2345/3978 (59%)]\tLoss: 0.118188\n",
            "Train Epoch: 2 [2350/3978 (59%)]\tLoss: 0.177230\n",
            "Train Epoch: 2 [2355/3978 (59%)]\tLoss: 0.569335\n",
            "Train Epoch: 2 [2360/3978 (59%)]\tLoss: 0.083205\n",
            "Train Epoch: 2 [2365/3978 (59%)]\tLoss: 0.347996\n",
            "Train Epoch: 2 [2370/3978 (60%)]\tLoss: 0.555245\n",
            "Train Epoch: 2 [2375/3978 (60%)]\tLoss: 0.138636\n",
            "Train Epoch: 2 [2380/3978 (60%)]\tLoss: 0.393675\n",
            "Train Epoch: 2 [2385/3978 (60%)]\tLoss: 0.205065\n",
            "Train Epoch: 2 [2390/3978 (60%)]\tLoss: 0.183750\n",
            "Train Epoch: 2 [2395/3978 (60%)]\tLoss: 0.039469\n",
            "Train Epoch: 2 [2400/3978 (60%)]\tLoss: 0.207543\n",
            "Train Epoch: 2 [2405/3978 (60%)]\tLoss: 0.141405\n",
            "Train Epoch: 2 [2410/3978 (61%)]\tLoss: 0.405818\n",
            "Train Epoch: 2 [2415/3978 (61%)]\tLoss: 0.105032\n",
            "Train Epoch: 2 [2420/3978 (61%)]\tLoss: 0.117082\n",
            "Train Epoch: 2 [2425/3978 (61%)]\tLoss: 0.058068\n",
            "Train Epoch: 2 [2430/3978 (61%)]\tLoss: 0.125624\n",
            "Train Epoch: 2 [2435/3978 (61%)]\tLoss: 0.106804\n",
            "Train Epoch: 2 [2440/3978 (61%)]\tLoss: 0.092041\n",
            "Train Epoch: 2 [2445/3978 (61%)]\tLoss: 0.173311\n",
            "Train Epoch: 2 [2450/3978 (62%)]\tLoss: 0.130310\n",
            "Train Epoch: 2 [2455/3978 (62%)]\tLoss: 0.672430\n",
            "Train Epoch: 2 [2460/3978 (62%)]\tLoss: 0.103322\n",
            "Train Epoch: 2 [2465/3978 (62%)]\tLoss: 0.048752\n",
            "Train Epoch: 2 [2470/3978 (62%)]\tLoss: 0.077176\n",
            "Train Epoch: 2 [2475/3978 (62%)]\tLoss: 0.212776\n",
            "Train Epoch: 2 [2480/3978 (62%)]\tLoss: 0.475034\n",
            "Train Epoch: 2 [2485/3978 (62%)]\tLoss: 0.350237\n",
            "Train Epoch: 2 [2490/3978 (63%)]\tLoss: 0.364927\n",
            "Train Epoch: 2 [2495/3978 (63%)]\tLoss: 0.391401\n",
            "Train Epoch: 2 [2500/3978 (63%)]\tLoss: 0.259449\n",
            "Train Epoch: 2 [2505/3978 (63%)]\tLoss: 0.087122\n",
            "Train Epoch: 2 [2510/3978 (63%)]\tLoss: 0.305229\n",
            "Train Epoch: 2 [2515/3978 (63%)]\tLoss: 0.140359\n",
            "Train Epoch: 2 [2520/3978 (63%)]\tLoss: 0.192088\n",
            "Train Epoch: 2 [2525/3978 (63%)]\tLoss: 0.490859\n",
            "Train Epoch: 2 [2530/3978 (64%)]\tLoss: 0.317782\n",
            "Train Epoch: 2 [2535/3978 (64%)]\tLoss: 0.201283\n",
            "Train Epoch: 2 [2540/3978 (64%)]\tLoss: 0.767695\n",
            "Train Epoch: 2 [2545/3978 (64%)]\tLoss: 0.146562\n",
            "Train Epoch: 2 [2550/3978 (64%)]\tLoss: 0.311034\n",
            "Train Epoch: 2 [2555/3978 (64%)]\tLoss: 0.369296\n",
            "Train Epoch: 2 [2560/3978 (64%)]\tLoss: 0.393454\n",
            "Train Epoch: 2 [2565/3978 (64%)]\tLoss: 0.473847\n",
            "Train Epoch: 2 [2570/3978 (65%)]\tLoss: 0.227093\n",
            "Train Epoch: 2 [2575/3978 (65%)]\tLoss: 0.286232\n",
            "Train Epoch: 2 [2580/3978 (65%)]\tLoss: 0.214909\n",
            "Train Epoch: 2 [2585/3978 (65%)]\tLoss: 0.180262\n",
            "Train Epoch: 2 [2590/3978 (65%)]\tLoss: 0.191239\n",
            "Train Epoch: 2 [2595/3978 (65%)]\tLoss: 0.241932\n",
            "Train Epoch: 2 [2600/3978 (65%)]\tLoss: 0.335451\n",
            "Train Epoch: 2 [2605/3978 (65%)]\tLoss: 0.270544\n",
            "Train Epoch: 2 [2610/3978 (66%)]\tLoss: 0.231732\n",
            "Train Epoch: 2 [2615/3978 (66%)]\tLoss: 0.338524\n",
            "Train Epoch: 2 [2620/3978 (66%)]\tLoss: 0.070637\n",
            "Train Epoch: 2 [2625/3978 (66%)]\tLoss: 0.361391\n",
            "Train Epoch: 2 [2630/3978 (66%)]\tLoss: 0.065958\n",
            "Train Epoch: 2 [2635/3978 (66%)]\tLoss: 0.556699\n",
            "Train Epoch: 2 [2640/3978 (66%)]\tLoss: 0.418014\n",
            "Train Epoch: 2 [2645/3978 (66%)]\tLoss: 0.249307\n",
            "Train Epoch: 2 [2650/3978 (67%)]\tLoss: 0.322843\n",
            "Train Epoch: 2 [2655/3978 (67%)]\tLoss: 0.121127\n",
            "Train Epoch: 2 [2660/3978 (67%)]\tLoss: 0.042481\n",
            "Train Epoch: 2 [2665/3978 (67%)]\tLoss: 0.424919\n",
            "Train Epoch: 2 [2670/3978 (67%)]\tLoss: 0.042932\n",
            "Train Epoch: 2 [2675/3978 (67%)]\tLoss: 0.054279\n",
            "Train Epoch: 2 [2680/3978 (67%)]\tLoss: 0.074698\n",
            "Train Epoch: 2 [2685/3978 (67%)]\tLoss: 0.338480\n",
            "Train Epoch: 2 [2690/3978 (68%)]\tLoss: 0.048481\n",
            "Train Epoch: 2 [2695/3978 (68%)]\tLoss: 0.486460\n",
            "Train Epoch: 2 [2700/3978 (68%)]\tLoss: 0.791721\n",
            "Train Epoch: 2 [2705/3978 (68%)]\tLoss: 0.202071\n",
            "Train Epoch: 2 [2710/3978 (68%)]\tLoss: 0.118572\n",
            "Train Epoch: 2 [2715/3978 (68%)]\tLoss: 0.076717\n",
            "Train Epoch: 2 [2720/3978 (68%)]\tLoss: 0.076626\n",
            "Train Epoch: 2 [2725/3978 (68%)]\tLoss: 0.194107\n",
            "Train Epoch: 2 [2730/3978 (69%)]\tLoss: 0.106521\n",
            "Train Epoch: 2 [2735/3978 (69%)]\tLoss: 0.226666\n",
            "Train Epoch: 2 [2740/3978 (69%)]\tLoss: 0.119793\n",
            "Train Epoch: 2 [2745/3978 (69%)]\tLoss: 0.186851\n",
            "Train Epoch: 2 [2750/3978 (69%)]\tLoss: 0.558706\n",
            "Train Epoch: 2 [2755/3978 (69%)]\tLoss: 0.526246\n",
            "Train Epoch: 2 [2760/3978 (69%)]\tLoss: 0.363925\n",
            "Train Epoch: 2 [2765/3978 (69%)]\tLoss: 0.105972\n",
            "Train Epoch: 2 [2770/3978 (70%)]\tLoss: 0.408881\n",
            "Train Epoch: 2 [2775/3978 (70%)]\tLoss: 0.281893\n",
            "Train Epoch: 2 [2780/3978 (70%)]\tLoss: 0.199208\n",
            "Train Epoch: 2 [2785/3978 (70%)]\tLoss: 0.385489\n",
            "Train Epoch: 2 [2790/3978 (70%)]\tLoss: 0.465260\n",
            "Train Epoch: 2 [2795/3978 (70%)]\tLoss: 0.493212\n",
            "Train Epoch: 2 [2800/3978 (70%)]\tLoss: 0.189205\n",
            "Train Epoch: 2 [2805/3978 (70%)]\tLoss: 0.618476\n",
            "Train Epoch: 2 [2810/3978 (71%)]\tLoss: 0.188630\n",
            "Train Epoch: 2 [2815/3978 (71%)]\tLoss: 0.136646\n",
            "Train Epoch: 2 [2820/3978 (71%)]\tLoss: 0.293648\n",
            "Train Epoch: 2 [2825/3978 (71%)]\tLoss: 0.304940\n",
            "Train Epoch: 2 [2830/3978 (71%)]\tLoss: 0.332246\n",
            "Train Epoch: 2 [2835/3978 (71%)]\tLoss: 0.618588\n",
            "Train Epoch: 2 [2840/3978 (71%)]\tLoss: 0.102157\n",
            "Train Epoch: 2 [2845/3978 (71%)]\tLoss: 0.229583\n",
            "Train Epoch: 2 [2850/3978 (72%)]\tLoss: 0.298067\n",
            "Train Epoch: 2 [2855/3978 (72%)]\tLoss: 0.086603\n",
            "Train Epoch: 2 [2860/3978 (72%)]\tLoss: 0.315374\n",
            "Train Epoch: 2 [2865/3978 (72%)]\tLoss: 0.125789\n",
            "Train Epoch: 2 [2870/3978 (72%)]\tLoss: 0.267269\n",
            "Train Epoch: 2 [2875/3978 (72%)]\tLoss: 0.138099\n",
            "Train Epoch: 2 [2880/3978 (72%)]\tLoss: 0.563104\n",
            "Train Epoch: 2 [2885/3978 (72%)]\tLoss: 0.081350\n",
            "Train Epoch: 2 [2890/3978 (73%)]\tLoss: 0.185960\n",
            "Train Epoch: 2 [2895/3978 (73%)]\tLoss: 0.342625\n",
            "Train Epoch: 2 [2900/3978 (73%)]\tLoss: 0.072701\n",
            "Train Epoch: 2 [2905/3978 (73%)]\tLoss: 0.258106\n",
            "Train Epoch: 2 [2910/3978 (73%)]\tLoss: 0.273881\n",
            "Train Epoch: 2 [2915/3978 (73%)]\tLoss: 0.066405\n",
            "Train Epoch: 2 [2920/3978 (73%)]\tLoss: 0.102883\n",
            "Train Epoch: 2 [2925/3978 (73%)]\tLoss: 0.316054\n",
            "Train Epoch: 2 [2930/3978 (74%)]\tLoss: 0.177056\n",
            "Train Epoch: 2 [2935/3978 (74%)]\tLoss: 0.152336\n",
            "Train Epoch: 2 [2940/3978 (74%)]\tLoss: 0.106330\n",
            "Train Epoch: 2 [2945/3978 (74%)]\tLoss: 0.061288\n",
            "Train Epoch: 2 [2950/3978 (74%)]\tLoss: 0.177737\n",
            "Train Epoch: 2 [2955/3978 (74%)]\tLoss: 0.316823\n",
            "Train Epoch: 2 [2960/3978 (74%)]\tLoss: 0.078039\n",
            "Train Epoch: 2 [2965/3978 (74%)]\tLoss: 0.434093\n",
            "Train Epoch: 2 [2970/3978 (75%)]\tLoss: 0.253611\n",
            "Train Epoch: 2 [2975/3978 (75%)]\tLoss: 0.058923\n",
            "Train Epoch: 2 [2980/3978 (75%)]\tLoss: 0.092712\n",
            "Train Epoch: 2 [2985/3978 (75%)]\tLoss: 0.242967\n",
            "Train Epoch: 2 [2990/3978 (75%)]\tLoss: 0.437944\n",
            "Train Epoch: 2 [2995/3978 (75%)]\tLoss: 0.098194\n",
            "Train Epoch: 2 [3000/3978 (75%)]\tLoss: 0.330753\n",
            "Train Epoch: 2 [3005/3978 (76%)]\tLoss: 0.462591\n",
            "Train Epoch: 2 [3010/3978 (76%)]\tLoss: 0.333815\n",
            "Train Epoch: 2 [3015/3978 (76%)]\tLoss: 0.307439\n",
            "Train Epoch: 2 [3020/3978 (76%)]\tLoss: 0.212174\n",
            "Train Epoch: 2 [3025/3978 (76%)]\tLoss: 0.763300\n",
            "Train Epoch: 2 [3030/3978 (76%)]\tLoss: 0.106752\n",
            "Train Epoch: 2 [3035/3978 (76%)]\tLoss: 0.329979\n",
            "Train Epoch: 2 [3040/3978 (76%)]\tLoss: 0.708884\n",
            "Train Epoch: 2 [3045/3978 (77%)]\tLoss: 0.371155\n",
            "Train Epoch: 2 [3050/3978 (77%)]\tLoss: 0.472233\n",
            "Train Epoch: 2 [3055/3978 (77%)]\tLoss: 0.465169\n",
            "Train Epoch: 2 [3060/3978 (77%)]\tLoss: 0.129411\n",
            "Train Epoch: 2 [3065/3978 (77%)]\tLoss: 0.271487\n",
            "Train Epoch: 2 [3070/3978 (77%)]\tLoss: 0.346196\n",
            "Train Epoch: 2 [3075/3978 (77%)]\tLoss: 0.167548\n",
            "Train Epoch: 2 [3080/3978 (77%)]\tLoss: 0.410244\n",
            "Train Epoch: 2 [3085/3978 (78%)]\tLoss: 0.342502\n",
            "Train Epoch: 2 [3090/3978 (78%)]\tLoss: 0.351078\n",
            "Train Epoch: 2 [3095/3978 (78%)]\tLoss: 0.565315\n",
            "Train Epoch: 2 [3100/3978 (78%)]\tLoss: 0.406122\n",
            "Train Epoch: 2 [3105/3978 (78%)]\tLoss: 0.096792\n",
            "Train Epoch: 2 [3110/3978 (78%)]\tLoss: 0.292926\n",
            "Train Epoch: 2 [3115/3978 (78%)]\tLoss: 0.428861\n",
            "Train Epoch: 2 [3120/3978 (78%)]\tLoss: 0.044136\n",
            "Train Epoch: 2 [3125/3978 (79%)]\tLoss: 0.661650\n",
            "Train Epoch: 2 [3130/3978 (79%)]\tLoss: 0.308322\n",
            "Train Epoch: 2 [3135/3978 (79%)]\tLoss: 0.172620\n",
            "Train Epoch: 2 [3140/3978 (79%)]\tLoss: 0.099085\n",
            "Train Epoch: 2 [3145/3978 (79%)]\tLoss: 0.174340\n",
            "Train Epoch: 2 [3150/3978 (79%)]\tLoss: 0.336871\n",
            "Train Epoch: 2 [3155/3978 (79%)]\tLoss: 0.135411\n",
            "Train Epoch: 2 [3160/3978 (79%)]\tLoss: 0.626704\n",
            "Train Epoch: 2 [3165/3978 (80%)]\tLoss: 0.230040\n",
            "Train Epoch: 2 [3170/3978 (80%)]\tLoss: 0.098994\n",
            "Train Epoch: 2 [3175/3978 (80%)]\tLoss: 0.278783\n",
            "Train Epoch: 2 [3180/3978 (80%)]\tLoss: 0.146250\n",
            "Train Epoch: 2 [3185/3978 (80%)]\tLoss: 0.358900\n",
            "Train Epoch: 2 [3190/3978 (80%)]\tLoss: 0.777431\n",
            "Train Epoch: 2 [3195/3978 (80%)]\tLoss: 0.056119\n",
            "Train Epoch: 2 [3200/3978 (80%)]\tLoss: 0.170811\n",
            "Train Epoch: 2 [3205/3978 (81%)]\tLoss: 0.364561\n",
            "Train Epoch: 2 [3210/3978 (81%)]\tLoss: 0.231836\n",
            "Train Epoch: 2 [3215/3978 (81%)]\tLoss: 0.249363\n",
            "Train Epoch: 2 [3220/3978 (81%)]\tLoss: 0.599283\n",
            "Train Epoch: 2 [3225/3978 (81%)]\tLoss: 0.862578\n",
            "Train Epoch: 2 [3230/3978 (81%)]\tLoss: 0.161469\n",
            "Train Epoch: 2 [3235/3978 (81%)]\tLoss: 0.439089\n",
            "Train Epoch: 2 [3240/3978 (81%)]\tLoss: 0.607550\n",
            "Train Epoch: 2 [3245/3978 (82%)]\tLoss: 0.224458\n",
            "Train Epoch: 2 [3250/3978 (82%)]\tLoss: 0.309296\n",
            "Train Epoch: 2 [3255/3978 (82%)]\tLoss: 0.296359\n",
            "Train Epoch: 2 [3260/3978 (82%)]\tLoss: 0.141477\n",
            "Train Epoch: 2 [3265/3978 (82%)]\tLoss: 0.516178\n",
            "Train Epoch: 2 [3270/3978 (82%)]\tLoss: 0.183842\n",
            "Train Epoch: 2 [3275/3978 (82%)]\tLoss: 0.275897\n",
            "Train Epoch: 2 [3280/3978 (82%)]\tLoss: 0.104462\n",
            "Train Epoch: 2 [3285/3978 (83%)]\tLoss: 0.104742\n",
            "Train Epoch: 2 [3290/3978 (83%)]\tLoss: 0.353856\n",
            "Train Epoch: 2 [3295/3978 (83%)]\tLoss: 0.340430\n",
            "Train Epoch: 2 [3300/3978 (83%)]\tLoss: 0.278889\n",
            "Train Epoch: 2 [3305/3978 (83%)]\tLoss: 0.279040\n",
            "Train Epoch: 2 [3310/3978 (83%)]\tLoss: 0.421461\n",
            "Train Epoch: 2 [3315/3978 (83%)]\tLoss: 0.210591\n",
            "Train Epoch: 2 [3320/3978 (83%)]\tLoss: 0.326738\n",
            "Train Epoch: 2 [3325/3978 (84%)]\tLoss: 0.231995\n",
            "Train Epoch: 2 [3330/3978 (84%)]\tLoss: 0.276464\n",
            "Train Epoch: 2 [3335/3978 (84%)]\tLoss: 0.708142\n",
            "Train Epoch: 2 [3340/3978 (84%)]\tLoss: 0.077244\n",
            "Train Epoch: 2 [3345/3978 (84%)]\tLoss: 0.515489\n",
            "Train Epoch: 2 [3350/3978 (84%)]\tLoss: 0.190393\n",
            "Train Epoch: 2 [3355/3978 (84%)]\tLoss: 0.526344\n",
            "Train Epoch: 2 [3360/3978 (84%)]\tLoss: 0.402308\n",
            "Train Epoch: 2 [3365/3978 (85%)]\tLoss: 0.274441\n",
            "Train Epoch: 2 [3370/3978 (85%)]\tLoss: 0.430455\n",
            "Train Epoch: 2 [3375/3978 (85%)]\tLoss: 0.589139\n",
            "Train Epoch: 2 [3380/3978 (85%)]\tLoss: 0.275241\n",
            "Train Epoch: 2 [3385/3978 (85%)]\tLoss: 0.515734\n",
            "Train Epoch: 2 [3390/3978 (85%)]\tLoss: 0.523635\n",
            "Train Epoch: 2 [3395/3978 (85%)]\tLoss: 0.171402\n",
            "Train Epoch: 2 [3400/3978 (85%)]\tLoss: 0.117164\n",
            "Train Epoch: 2 [3405/3978 (86%)]\tLoss: 0.234282\n",
            "Train Epoch: 2 [3410/3978 (86%)]\tLoss: 0.341649\n",
            "Train Epoch: 2 [3415/3978 (86%)]\tLoss: 0.119546\n",
            "Train Epoch: 2 [3420/3978 (86%)]\tLoss: 0.377191\n",
            "Train Epoch: 2 [3425/3978 (86%)]\tLoss: 0.684117\n",
            "Train Epoch: 2 [3430/3978 (86%)]\tLoss: 0.164031\n",
            "Train Epoch: 2 [3435/3978 (86%)]\tLoss: 0.840897\n",
            "Train Epoch: 2 [3440/3978 (86%)]\tLoss: 0.567788\n",
            "Train Epoch: 2 [3445/3978 (87%)]\tLoss: 0.225099\n",
            "Train Epoch: 2 [3450/3978 (87%)]\tLoss: 0.059994\n",
            "Train Epoch: 2 [3455/3978 (87%)]\tLoss: 0.547961\n",
            "Train Epoch: 2 [3460/3978 (87%)]\tLoss: 0.740178\n",
            "Train Epoch: 2 [3465/3978 (87%)]\tLoss: 0.023838\n",
            "Train Epoch: 2 [3470/3978 (87%)]\tLoss: 0.246259\n",
            "Train Epoch: 2 [3475/3978 (87%)]\tLoss: 0.431268\n",
            "Train Epoch: 2 [3480/3978 (87%)]\tLoss: 0.017285\n",
            "Train Epoch: 2 [3485/3978 (88%)]\tLoss: 0.280144\n",
            "Train Epoch: 2 [3490/3978 (88%)]\tLoss: 0.220824\n",
            "Train Epoch: 2 [3495/3978 (88%)]\tLoss: 0.387350\n",
            "Train Epoch: 2 [3500/3978 (88%)]\tLoss: 0.097544\n",
            "Train Epoch: 2 [3505/3978 (88%)]\tLoss: 0.059560\n",
            "Train Epoch: 2 [3510/3978 (88%)]\tLoss: 0.258152\n",
            "Train Epoch: 2 [3515/3978 (88%)]\tLoss: 0.200569\n",
            "Train Epoch: 2 [3520/3978 (88%)]\tLoss: 0.091498\n",
            "Train Epoch: 2 [3525/3978 (89%)]\tLoss: 0.320161\n",
            "Train Epoch: 2 [3530/3978 (89%)]\tLoss: 0.069384\n",
            "Train Epoch: 2 [3535/3978 (89%)]\tLoss: 0.113550\n",
            "Train Epoch: 2 [3540/3978 (89%)]\tLoss: 0.225820\n",
            "Train Epoch: 2 [3545/3978 (89%)]\tLoss: 0.435431\n",
            "Train Epoch: 2 [3550/3978 (89%)]\tLoss: 0.139158\n",
            "Train Epoch: 2 [3555/3978 (89%)]\tLoss: 0.209984\n",
            "Train Epoch: 2 [3560/3978 (89%)]\tLoss: 0.299594\n",
            "Train Epoch: 2 [3565/3978 (90%)]\tLoss: 0.132815\n",
            "Train Epoch: 2 [3570/3978 (90%)]\tLoss: 0.379789\n",
            "Train Epoch: 2 [3575/3978 (90%)]\tLoss: 0.079444\n",
            "Train Epoch: 2 [3580/3978 (90%)]\tLoss: 0.006483\n",
            "Train Epoch: 2 [3585/3978 (90%)]\tLoss: 0.210760\n",
            "Train Epoch: 2 [3590/3978 (90%)]\tLoss: 0.118923\n",
            "Train Epoch: 2 [3595/3978 (90%)]\tLoss: 0.677254\n",
            "Train Epoch: 2 [3600/3978 (90%)]\tLoss: 0.173835\n",
            "Train Epoch: 2 [3605/3978 (91%)]\tLoss: 0.570992\n",
            "Train Epoch: 2 [3610/3978 (91%)]\tLoss: 0.492341\n",
            "Train Epoch: 2 [3615/3978 (91%)]\tLoss: 0.147039\n",
            "Train Epoch: 2 [3620/3978 (91%)]\tLoss: 0.487698\n",
            "Train Epoch: 2 [3625/3978 (91%)]\tLoss: 0.313341\n",
            "Train Epoch: 2 [3630/3978 (91%)]\tLoss: 0.071498\n",
            "Train Epoch: 2 [3635/3978 (91%)]\tLoss: 0.358881\n",
            "Train Epoch: 2 [3640/3978 (91%)]\tLoss: 0.218995\n",
            "Train Epoch: 2 [3645/3978 (92%)]\tLoss: 0.398373\n",
            "Train Epoch: 2 [3650/3978 (92%)]\tLoss: 0.316015\n",
            "Train Epoch: 2 [3655/3978 (92%)]\tLoss: 0.271988\n",
            "Train Epoch: 2 [3660/3978 (92%)]\tLoss: 0.268851\n",
            "Train Epoch: 2 [3665/3978 (92%)]\tLoss: 0.313779\n",
            "Train Epoch: 2 [3670/3978 (92%)]\tLoss: 0.293598\n",
            "Train Epoch: 2 [3675/3978 (92%)]\tLoss: 0.265859\n",
            "Train Epoch: 2 [3680/3978 (92%)]\tLoss: 0.207690\n",
            "Train Epoch: 2 [3685/3978 (93%)]\tLoss: 0.330926\n",
            "Train Epoch: 2 [3690/3978 (93%)]\tLoss: 0.192295\n",
            "Train Epoch: 2 [3695/3978 (93%)]\tLoss: 0.425021\n",
            "Train Epoch: 2 [3700/3978 (93%)]\tLoss: 0.115302\n",
            "Train Epoch: 2 [3705/3978 (93%)]\tLoss: 0.586906\n",
            "Train Epoch: 2 [3710/3978 (93%)]\tLoss: 0.449317\n",
            "Train Epoch: 2 [3715/3978 (93%)]\tLoss: 0.094200\n",
            "Train Epoch: 2 [3720/3978 (93%)]\tLoss: 0.012972\n",
            "Train Epoch: 2 [3725/3978 (94%)]\tLoss: 0.472484\n",
            "Train Epoch: 2 [3730/3978 (94%)]\tLoss: 0.048723\n",
            "Train Epoch: 2 [3735/3978 (94%)]\tLoss: 0.394524\n",
            "Train Epoch: 2 [3740/3978 (94%)]\tLoss: 0.290017\n",
            "Train Epoch: 2 [3745/3978 (94%)]\tLoss: 0.405801\n",
            "Train Epoch: 2 [3750/3978 (94%)]\tLoss: 0.558487\n",
            "Train Epoch: 2 [3755/3978 (94%)]\tLoss: 0.462955\n",
            "Train Epoch: 2 [3760/3978 (94%)]\tLoss: 0.709720\n",
            "Train Epoch: 2 [3765/3978 (95%)]\tLoss: 0.133680\n",
            "Train Epoch: 2 [3770/3978 (95%)]\tLoss: 0.316028\n",
            "Train Epoch: 2 [3775/3978 (95%)]\tLoss: 0.168273\n",
            "Train Epoch: 2 [3780/3978 (95%)]\tLoss: 0.314111\n",
            "Train Epoch: 2 [3785/3978 (95%)]\tLoss: 0.162972\n",
            "Train Epoch: 2 [3790/3978 (95%)]\tLoss: 0.635121\n",
            "Train Epoch: 2 [3795/3978 (95%)]\tLoss: 0.215414\n",
            "Train Epoch: 2 [3800/3978 (95%)]\tLoss: 0.379473\n",
            "Train Epoch: 2 [3805/3978 (96%)]\tLoss: 0.497667\n",
            "Train Epoch: 2 [3810/3978 (96%)]\tLoss: 0.148730\n",
            "Train Epoch: 2 [3815/3978 (96%)]\tLoss: 0.220922\n",
            "Train Epoch: 2 [3820/3978 (96%)]\tLoss: 0.191511\n",
            "Train Epoch: 2 [3825/3978 (96%)]\tLoss: 0.428412\n",
            "Train Epoch: 2 [3830/3978 (96%)]\tLoss: 0.663604\n",
            "Train Epoch: 2 [3835/3978 (96%)]\tLoss: 0.210057\n",
            "Train Epoch: 2 [3840/3978 (96%)]\tLoss: 0.063518\n",
            "Train Epoch: 2 [3845/3978 (97%)]\tLoss: 0.117767\n",
            "Train Epoch: 2 [3850/3978 (97%)]\tLoss: 0.135973\n",
            "Train Epoch: 2 [3855/3978 (97%)]\tLoss: 0.209245\n",
            "Train Epoch: 2 [3860/3978 (97%)]\tLoss: 0.079390\n",
            "Train Epoch: 2 [3865/3978 (97%)]\tLoss: 0.245796\n",
            "Train Epoch: 2 [3870/3978 (97%)]\tLoss: 0.581412\n",
            "Train Epoch: 2 [3875/3978 (97%)]\tLoss: 0.784908\n",
            "Train Epoch: 2 [3880/3978 (97%)]\tLoss: 0.104565\n",
            "Train Epoch: 2 [3885/3978 (98%)]\tLoss: 0.673092\n",
            "Train Epoch: 2 [3890/3978 (98%)]\tLoss: 0.108203\n",
            "Train Epoch: 2 [3895/3978 (98%)]\tLoss: 0.662634\n",
            "Train Epoch: 2 [3900/3978 (98%)]\tLoss: 0.240876\n",
            "Train Epoch: 2 [3905/3978 (98%)]\tLoss: 0.435526\n",
            "Train Epoch: 2 [3910/3978 (98%)]\tLoss: 0.204255\n",
            "Train Epoch: 2 [3915/3978 (98%)]\tLoss: 0.242819\n",
            "Train Epoch: 2 [3920/3978 (98%)]\tLoss: 0.404108\n",
            "Train Epoch: 2 [3925/3978 (99%)]\tLoss: 0.297477\n",
            "Train Epoch: 2 [3930/3978 (99%)]\tLoss: 0.074825\n",
            "Train Epoch: 2 [3935/3978 (99%)]\tLoss: 0.195318\n",
            "Train Epoch: 2 [3940/3978 (99%)]\tLoss: 0.331477\n",
            "Train Epoch: 2 [3945/3978 (99%)]\tLoss: 0.221557\n",
            "Train Epoch: 2 [3950/3978 (99%)]\tLoss: 0.482890\n",
            "Train Epoch: 2 [3955/3978 (99%)]\tLoss: 0.591148\n",
            "Train Epoch: 2 [3960/3978 (99%)]\tLoss: 0.084160\n",
            "Train Epoch: 2 [3965/3978 (100%)]\tLoss: 0.110183\n",
            "Train Epoch: 2 [3970/3978 (100%)]\tLoss: 0.484580\n",
            "Train Epoch: 2 [2385/3978 (100%)]\tLoss: 0.112625\n",
            "Epoch\n",
            "train/train_loss: 0.1126248687505722\n",
            "\n",
            "Train Loss: 0.113, Valid Loss: 0.379497, Accuracy: 0.36\n",
            "Train Epoch: 3 [0/3978 (0%)]\tLoss: 0.460470\n",
            "Train Epoch: 3 [5/3978 (0%)]\tLoss: 0.628292\n",
            "Train Epoch: 3 [10/3978 (0%)]\tLoss: 0.355270\n",
            "Train Epoch: 3 [15/3978 (0%)]\tLoss: 0.315088\n",
            "Train Epoch: 3 [20/3978 (1%)]\tLoss: 0.348606\n",
            "Train Epoch: 3 [25/3978 (1%)]\tLoss: 0.313946\n",
            "Train Epoch: 3 [30/3978 (1%)]\tLoss: 0.327955\n",
            "Train Epoch: 3 [35/3978 (1%)]\tLoss: 0.509021\n",
            "Train Epoch: 3 [40/3978 (1%)]\tLoss: 0.235096\n",
            "Train Epoch: 3 [45/3978 (1%)]\tLoss: 0.232817\n",
            "Train Epoch: 3 [50/3978 (1%)]\tLoss: 0.153141\n",
            "Train Epoch: 3 [55/3978 (1%)]\tLoss: 0.156175\n",
            "Train Epoch: 3 [60/3978 (2%)]\tLoss: 0.371132\n",
            "Train Epoch: 3 [65/3978 (2%)]\tLoss: 0.181104\n",
            "Train Epoch: 3 [70/3978 (2%)]\tLoss: 0.285296\n",
            "Train Epoch: 3 [75/3978 (2%)]\tLoss: 0.075073\n",
            "Train Epoch: 3 [80/3978 (2%)]\tLoss: 0.298123\n",
            "Train Epoch: 3 [85/3978 (2%)]\tLoss: 0.378639\n",
            "Train Epoch: 3 [90/3978 (2%)]\tLoss: 0.284875\n",
            "Train Epoch: 3 [95/3978 (2%)]\tLoss: 0.136298\n",
            "Train Epoch: 3 [100/3978 (3%)]\tLoss: 0.396765\n",
            "Train Epoch: 3 [105/3978 (3%)]\tLoss: 0.323236\n",
            "Train Epoch: 3 [110/3978 (3%)]\tLoss: 0.080366\n",
            "Train Epoch: 3 [115/3978 (3%)]\tLoss: 0.308837\n",
            "Train Epoch: 3 [120/3978 (3%)]\tLoss: 0.115741\n",
            "Train Epoch: 3 [125/3978 (3%)]\tLoss: 0.170783\n",
            "Train Epoch: 3 [130/3978 (3%)]\tLoss: 0.105621\n",
            "Train Epoch: 3 [135/3978 (3%)]\tLoss: 0.210178\n",
            "Train Epoch: 3 [140/3978 (4%)]\tLoss: 0.043086\n",
            "Train Epoch: 3 [145/3978 (4%)]\tLoss: 0.082075\n",
            "Train Epoch: 3 [150/3978 (4%)]\tLoss: 0.516551\n",
            "Train Epoch: 3 [155/3978 (4%)]\tLoss: 0.436125\n",
            "Train Epoch: 3 [160/3978 (4%)]\tLoss: 0.211857\n",
            "Train Epoch: 3 [165/3978 (4%)]\tLoss: 0.215105\n",
            "Train Epoch: 3 [170/3978 (4%)]\tLoss: 0.361356\n",
            "Train Epoch: 3 [175/3978 (4%)]\tLoss: 0.133015\n",
            "Train Epoch: 3 [180/3978 (5%)]\tLoss: 0.532678\n",
            "Train Epoch: 3 [185/3978 (5%)]\tLoss: 0.603793\n",
            "Train Epoch: 3 [190/3978 (5%)]\tLoss: 0.533348\n",
            "Train Epoch: 3 [195/3978 (5%)]\tLoss: 0.277037\n",
            "Train Epoch: 3 [200/3978 (5%)]\tLoss: 0.164951\n",
            "Train Epoch: 3 [205/3978 (5%)]\tLoss: 0.138703\n",
            "Train Epoch: 3 [210/3978 (5%)]\tLoss: 0.105172\n",
            "Train Epoch: 3 [215/3978 (5%)]\tLoss: 0.105668\n",
            "Train Epoch: 3 [220/3978 (6%)]\tLoss: 0.063420\n",
            "Train Epoch: 3 [225/3978 (6%)]\tLoss: 0.400561\n",
            "Train Epoch: 3 [230/3978 (6%)]\tLoss: 0.202384\n",
            "Train Epoch: 3 [235/3978 (6%)]\tLoss: 0.227388\n",
            "Train Epoch: 3 [240/3978 (6%)]\tLoss: 0.144370\n",
            "Train Epoch: 3 [245/3978 (6%)]\tLoss: 0.154222\n",
            "Train Epoch: 3 [250/3978 (6%)]\tLoss: 0.275088\n",
            "Train Epoch: 3 [255/3978 (6%)]\tLoss: 0.029435\n",
            "Train Epoch: 3 [260/3978 (7%)]\tLoss: 0.454859\n",
            "Train Epoch: 3 [265/3978 (7%)]\tLoss: 0.147488\n",
            "Train Epoch: 3 [270/3978 (7%)]\tLoss: 0.646723\n",
            "Train Epoch: 3 [275/3978 (7%)]\tLoss: 0.488964\n",
            "Train Epoch: 3 [280/3978 (7%)]\tLoss: 0.119270\n",
            "Train Epoch: 3 [285/3978 (7%)]\tLoss: 0.491616\n",
            "Train Epoch: 3 [290/3978 (7%)]\tLoss: 0.459368\n",
            "Train Epoch: 3 [295/3978 (7%)]\tLoss: 0.172214\n",
            "Train Epoch: 3 [300/3978 (8%)]\tLoss: 0.259789\n",
            "Train Epoch: 3 [305/3978 (8%)]\tLoss: 0.476243\n",
            "Train Epoch: 3 [310/3978 (8%)]\tLoss: 0.388576\n",
            "Train Epoch: 3 [315/3978 (8%)]\tLoss: 0.568255\n",
            "Train Epoch: 3 [320/3978 (8%)]\tLoss: 0.501394\n",
            "Train Epoch: 3 [325/3978 (8%)]\tLoss: 0.387411\n",
            "Train Epoch: 3 [330/3978 (8%)]\tLoss: 0.129283\n",
            "Train Epoch: 3 [335/3978 (8%)]\tLoss: 0.278695\n",
            "Train Epoch: 3 [340/3978 (9%)]\tLoss: 0.315689\n",
            "Train Epoch: 3 [345/3978 (9%)]\tLoss: 0.425644\n",
            "Train Epoch: 3 [350/3978 (9%)]\tLoss: 0.116509\n",
            "Train Epoch: 3 [355/3978 (9%)]\tLoss: 0.200387\n",
            "Train Epoch: 3 [360/3978 (9%)]\tLoss: 0.130173\n",
            "Train Epoch: 3 [365/3978 (9%)]\tLoss: 0.376622\n",
            "Train Epoch: 3 [370/3978 (9%)]\tLoss: 0.248401\n",
            "Train Epoch: 3 [375/3978 (9%)]\tLoss: 0.280071\n",
            "Train Epoch: 3 [380/3978 (10%)]\tLoss: 0.095960\n",
            "Train Epoch: 3 [385/3978 (10%)]\tLoss: 0.380803\n",
            "Train Epoch: 3 [390/3978 (10%)]\tLoss: 0.077376\n",
            "Train Epoch: 3 [395/3978 (10%)]\tLoss: 0.135310\n",
            "Train Epoch: 3 [400/3978 (10%)]\tLoss: 0.055561\n",
            "Train Epoch: 3 [405/3978 (10%)]\tLoss: 0.543650\n",
            "Train Epoch: 3 [410/3978 (10%)]\tLoss: 0.125586\n",
            "Train Epoch: 3 [415/3978 (10%)]\tLoss: 0.197188\n",
            "Train Epoch: 3 [420/3978 (11%)]\tLoss: 0.275768\n",
            "Train Epoch: 3 [425/3978 (11%)]\tLoss: 0.101357\n",
            "Train Epoch: 3 [430/3978 (11%)]\tLoss: 0.275612\n",
            "Train Epoch: 3 [435/3978 (11%)]\tLoss: 0.064248\n",
            "Train Epoch: 3 [440/3978 (11%)]\tLoss: 0.285504\n",
            "Train Epoch: 3 [445/3978 (11%)]\tLoss: 0.129526\n",
            "Train Epoch: 3 [450/3978 (11%)]\tLoss: 0.124538\n",
            "Train Epoch: 3 [455/3978 (11%)]\tLoss: 0.098287\n",
            "Train Epoch: 3 [460/3978 (12%)]\tLoss: 0.465969\n",
            "Train Epoch: 3 [465/3978 (12%)]\tLoss: 0.136828\n",
            "Train Epoch: 3 [470/3978 (12%)]\tLoss: 0.635006\n",
            "Train Epoch: 3 [475/3978 (12%)]\tLoss: 0.119569\n",
            "Train Epoch: 3 [480/3978 (12%)]\tLoss: 0.562294\n",
            "Train Epoch: 3 [485/3978 (12%)]\tLoss: 0.060245\n",
            "Train Epoch: 3 [490/3978 (12%)]\tLoss: 0.141605\n",
            "Train Epoch: 3 [495/3978 (12%)]\tLoss: 0.333067\n",
            "Train Epoch: 3 [500/3978 (13%)]\tLoss: 0.072618\n",
            "Train Epoch: 3 [505/3978 (13%)]\tLoss: 0.039972\n",
            "Train Epoch: 3 [510/3978 (13%)]\tLoss: 0.222562\n",
            "Train Epoch: 3 [515/3978 (13%)]\tLoss: 0.204873\n",
            "Train Epoch: 3 [520/3978 (13%)]\tLoss: 0.324164\n",
            "Train Epoch: 3 [525/3978 (13%)]\tLoss: 0.750607\n",
            "Train Epoch: 3 [530/3978 (13%)]\tLoss: 0.094468\n",
            "Train Epoch: 3 [535/3978 (13%)]\tLoss: 0.188916\n",
            "Train Epoch: 3 [540/3978 (14%)]\tLoss: 0.351206\n",
            "Train Epoch: 3 [545/3978 (14%)]\tLoss: 0.293343\n",
            "Train Epoch: 3 [550/3978 (14%)]\tLoss: 0.702781\n",
            "Train Epoch: 3 [555/3978 (14%)]\tLoss: 0.096314\n",
            "Train Epoch: 3 [560/3978 (14%)]\tLoss: 0.314247\n",
            "Train Epoch: 3 [565/3978 (14%)]\tLoss: 0.346865\n",
            "Train Epoch: 3 [570/3978 (14%)]\tLoss: 0.377840\n",
            "Train Epoch: 3 [575/3978 (14%)]\tLoss: 0.151160\n",
            "Train Epoch: 3 [580/3978 (15%)]\tLoss: 0.240447\n",
            "Train Epoch: 3 [585/3978 (15%)]\tLoss: 0.348985\n",
            "Train Epoch: 3 [590/3978 (15%)]\tLoss: 0.249285\n",
            "Train Epoch: 3 [595/3978 (15%)]\tLoss: 0.079771\n",
            "Train Epoch: 3 [600/3978 (15%)]\tLoss: 0.225591\n",
            "Train Epoch: 3 [605/3978 (15%)]\tLoss: 0.349626\n",
            "Train Epoch: 3 [610/3978 (15%)]\tLoss: 0.260898\n",
            "Train Epoch: 3 [615/3978 (15%)]\tLoss: 0.400809\n",
            "Train Epoch: 3 [620/3978 (16%)]\tLoss: 0.504250\n",
            "Train Epoch: 3 [625/3978 (16%)]\tLoss: 0.195474\n",
            "Train Epoch: 3 [630/3978 (16%)]\tLoss: 0.138483\n",
            "Train Epoch: 3 [635/3978 (16%)]\tLoss: 0.378386\n",
            "Train Epoch: 3 [640/3978 (16%)]\tLoss: 0.189538\n",
            "Train Epoch: 3 [645/3978 (16%)]\tLoss: 0.200316\n",
            "Train Epoch: 3 [650/3978 (16%)]\tLoss: 0.351055\n",
            "Train Epoch: 3 [655/3978 (16%)]\tLoss: 0.155127\n",
            "Train Epoch: 3 [660/3978 (17%)]\tLoss: 0.127872\n",
            "Train Epoch: 3 [665/3978 (17%)]\tLoss: 0.140396\n",
            "Train Epoch: 3 [670/3978 (17%)]\tLoss: 0.551705\n",
            "Train Epoch: 3 [675/3978 (17%)]\tLoss: 0.438119\n",
            "Train Epoch: 3 [680/3978 (17%)]\tLoss: 0.181796\n",
            "Train Epoch: 3 [685/3978 (17%)]\tLoss: 0.285377\n",
            "Train Epoch: 3 [690/3978 (17%)]\tLoss: 0.042162\n",
            "Train Epoch: 3 [695/3978 (17%)]\tLoss: 0.137762\n",
            "Train Epoch: 3 [700/3978 (18%)]\tLoss: 0.356051\n",
            "Train Epoch: 3 [705/3978 (18%)]\tLoss: 0.086100\n",
            "Train Epoch: 3 [710/3978 (18%)]\tLoss: 0.287027\n",
            "Train Epoch: 3 [715/3978 (18%)]\tLoss: 0.204118\n",
            "Train Epoch: 3 [720/3978 (18%)]\tLoss: 0.039658\n",
            "Train Epoch: 3 [725/3978 (18%)]\tLoss: 0.088642\n",
            "Train Epoch: 3 [730/3978 (18%)]\tLoss: 0.257106\n",
            "Train Epoch: 3 [735/3978 (18%)]\tLoss: 0.852620\n",
            "Train Epoch: 3 [740/3978 (19%)]\tLoss: 0.208070\n",
            "Train Epoch: 3 [745/3978 (19%)]\tLoss: 0.318004\n",
            "Train Epoch: 3 [750/3978 (19%)]\tLoss: 0.039601\n",
            "Train Epoch: 3 [755/3978 (19%)]\tLoss: 0.402795\n",
            "Train Epoch: 3 [760/3978 (19%)]\tLoss: 0.275156\n",
            "Train Epoch: 3 [765/3978 (19%)]\tLoss: 0.296728\n",
            "Train Epoch: 3 [770/3978 (19%)]\tLoss: 0.435432\n",
            "Train Epoch: 3 [775/3978 (19%)]\tLoss: 0.400277\n",
            "Train Epoch: 3 [780/3978 (20%)]\tLoss: 0.228317\n",
            "Train Epoch: 3 [785/3978 (20%)]\tLoss: 0.552705\n",
            "Train Epoch: 3 [790/3978 (20%)]\tLoss: 0.254039\n",
            "Train Epoch: 3 [795/3978 (20%)]\tLoss: 0.296640\n",
            "Train Epoch: 3 [800/3978 (20%)]\tLoss: 0.153215\n",
            "Train Epoch: 3 [805/3978 (20%)]\tLoss: 0.294053\n",
            "Train Epoch: 3 [810/3978 (20%)]\tLoss: 0.308153\n",
            "Train Epoch: 3 [815/3978 (20%)]\tLoss: 0.048756\n",
            "Train Epoch: 3 [820/3978 (21%)]\tLoss: 0.272709\n",
            "Train Epoch: 3 [825/3978 (21%)]\tLoss: 0.338085\n",
            "Train Epoch: 3 [830/3978 (21%)]\tLoss: 0.251216\n",
            "Train Epoch: 3 [835/3978 (21%)]\tLoss: 0.306813\n",
            "Train Epoch: 3 [840/3978 (21%)]\tLoss: 0.415030\n",
            "Train Epoch: 3 [845/3978 (21%)]\tLoss: 0.217446\n",
            "Train Epoch: 3 [850/3978 (21%)]\tLoss: 0.206994\n",
            "Train Epoch: 3 [855/3978 (21%)]\tLoss: 0.192686\n",
            "Train Epoch: 3 [860/3978 (22%)]\tLoss: 0.624775\n",
            "Train Epoch: 3 [865/3978 (22%)]\tLoss: 0.583117\n",
            "Train Epoch: 3 [870/3978 (22%)]\tLoss: 0.628076\n",
            "Train Epoch: 3 [875/3978 (22%)]\tLoss: 0.407263\n",
            "Train Epoch: 3 [880/3978 (22%)]\tLoss: 0.059098\n",
            "Train Epoch: 3 [885/3978 (22%)]\tLoss: 0.331310\n",
            "Train Epoch: 3 [890/3978 (22%)]\tLoss: 0.069955\n",
            "Train Epoch: 3 [895/3978 (22%)]\tLoss: 0.272141\n",
            "Train Epoch: 3 [900/3978 (23%)]\tLoss: 0.185100\n",
            "Train Epoch: 3 [905/3978 (23%)]\tLoss: 0.330741\n",
            "Train Epoch: 3 [910/3978 (23%)]\tLoss: 0.172862\n",
            "Train Epoch: 3 [915/3978 (23%)]\tLoss: 0.275812\n",
            "Train Epoch: 3 [920/3978 (23%)]\tLoss: 0.214897\n",
            "Train Epoch: 3 [925/3978 (23%)]\tLoss: 0.063812\n",
            "Train Epoch: 3 [930/3978 (23%)]\tLoss: 0.553811\n",
            "Train Epoch: 3 [935/3978 (23%)]\tLoss: 0.089487\n",
            "Train Epoch: 3 [940/3978 (24%)]\tLoss: 0.393344\n",
            "Train Epoch: 3 [945/3978 (24%)]\tLoss: 0.233021\n",
            "Train Epoch: 3 [950/3978 (24%)]\tLoss: 0.478130\n",
            "Train Epoch: 3 [955/3978 (24%)]\tLoss: 0.341462\n",
            "Train Epoch: 3 [960/3978 (24%)]\tLoss: 0.474672\n",
            "Train Epoch: 3 [965/3978 (24%)]\tLoss: 0.200021\n",
            "Train Epoch: 3 [970/3978 (24%)]\tLoss: 0.048368\n",
            "Train Epoch: 3 [975/3978 (24%)]\tLoss: 0.203813\n",
            "Train Epoch: 3 [980/3978 (25%)]\tLoss: 0.376990\n",
            "Train Epoch: 3 [985/3978 (25%)]\tLoss: 0.435337\n",
            "Train Epoch: 3 [990/3978 (25%)]\tLoss: 0.076540\n",
            "Train Epoch: 3 [995/3978 (25%)]\tLoss: 0.413702\n",
            "Train Epoch: 3 [1000/3978 (25%)]\tLoss: 0.314807\n",
            "Train Epoch: 3 [1005/3978 (25%)]\tLoss: 0.264549\n",
            "Train Epoch: 3 [1010/3978 (25%)]\tLoss: 0.197337\n",
            "Train Epoch: 3 [1015/3978 (26%)]\tLoss: 0.135462\n",
            "Train Epoch: 3 [1020/3978 (26%)]\tLoss: 0.256389\n",
            "Train Epoch: 3 [1025/3978 (26%)]\tLoss: 0.177339\n",
            "Train Epoch: 3 [1030/3978 (26%)]\tLoss: 0.201707\n",
            "Train Epoch: 3 [1035/3978 (26%)]\tLoss: 0.189875\n",
            "Train Epoch: 3 [1040/3978 (26%)]\tLoss: 0.363881\n",
            "Train Epoch: 3 [1045/3978 (26%)]\tLoss: 0.091278\n",
            "Train Epoch: 3 [1050/3978 (26%)]\tLoss: 0.164078\n",
            "Train Epoch: 3 [1055/3978 (27%)]\tLoss: 0.427929\n",
            "Train Epoch: 3 [1060/3978 (27%)]\tLoss: 0.508719\n",
            "Train Epoch: 3 [1065/3978 (27%)]\tLoss: 0.253572\n",
            "Train Epoch: 3 [1070/3978 (27%)]\tLoss: 0.436159\n",
            "Train Epoch: 3 [1075/3978 (27%)]\tLoss: 0.212522\n",
            "Train Epoch: 3 [1080/3978 (27%)]\tLoss: 0.785431\n",
            "Train Epoch: 3 [1085/3978 (27%)]\tLoss: 0.379022\n",
            "Train Epoch: 3 [1090/3978 (27%)]\tLoss: 0.465505\n",
            "Train Epoch: 3 [1095/3978 (28%)]\tLoss: 0.523524\n",
            "Train Epoch: 3 [1100/3978 (28%)]\tLoss: 0.083488\n",
            "Train Epoch: 3 [1105/3978 (28%)]\tLoss: 0.359969\n",
            "Train Epoch: 3 [1110/3978 (28%)]\tLoss: 0.101441\n",
            "Train Epoch: 3 [1115/3978 (28%)]\tLoss: 0.223401\n",
            "Train Epoch: 3 [1120/3978 (28%)]\tLoss: 0.335005\n",
            "Train Epoch: 3 [1125/3978 (28%)]\tLoss: 0.151628\n",
            "Train Epoch: 3 [1130/3978 (28%)]\tLoss: 0.376849\n",
            "Train Epoch: 3 [1135/3978 (29%)]\tLoss: 0.659607\n",
            "Train Epoch: 3 [1140/3978 (29%)]\tLoss: 0.118451\n",
            "Train Epoch: 3 [1145/3978 (29%)]\tLoss: 0.143713\n",
            "Train Epoch: 3 [1150/3978 (29%)]\tLoss: 0.151259\n",
            "Train Epoch: 3 [1155/3978 (29%)]\tLoss: 0.082017\n",
            "Train Epoch: 3 [1160/3978 (29%)]\tLoss: 0.171603\n",
            "Train Epoch: 3 [1165/3978 (29%)]\tLoss: 0.257653\n",
            "Train Epoch: 3 [1170/3978 (29%)]\tLoss: 0.398365\n",
            "Train Epoch: 3 [1175/3978 (30%)]\tLoss: 0.415643\n",
            "Train Epoch: 3 [1180/3978 (30%)]\tLoss: 0.179838\n",
            "Train Epoch: 3 [1185/3978 (30%)]\tLoss: 0.116047\n",
            "Train Epoch: 3 [1190/3978 (30%)]\tLoss: 0.592897\n",
            "Train Epoch: 3 [1195/3978 (30%)]\tLoss: 0.841767\n",
            "Train Epoch: 3 [1200/3978 (30%)]\tLoss: 0.218490\n",
            "Train Epoch: 3 [1205/3978 (30%)]\tLoss: 0.276877\n",
            "Train Epoch: 3 [1210/3978 (30%)]\tLoss: 0.197795\n",
            "Train Epoch: 3 [1215/3978 (31%)]\tLoss: 0.157487\n",
            "Train Epoch: 3 [1220/3978 (31%)]\tLoss: 0.622180\n",
            "Train Epoch: 3 [1225/3978 (31%)]\tLoss: 0.166483\n",
            "Train Epoch: 3 [1230/3978 (31%)]\tLoss: 0.364351\n",
            "Train Epoch: 3 [1235/3978 (31%)]\tLoss: 0.292253\n",
            "Train Epoch: 3 [1240/3978 (31%)]\tLoss: 0.088135\n",
            "Train Epoch: 3 [1245/3978 (31%)]\tLoss: 0.233086\n",
            "Train Epoch: 3 [1250/3978 (31%)]\tLoss: 0.386267\n",
            "Train Epoch: 3 [1255/3978 (32%)]\tLoss: 0.134451\n",
            "Train Epoch: 3 [1260/3978 (32%)]\tLoss: 0.318831\n",
            "Train Epoch: 3 [1265/3978 (32%)]\tLoss: 0.208677\n",
            "Train Epoch: 3 [1270/3978 (32%)]\tLoss: 0.124243\n",
            "Train Epoch: 3 [1275/3978 (32%)]\tLoss: 0.477451\n",
            "Train Epoch: 3 [1280/3978 (32%)]\tLoss: 0.203244\n",
            "Train Epoch: 3 [1285/3978 (32%)]\tLoss: 0.250886\n",
            "Train Epoch: 3 [1290/3978 (32%)]\tLoss: 0.092722\n",
            "Train Epoch: 3 [1295/3978 (33%)]\tLoss: 0.364728\n",
            "Train Epoch: 3 [1300/3978 (33%)]\tLoss: 0.153253\n",
            "Train Epoch: 3 [1305/3978 (33%)]\tLoss: 0.234785\n",
            "Train Epoch: 3 [1310/3978 (33%)]\tLoss: 0.120724\n",
            "Train Epoch: 3 [1315/3978 (33%)]\tLoss: 0.676313\n",
            "Train Epoch: 3 [1320/3978 (33%)]\tLoss: 0.170688\n",
            "Train Epoch: 3 [1325/3978 (33%)]\tLoss: 0.253500\n",
            "Train Epoch: 3 [1330/3978 (33%)]\tLoss: 0.202820\n",
            "Train Epoch: 3 [1335/3978 (34%)]\tLoss: 0.259620\n",
            "Train Epoch: 3 [1340/3978 (34%)]\tLoss: 0.386414\n",
            "Train Epoch: 3 [1345/3978 (34%)]\tLoss: 0.369859\n",
            "Train Epoch: 3 [1350/3978 (34%)]\tLoss: 0.123515\n",
            "Train Epoch: 3 [1355/3978 (34%)]\tLoss: 0.285216\n",
            "Train Epoch: 3 [1360/3978 (34%)]\tLoss: 0.378433\n",
            "Train Epoch: 3 [1365/3978 (34%)]\tLoss: 0.438172\n",
            "Train Epoch: 3 [1370/3978 (34%)]\tLoss: 0.080645\n",
            "Train Epoch: 3 [1375/3978 (35%)]\tLoss: 0.753046\n",
            "Train Epoch: 3 [1380/3978 (35%)]\tLoss: 0.070106\n",
            "Train Epoch: 3 [1385/3978 (35%)]\tLoss: 0.503379\n",
            "Train Epoch: 3 [1390/3978 (35%)]\tLoss: 0.359711\n",
            "Train Epoch: 3 [1395/3978 (35%)]\tLoss: 0.035534\n",
            "Train Epoch: 3 [1400/3978 (35%)]\tLoss: 0.285187\n",
            "Train Epoch: 3 [1405/3978 (35%)]\tLoss: 0.171549\n",
            "Train Epoch: 3 [1410/3978 (35%)]\tLoss: 0.243638\n",
            "Train Epoch: 3 [1415/3978 (36%)]\tLoss: 0.179506\n",
            "Train Epoch: 3 [1420/3978 (36%)]\tLoss: 0.053997\n",
            "Train Epoch: 3 [1425/3978 (36%)]\tLoss: 0.098276\n",
            "Train Epoch: 3 [1430/3978 (36%)]\tLoss: 0.135894\n",
            "Train Epoch: 3 [1435/3978 (36%)]\tLoss: 0.277735\n",
            "Train Epoch: 3 [1440/3978 (36%)]\tLoss: 0.222602\n",
            "Train Epoch: 3 [1445/3978 (36%)]\tLoss: 0.426361\n",
            "Train Epoch: 3 [1450/3978 (36%)]\tLoss: 0.271440\n",
            "Train Epoch: 3 [1455/3978 (37%)]\tLoss: 0.168509\n",
            "Train Epoch: 3 [1460/3978 (37%)]\tLoss: 0.343695\n",
            "Train Epoch: 3 [1465/3978 (37%)]\tLoss: 0.105970\n",
            "Train Epoch: 3 [1470/3978 (37%)]\tLoss: 0.531744\n",
            "Train Epoch: 3 [1475/3978 (37%)]\tLoss: 0.302415\n",
            "Train Epoch: 3 [1480/3978 (37%)]\tLoss: 0.086529\n",
            "Train Epoch: 3 [1485/3978 (37%)]\tLoss: 0.375776\n",
            "Train Epoch: 3 [1490/3978 (37%)]\tLoss: 0.499466\n",
            "Train Epoch: 3 [1495/3978 (38%)]\tLoss: 0.257559\n",
            "Train Epoch: 3 [1500/3978 (38%)]\tLoss: 0.107012\n",
            "Train Epoch: 3 [1505/3978 (38%)]\tLoss: 0.292965\n",
            "Train Epoch: 3 [1510/3978 (38%)]\tLoss: 0.083346\n",
            "Train Epoch: 3 [1515/3978 (38%)]\tLoss: 0.133269\n",
            "Train Epoch: 3 [1520/3978 (38%)]\tLoss: 0.158224\n",
            "Train Epoch: 3 [1525/3978 (38%)]\tLoss: 0.124085\n",
            "Train Epoch: 3 [1530/3978 (38%)]\tLoss: 0.041651\n",
            "Train Epoch: 3 [1535/3978 (39%)]\tLoss: 0.222002\n",
            "Train Epoch: 3 [1540/3978 (39%)]\tLoss: 0.263573\n",
            "Train Epoch: 3 [1545/3978 (39%)]\tLoss: 0.532790\n",
            "Train Epoch: 3 [1550/3978 (39%)]\tLoss: 0.443805\n",
            "Train Epoch: 3 [1555/3978 (39%)]\tLoss: 0.273799\n",
            "Train Epoch: 3 [1560/3978 (39%)]\tLoss: 0.270378\n",
            "Train Epoch: 3 [1565/3978 (39%)]\tLoss: 0.289265\n",
            "Train Epoch: 3 [1570/3978 (39%)]\tLoss: 0.449007\n",
            "Train Epoch: 3 [1575/3978 (40%)]\tLoss: 0.544160\n",
            "Train Epoch: 3 [1580/3978 (40%)]\tLoss: 0.638005\n",
            "Train Epoch: 3 [1585/3978 (40%)]\tLoss: 0.418078\n",
            "Train Epoch: 3 [1590/3978 (40%)]\tLoss: 0.155341\n",
            "Train Epoch: 3 [1595/3978 (40%)]\tLoss: 0.290542\n",
            "Train Epoch: 3 [1600/3978 (40%)]\tLoss: 0.231125\n",
            "Train Epoch: 3 [1605/3978 (40%)]\tLoss: 0.414955\n",
            "Train Epoch: 3 [1610/3978 (40%)]\tLoss: 0.370790\n",
            "Train Epoch: 3 [1615/3978 (41%)]\tLoss: 0.391249\n",
            "Train Epoch: 3 [1620/3978 (41%)]\tLoss: 0.216012\n",
            "Train Epoch: 3 [1625/3978 (41%)]\tLoss: 0.400730\n",
            "Train Epoch: 3 [1630/3978 (41%)]\tLoss: 0.405900\n",
            "Train Epoch: 3 [1635/3978 (41%)]\tLoss: 0.191261\n",
            "Train Epoch: 3 [1640/3978 (41%)]\tLoss: 0.153623\n",
            "Train Epoch: 3 [1645/3978 (41%)]\tLoss: 0.143456\n",
            "Train Epoch: 3 [1650/3978 (41%)]\tLoss: 0.389447\n",
            "Train Epoch: 3 [1655/3978 (42%)]\tLoss: 0.118034\n",
            "Train Epoch: 3 [1660/3978 (42%)]\tLoss: 0.097229\n",
            "Train Epoch: 3 [1665/3978 (42%)]\tLoss: 0.287535\n",
            "Train Epoch: 3 [1670/3978 (42%)]\tLoss: 0.349430\n",
            "Train Epoch: 3 [1675/3978 (42%)]\tLoss: 0.024109\n",
            "Train Epoch: 3 [1680/3978 (42%)]\tLoss: 0.131153\n",
            "Train Epoch: 3 [1685/3978 (42%)]\tLoss: 0.293838\n",
            "Train Epoch: 3 [1690/3978 (42%)]\tLoss: 0.404794\n",
            "Train Epoch: 3 [1695/3978 (43%)]\tLoss: 0.621630\n",
            "Train Epoch: 3 [1700/3978 (43%)]\tLoss: 0.077362\n",
            "Train Epoch: 3 [1705/3978 (43%)]\tLoss: 0.523229\n",
            "Train Epoch: 3 [1710/3978 (43%)]\tLoss: 0.170463\n",
            "Train Epoch: 3 [1715/3978 (43%)]\tLoss: 0.107876\n",
            "Train Epoch: 3 [1720/3978 (43%)]\tLoss: 0.430814\n",
            "Train Epoch: 3 [1725/3978 (43%)]\tLoss: 0.709715\n",
            "Train Epoch: 3 [1730/3978 (43%)]\tLoss: 1.027459\n",
            "Train Epoch: 3 [1735/3978 (44%)]\tLoss: 0.142548\n",
            "Train Epoch: 3 [1740/3978 (44%)]\tLoss: 0.529708\n",
            "Train Epoch: 3 [1745/3978 (44%)]\tLoss: 0.229026\n",
            "Train Epoch: 3 [1750/3978 (44%)]\tLoss: 0.453675\n",
            "Train Epoch: 3 [1755/3978 (44%)]\tLoss: 0.466095\n",
            "Train Epoch: 3 [1760/3978 (44%)]\tLoss: 0.102999\n",
            "Train Epoch: 3 [1765/3978 (44%)]\tLoss: 0.315717\n",
            "Train Epoch: 3 [1770/3978 (44%)]\tLoss: 0.275078\n",
            "Train Epoch: 3 [1775/3978 (45%)]\tLoss: 0.100309\n",
            "Train Epoch: 3 [1780/3978 (45%)]\tLoss: 0.372551\n",
            "Train Epoch: 3 [1785/3978 (45%)]\tLoss: 0.165685\n",
            "Train Epoch: 3 [1790/3978 (45%)]\tLoss: 0.489656\n",
            "Train Epoch: 3 [1795/3978 (45%)]\tLoss: 0.135191\n",
            "Train Epoch: 3 [1800/3978 (45%)]\tLoss: 0.279681\n",
            "Train Epoch: 3 [1805/3978 (45%)]\tLoss: 0.154318\n",
            "Train Epoch: 3 [1810/3978 (45%)]\tLoss: 0.326257\n",
            "Train Epoch: 3 [1815/3978 (46%)]\tLoss: 0.131049\n",
            "Train Epoch: 3 [1820/3978 (46%)]\tLoss: 0.217833\n",
            "Train Epoch: 3 [1825/3978 (46%)]\tLoss: 0.082192\n",
            "Train Epoch: 3 [1830/3978 (46%)]\tLoss: 0.246122\n",
            "Train Epoch: 3 [1835/3978 (46%)]\tLoss: 0.197300\n",
            "Train Epoch: 3 [1840/3978 (46%)]\tLoss: 0.491862\n",
            "Train Epoch: 3 [1845/3978 (46%)]\tLoss: 0.091215\n",
            "Train Epoch: 3 [1850/3978 (46%)]\tLoss: 0.192585\n",
            "Train Epoch: 3 [1855/3978 (47%)]\tLoss: 0.106356\n",
            "Train Epoch: 3 [1860/3978 (47%)]\tLoss: 0.639668\n",
            "Train Epoch: 3 [1865/3978 (47%)]\tLoss: 0.358074\n",
            "Train Epoch: 3 [1870/3978 (47%)]\tLoss: 0.379198\n",
            "Train Epoch: 3 [1875/3978 (47%)]\tLoss: 0.180666\n",
            "Train Epoch: 3 [1880/3978 (47%)]\tLoss: 0.551858\n",
            "Train Epoch: 3 [1885/3978 (47%)]\tLoss: 0.137007\n",
            "Train Epoch: 3 [1890/3978 (47%)]\tLoss: 0.288138\n",
            "Train Epoch: 3 [1895/3978 (48%)]\tLoss: 0.313781\n",
            "Train Epoch: 3 [1900/3978 (48%)]\tLoss: 0.569066\n",
            "Train Epoch: 3 [1905/3978 (48%)]\tLoss: 0.421403\n",
            "Train Epoch: 3 [1910/3978 (48%)]\tLoss: 0.175504\n",
            "Train Epoch: 3 [1915/3978 (48%)]\tLoss: 0.511218\n",
            "Train Epoch: 3 [1920/3978 (48%)]\tLoss: 0.158411\n",
            "Train Epoch: 3 [1925/3978 (48%)]\tLoss: 0.279540\n",
            "Train Epoch: 3 [1930/3978 (48%)]\tLoss: 0.052805\n",
            "Train Epoch: 3 [1935/3978 (49%)]\tLoss: 0.702525\n",
            "Train Epoch: 3 [1940/3978 (49%)]\tLoss: 0.194251\n",
            "Train Epoch: 3 [1945/3978 (49%)]\tLoss: 0.110634\n",
            "Train Epoch: 3 [1950/3978 (49%)]\tLoss: 0.093822\n",
            "Train Epoch: 3 [1955/3978 (49%)]\tLoss: 0.209256\n",
            "Train Epoch: 3 [1960/3978 (49%)]\tLoss: 0.219851\n",
            "Train Epoch: 3 [1965/3978 (49%)]\tLoss: 0.337224\n",
            "Train Epoch: 3 [1970/3978 (49%)]\tLoss: 0.114859\n",
            "Train Epoch: 3 [1975/3978 (50%)]\tLoss: 0.220400\n",
            "Train Epoch: 3 [1980/3978 (50%)]\tLoss: 0.483026\n",
            "Train Epoch: 3 [1985/3978 (50%)]\tLoss: 0.101494\n",
            "Train Epoch: 3 [1990/3978 (50%)]\tLoss: 0.139271\n",
            "Train Epoch: 3 [1995/3978 (50%)]\tLoss: 0.329194\n",
            "Train Epoch: 3 [2000/3978 (50%)]\tLoss: 0.469225\n",
            "Train Epoch: 3 [2005/3978 (50%)]\tLoss: 0.081482\n",
            "Train Epoch: 3 [2010/3978 (51%)]\tLoss: 0.129629\n",
            "Train Epoch: 3 [2015/3978 (51%)]\tLoss: 0.066492\n",
            "Train Epoch: 3 [2020/3978 (51%)]\tLoss: 0.603871\n",
            "Train Epoch: 3 [2025/3978 (51%)]\tLoss: 0.665806\n",
            "Train Epoch: 3 [2030/3978 (51%)]\tLoss: 0.136570\n",
            "Train Epoch: 3 [2035/3978 (51%)]\tLoss: 0.608506\n",
            "Train Epoch: 3 [2040/3978 (51%)]\tLoss: 0.373215\n",
            "Train Epoch: 3 [2045/3978 (51%)]\tLoss: 0.405323\n",
            "Train Epoch: 3 [2050/3978 (52%)]\tLoss: 0.157245\n",
            "Train Epoch: 3 [2055/3978 (52%)]\tLoss: 0.315726\n",
            "Train Epoch: 3 [2060/3978 (52%)]\tLoss: 0.103870\n",
            "Train Epoch: 3 [2065/3978 (52%)]\tLoss: 0.451640\n",
            "Train Epoch: 3 [2070/3978 (52%)]\tLoss: 0.467342\n",
            "Train Epoch: 3 [2075/3978 (52%)]\tLoss: 0.271654\n",
            "Train Epoch: 3 [2080/3978 (52%)]\tLoss: 0.201906\n",
            "Train Epoch: 3 [2085/3978 (52%)]\tLoss: 0.112699\n",
            "Train Epoch: 3 [2090/3978 (53%)]\tLoss: 0.101182\n",
            "Train Epoch: 3 [2095/3978 (53%)]\tLoss: 0.082807\n",
            "Train Epoch: 3 [2100/3978 (53%)]\tLoss: 0.464027\n",
            "Train Epoch: 3 [2105/3978 (53%)]\tLoss: 0.154154\n",
            "Train Epoch: 3 [2110/3978 (53%)]\tLoss: 0.051929\n",
            "Train Epoch: 3 [2115/3978 (53%)]\tLoss: 0.335160\n",
            "Train Epoch: 3 [2120/3978 (53%)]\tLoss: 0.404317\n",
            "Train Epoch: 3 [2125/3978 (53%)]\tLoss: 0.208670\n",
            "Train Epoch: 3 [2130/3978 (54%)]\tLoss: 0.598206\n",
            "Train Epoch: 3 [2135/3978 (54%)]\tLoss: 0.400165\n",
            "Train Epoch: 3 [2140/3978 (54%)]\tLoss: 0.201440\n",
            "Train Epoch: 3 [2145/3978 (54%)]\tLoss: 0.308806\n",
            "Train Epoch: 3 [2150/3978 (54%)]\tLoss: 0.377838\n",
            "Train Epoch: 3 [2155/3978 (54%)]\tLoss: 0.087431\n",
            "Train Epoch: 3 [2160/3978 (54%)]\tLoss: 0.528460\n",
            "Train Epoch: 3 [2165/3978 (54%)]\tLoss: 0.263459\n",
            "Train Epoch: 3 [2170/3978 (55%)]\tLoss: 0.141117\n",
            "Train Epoch: 3 [2175/3978 (55%)]\tLoss: 0.837518\n",
            "Train Epoch: 3 [2180/3978 (55%)]\tLoss: 0.206233\n",
            "Train Epoch: 3 [2185/3978 (55%)]\tLoss: 0.217435\n",
            "Train Epoch: 3 [2190/3978 (55%)]\tLoss: 0.275736\n",
            "Train Epoch: 3 [2195/3978 (55%)]\tLoss: 0.614555\n",
            "Train Epoch: 3 [2200/3978 (55%)]\tLoss: 0.301893\n",
            "Train Epoch: 3 [2205/3978 (55%)]\tLoss: 0.154390\n",
            "Train Epoch: 3 [2210/3978 (56%)]\tLoss: 0.374308\n",
            "Train Epoch: 3 [2215/3978 (56%)]\tLoss: 0.073649\n",
            "Train Epoch: 3 [2220/3978 (56%)]\tLoss: 0.365491\n",
            "Train Epoch: 3 [2225/3978 (56%)]\tLoss: 0.108979\n",
            "Train Epoch: 3 [2230/3978 (56%)]\tLoss: 0.195326\n",
            "Train Epoch: 3 [2235/3978 (56%)]\tLoss: 0.263841\n",
            "Train Epoch: 3 [2240/3978 (56%)]\tLoss: 0.179975\n",
            "Train Epoch: 3 [2245/3978 (56%)]\tLoss: 0.463192\n",
            "Train Epoch: 3 [2250/3978 (57%)]\tLoss: 0.135826\n",
            "Train Epoch: 3 [2255/3978 (57%)]\tLoss: 0.078047\n",
            "Train Epoch: 3 [2260/3978 (57%)]\tLoss: 0.063884\n",
            "Train Epoch: 3 [2265/3978 (57%)]\tLoss: 0.283018\n",
            "Train Epoch: 3 [2270/3978 (57%)]\tLoss: 0.147644\n",
            "Train Epoch: 3 [2275/3978 (57%)]\tLoss: 0.440675\n",
            "Train Epoch: 3 [2280/3978 (57%)]\tLoss: 0.244338\n",
            "Train Epoch: 3 [2285/3978 (57%)]\tLoss: 0.020884\n",
            "Train Epoch: 3 [2290/3978 (58%)]\tLoss: 0.048146\n",
            "Train Epoch: 3 [2295/3978 (58%)]\tLoss: 0.319969\n",
            "Train Epoch: 3 [2300/3978 (58%)]\tLoss: 0.550682\n",
            "Train Epoch: 3 [2305/3978 (58%)]\tLoss: 0.169509\n",
            "Train Epoch: 3 [2310/3978 (58%)]\tLoss: 0.158883\n",
            "Train Epoch: 3 [2315/3978 (58%)]\tLoss: 0.170501\n",
            "Train Epoch: 3 [2320/3978 (58%)]\tLoss: 0.090234\n",
            "Train Epoch: 3 [2325/3978 (58%)]\tLoss: 0.068294\n",
            "Train Epoch: 3 [2330/3978 (59%)]\tLoss: 0.247526\n",
            "Train Epoch: 3 [2335/3978 (59%)]\tLoss: 0.197451\n",
            "Train Epoch: 3 [2340/3978 (59%)]\tLoss: 0.465417\n",
            "Train Epoch: 3 [2345/3978 (59%)]\tLoss: 0.511670\n",
            "Train Epoch: 3 [2350/3978 (59%)]\tLoss: 0.204048\n",
            "Train Epoch: 3 [2355/3978 (59%)]\tLoss: 0.227094\n",
            "Train Epoch: 3 [2360/3978 (59%)]\tLoss: 0.073517\n",
            "Train Epoch: 3 [2365/3978 (59%)]\tLoss: 0.341900\n",
            "Train Epoch: 3 [2370/3978 (60%)]\tLoss: 0.073446\n",
            "Train Epoch: 3 [2375/3978 (60%)]\tLoss: 0.494188\n",
            "Train Epoch: 3 [2380/3978 (60%)]\tLoss: 0.245244\n",
            "Train Epoch: 3 [2385/3978 (60%)]\tLoss: 0.090095\n",
            "Train Epoch: 3 [2390/3978 (60%)]\tLoss: 0.080986\n",
            "Train Epoch: 3 [2395/3978 (60%)]\tLoss: 0.218919\n",
            "Train Epoch: 3 [2400/3978 (60%)]\tLoss: 0.220141\n",
            "Train Epoch: 3 [2405/3978 (60%)]\tLoss: 0.120847\n",
            "Train Epoch: 3 [2410/3978 (61%)]\tLoss: 0.090140\n",
            "Train Epoch: 3 [2415/3978 (61%)]\tLoss: 0.103551\n",
            "Train Epoch: 3 [2420/3978 (61%)]\tLoss: 0.149184\n",
            "Train Epoch: 3 [2425/3978 (61%)]\tLoss: 0.051886\n",
            "Train Epoch: 3 [2430/3978 (61%)]\tLoss: 0.096043\n",
            "Train Epoch: 3 [2435/3978 (61%)]\tLoss: 0.372702\n",
            "Train Epoch: 3 [2440/3978 (61%)]\tLoss: 0.413174\n",
            "Train Epoch: 3 [2445/3978 (61%)]\tLoss: 0.217935\n",
            "Train Epoch: 3 [2450/3978 (62%)]\tLoss: 0.112086\n",
            "Train Epoch: 3 [2455/3978 (62%)]\tLoss: 0.037550\n",
            "Train Epoch: 3 [2460/3978 (62%)]\tLoss: 0.161443\n",
            "Train Epoch: 3 [2465/3978 (62%)]\tLoss: 0.046137\n",
            "Train Epoch: 3 [2470/3978 (62%)]\tLoss: 0.580078\n",
            "Train Epoch: 3 [2475/3978 (62%)]\tLoss: 0.322808\n",
            "Train Epoch: 3 [2480/3978 (62%)]\tLoss: 0.028749\n",
            "Train Epoch: 3 [2485/3978 (62%)]\tLoss: 0.515528\n",
            "Train Epoch: 3 [2490/3978 (63%)]\tLoss: 0.707889\n",
            "Train Epoch: 3 [2495/3978 (63%)]\tLoss: 0.376768\n",
            "Train Epoch: 3 [2500/3978 (63%)]\tLoss: 0.297139\n",
            "Train Epoch: 3 [2505/3978 (63%)]\tLoss: 0.102655\n",
            "Train Epoch: 3 [2510/3978 (63%)]\tLoss: 0.173421\n",
            "Train Epoch: 3 [2515/3978 (63%)]\tLoss: 0.627834\n",
            "Train Epoch: 3 [2520/3978 (63%)]\tLoss: 0.985281\n",
            "Train Epoch: 3 [2525/3978 (63%)]\tLoss: 0.079411\n",
            "Train Epoch: 3 [2530/3978 (64%)]\tLoss: 0.360443\n",
            "Train Epoch: 3 [2535/3978 (64%)]\tLoss: 0.338148\n",
            "Train Epoch: 3 [2540/3978 (64%)]\tLoss: 0.148193\n",
            "Train Epoch: 3 [2545/3978 (64%)]\tLoss: 0.237427\n",
            "Train Epoch: 3 [2550/3978 (64%)]\tLoss: 0.114934\n",
            "Train Epoch: 3 [2555/3978 (64%)]\tLoss: 0.130689\n",
            "Train Epoch: 3 [2560/3978 (64%)]\tLoss: 0.228583\n",
            "Train Epoch: 3 [2565/3978 (64%)]\tLoss: 0.316127\n",
            "Train Epoch: 3 [2570/3978 (65%)]\tLoss: 0.347315\n",
            "Train Epoch: 3 [2575/3978 (65%)]\tLoss: 0.609274\n",
            "Train Epoch: 3 [2580/3978 (65%)]\tLoss: 0.322378\n",
            "Train Epoch: 3 [2585/3978 (65%)]\tLoss: 0.139776\n",
            "Train Epoch: 3 [2590/3978 (65%)]\tLoss: 0.313769\n",
            "Train Epoch: 3 [2595/3978 (65%)]\tLoss: 0.129875\n",
            "Train Epoch: 3 [2600/3978 (65%)]\tLoss: 0.292335\n",
            "Train Epoch: 3 [2605/3978 (65%)]\tLoss: 0.395914\n",
            "Train Epoch: 3 [2610/3978 (66%)]\tLoss: 0.644854\n",
            "Train Epoch: 3 [2615/3978 (66%)]\tLoss: 0.661530\n",
            "Train Epoch: 3 [2620/3978 (66%)]\tLoss: 0.537404\n",
            "Train Epoch: 3 [2625/3978 (66%)]\tLoss: 0.410057\n",
            "Train Epoch: 3 [2630/3978 (66%)]\tLoss: 0.246800\n",
            "Train Epoch: 3 [2635/3978 (66%)]\tLoss: 0.230854\n",
            "Train Epoch: 3 [2640/3978 (66%)]\tLoss: 0.097731\n",
            "Train Epoch: 3 [2645/3978 (66%)]\tLoss: 0.164139\n",
            "Train Epoch: 3 [2650/3978 (67%)]\tLoss: 0.827414\n",
            "Train Epoch: 3 [2655/3978 (67%)]\tLoss: 0.260891\n",
            "Train Epoch: 3 [2660/3978 (67%)]\tLoss: 0.146700\n",
            "Train Epoch: 3 [2665/3978 (67%)]\tLoss: 0.210051\n",
            "Train Epoch: 3 [2670/3978 (67%)]\tLoss: 0.283123\n",
            "Train Epoch: 3 [2675/3978 (67%)]\tLoss: 0.683141\n",
            "Train Epoch: 3 [2680/3978 (67%)]\tLoss: 0.125797\n",
            "Train Epoch: 3 [2685/3978 (67%)]\tLoss: 0.114523\n",
            "Train Epoch: 3 [2690/3978 (68%)]\tLoss: 0.088120\n",
            "Train Epoch: 3 [2695/3978 (68%)]\tLoss: 0.082330\n",
            "Train Epoch: 3 [2700/3978 (68%)]\tLoss: 0.134575\n",
            "Train Epoch: 3 [2705/3978 (68%)]\tLoss: 0.325531\n",
            "Train Epoch: 3 [2710/3978 (68%)]\tLoss: 0.093298\n",
            "Train Epoch: 3 [2715/3978 (68%)]\tLoss: 0.362900\n",
            "Train Epoch: 3 [2720/3978 (68%)]\tLoss: 0.194800\n",
            "Train Epoch: 3 [2725/3978 (68%)]\tLoss: 0.391089\n",
            "Train Epoch: 3 [2730/3978 (69%)]\tLoss: 0.706925\n",
            "Train Epoch: 3 [2735/3978 (69%)]\tLoss: 0.280338\n",
            "Train Epoch: 3 [2740/3978 (69%)]\tLoss: 0.384768\n",
            "Train Epoch: 3 [2745/3978 (69%)]\tLoss: 0.383109\n",
            "Train Epoch: 3 [2750/3978 (69%)]\tLoss: 0.395085\n",
            "Train Epoch: 3 [2755/3978 (69%)]\tLoss: 0.479033\n",
            "Train Epoch: 3 [2760/3978 (69%)]\tLoss: 0.385365\n",
            "Train Epoch: 3 [2765/3978 (69%)]\tLoss: 0.297180\n",
            "Train Epoch: 3 [2770/3978 (70%)]\tLoss: 0.146178\n",
            "Train Epoch: 3 [2775/3978 (70%)]\tLoss: 0.382355\n",
            "Train Epoch: 3 [2780/3978 (70%)]\tLoss: 0.223773\n",
            "Train Epoch: 3 [2785/3978 (70%)]\tLoss: 0.475466\n",
            "Train Epoch: 3 [2790/3978 (70%)]\tLoss: 0.697828\n",
            "Train Epoch: 3 [2795/3978 (70%)]\tLoss: 0.397344\n",
            "Train Epoch: 3 [2800/3978 (70%)]\tLoss: 0.180847\n",
            "Train Epoch: 3 [2805/3978 (70%)]\tLoss: 0.313033\n",
            "Train Epoch: 3 [2810/3978 (71%)]\tLoss: 0.304011\n",
            "Train Epoch: 3 [2815/3978 (71%)]\tLoss: 0.123667\n",
            "Train Epoch: 3 [2820/3978 (71%)]\tLoss: 0.319452\n",
            "Train Epoch: 3 [2825/3978 (71%)]\tLoss: 0.345951\n",
            "Train Epoch: 3 [2830/3978 (71%)]\tLoss: 0.200020\n",
            "Train Epoch: 3 [2835/3978 (71%)]\tLoss: 0.317249\n",
            "Train Epoch: 3 [2840/3978 (71%)]\tLoss: 0.109010\n",
            "Train Epoch: 3 [2845/3978 (71%)]\tLoss: 0.210408\n",
            "Train Epoch: 3 [2850/3978 (72%)]\tLoss: 0.302991\n",
            "Train Epoch: 3 [2855/3978 (72%)]\tLoss: 0.320307\n",
            "Train Epoch: 3 [2860/3978 (72%)]\tLoss: 0.265405\n",
            "Train Epoch: 3 [2865/3978 (72%)]\tLoss: 0.113094\n",
            "Train Epoch: 3 [2870/3978 (72%)]\tLoss: 0.283856\n",
            "Train Epoch: 3 [2875/3978 (72%)]\tLoss: 0.093599\n",
            "Train Epoch: 3 [2880/3978 (72%)]\tLoss: 0.333029\n",
            "Train Epoch: 3 [2885/3978 (72%)]\tLoss: 0.076718\n",
            "Train Epoch: 3 [2890/3978 (73%)]\tLoss: 0.823376\n",
            "Train Epoch: 3 [2895/3978 (73%)]\tLoss: 0.154191\n",
            "Train Epoch: 3 [2900/3978 (73%)]\tLoss: 0.630307\n",
            "Train Epoch: 3 [2905/3978 (73%)]\tLoss: 0.127075\n",
            "Train Epoch: 3 [2910/3978 (73%)]\tLoss: 0.344858\n",
            "Train Epoch: 3 [2915/3978 (73%)]\tLoss: 0.319946\n",
            "Train Epoch: 3 [2920/3978 (73%)]\tLoss: 0.309306\n",
            "Train Epoch: 3 [2925/3978 (73%)]\tLoss: 0.083050\n",
            "Train Epoch: 3 [2930/3978 (74%)]\tLoss: 0.409067\n",
            "Train Epoch: 3 [2935/3978 (74%)]\tLoss: 0.324698\n",
            "Train Epoch: 3 [2940/3978 (74%)]\tLoss: 0.439611\n",
            "Train Epoch: 3 [2945/3978 (74%)]\tLoss: 0.379355\n",
            "Train Epoch: 3 [2950/3978 (74%)]\tLoss: 0.269983\n",
            "Train Epoch: 3 [2955/3978 (74%)]\tLoss: 0.536852\n",
            "Train Epoch: 3 [2960/3978 (74%)]\tLoss: 0.279050\n",
            "Train Epoch: 3 [2965/3978 (74%)]\tLoss: 0.477759\n",
            "Train Epoch: 3 [2970/3978 (75%)]\tLoss: 0.115220\n",
            "Train Epoch: 3 [2975/3978 (75%)]\tLoss: 0.142306\n",
            "Train Epoch: 3 [2980/3978 (75%)]\tLoss: 0.164859\n",
            "Train Epoch: 3 [2985/3978 (75%)]\tLoss: 0.631055\n",
            "Train Epoch: 3 [2990/3978 (75%)]\tLoss: 0.318595\n",
            "Train Epoch: 3 [2995/3978 (75%)]\tLoss: 0.258690\n",
            "Train Epoch: 3 [3000/3978 (75%)]\tLoss: 0.438905\n",
            "Train Epoch: 3 [3005/3978 (76%)]\tLoss: 0.178099\n",
            "Train Epoch: 3 [3010/3978 (76%)]\tLoss: 0.205282\n",
            "Train Epoch: 3 [3015/3978 (76%)]\tLoss: 0.411185\n",
            "Train Epoch: 3 [3020/3978 (76%)]\tLoss: 0.160139\n",
            "Train Epoch: 3 [3025/3978 (76%)]\tLoss: 0.118818\n",
            "Train Epoch: 3 [3030/3978 (76%)]\tLoss: 0.249997\n",
            "Train Epoch: 3 [3035/3978 (76%)]\tLoss: 0.245737\n",
            "Train Epoch: 3 [3040/3978 (76%)]\tLoss: 0.640182\n",
            "Train Epoch: 3 [3045/3978 (77%)]\tLoss: 0.119329\n",
            "Train Epoch: 3 [3050/3978 (77%)]\tLoss: 0.126929\n",
            "Train Epoch: 3 [3055/3978 (77%)]\tLoss: 0.477525\n",
            "Train Epoch: 3 [3060/3978 (77%)]\tLoss: 0.113984\n",
            "Train Epoch: 3 [3065/3978 (77%)]\tLoss: 0.619853\n",
            "Train Epoch: 3 [3070/3978 (77%)]\tLoss: 0.113994\n",
            "Train Epoch: 3 [3075/3978 (77%)]\tLoss: 0.300466\n",
            "Train Epoch: 3 [3080/3978 (77%)]\tLoss: 0.215276\n",
            "Train Epoch: 3 [3085/3978 (78%)]\tLoss: 0.400023\n",
            "Train Epoch: 3 [3090/3978 (78%)]\tLoss: 0.196864\n",
            "Train Epoch: 3 [3095/3978 (78%)]\tLoss: 0.044436\n",
            "Train Epoch: 3 [3100/3978 (78%)]\tLoss: 0.131504\n",
            "Train Epoch: 3 [3105/3978 (78%)]\tLoss: 0.344381\n",
            "Train Epoch: 3 [3110/3978 (78%)]\tLoss: 0.090192\n",
            "Train Epoch: 3 [3115/3978 (78%)]\tLoss: 0.564130\n",
            "Train Epoch: 3 [3120/3978 (78%)]\tLoss: 0.286461\n",
            "Train Epoch: 3 [3125/3978 (79%)]\tLoss: 0.363744\n",
            "Train Epoch: 3 [3130/3978 (79%)]\tLoss: 0.401920\n",
            "Train Epoch: 3 [3135/3978 (79%)]\tLoss: 0.077429\n",
            "Train Epoch: 3 [3140/3978 (79%)]\tLoss: 0.253493\n",
            "Train Epoch: 3 [3145/3978 (79%)]\tLoss: 0.386957\n",
            "Train Epoch: 3 [3150/3978 (79%)]\tLoss: 0.247669\n",
            "Train Epoch: 3 [3155/3978 (79%)]\tLoss: 0.275756\n",
            "Train Epoch: 3 [3160/3978 (79%)]\tLoss: 0.536357\n",
            "Train Epoch: 3 [3165/3978 (80%)]\tLoss: 0.088383\n",
            "Train Epoch: 3 [3170/3978 (80%)]\tLoss: 0.074978\n",
            "Train Epoch: 3 [3175/3978 (80%)]\tLoss: 0.386824\n",
            "Train Epoch: 3 [3180/3978 (80%)]\tLoss: 0.166477\n",
            "Train Epoch: 3 [3185/3978 (80%)]\tLoss: 0.395303\n",
            "Train Epoch: 3 [3190/3978 (80%)]\tLoss: 0.182581\n",
            "Train Epoch: 3 [3195/3978 (80%)]\tLoss: 0.400558\n",
            "Train Epoch: 3 [3200/3978 (80%)]\tLoss: 0.336983\n",
            "Train Epoch: 3 [3205/3978 (81%)]\tLoss: 0.237097\n",
            "Train Epoch: 3 [3210/3978 (81%)]\tLoss: 0.172431\n",
            "Train Epoch: 3 [3215/3978 (81%)]\tLoss: 0.268533\n",
            "Train Epoch: 3 [3220/3978 (81%)]\tLoss: 0.289532\n",
            "Train Epoch: 3 [3225/3978 (81%)]\tLoss: 0.189246\n",
            "Train Epoch: 3 [3230/3978 (81%)]\tLoss: 0.058698\n",
            "Train Epoch: 3 [3235/3978 (81%)]\tLoss: 0.378679\n",
            "Train Epoch: 3 [3240/3978 (81%)]\tLoss: 0.233616\n",
            "Train Epoch: 3 [3245/3978 (82%)]\tLoss: 0.332548\n",
            "Train Epoch: 3 [3250/3978 (82%)]\tLoss: 0.288936\n",
            "Train Epoch: 3 [3255/3978 (82%)]\tLoss: 0.302921\n",
            "Train Epoch: 3 [3260/3978 (82%)]\tLoss: 0.186387\n",
            "Train Epoch: 3 [3265/3978 (82%)]\tLoss: 0.138289\n",
            "Train Epoch: 3 [3270/3978 (82%)]\tLoss: 0.390642\n",
            "Train Epoch: 3 [3275/3978 (82%)]\tLoss: 0.633761\n",
            "Train Epoch: 3 [3280/3978 (82%)]\tLoss: 0.389365\n",
            "Train Epoch: 3 [3285/3978 (83%)]\tLoss: 0.251500\n",
            "Train Epoch: 3 [3290/3978 (83%)]\tLoss: 0.183705\n",
            "Train Epoch: 3 [3295/3978 (83%)]\tLoss: 0.081417\n",
            "Train Epoch: 3 [3300/3978 (83%)]\tLoss: 0.624925\n",
            "Train Epoch: 3 [3305/3978 (83%)]\tLoss: 0.197748\n",
            "Train Epoch: 3 [3310/3978 (83%)]\tLoss: 0.796714\n",
            "Train Epoch: 3 [3315/3978 (83%)]\tLoss: 0.617390\n",
            "Train Epoch: 3 [3320/3978 (83%)]\tLoss: 0.249862\n",
            "Train Epoch: 3 [3325/3978 (84%)]\tLoss: 0.138606\n",
            "Train Epoch: 3 [3330/3978 (84%)]\tLoss: 0.206754\n",
            "Train Epoch: 3 [3335/3978 (84%)]\tLoss: 0.605482\n",
            "Train Epoch: 3 [3340/3978 (84%)]\tLoss: 0.293166\n",
            "Train Epoch: 3 [3345/3978 (84%)]\tLoss: 0.339021\n",
            "Train Epoch: 3 [3350/3978 (84%)]\tLoss: 0.343511\n",
            "Train Epoch: 3 [3355/3978 (84%)]\tLoss: 0.213815\n",
            "Train Epoch: 3 [3360/3978 (84%)]\tLoss: 0.367097\n",
            "Train Epoch: 3 [3365/3978 (85%)]\tLoss: 0.226699\n",
            "Train Epoch: 3 [3370/3978 (85%)]\tLoss: 0.094560\n",
            "Train Epoch: 3 [3375/3978 (85%)]\tLoss: 0.176106\n",
            "Train Epoch: 3 [3380/3978 (85%)]\tLoss: 0.040464\n",
            "Train Epoch: 3 [3385/3978 (85%)]\tLoss: 0.153503\n",
            "Train Epoch: 3 [3390/3978 (85%)]\tLoss: 0.411721\n",
            "Train Epoch: 3 [3395/3978 (85%)]\tLoss: 0.187289\n",
            "Train Epoch: 3 [3400/3978 (85%)]\tLoss: 0.241398\n",
            "Train Epoch: 3 [3405/3978 (86%)]\tLoss: 0.229543\n",
            "Train Epoch: 3 [3410/3978 (86%)]\tLoss: 0.331854\n",
            "Train Epoch: 3 [3415/3978 (86%)]\tLoss: 0.100680\n",
            "Train Epoch: 3 [3420/3978 (86%)]\tLoss: 0.220163\n",
            "Train Epoch: 3 [3425/3978 (86%)]\tLoss: 0.058572\n",
            "Train Epoch: 3 [3430/3978 (86%)]\tLoss: 0.174385\n",
            "Train Epoch: 3 [3435/3978 (86%)]\tLoss: 0.058265\n",
            "Train Epoch: 3 [3440/3978 (86%)]\tLoss: 0.418399\n",
            "Train Epoch: 3 [3445/3978 (87%)]\tLoss: 0.521204\n",
            "Train Epoch: 3 [3450/3978 (87%)]\tLoss: 0.147991\n",
            "Train Epoch: 3 [3455/3978 (87%)]\tLoss: 0.599149\n",
            "Train Epoch: 3 [3460/3978 (87%)]\tLoss: 0.083933\n",
            "Train Epoch: 3 [3465/3978 (87%)]\tLoss: 0.277239\n",
            "Train Epoch: 3 [3470/3978 (87%)]\tLoss: 0.178309\n",
            "Train Epoch: 3 [3475/3978 (87%)]\tLoss: 0.455581\n",
            "Train Epoch: 3 [3480/3978 (87%)]\tLoss: 0.108518\n",
            "Train Epoch: 3 [3485/3978 (88%)]\tLoss: 0.410409\n",
            "Train Epoch: 3 [3490/3978 (88%)]\tLoss: 0.248536\n",
            "Train Epoch: 3 [3495/3978 (88%)]\tLoss: 0.075521\n",
            "Train Epoch: 3 [3500/3978 (88%)]\tLoss: 0.108298\n",
            "Train Epoch: 3 [3505/3978 (88%)]\tLoss: 0.286302\n",
            "Train Epoch: 3 [3510/3978 (88%)]\tLoss: 0.250993\n",
            "Train Epoch: 3 [3515/3978 (88%)]\tLoss: 0.211773\n",
            "Train Epoch: 3 [3520/3978 (88%)]\tLoss: 0.268916\n",
            "Train Epoch: 3 [3525/3978 (89%)]\tLoss: 0.342822\n",
            "Train Epoch: 3 [3530/3978 (89%)]\tLoss: 0.065693\n",
            "Train Epoch: 3 [3535/3978 (89%)]\tLoss: 0.277261\n",
            "Train Epoch: 3 [3540/3978 (89%)]\tLoss: 0.124763\n",
            "Train Epoch: 3 [3545/3978 (89%)]\tLoss: 0.055143\n",
            "Train Epoch: 3 [3550/3978 (89%)]\tLoss: 0.050534\n",
            "Train Epoch: 3 [3555/3978 (89%)]\tLoss: 0.144237\n",
            "Train Epoch: 3 [3560/3978 (89%)]\tLoss: 0.310579\n",
            "Train Epoch: 3 [3565/3978 (90%)]\tLoss: 0.151225\n",
            "Train Epoch: 3 [3570/3978 (90%)]\tLoss: 0.242372\n",
            "Train Epoch: 3 [3575/3978 (90%)]\tLoss: 0.463061\n",
            "Train Epoch: 3 [3580/3978 (90%)]\tLoss: 0.180965\n",
            "Train Epoch: 3 [3585/3978 (90%)]\tLoss: 0.113703\n",
            "Train Epoch: 3 [3590/3978 (90%)]\tLoss: 0.068835\n",
            "Train Epoch: 3 [3595/3978 (90%)]\tLoss: 0.448682\n",
            "Train Epoch: 3 [3600/3978 (90%)]\tLoss: 0.320500\n",
            "Train Epoch: 3 [3605/3978 (91%)]\tLoss: 0.031382\n",
            "Train Epoch: 3 [3610/3978 (91%)]\tLoss: 0.415785\n",
            "Train Epoch: 3 [3615/3978 (91%)]\tLoss: 0.267572\n",
            "Train Epoch: 3 [3620/3978 (91%)]\tLoss: 0.124974\n",
            "Train Epoch: 3 [3625/3978 (91%)]\tLoss: 0.318508\n",
            "Train Epoch: 3 [3630/3978 (91%)]\tLoss: 0.125921\n",
            "Train Epoch: 3 [3635/3978 (91%)]\tLoss: 0.161102\n",
            "Train Epoch: 3 [3640/3978 (91%)]\tLoss: 0.338563\n",
            "Train Epoch: 3 [3645/3978 (92%)]\tLoss: 0.087097\n",
            "Train Epoch: 3 [3650/3978 (92%)]\tLoss: 0.052207\n",
            "Train Epoch: 3 [3655/3978 (92%)]\tLoss: 0.280890\n",
            "Train Epoch: 3 [3660/3978 (92%)]\tLoss: 0.639599\n",
            "Train Epoch: 3 [3665/3978 (92%)]\tLoss: 0.132054\n",
            "Train Epoch: 3 [3670/3978 (92%)]\tLoss: 0.492687\n",
            "Train Epoch: 3 [3675/3978 (92%)]\tLoss: 0.049227\n",
            "Train Epoch: 3 [3680/3978 (92%)]\tLoss: 0.154716\n",
            "Train Epoch: 3 [3685/3978 (93%)]\tLoss: 0.075567\n",
            "Train Epoch: 3 [3690/3978 (93%)]\tLoss: 0.105899\n",
            "Train Epoch: 3 [3695/3978 (93%)]\tLoss: 0.195455\n",
            "Train Epoch: 3 [3700/3978 (93%)]\tLoss: 0.066796\n",
            "Train Epoch: 3 [3705/3978 (93%)]\tLoss: 0.325376\n",
            "Train Epoch: 3 [3710/3978 (93%)]\tLoss: 0.146178\n",
            "Train Epoch: 3 [3715/3978 (93%)]\tLoss: 0.614873\n",
            "Train Epoch: 3 [3720/3978 (93%)]\tLoss: 0.059113\n",
            "Train Epoch: 3 [3725/3978 (94%)]\tLoss: 0.205742\n",
            "Train Epoch: 3 [3730/3978 (94%)]\tLoss: 0.436807\n",
            "Train Epoch: 3 [3735/3978 (94%)]\tLoss: 0.482057\n",
            "Train Epoch: 3 [3740/3978 (94%)]\tLoss: 0.087708\n",
            "Train Epoch: 3 [3745/3978 (94%)]\tLoss: 0.106385\n",
            "Train Epoch: 3 [3750/3978 (94%)]\tLoss: 0.103180\n",
            "Train Epoch: 3 [3755/3978 (94%)]\tLoss: 0.256695\n",
            "Train Epoch: 3 [3760/3978 (94%)]\tLoss: 0.081293\n",
            "Train Epoch: 3 [3765/3978 (95%)]\tLoss: 0.132939\n",
            "Train Epoch: 3 [3770/3978 (95%)]\tLoss: 0.071500\n",
            "Train Epoch: 3 [3775/3978 (95%)]\tLoss: 0.220862\n",
            "Train Epoch: 3 [3780/3978 (95%)]\tLoss: 0.325315\n",
            "Train Epoch: 3 [3785/3978 (95%)]\tLoss: 0.105748\n",
            "Train Epoch: 3 [3790/3978 (95%)]\tLoss: 0.238217\n",
            "Train Epoch: 3 [3795/3978 (95%)]\tLoss: 0.185315\n",
            "Train Epoch: 3 [3800/3978 (95%)]\tLoss: 0.642794\n",
            "Train Epoch: 3 [3805/3978 (96%)]\tLoss: 0.617872\n",
            "Train Epoch: 3 [3810/3978 (96%)]\tLoss: 0.121985\n",
            "Train Epoch: 3 [3815/3978 (96%)]\tLoss: 0.203081\n",
            "Train Epoch: 3 [3820/3978 (96%)]\tLoss: 0.199702\n",
            "Train Epoch: 3 [3825/3978 (96%)]\tLoss: 0.293398\n",
            "Train Epoch: 3 [3830/3978 (96%)]\tLoss: 0.148325\n",
            "Train Epoch: 3 [3835/3978 (96%)]\tLoss: 0.491208\n",
            "Train Epoch: 3 [3840/3978 (96%)]\tLoss: 0.354892\n",
            "Train Epoch: 3 [3845/3978 (97%)]\tLoss: 0.089030\n",
            "Train Epoch: 3 [3850/3978 (97%)]\tLoss: 0.705671\n",
            "Train Epoch: 3 [3855/3978 (97%)]\tLoss: 0.088025\n",
            "Train Epoch: 3 [3860/3978 (97%)]\tLoss: 0.150059\n",
            "Train Epoch: 3 [3865/3978 (97%)]\tLoss: 0.213888\n",
            "Train Epoch: 3 [3870/3978 (97%)]\tLoss: 0.171254\n",
            "Train Epoch: 3 [3875/3978 (97%)]\tLoss: 0.117369\n",
            "Train Epoch: 3 [3880/3978 (97%)]\tLoss: 0.141244\n",
            "Train Epoch: 3 [3885/3978 (98%)]\tLoss: 0.307577\n",
            "Train Epoch: 3 [3890/3978 (98%)]\tLoss: 0.161100\n",
            "Train Epoch: 3 [3895/3978 (98%)]\tLoss: 0.186618\n",
            "Train Epoch: 3 [3900/3978 (98%)]\tLoss: 0.080308\n",
            "Train Epoch: 3 [3905/3978 (98%)]\tLoss: 0.290079\n",
            "Train Epoch: 3 [3910/3978 (98%)]\tLoss: 0.235583\n",
            "Train Epoch: 3 [3915/3978 (98%)]\tLoss: 0.179575\n",
            "Train Epoch: 3 [3920/3978 (98%)]\tLoss: 0.420102\n",
            "Train Epoch: 3 [3925/3978 (99%)]\tLoss: 0.078885\n",
            "Train Epoch: 3 [3930/3978 (99%)]\tLoss: 0.050151\n",
            "Train Epoch: 3 [3935/3978 (99%)]\tLoss: 0.470690\n",
            "Train Epoch: 3 [3940/3978 (99%)]\tLoss: 0.133360\n",
            "Train Epoch: 3 [3945/3978 (99%)]\tLoss: 0.208924\n",
            "Train Epoch: 3 [3950/3978 (99%)]\tLoss: 0.308434\n",
            "Train Epoch: 3 [3955/3978 (99%)]\tLoss: 0.163074\n",
            "Train Epoch: 3 [3960/3978 (99%)]\tLoss: 0.095063\n",
            "Train Epoch: 3 [3965/3978 (100%)]\tLoss: 0.382136\n",
            "Train Epoch: 3 [3970/3978 (100%)]\tLoss: 0.248018\n",
            "Train Epoch: 3 [2385/3978 (100%)]\tLoss: 0.072490\n",
            "Epoch\n",
            "train/train_loss: 0.07248983532190323\n",
            "\n",
            "Train Loss: 0.072, Valid Loss: 0.331266, Accuracy: 0.35\n",
            "Train Epoch: 4 [0/3978 (0%)]\tLoss: 0.425710\n",
            "Train Epoch: 4 [5/3978 (0%)]\tLoss: 0.257523\n",
            "Train Epoch: 4 [10/3978 (0%)]\tLoss: 0.309427\n",
            "Train Epoch: 4 [15/3978 (0%)]\tLoss: 0.256531\n",
            "Train Epoch: 4 [20/3978 (1%)]\tLoss: 0.177294\n",
            "Train Epoch: 4 [25/3978 (1%)]\tLoss: 0.426322\n",
            "Train Epoch: 4 [30/3978 (1%)]\tLoss: 0.079623\n",
            "Train Epoch: 4 [35/3978 (1%)]\tLoss: 0.173643\n",
            "Train Epoch: 4 [40/3978 (1%)]\tLoss: 0.327379\n",
            "Train Epoch: 4 [45/3978 (1%)]\tLoss: 0.128156\n",
            "Train Epoch: 4 [50/3978 (1%)]\tLoss: 0.068088\n",
            "Train Epoch: 4 [55/3978 (1%)]\tLoss: 0.284692\n",
            "Train Epoch: 4 [60/3978 (2%)]\tLoss: 0.287034\n",
            "Train Epoch: 4 [65/3978 (2%)]\tLoss: 0.229373\n",
            "Train Epoch: 4 [70/3978 (2%)]\tLoss: 0.159545\n",
            "Train Epoch: 4 [75/3978 (2%)]\tLoss: 0.110472\n",
            "Train Epoch: 4 [80/3978 (2%)]\tLoss: 0.232411\n",
            "Train Epoch: 4 [85/3978 (2%)]\tLoss: 0.207278\n",
            "Train Epoch: 4 [90/3978 (2%)]\tLoss: 0.084301\n",
            "Train Epoch: 4 [95/3978 (2%)]\tLoss: 0.309097\n",
            "Train Epoch: 4 [100/3978 (3%)]\tLoss: 0.243375\n",
            "Train Epoch: 4 [105/3978 (3%)]\tLoss: 0.462155\n",
            "Train Epoch: 4 [110/3978 (3%)]\tLoss: 0.428751\n",
            "Train Epoch: 4 [115/3978 (3%)]\tLoss: 0.065068\n",
            "Train Epoch: 4 [120/3978 (3%)]\tLoss: 0.028551\n",
            "Train Epoch: 4 [125/3978 (3%)]\tLoss: 0.577663\n",
            "Train Epoch: 4 [130/3978 (3%)]\tLoss: 0.148463\n",
            "Train Epoch: 4 [135/3978 (3%)]\tLoss: 0.069740\n",
            "Train Epoch: 4 [140/3978 (4%)]\tLoss: 0.503408\n",
            "Train Epoch: 4 [145/3978 (4%)]\tLoss: 0.331780\n",
            "Train Epoch: 4 [150/3978 (4%)]\tLoss: 0.155898\n",
            "Train Epoch: 4 [155/3978 (4%)]\tLoss: 0.756965\n",
            "Train Epoch: 4 [160/3978 (4%)]\tLoss: 0.352898\n",
            "Train Epoch: 4 [165/3978 (4%)]\tLoss: 0.473404\n",
            "Train Epoch: 4 [170/3978 (4%)]\tLoss: 0.230092\n",
            "Train Epoch: 4 [175/3978 (4%)]\tLoss: 0.178356\n",
            "Train Epoch: 4 [180/3978 (5%)]\tLoss: 0.218250\n",
            "Train Epoch: 4 [185/3978 (5%)]\tLoss: 0.579999\n",
            "Train Epoch: 4 [190/3978 (5%)]\tLoss: 0.105560\n",
            "Train Epoch: 4 [195/3978 (5%)]\tLoss: 0.119872\n",
            "Train Epoch: 4 [200/3978 (5%)]\tLoss: 0.267180\n",
            "Train Epoch: 4 [205/3978 (5%)]\tLoss: 0.222539\n",
            "Train Epoch: 4 [210/3978 (5%)]\tLoss: 0.119196\n",
            "Train Epoch: 4 [215/3978 (5%)]\tLoss: 0.078947\n",
            "Train Epoch: 4 [220/3978 (6%)]\tLoss: 0.078854\n",
            "Train Epoch: 4 [225/3978 (6%)]\tLoss: 0.177904\n",
            "Train Epoch: 4 [230/3978 (6%)]\tLoss: 0.621967\n",
            "Train Epoch: 4 [235/3978 (6%)]\tLoss: 0.284598\n",
            "Train Epoch: 4 [240/3978 (6%)]\tLoss: 0.109706\n",
            "Train Epoch: 4 [245/3978 (6%)]\tLoss: 0.332319\n",
            "Train Epoch: 4 [250/3978 (6%)]\tLoss: 0.079511\n",
            "Train Epoch: 4 [255/3978 (6%)]\tLoss: 0.317687\n",
            "Train Epoch: 4 [260/3978 (7%)]\tLoss: 0.082121\n",
            "Train Epoch: 4 [265/3978 (7%)]\tLoss: 0.345082\n",
            "Train Epoch: 4 [270/3978 (7%)]\tLoss: 0.578936\n",
            "Train Epoch: 4 [275/3978 (7%)]\tLoss: 0.387735\n",
            "Train Epoch: 4 [280/3978 (7%)]\tLoss: 0.060496\n",
            "Train Epoch: 4 [285/3978 (7%)]\tLoss: 0.053463\n",
            "Train Epoch: 4 [290/3978 (7%)]\tLoss: 0.402495\n",
            "Train Epoch: 4 [295/3978 (7%)]\tLoss: 0.217934\n",
            "Train Epoch: 4 [300/3978 (8%)]\tLoss: 0.155362\n",
            "Train Epoch: 4 [305/3978 (8%)]\tLoss: 0.629497\n",
            "Train Epoch: 4 [310/3978 (8%)]\tLoss: 0.122699\n",
            "Train Epoch: 4 [315/3978 (8%)]\tLoss: 0.248803\n",
            "Train Epoch: 4 [320/3978 (8%)]\tLoss: 0.139179\n",
            "Train Epoch: 4 [325/3978 (8%)]\tLoss: 0.113890\n",
            "Train Epoch: 4 [330/3978 (8%)]\tLoss: 0.516263\n",
            "Train Epoch: 4 [335/3978 (8%)]\tLoss: 0.404602\n",
            "Train Epoch: 4 [340/3978 (9%)]\tLoss: 0.187697\n",
            "Train Epoch: 4 [345/3978 (9%)]\tLoss: 0.055464\n",
            "Train Epoch: 4 [350/3978 (9%)]\tLoss: 0.330768\n",
            "Train Epoch: 4 [355/3978 (9%)]\tLoss: 0.404335\n",
            "Train Epoch: 4 [360/3978 (9%)]\tLoss: 0.480897\n",
            "Train Epoch: 4 [365/3978 (9%)]\tLoss: 0.426117\n",
            "Train Epoch: 4 [370/3978 (9%)]\tLoss: 0.402474\n",
            "Train Epoch: 4 [375/3978 (9%)]\tLoss: 0.246229\n",
            "Train Epoch: 4 [380/3978 (10%)]\tLoss: 0.372537\n",
            "Train Epoch: 4 [385/3978 (10%)]\tLoss: 0.391575\n",
            "Train Epoch: 4 [390/3978 (10%)]\tLoss: 0.150830\n",
            "Train Epoch: 4 [395/3978 (10%)]\tLoss: 0.219821\n",
            "Train Epoch: 4 [400/3978 (10%)]\tLoss: 0.255511\n",
            "Train Epoch: 4 [405/3978 (10%)]\tLoss: 0.283293\n",
            "Train Epoch: 4 [410/3978 (10%)]\tLoss: 0.106215\n",
            "Train Epoch: 4 [415/3978 (10%)]\tLoss: 0.471963\n",
            "Train Epoch: 4 [420/3978 (11%)]\tLoss: 0.550930\n",
            "Train Epoch: 4 [425/3978 (11%)]\tLoss: 0.256014\n",
            "Train Epoch: 4 [430/3978 (11%)]\tLoss: 0.266232\n",
            "Train Epoch: 4 [435/3978 (11%)]\tLoss: 0.179062\n",
            "Train Epoch: 4 [440/3978 (11%)]\tLoss: 0.111963\n",
            "Train Epoch: 4 [445/3978 (11%)]\tLoss: 0.080958\n",
            "Train Epoch: 4 [450/3978 (11%)]\tLoss: 0.313122\n",
            "Train Epoch: 4 [455/3978 (11%)]\tLoss: 0.198508\n",
            "Train Epoch: 4 [460/3978 (12%)]\tLoss: 0.564803\n",
            "Train Epoch: 4 [465/3978 (12%)]\tLoss: 0.039128\n",
            "Train Epoch: 4 [470/3978 (12%)]\tLoss: 0.109050\n",
            "Train Epoch: 4 [475/3978 (12%)]\tLoss: 0.090793\n",
            "Train Epoch: 4 [480/3978 (12%)]\tLoss: 0.362139\n",
            "Train Epoch: 4 [485/3978 (12%)]\tLoss: 0.043817\n",
            "Train Epoch: 4 [490/3978 (12%)]\tLoss: 0.560489\n",
            "Train Epoch: 4 [495/3978 (12%)]\tLoss: 0.053567\n",
            "Train Epoch: 4 [500/3978 (13%)]\tLoss: 0.617998\n",
            "Train Epoch: 4 [505/3978 (13%)]\tLoss: 0.077312\n",
            "Train Epoch: 4 [510/3978 (13%)]\tLoss: 0.305566\n",
            "Train Epoch: 4 [515/3978 (13%)]\tLoss: 0.246801\n",
            "Train Epoch: 4 [520/3978 (13%)]\tLoss: 0.143626\n",
            "Train Epoch: 4 [525/3978 (13%)]\tLoss: 0.458533\n",
            "Train Epoch: 4 [530/3978 (13%)]\tLoss: 0.200699\n",
            "Train Epoch: 4 [535/3978 (13%)]\tLoss: 0.057335\n",
            "Train Epoch: 4 [540/3978 (14%)]\tLoss: 0.281535\n",
            "Train Epoch: 4 [545/3978 (14%)]\tLoss: 0.313364\n",
            "Train Epoch: 4 [550/3978 (14%)]\tLoss: 0.294961\n",
            "Train Epoch: 4 [555/3978 (14%)]\tLoss: 0.332444\n",
            "Train Epoch: 4 [560/3978 (14%)]\tLoss: 1.192690\n",
            "Train Epoch: 4 [565/3978 (14%)]\tLoss: 0.176083\n",
            "Train Epoch: 4 [570/3978 (14%)]\tLoss: 0.090043\n",
            "Train Epoch: 4 [575/3978 (14%)]\tLoss: 0.297497\n",
            "Train Epoch: 4 [580/3978 (15%)]\tLoss: 0.077730\n",
            "Train Epoch: 4 [585/3978 (15%)]\tLoss: 0.267091\n",
            "Train Epoch: 4 [590/3978 (15%)]\tLoss: 0.068405\n",
            "Train Epoch: 4 [595/3978 (15%)]\tLoss: 0.125403\n",
            "Train Epoch: 4 [600/3978 (15%)]\tLoss: 0.233129\n",
            "Train Epoch: 4 [605/3978 (15%)]\tLoss: 0.362112\n",
            "Train Epoch: 4 [610/3978 (15%)]\tLoss: 0.245495\n",
            "Train Epoch: 4 [615/3978 (15%)]\tLoss: 0.422301\n",
            "Train Epoch: 4 [620/3978 (16%)]\tLoss: 0.313200\n",
            "Train Epoch: 4 [625/3978 (16%)]\tLoss: 0.198668\n",
            "Train Epoch: 4 [630/3978 (16%)]\tLoss: 0.533474\n",
            "Train Epoch: 4 [635/3978 (16%)]\tLoss: 0.537939\n",
            "Train Epoch: 4 [640/3978 (16%)]\tLoss: 0.298669\n",
            "Train Epoch: 4 [645/3978 (16%)]\tLoss: 0.439166\n",
            "Train Epoch: 4 [650/3978 (16%)]\tLoss: 0.081030\n",
            "Train Epoch: 4 [655/3978 (16%)]\tLoss: 0.275771\n",
            "Train Epoch: 4 [660/3978 (17%)]\tLoss: 0.183684\n",
            "Train Epoch: 4 [665/3978 (17%)]\tLoss: 0.119687\n",
            "Train Epoch: 4 [670/3978 (17%)]\tLoss: 0.468429\n",
            "Train Epoch: 4 [675/3978 (17%)]\tLoss: 0.233858\n",
            "Train Epoch: 4 [680/3978 (17%)]\tLoss: 0.332699\n",
            "Train Epoch: 4 [685/3978 (17%)]\tLoss: 0.139548\n",
            "Train Epoch: 4 [690/3978 (17%)]\tLoss: 0.527982\n",
            "Train Epoch: 4 [695/3978 (17%)]\tLoss: 0.104505\n",
            "Train Epoch: 4 [700/3978 (18%)]\tLoss: 0.222281\n",
            "Train Epoch: 4 [705/3978 (18%)]\tLoss: 0.245022\n",
            "Train Epoch: 4 [710/3978 (18%)]\tLoss: 0.281248\n",
            "Train Epoch: 4 [715/3978 (18%)]\tLoss: 0.477245\n",
            "Train Epoch: 4 [720/3978 (18%)]\tLoss: 0.137416\n",
            "Train Epoch: 4 [725/3978 (18%)]\tLoss: 0.413063\n",
            "Train Epoch: 4 [730/3978 (18%)]\tLoss: 0.236745\n",
            "Train Epoch: 4 [735/3978 (18%)]\tLoss: 0.125874\n",
            "Train Epoch: 4 [740/3978 (19%)]\tLoss: 0.559555\n",
            "Train Epoch: 4 [745/3978 (19%)]\tLoss: 0.210627\n",
            "Train Epoch: 4 [750/3978 (19%)]\tLoss: 0.085445\n",
            "Train Epoch: 4 [755/3978 (19%)]\tLoss: 0.151457\n",
            "Train Epoch: 4 [760/3978 (19%)]\tLoss: 0.148568\n",
            "Train Epoch: 4 [765/3978 (19%)]\tLoss: 0.232722\n",
            "Train Epoch: 4 [770/3978 (19%)]\tLoss: 0.130831\n",
            "Train Epoch: 4 [775/3978 (19%)]\tLoss: 0.197577\n",
            "Train Epoch: 4 [780/3978 (20%)]\tLoss: 0.233162\n",
            "Train Epoch: 4 [785/3978 (20%)]\tLoss: 0.390832\n",
            "Train Epoch: 4 [790/3978 (20%)]\tLoss: 0.171612\n",
            "Train Epoch: 4 [795/3978 (20%)]\tLoss: 0.409093\n",
            "Train Epoch: 4 [800/3978 (20%)]\tLoss: 0.517409\n",
            "Train Epoch: 4 [805/3978 (20%)]\tLoss: 0.355717\n",
            "Train Epoch: 4 [810/3978 (20%)]\tLoss: 0.175101\n",
            "Train Epoch: 4 [815/3978 (20%)]\tLoss: 0.236385\n",
            "Train Epoch: 4 [820/3978 (21%)]\tLoss: 0.374639\n",
            "Train Epoch: 4 [825/3978 (21%)]\tLoss: 0.374420\n",
            "Train Epoch: 4 [830/3978 (21%)]\tLoss: 0.467501\n",
            "Train Epoch: 4 [835/3978 (21%)]\tLoss: 0.239197\n",
            "Train Epoch: 4 [840/3978 (21%)]\tLoss: 0.414032\n",
            "Train Epoch: 4 [845/3978 (21%)]\tLoss: 0.432417\n",
            "Train Epoch: 4 [850/3978 (21%)]\tLoss: 0.151507\n",
            "Train Epoch: 4 [855/3978 (21%)]\tLoss: 0.257533\n",
            "Train Epoch: 4 [860/3978 (22%)]\tLoss: 0.454354\n",
            "Train Epoch: 4 [865/3978 (22%)]\tLoss: 0.356007\n",
            "Train Epoch: 4 [870/3978 (22%)]\tLoss: 0.453933\n",
            "Train Epoch: 4 [875/3978 (22%)]\tLoss: 0.223372\n",
            "Train Epoch: 4 [880/3978 (22%)]\tLoss: 0.363451\n",
            "Train Epoch: 4 [885/3978 (22%)]\tLoss: 0.153067\n",
            "Train Epoch: 4 [890/3978 (22%)]\tLoss: 0.329634\n",
            "Train Epoch: 4 [895/3978 (22%)]\tLoss: 0.222441\n",
            "Train Epoch: 4 [900/3978 (23%)]\tLoss: 0.239014\n",
            "Train Epoch: 4 [905/3978 (23%)]\tLoss: 0.423463\n",
            "Train Epoch: 4 [910/3978 (23%)]\tLoss: 0.354026\n",
            "Train Epoch: 4 [915/3978 (23%)]\tLoss: 0.428897\n",
            "Train Epoch: 4 [920/3978 (23%)]\tLoss: 0.161005\n",
            "Train Epoch: 4 [925/3978 (23%)]\tLoss: 0.281271\n",
            "Train Epoch: 4 [930/3978 (23%)]\tLoss: 0.088372\n",
            "Train Epoch: 4 [935/3978 (23%)]\tLoss: 0.210320\n",
            "Train Epoch: 4 [940/3978 (24%)]\tLoss: 0.293996\n",
            "Train Epoch: 4 [945/3978 (24%)]\tLoss: 0.091277\n",
            "Train Epoch: 4 [950/3978 (24%)]\tLoss: 0.121339\n",
            "Train Epoch: 4 [955/3978 (24%)]\tLoss: 0.229809\n",
            "Train Epoch: 4 [960/3978 (24%)]\tLoss: 0.410422\n",
            "Train Epoch: 4 [965/3978 (24%)]\tLoss: 0.333635\n",
            "Train Epoch: 4 [970/3978 (24%)]\tLoss: 0.260521\n",
            "Train Epoch: 4 [975/3978 (24%)]\tLoss: 0.504149\n",
            "Train Epoch: 4 [980/3978 (25%)]\tLoss: 0.099890\n",
            "Train Epoch: 4 [985/3978 (25%)]\tLoss: 0.466150\n",
            "Train Epoch: 4 [990/3978 (25%)]\tLoss: 0.277736\n",
            "Train Epoch: 4 [995/3978 (25%)]\tLoss: 0.331736\n",
            "Train Epoch: 4 [1000/3978 (25%)]\tLoss: 0.364405\n",
            "Train Epoch: 4 [1005/3978 (25%)]\tLoss: 0.311210\n",
            "Train Epoch: 4 [1010/3978 (25%)]\tLoss: 0.069595\n",
            "Train Epoch: 4 [1015/3978 (26%)]\tLoss: 0.554292\n",
            "Train Epoch: 4 [1020/3978 (26%)]\tLoss: 0.262755\n",
            "Train Epoch: 4 [1025/3978 (26%)]\tLoss: 0.664745\n",
            "Train Epoch: 4 [1030/3978 (26%)]\tLoss: 0.243077\n",
            "Train Epoch: 4 [1035/3978 (26%)]\tLoss: 0.406336\n",
            "Train Epoch: 4 [1040/3978 (26%)]\tLoss: 0.707652\n",
            "Train Epoch: 4 [1045/3978 (26%)]\tLoss: 0.226282\n",
            "Train Epoch: 4 [1050/3978 (26%)]\tLoss: 0.247219\n",
            "Train Epoch: 4 [1055/3978 (27%)]\tLoss: 0.317265\n",
            "Train Epoch: 4 [1060/3978 (27%)]\tLoss: 0.419526\n",
            "Train Epoch: 4 [1065/3978 (27%)]\tLoss: 0.456726\n",
            "Train Epoch: 4 [1070/3978 (27%)]\tLoss: 0.639529\n",
            "Train Epoch: 4 [1075/3978 (27%)]\tLoss: 0.665198\n",
            "Train Epoch: 4 [1080/3978 (27%)]\tLoss: 0.290115\n",
            "Train Epoch: 4 [1085/3978 (27%)]\tLoss: 0.376413\n",
            "Train Epoch: 4 [1090/3978 (27%)]\tLoss: 0.177893\n",
            "Train Epoch: 4 [1095/3978 (28%)]\tLoss: 0.272217\n",
            "Train Epoch: 4 [1100/3978 (28%)]\tLoss: 0.251765\n",
            "Train Epoch: 4 [1105/3978 (28%)]\tLoss: 0.342265\n",
            "Train Epoch: 4 [1110/3978 (28%)]\tLoss: 0.409869\n",
            "Train Epoch: 4 [1115/3978 (28%)]\tLoss: 0.272942\n",
            "Train Epoch: 4 [1120/3978 (28%)]\tLoss: 0.046243\n",
            "Train Epoch: 4 [1125/3978 (28%)]\tLoss: 0.366422\n",
            "Train Epoch: 4 [1130/3978 (28%)]\tLoss: 0.371833\n",
            "Train Epoch: 4 [1135/3978 (29%)]\tLoss: 0.077579\n",
            "Train Epoch: 4 [1140/3978 (29%)]\tLoss: 0.114692\n",
            "Train Epoch: 4 [1145/3978 (29%)]\tLoss: 0.610191\n",
            "Train Epoch: 4 [1150/3978 (29%)]\tLoss: 0.086610\n",
            "Train Epoch: 4 [1155/3978 (29%)]\tLoss: 0.377005\n",
            "Train Epoch: 4 [1160/3978 (29%)]\tLoss: 0.108551\n",
            "Train Epoch: 4 [1165/3978 (29%)]\tLoss: 0.437812\n",
            "Train Epoch: 4 [1170/3978 (29%)]\tLoss: 0.421485\n",
            "Train Epoch: 4 [1175/3978 (30%)]\tLoss: 0.078277\n",
            "Train Epoch: 4 [1180/3978 (30%)]\tLoss: 0.494216\n",
            "Train Epoch: 4 [1185/3978 (30%)]\tLoss: 0.484071\n",
            "Train Epoch: 4 [1190/3978 (30%)]\tLoss: 0.195741\n",
            "Train Epoch: 4 [1195/3978 (30%)]\tLoss: 0.097370\n",
            "Train Epoch: 4 [1200/3978 (30%)]\tLoss: 0.591640\n",
            "Train Epoch: 4 [1205/3978 (30%)]\tLoss: 0.652603\n",
            "Train Epoch: 4 [1210/3978 (30%)]\tLoss: 0.441284\n",
            "Train Epoch: 4 [1215/3978 (31%)]\tLoss: 0.060187\n",
            "Train Epoch: 4 [1220/3978 (31%)]\tLoss: 0.584119\n",
            "Train Epoch: 4 [1225/3978 (31%)]\tLoss: 0.411281\n",
            "Train Epoch: 4 [1230/3978 (31%)]\tLoss: 0.500767\n",
            "Train Epoch: 4 [1235/3978 (31%)]\tLoss: 0.169123\n",
            "Train Epoch: 4 [1240/3978 (31%)]\tLoss: 0.085097\n",
            "Train Epoch: 4 [1245/3978 (31%)]\tLoss: 0.552773\n",
            "Train Epoch: 4 [1250/3978 (31%)]\tLoss: 0.206082\n",
            "Train Epoch: 4 [1255/3978 (32%)]\tLoss: 0.301086\n",
            "Train Epoch: 4 [1260/3978 (32%)]\tLoss: 0.365354\n",
            "Train Epoch: 4 [1265/3978 (32%)]\tLoss: 0.123201\n",
            "Train Epoch: 4 [1270/3978 (32%)]\tLoss: 0.166616\n",
            "Train Epoch: 4 [1275/3978 (32%)]\tLoss: 0.189762\n",
            "Train Epoch: 4 [1280/3978 (32%)]\tLoss: 0.131120\n",
            "Train Epoch: 4 [1285/3978 (32%)]\tLoss: 0.118577\n",
            "Train Epoch: 4 [1290/3978 (32%)]\tLoss: 0.093551\n",
            "Train Epoch: 4 [1295/3978 (33%)]\tLoss: 0.183671\n",
            "Train Epoch: 4 [1300/3978 (33%)]\tLoss: 0.107880\n",
            "Train Epoch: 4 [1305/3978 (33%)]\tLoss: 0.201872\n",
            "Train Epoch: 4 [1310/3978 (33%)]\tLoss: 0.236268\n",
            "Train Epoch: 4 [1315/3978 (33%)]\tLoss: 0.395251\n",
            "Train Epoch: 4 [1320/3978 (33%)]\tLoss: 0.045277\n",
            "Train Epoch: 4 [1325/3978 (33%)]\tLoss: 0.312142\n",
            "Train Epoch: 4 [1330/3978 (33%)]\tLoss: 0.212999\n",
            "Train Epoch: 4 [1335/3978 (34%)]\tLoss: 0.052917\n",
            "Train Epoch: 4 [1340/3978 (34%)]\tLoss: 0.237253\n",
            "Train Epoch: 4 [1345/3978 (34%)]\tLoss: 0.177774\n",
            "Train Epoch: 4 [1350/3978 (34%)]\tLoss: 0.302582\n",
            "Train Epoch: 4 [1355/3978 (34%)]\tLoss: 0.062614\n",
            "Train Epoch: 4 [1360/3978 (34%)]\tLoss: 0.170268\n",
            "Train Epoch: 4 [1365/3978 (34%)]\tLoss: 0.248080\n",
            "Train Epoch: 4 [1370/3978 (34%)]\tLoss: 0.176199\n",
            "Train Epoch: 4 [1375/3978 (35%)]\tLoss: 0.314576\n",
            "Train Epoch: 4 [1380/3978 (35%)]\tLoss: 0.764035\n",
            "Train Epoch: 4 [1385/3978 (35%)]\tLoss: 0.080095\n",
            "Train Epoch: 4 [1390/3978 (35%)]\tLoss: 0.328467\n",
            "Train Epoch: 4 [1395/3978 (35%)]\tLoss: 0.180709\n",
            "Train Epoch: 4 [1400/3978 (35%)]\tLoss: 0.020463\n",
            "Train Epoch: 4 [1405/3978 (35%)]\tLoss: 0.365862\n",
            "Train Epoch: 4 [1410/3978 (35%)]\tLoss: 0.633007\n",
            "Train Epoch: 4 [1415/3978 (36%)]\tLoss: 0.110659\n",
            "Train Epoch: 4 [1420/3978 (36%)]\tLoss: 0.373476\n",
            "Train Epoch: 4 [1425/3978 (36%)]\tLoss: 0.086902\n",
            "Train Epoch: 4 [1430/3978 (36%)]\tLoss: 0.152218\n",
            "Train Epoch: 4 [1435/3978 (36%)]\tLoss: 0.079136\n",
            "Train Epoch: 4 [1440/3978 (36%)]\tLoss: 0.105590\n",
            "Train Epoch: 4 [1445/3978 (36%)]\tLoss: 0.652989\n",
            "Train Epoch: 4 [1450/3978 (36%)]\tLoss: 0.137930\n",
            "Train Epoch: 4 [1455/3978 (37%)]\tLoss: 0.139136\n",
            "Train Epoch: 4 [1460/3978 (37%)]\tLoss: 0.236518\n",
            "Train Epoch: 4 [1465/3978 (37%)]\tLoss: 0.182734\n",
            "Train Epoch: 4 [1470/3978 (37%)]\tLoss: 0.735750\n",
            "Train Epoch: 4 [1475/3978 (37%)]\tLoss: 0.344789\n",
            "Train Epoch: 4 [1480/3978 (37%)]\tLoss: 0.392469\n",
            "Train Epoch: 4 [1485/3978 (37%)]\tLoss: 0.084695\n",
            "Train Epoch: 4 [1490/3978 (37%)]\tLoss: 0.141979\n",
            "Train Epoch: 4 [1495/3978 (38%)]\tLoss: 0.156702\n",
            "Train Epoch: 4 [1500/3978 (38%)]\tLoss: 0.350439\n",
            "Train Epoch: 4 [1505/3978 (38%)]\tLoss: 0.317799\n",
            "Train Epoch: 4 [1510/3978 (38%)]\tLoss: 0.240640\n",
            "Train Epoch: 4 [1515/3978 (38%)]\tLoss: 0.357390\n",
            "Train Epoch: 4 [1520/3978 (38%)]\tLoss: 0.079287\n",
            "Train Epoch: 4 [1525/3978 (38%)]\tLoss: 0.508466\n",
            "Train Epoch: 4 [1530/3978 (38%)]\tLoss: 0.480915\n",
            "Train Epoch: 4 [1535/3978 (39%)]\tLoss: 0.312891\n",
            "Train Epoch: 4 [1540/3978 (39%)]\tLoss: 0.062594\n",
            "Train Epoch: 4 [1545/3978 (39%)]\tLoss: 0.302381\n",
            "Train Epoch: 4 [1550/3978 (39%)]\tLoss: 0.250916\n",
            "Train Epoch: 4 [1555/3978 (39%)]\tLoss: 0.133895\n",
            "Train Epoch: 4 [1560/3978 (39%)]\tLoss: 0.101887\n",
            "Train Epoch: 4 [1565/3978 (39%)]\tLoss: 0.345899\n",
            "Train Epoch: 4 [1570/3978 (39%)]\tLoss: 0.054220\n",
            "Train Epoch: 4 [1575/3978 (40%)]\tLoss: 0.295805\n",
            "Train Epoch: 4 [1580/3978 (40%)]\tLoss: 0.260345\n",
            "Train Epoch: 4 [1585/3978 (40%)]\tLoss: 0.318422\n",
            "Train Epoch: 4 [1590/3978 (40%)]\tLoss: 0.609645\n",
            "Train Epoch: 4 [1595/3978 (40%)]\tLoss: 0.644121\n",
            "Train Epoch: 4 [1600/3978 (40%)]\tLoss: 0.312124\n",
            "Train Epoch: 4 [1605/3978 (40%)]\tLoss: 0.480224\n",
            "Train Epoch: 4 [1610/3978 (40%)]\tLoss: 0.288686\n",
            "Train Epoch: 4 [1615/3978 (41%)]\tLoss: 0.068031\n",
            "Train Epoch: 4 [1620/3978 (41%)]\tLoss: 0.217158\n",
            "Train Epoch: 4 [1625/3978 (41%)]\tLoss: 0.152804\n",
            "Train Epoch: 4 [1630/3978 (41%)]\tLoss: 0.188299\n",
            "Train Epoch: 4 [1635/3978 (41%)]\tLoss: 0.080168\n",
            "Train Epoch: 4 [1640/3978 (41%)]\tLoss: 0.118937\n",
            "Train Epoch: 4 [1645/3978 (41%)]\tLoss: 0.648326\n",
            "Train Epoch: 4 [1650/3978 (41%)]\tLoss: 0.540527\n",
            "Train Epoch: 4 [1655/3978 (42%)]\tLoss: 0.121941\n",
            "Train Epoch: 4 [1660/3978 (42%)]\tLoss: 0.329589\n",
            "Train Epoch: 4 [1665/3978 (42%)]\tLoss: 0.098932\n",
            "Train Epoch: 4 [1670/3978 (42%)]\tLoss: 0.285032\n",
            "Train Epoch: 4 [1675/3978 (42%)]\tLoss: 0.307759\n",
            "Train Epoch: 4 [1680/3978 (42%)]\tLoss: 0.132128\n",
            "Train Epoch: 4 [1685/3978 (42%)]\tLoss: 0.175182\n",
            "Train Epoch: 4 [1690/3978 (42%)]\tLoss: 0.209464\n",
            "Train Epoch: 4 [1695/3978 (43%)]\tLoss: 0.384939\n",
            "Train Epoch: 4 [1700/3978 (43%)]\tLoss: 0.173539\n",
            "Train Epoch: 4 [1705/3978 (43%)]\tLoss: 0.341082\n",
            "Train Epoch: 4 [1710/3978 (43%)]\tLoss: 0.165378\n",
            "Train Epoch: 4 [1715/3978 (43%)]\tLoss: 0.130653\n",
            "Train Epoch: 4 [1720/3978 (43%)]\tLoss: 0.463797\n",
            "Train Epoch: 4 [1725/3978 (43%)]\tLoss: 0.139403\n",
            "Train Epoch: 4 [1730/3978 (43%)]\tLoss: 0.274313\n",
            "Train Epoch: 4 [1735/3978 (44%)]\tLoss: 0.552879\n",
            "Train Epoch: 4 [1740/3978 (44%)]\tLoss: 0.260872\n",
            "Train Epoch: 4 [1745/3978 (44%)]\tLoss: 0.275458\n",
            "Train Epoch: 4 [1750/3978 (44%)]\tLoss: 0.192899\n",
            "Train Epoch: 4 [1755/3978 (44%)]\tLoss: 0.822243\n",
            "Train Epoch: 4 [1760/3978 (44%)]\tLoss: 0.422366\n",
            "Train Epoch: 4 [1765/3978 (44%)]\tLoss: 0.325649\n",
            "Train Epoch: 4 [1770/3978 (44%)]\tLoss: 0.184262\n",
            "Train Epoch: 4 [1775/3978 (45%)]\tLoss: 0.219127\n",
            "Train Epoch: 4 [1780/3978 (45%)]\tLoss: 0.553462\n",
            "Train Epoch: 4 [1785/3978 (45%)]\tLoss: 0.277700\n",
            "Train Epoch: 4 [1790/3978 (45%)]\tLoss: 0.058073\n",
            "Train Epoch: 4 [1795/3978 (45%)]\tLoss: 0.135907\n",
            "Train Epoch: 4 [1800/3978 (45%)]\tLoss: 0.283412\n",
            "Train Epoch: 4 [1805/3978 (45%)]\tLoss: 0.447622\n",
            "Train Epoch: 4 [1810/3978 (45%)]\tLoss: 0.524057\n",
            "Train Epoch: 4 [1815/3978 (46%)]\tLoss: 0.198344\n",
            "Train Epoch: 4 [1820/3978 (46%)]\tLoss: 0.470408\n",
            "Train Epoch: 4 [1825/3978 (46%)]\tLoss: 0.201204\n",
            "Train Epoch: 4 [1830/3978 (46%)]\tLoss: 0.199210\n",
            "Train Epoch: 4 [1835/3978 (46%)]\tLoss: 0.236603\n",
            "Train Epoch: 4 [1840/3978 (46%)]\tLoss: 0.255061\n",
            "Train Epoch: 4 [1845/3978 (46%)]\tLoss: 0.497331\n",
            "Train Epoch: 4 [1850/3978 (46%)]\tLoss: 0.173289\n",
            "Train Epoch: 4 [1855/3978 (47%)]\tLoss: 0.139063\n",
            "Train Epoch: 4 [1860/3978 (47%)]\tLoss: 0.229760\n",
            "Train Epoch: 4 [1865/3978 (47%)]\tLoss: 0.456960\n",
            "Train Epoch: 4 [1870/3978 (47%)]\tLoss: 0.248195\n",
            "Train Epoch: 4 [1875/3978 (47%)]\tLoss: 0.123545\n",
            "Train Epoch: 4 [1880/3978 (47%)]\tLoss: 0.094577\n",
            "Train Epoch: 4 [1885/3978 (47%)]\tLoss: 0.060741\n",
            "Train Epoch: 4 [1890/3978 (47%)]\tLoss: 0.314723\n",
            "Train Epoch: 4 [1895/3978 (48%)]\tLoss: 0.700009\n",
            "Train Epoch: 4 [1900/3978 (48%)]\tLoss: 0.083497\n",
            "Train Epoch: 4 [1905/3978 (48%)]\tLoss: 0.103085\n",
            "Train Epoch: 4 [1910/3978 (48%)]\tLoss: 0.079683\n",
            "Train Epoch: 4 [1915/3978 (48%)]\tLoss: 0.063402\n",
            "Train Epoch: 4 [1920/3978 (48%)]\tLoss: 0.249132\n",
            "Train Epoch: 4 [1925/3978 (48%)]\tLoss: 0.368953\n",
            "Train Epoch: 4 [1930/3978 (48%)]\tLoss: 0.117397\n",
            "Train Epoch: 4 [1935/3978 (49%)]\tLoss: 0.032609\n",
            "Train Epoch: 4 [1940/3978 (49%)]\tLoss: 0.371263\n",
            "Train Epoch: 4 [1945/3978 (49%)]\tLoss: 0.611051\n",
            "Train Epoch: 4 [1950/3978 (49%)]\tLoss: 0.081950\n",
            "Train Epoch: 4 [1955/3978 (49%)]\tLoss: 0.583096\n",
            "Train Epoch: 4 [1960/3978 (49%)]\tLoss: 0.295657\n",
            "Train Epoch: 4 [1965/3978 (49%)]\tLoss: 0.137605\n",
            "Train Epoch: 4 [1970/3978 (49%)]\tLoss: 0.106662\n",
            "Train Epoch: 4 [1975/3978 (50%)]\tLoss: 0.952227\n",
            "Train Epoch: 4 [1980/3978 (50%)]\tLoss: 0.085393\n",
            "Train Epoch: 4 [1985/3978 (50%)]\tLoss: 0.253193\n",
            "Train Epoch: 4 [1990/3978 (50%)]\tLoss: 0.344853\n",
            "Train Epoch: 4 [1995/3978 (50%)]\tLoss: 0.348769\n",
            "Train Epoch: 4 [2000/3978 (50%)]\tLoss: 0.174967\n",
            "Train Epoch: 4 [2005/3978 (50%)]\tLoss: 0.155893\n",
            "Train Epoch: 4 [2010/3978 (51%)]\tLoss: 0.088882\n",
            "Train Epoch: 4 [2015/3978 (51%)]\tLoss: 0.140337\n",
            "Train Epoch: 4 [2020/3978 (51%)]\tLoss: 0.128210\n",
            "Train Epoch: 4 [2025/3978 (51%)]\tLoss: 0.549821\n",
            "Train Epoch: 4 [2030/3978 (51%)]\tLoss: 0.078748\n",
            "Train Epoch: 4 [2035/3978 (51%)]\tLoss: 0.221523\n",
            "Train Epoch: 4 [2040/3978 (51%)]\tLoss: 0.109570\n",
            "Train Epoch: 4 [2045/3978 (51%)]\tLoss: 0.088564\n",
            "Train Epoch: 4 [2050/3978 (52%)]\tLoss: 0.217345\n",
            "Train Epoch: 4 [2055/3978 (52%)]\tLoss: 0.153530\n",
            "Train Epoch: 4 [2060/3978 (52%)]\tLoss: 0.141043\n",
            "Train Epoch: 4 [2065/3978 (52%)]\tLoss: 0.458256\n",
            "Train Epoch: 4 [2070/3978 (52%)]\tLoss: 0.225501\n",
            "Train Epoch: 4 [2075/3978 (52%)]\tLoss: 0.135521\n",
            "Train Epoch: 4 [2080/3978 (52%)]\tLoss: 0.087187\n",
            "Train Epoch: 4 [2085/3978 (52%)]\tLoss: 0.349218\n",
            "Train Epoch: 4 [2090/3978 (53%)]\tLoss: 0.053842\n",
            "Train Epoch: 4 [2095/3978 (53%)]\tLoss: 0.032434\n",
            "Train Epoch: 4 [2100/3978 (53%)]\tLoss: 0.027519\n",
            "Train Epoch: 4 [2105/3978 (53%)]\tLoss: 0.434346\n",
            "Train Epoch: 4 [2110/3978 (53%)]\tLoss: 0.164053\n",
            "Train Epoch: 4 [2115/3978 (53%)]\tLoss: 0.527045\n",
            "Train Epoch: 4 [2120/3978 (53%)]\tLoss: 0.534553\n",
            "Train Epoch: 4 [2125/3978 (53%)]\tLoss: 0.358382\n",
            "Train Epoch: 4 [2130/3978 (54%)]\tLoss: 0.114346\n",
            "Train Epoch: 4 [2135/3978 (54%)]\tLoss: 0.173672\n",
            "Train Epoch: 4 [2140/3978 (54%)]\tLoss: 0.355424\n",
            "Train Epoch: 4 [2145/3978 (54%)]\tLoss: 0.317206\n",
            "Train Epoch: 4 [2150/3978 (54%)]\tLoss: 0.198013\n",
            "Train Epoch: 4 [2155/3978 (54%)]\tLoss: 0.293360\n",
            "Train Epoch: 4 [2160/3978 (54%)]\tLoss: 0.068768\n",
            "Train Epoch: 4 [2165/3978 (54%)]\tLoss: 0.189551\n",
            "Train Epoch: 4 [2170/3978 (55%)]\tLoss: 0.316414\n",
            "Train Epoch: 4 [2175/3978 (55%)]\tLoss: 0.169874\n",
            "Train Epoch: 4 [2180/3978 (55%)]\tLoss: 0.239507\n",
            "Train Epoch: 4 [2185/3978 (55%)]\tLoss: 0.767937\n",
            "Train Epoch: 4 [2190/3978 (55%)]\tLoss: 0.113404\n",
            "Train Epoch: 4 [2195/3978 (55%)]\tLoss: 0.132242\n",
            "Train Epoch: 4 [2200/3978 (55%)]\tLoss: 0.548483\n",
            "Train Epoch: 4 [2205/3978 (55%)]\tLoss: 0.130410\n",
            "Train Epoch: 4 [2210/3978 (56%)]\tLoss: 0.231460\n",
            "Train Epoch: 4 [2215/3978 (56%)]\tLoss: 0.148149\n",
            "Train Epoch: 4 [2220/3978 (56%)]\tLoss: 0.399659\n",
            "Train Epoch: 4 [2225/3978 (56%)]\tLoss: 0.282499\n",
            "Train Epoch: 4 [2230/3978 (56%)]\tLoss: 0.272928\n",
            "Train Epoch: 4 [2235/3978 (56%)]\tLoss: 0.465474\n",
            "Train Epoch: 4 [2240/3978 (56%)]\tLoss: 0.247522\n",
            "Train Epoch: 4 [2245/3978 (56%)]\tLoss: 0.262249\n",
            "Train Epoch: 4 [2250/3978 (57%)]\tLoss: 0.201791\n",
            "Train Epoch: 4 [2255/3978 (57%)]\tLoss: 0.273022\n",
            "Train Epoch: 4 [2260/3978 (57%)]\tLoss: 0.348130\n",
            "Train Epoch: 4 [2265/3978 (57%)]\tLoss: 0.031654\n",
            "Train Epoch: 4 [2270/3978 (57%)]\tLoss: 0.168887\n",
            "Train Epoch: 4 [2275/3978 (57%)]\tLoss: 0.255781\n",
            "Train Epoch: 4 [2280/3978 (57%)]\tLoss: 0.295399\n",
            "Train Epoch: 4 [2285/3978 (57%)]\tLoss: 0.063776\n",
            "Train Epoch: 4 [2290/3978 (58%)]\tLoss: 0.207378\n",
            "Train Epoch: 4 [2295/3978 (58%)]\tLoss: 0.170386\n",
            "Train Epoch: 4 [2300/3978 (58%)]\tLoss: 0.132111\n",
            "Train Epoch: 4 [2305/3978 (58%)]\tLoss: 0.153379\n",
            "Train Epoch: 4 [2310/3978 (58%)]\tLoss: 0.614823\n",
            "Train Epoch: 4 [2315/3978 (58%)]\tLoss: 0.120096\n",
            "Train Epoch: 4 [2320/3978 (58%)]\tLoss: 0.161531\n",
            "Train Epoch: 4 [2325/3978 (58%)]\tLoss: 0.529223\n",
            "Train Epoch: 4 [2330/3978 (59%)]\tLoss: 0.239803\n",
            "Train Epoch: 4 [2335/3978 (59%)]\tLoss: 0.127367\n",
            "Train Epoch: 4 [2340/3978 (59%)]\tLoss: 0.137897\n",
            "Train Epoch: 4 [2345/3978 (59%)]\tLoss: 0.557294\n",
            "Train Epoch: 4 [2350/3978 (59%)]\tLoss: 0.463703\n",
            "Train Epoch: 4 [2355/3978 (59%)]\tLoss: 0.282850\n",
            "Train Epoch: 4 [2360/3978 (59%)]\tLoss: 0.088714\n",
            "Train Epoch: 4 [2365/3978 (59%)]\tLoss: 0.520279\n",
            "Train Epoch: 4 [2370/3978 (60%)]\tLoss: 0.128989\n",
            "Train Epoch: 4 [2375/3978 (60%)]\tLoss: 0.217967\n",
            "Train Epoch: 4 [2380/3978 (60%)]\tLoss: 0.065477\n",
            "Train Epoch: 4 [2385/3978 (60%)]\tLoss: 0.235613\n",
            "Train Epoch: 4 [2390/3978 (60%)]\tLoss: 0.382369\n",
            "Train Epoch: 4 [2395/3978 (60%)]\tLoss: 0.305604\n",
            "Train Epoch: 4 [2400/3978 (60%)]\tLoss: 0.304314\n",
            "Train Epoch: 4 [2405/3978 (60%)]\tLoss: 0.164327\n",
            "Train Epoch: 4 [2410/3978 (61%)]\tLoss: 0.313611\n",
            "Train Epoch: 4 [2415/3978 (61%)]\tLoss: 0.127710\n",
            "Train Epoch: 4 [2420/3978 (61%)]\tLoss: 0.488629\n",
            "Train Epoch: 4 [2425/3978 (61%)]\tLoss: 0.090365\n",
            "Train Epoch: 4 [2430/3978 (61%)]\tLoss: 0.094054\n",
            "Train Epoch: 4 [2435/3978 (61%)]\tLoss: 0.227176\n",
            "Train Epoch: 4 [2440/3978 (61%)]\tLoss: 0.153751\n",
            "Train Epoch: 4 [2445/3978 (61%)]\tLoss: 0.186343\n",
            "Train Epoch: 4 [2450/3978 (62%)]\tLoss: 0.099504\n",
            "Train Epoch: 4 [2455/3978 (62%)]\tLoss: 0.031719\n",
            "Train Epoch: 4 [2460/3978 (62%)]\tLoss: 0.109211\n",
            "Train Epoch: 4 [2465/3978 (62%)]\tLoss: 0.169292\n",
            "Train Epoch: 4 [2470/3978 (62%)]\tLoss: 0.285386\n",
            "Train Epoch: 4 [2475/3978 (62%)]\tLoss: 0.255166\n",
            "Train Epoch: 4 [2480/3978 (62%)]\tLoss: 0.275978\n",
            "Train Epoch: 4 [2485/3978 (62%)]\tLoss: 0.533797\n",
            "Train Epoch: 4 [2490/3978 (63%)]\tLoss: 0.192659\n",
            "Train Epoch: 4 [2495/3978 (63%)]\tLoss: 0.732846\n",
            "Train Epoch: 4 [2500/3978 (63%)]\tLoss: 0.040887\n",
            "Train Epoch: 4 [2505/3978 (63%)]\tLoss: 0.306022\n",
            "Train Epoch: 4 [2510/3978 (63%)]\tLoss: 0.162048\n",
            "Train Epoch: 4 [2515/3978 (63%)]\tLoss: 0.300441\n",
            "Train Epoch: 4 [2520/3978 (63%)]\tLoss: 0.689603\n",
            "Train Epoch: 4 [2525/3978 (63%)]\tLoss: 0.247937\n",
            "Train Epoch: 4 [2530/3978 (64%)]\tLoss: 0.226602\n",
            "Train Epoch: 4 [2535/3978 (64%)]\tLoss: 0.095508\n",
            "Train Epoch: 4 [2540/3978 (64%)]\tLoss: 0.246684\n",
            "Train Epoch: 4 [2545/3978 (64%)]\tLoss: 0.308540\n",
            "Train Epoch: 4 [2550/3978 (64%)]\tLoss: 0.345915\n",
            "Train Epoch: 4 [2555/3978 (64%)]\tLoss: 0.314856\n",
            "Train Epoch: 4 [2560/3978 (64%)]\tLoss: 0.382716\n",
            "Train Epoch: 4 [2565/3978 (64%)]\tLoss: 0.268534\n",
            "Train Epoch: 4 [2570/3978 (65%)]\tLoss: 0.260586\n",
            "Train Epoch: 4 [2575/3978 (65%)]\tLoss: 0.454472\n",
            "Train Epoch: 4 [2580/3978 (65%)]\tLoss: 0.203861\n",
            "Train Epoch: 4 [2585/3978 (65%)]\tLoss: 0.175363\n",
            "Train Epoch: 4 [2590/3978 (65%)]\tLoss: 0.148338\n",
            "Train Epoch: 4 [2595/3978 (65%)]\tLoss: 0.137886\n",
            "Train Epoch: 4 [2600/3978 (65%)]\tLoss: 0.427785\n",
            "Train Epoch: 4 [2605/3978 (65%)]\tLoss: 0.314864\n",
            "Train Epoch: 4 [2610/3978 (66%)]\tLoss: 0.208676\n",
            "Train Epoch: 4 [2615/3978 (66%)]\tLoss: 0.306761\n",
            "Train Epoch: 4 [2620/3978 (66%)]\tLoss: 0.334701\n",
            "Train Epoch: 4 [2625/3978 (66%)]\tLoss: 0.389957\n",
            "Train Epoch: 4 [2630/3978 (66%)]\tLoss: 0.117422\n",
            "Train Epoch: 4 [2635/3978 (66%)]\tLoss: 0.493534\n",
            "Train Epoch: 4 [2640/3978 (66%)]\tLoss: 0.228079\n",
            "Train Epoch: 4 [2645/3978 (66%)]\tLoss: 0.385383\n",
            "Train Epoch: 4 [2650/3978 (67%)]\tLoss: 0.085937\n",
            "Train Epoch: 4 [2655/3978 (67%)]\tLoss: 0.206049\n",
            "Train Epoch: 4 [2660/3978 (67%)]\tLoss: 0.625184\n",
            "Train Epoch: 4 [2665/3978 (67%)]\tLoss: 0.310406\n",
            "Train Epoch: 4 [2670/3978 (67%)]\tLoss: 0.212811\n",
            "Train Epoch: 4 [2675/3978 (67%)]\tLoss: 0.148169\n",
            "Train Epoch: 4 [2680/3978 (67%)]\tLoss: 0.131852\n",
            "Train Epoch: 4 [2685/3978 (67%)]\tLoss: 0.568809\n",
            "Train Epoch: 4 [2690/3978 (68%)]\tLoss: 0.274669\n",
            "Train Epoch: 4 [2695/3978 (68%)]\tLoss: 0.366972\n",
            "Train Epoch: 4 [2700/3978 (68%)]\tLoss: 0.211445\n",
            "Train Epoch: 4 [2705/3978 (68%)]\tLoss: 0.659182\n",
            "Train Epoch: 4 [2710/3978 (68%)]\tLoss: 0.089762\n",
            "Train Epoch: 4 [2715/3978 (68%)]\tLoss: 0.204351\n",
            "Train Epoch: 4 [2720/3978 (68%)]\tLoss: 0.318297\n",
            "Train Epoch: 4 [2725/3978 (68%)]\tLoss: 0.443123\n",
            "Train Epoch: 4 [2730/3978 (69%)]\tLoss: 0.090716\n",
            "Train Epoch: 4 [2735/3978 (69%)]\tLoss: 0.276001\n",
            "Train Epoch: 4 [2740/3978 (69%)]\tLoss: 0.105600\n",
            "Train Epoch: 4 [2745/3978 (69%)]\tLoss: 0.399092\n",
            "Train Epoch: 4 [2750/3978 (69%)]\tLoss: 0.328126\n",
            "Train Epoch: 4 [2755/3978 (69%)]\tLoss: 0.165820\n",
            "Train Epoch: 4 [2760/3978 (69%)]\tLoss: 0.410669\n",
            "Train Epoch: 4 [2765/3978 (69%)]\tLoss: 0.112862\n",
            "Train Epoch: 4 [2770/3978 (70%)]\tLoss: 0.341221\n",
            "Train Epoch: 4 [2775/3978 (70%)]\tLoss: 0.345105\n",
            "Train Epoch: 4 [2780/3978 (70%)]\tLoss: 0.416112\n",
            "Train Epoch: 4 [2785/3978 (70%)]\tLoss: 0.082081\n",
            "Train Epoch: 4 [2790/3978 (70%)]\tLoss: 0.211938\n",
            "Train Epoch: 4 [2795/3978 (70%)]\tLoss: 0.179424\n",
            "Train Epoch: 4 [2800/3978 (70%)]\tLoss: 0.119445\n",
            "Train Epoch: 4 [2805/3978 (70%)]\tLoss: 0.192525\n",
            "Train Epoch: 4 [2810/3978 (71%)]\tLoss: 0.508949\n",
            "Train Epoch: 4 [2815/3978 (71%)]\tLoss: 0.077920\n",
            "Train Epoch: 4 [2820/3978 (71%)]\tLoss: 0.294588\n",
            "Train Epoch: 4 [2825/3978 (71%)]\tLoss: 0.080615\n",
            "Train Epoch: 4 [2830/3978 (71%)]\tLoss: 0.074530\n",
            "Train Epoch: 4 [2835/3978 (71%)]\tLoss: 0.265794\n",
            "Train Epoch: 4 [2840/3978 (71%)]\tLoss: 0.151008\n",
            "Train Epoch: 4 [2845/3978 (71%)]\tLoss: 0.107073\n",
            "Train Epoch: 4 [2850/3978 (72%)]\tLoss: 0.158788\n",
            "Train Epoch: 4 [2855/3978 (72%)]\tLoss: 0.163217\n",
            "Train Epoch: 4 [2860/3978 (72%)]\tLoss: 0.998663\n",
            "Train Epoch: 4 [2865/3978 (72%)]\tLoss: 1.086996\n",
            "Train Epoch: 4 [2870/3978 (72%)]\tLoss: 0.358046\n",
            "Train Epoch: 4 [2875/3978 (72%)]\tLoss: 0.565120\n",
            "Train Epoch: 4 [2880/3978 (72%)]\tLoss: 0.101818\n",
            "Train Epoch: 4 [2885/3978 (72%)]\tLoss: 0.372467\n",
            "Train Epoch: 4 [2890/3978 (73%)]\tLoss: 0.180316\n",
            "Train Epoch: 4 [2895/3978 (73%)]\tLoss: 0.756290\n",
            "Train Epoch: 4 [2900/3978 (73%)]\tLoss: 0.564134\n",
            "Train Epoch: 4 [2905/3978 (73%)]\tLoss: 0.347321\n",
            "Train Epoch: 4 [2910/3978 (73%)]\tLoss: 0.199824\n",
            "Train Epoch: 4 [2915/3978 (73%)]\tLoss: 0.164279\n",
            "Train Epoch: 4 [2920/3978 (73%)]\tLoss: 0.422368\n",
            "Train Epoch: 4 [2925/3978 (73%)]\tLoss: 0.237780\n",
            "Train Epoch: 4 [2930/3978 (74%)]\tLoss: 0.525995\n",
            "Train Epoch: 4 [2935/3978 (74%)]\tLoss: 0.245495\n",
            "Train Epoch: 4 [2940/3978 (74%)]\tLoss: 0.216442\n",
            "Train Epoch: 4 [2945/3978 (74%)]\tLoss: 0.225107\n",
            "Train Epoch: 4 [2950/3978 (74%)]\tLoss: 0.155765\n",
            "Train Epoch: 4 [2955/3978 (74%)]\tLoss: 0.224710\n",
            "Train Epoch: 4 [2960/3978 (74%)]\tLoss: 0.148417\n",
            "Train Epoch: 4 [2965/3978 (74%)]\tLoss: 0.238852\n",
            "Train Epoch: 4 [2970/3978 (75%)]\tLoss: 0.080243\n",
            "Train Epoch: 4 [2975/3978 (75%)]\tLoss: 0.124953\n",
            "Train Epoch: 4 [2980/3978 (75%)]\tLoss: 0.392428\n",
            "Train Epoch: 4 [2985/3978 (75%)]\tLoss: 0.404822\n",
            "Train Epoch: 4 [2990/3978 (75%)]\tLoss: 0.086518\n",
            "Train Epoch: 4 [2995/3978 (75%)]\tLoss: 0.518375\n",
            "Train Epoch: 4 [3000/3978 (75%)]\tLoss: 0.510637\n",
            "Train Epoch: 4 [3005/3978 (76%)]\tLoss: 0.251455\n",
            "Train Epoch: 4 [3010/3978 (76%)]\tLoss: 0.280759\n",
            "Train Epoch: 4 [3015/3978 (76%)]\tLoss: 0.212670\n",
            "Train Epoch: 4 [3020/3978 (76%)]\tLoss: 0.489998\n",
            "Train Epoch: 4 [3025/3978 (76%)]\tLoss: 0.111049\n",
            "Train Epoch: 4 [3030/3978 (76%)]\tLoss: 0.109372\n",
            "Train Epoch: 4 [3035/3978 (76%)]\tLoss: 0.351440\n",
            "Train Epoch: 4 [3040/3978 (76%)]\tLoss: 0.079030\n",
            "Train Epoch: 4 [3045/3978 (77%)]\tLoss: 0.188339\n",
            "Train Epoch: 4 [3050/3978 (77%)]\tLoss: 0.287297\n",
            "Train Epoch: 4 [3055/3978 (77%)]\tLoss: 0.317542\n",
            "Train Epoch: 4 [3060/3978 (77%)]\tLoss: 0.567743\n",
            "Train Epoch: 4 [3065/3978 (77%)]\tLoss: 0.298331\n",
            "Train Epoch: 4 [3070/3978 (77%)]\tLoss: 0.258319\n",
            "Train Epoch: 4 [3075/3978 (77%)]\tLoss: 0.429838\n",
            "Train Epoch: 4 [3080/3978 (77%)]\tLoss: 0.315474\n",
            "Train Epoch: 4 [3085/3978 (78%)]\tLoss: 0.137720\n",
            "Train Epoch: 4 [3090/3978 (78%)]\tLoss: 0.320244\n",
            "Train Epoch: 4 [3095/3978 (78%)]\tLoss: 0.160372\n",
            "Train Epoch: 4 [3100/3978 (78%)]\tLoss: 0.182336\n",
            "Train Epoch: 4 [3105/3978 (78%)]\tLoss: 0.260892\n",
            "Train Epoch: 4 [3110/3978 (78%)]\tLoss: 0.109673\n",
            "Train Epoch: 4 [3115/3978 (78%)]\tLoss: 0.189159\n",
            "Train Epoch: 4 [3120/3978 (78%)]\tLoss: 0.188605\n",
            "Train Epoch: 4 [3125/3978 (79%)]\tLoss: 0.156840\n",
            "Train Epoch: 4 [3130/3978 (79%)]\tLoss: 0.075252\n",
            "Train Epoch: 4 [3135/3978 (79%)]\tLoss: 0.388810\n",
            "Train Epoch: 4 [3140/3978 (79%)]\tLoss: 0.193814\n",
            "Train Epoch: 4 [3145/3978 (79%)]\tLoss: 0.196305\n",
            "Train Epoch: 4 [3150/3978 (79%)]\tLoss: 0.058634\n",
            "Train Epoch: 4 [3155/3978 (79%)]\tLoss: 0.514595\n",
            "Train Epoch: 4 [3160/3978 (79%)]\tLoss: 0.044162\n",
            "Train Epoch: 4 [3165/3978 (80%)]\tLoss: 0.261005\n",
            "Train Epoch: 4 [3170/3978 (80%)]\tLoss: 0.093269\n",
            "Train Epoch: 4 [3175/3978 (80%)]\tLoss: 0.310311\n",
            "Train Epoch: 4 [3180/3978 (80%)]\tLoss: 0.435715\n",
            "Train Epoch: 4 [3185/3978 (80%)]\tLoss: 0.314258\n",
            "Train Epoch: 4 [3190/3978 (80%)]\tLoss: 0.408354\n",
            "Train Epoch: 4 [3195/3978 (80%)]\tLoss: 0.213716\n",
            "Train Epoch: 4 [3200/3978 (80%)]\tLoss: 0.210015\n",
            "Train Epoch: 4 [3205/3978 (81%)]\tLoss: 0.375281\n",
            "Train Epoch: 4 [3210/3978 (81%)]\tLoss: 0.366545\n",
            "Train Epoch: 4 [3215/3978 (81%)]\tLoss: 0.304671\n",
            "Train Epoch: 4 [3220/3978 (81%)]\tLoss: 0.249784\n",
            "Train Epoch: 4 [3225/3978 (81%)]\tLoss: 0.176600\n",
            "Train Epoch: 4 [3230/3978 (81%)]\tLoss: 0.253793\n",
            "Train Epoch: 4 [3235/3978 (81%)]\tLoss: 0.336861\n",
            "Train Epoch: 4 [3240/3978 (81%)]\tLoss: 0.175174\n",
            "Train Epoch: 4 [3245/3978 (82%)]\tLoss: 0.332142\n",
            "Train Epoch: 4 [3250/3978 (82%)]\tLoss: 0.351134\n",
            "Train Epoch: 4 [3255/3978 (82%)]\tLoss: 0.284462\n",
            "Train Epoch: 4 [3260/3978 (82%)]\tLoss: 0.084040\n",
            "Train Epoch: 4 [3265/3978 (82%)]\tLoss: 0.180274\n",
            "Train Epoch: 4 [3270/3978 (82%)]\tLoss: 0.103452\n",
            "Train Epoch: 4 [3275/3978 (82%)]\tLoss: 0.405196\n",
            "Train Epoch: 4 [3280/3978 (82%)]\tLoss: 0.246684\n",
            "Train Epoch: 4 [3285/3978 (83%)]\tLoss: 0.208317\n",
            "Train Epoch: 4 [3290/3978 (83%)]\tLoss: 0.194674\n",
            "Train Epoch: 4 [3295/3978 (83%)]\tLoss: 0.159360\n",
            "Train Epoch: 4 [3300/3978 (83%)]\tLoss: 0.111195\n",
            "Train Epoch: 4 [3305/3978 (83%)]\tLoss: 0.450389\n",
            "Train Epoch: 4 [3310/3978 (83%)]\tLoss: 0.386537\n",
            "Train Epoch: 4 [3315/3978 (83%)]\tLoss: 0.553268\n",
            "Train Epoch: 4 [3320/3978 (83%)]\tLoss: 0.079527\n",
            "Train Epoch: 4 [3325/3978 (84%)]\tLoss: 0.260501\n",
            "Train Epoch: 4 [3330/3978 (84%)]\tLoss: 0.086727\n",
            "Train Epoch: 4 [3335/3978 (84%)]\tLoss: 0.145972\n",
            "Train Epoch: 4 [3340/3978 (84%)]\tLoss: 0.062918\n",
            "Train Epoch: 4 [3345/3978 (84%)]\tLoss: 0.421313\n",
            "Train Epoch: 4 [3350/3978 (84%)]\tLoss: 0.072076\n",
            "Train Epoch: 4 [3355/3978 (84%)]\tLoss: 0.264328\n",
            "Train Epoch: 4 [3360/3978 (84%)]\tLoss: 0.074408\n",
            "Train Epoch: 4 [3365/3978 (85%)]\tLoss: 0.563606\n",
            "Train Epoch: 4 [3370/3978 (85%)]\tLoss: 0.243525\n",
            "Train Epoch: 4 [3375/3978 (85%)]\tLoss: 0.252553\n",
            "Train Epoch: 4 [3380/3978 (85%)]\tLoss: 0.267941\n",
            "Train Epoch: 4 [3385/3978 (85%)]\tLoss: 0.032032\n",
            "Train Epoch: 4 [3390/3978 (85%)]\tLoss: 0.191228\n",
            "Train Epoch: 4 [3395/3978 (85%)]\tLoss: 0.172751\n",
            "Train Epoch: 4 [3400/3978 (85%)]\tLoss: 0.220102\n",
            "Train Epoch: 4 [3405/3978 (86%)]\tLoss: 0.146037\n",
            "Train Epoch: 4 [3410/3978 (86%)]\tLoss: 0.328986\n",
            "Train Epoch: 4 [3415/3978 (86%)]\tLoss: 0.429581\n",
            "Train Epoch: 4 [3420/3978 (86%)]\tLoss: 0.226830\n",
            "Train Epoch: 4 [3425/3978 (86%)]\tLoss: 0.292483\n",
            "Train Epoch: 4 [3430/3978 (86%)]\tLoss: 0.106049\n",
            "Train Epoch: 4 [3435/3978 (86%)]\tLoss: 0.280795\n",
            "Train Epoch: 4 [3440/3978 (86%)]\tLoss: 0.599346\n",
            "Train Epoch: 4 [3445/3978 (87%)]\tLoss: 0.211354\n",
            "Train Epoch: 4 [3450/3978 (87%)]\tLoss: 0.384339\n",
            "Train Epoch: 4 [3455/3978 (87%)]\tLoss: 0.626374\n",
            "Train Epoch: 4 [3460/3978 (87%)]\tLoss: 0.464498\n",
            "Train Epoch: 4 [3465/3978 (87%)]\tLoss: 0.402334\n",
            "Train Epoch: 4 [3470/3978 (87%)]\tLoss: 0.398460\n",
            "Train Epoch: 4 [3475/3978 (87%)]\tLoss: 0.169952\n",
            "Train Epoch: 4 [3480/3978 (87%)]\tLoss: 0.650378\n",
            "Train Epoch: 4 [3485/3978 (88%)]\tLoss: 0.148428\n",
            "Train Epoch: 4 [3490/3978 (88%)]\tLoss: 0.339063\n",
            "Train Epoch: 4 [3495/3978 (88%)]\tLoss: 0.155691\n",
            "Train Epoch: 4 [3500/3978 (88%)]\tLoss: 0.126331\n",
            "Train Epoch: 4 [3505/3978 (88%)]\tLoss: 0.334358\n",
            "Train Epoch: 4 [3510/3978 (88%)]\tLoss: 0.304840\n",
            "Train Epoch: 4 [3515/3978 (88%)]\tLoss: 0.072769\n",
            "Train Epoch: 4 [3520/3978 (88%)]\tLoss: 0.192498\n",
            "Train Epoch: 4 [3525/3978 (89%)]\tLoss: 0.140699\n",
            "Train Epoch: 4 [3530/3978 (89%)]\tLoss: 0.199116\n",
            "Train Epoch: 4 [3535/3978 (89%)]\tLoss: 0.088319\n",
            "Train Epoch: 4 [3540/3978 (89%)]\tLoss: 0.096768\n",
            "Train Epoch: 4 [3545/3978 (89%)]\tLoss: 0.066481\n",
            "Train Epoch: 4 [3550/3978 (89%)]\tLoss: 0.264358\n",
            "Train Epoch: 4 [3555/3978 (89%)]\tLoss: 0.149197\n",
            "Train Epoch: 4 [3560/3978 (89%)]\tLoss: 0.517802\n",
            "Train Epoch: 4 [3565/3978 (90%)]\tLoss: 0.413032\n",
            "Train Epoch: 4 [3570/3978 (90%)]\tLoss: 0.127029\n",
            "Train Epoch: 4 [3575/3978 (90%)]\tLoss: 0.073541\n",
            "Train Epoch: 4 [3580/3978 (90%)]\tLoss: 0.177373\n",
            "Train Epoch: 4 [3585/3978 (90%)]\tLoss: 0.265584\n",
            "Train Epoch: 4 [3590/3978 (90%)]\tLoss: 0.333760\n",
            "Train Epoch: 4 [3595/3978 (90%)]\tLoss: 0.101185\n",
            "Train Epoch: 4 [3600/3978 (90%)]\tLoss: 0.128351\n",
            "Train Epoch: 4 [3605/3978 (91%)]\tLoss: 0.594726\n",
            "Train Epoch: 4 [3610/3978 (91%)]\tLoss: 0.134678\n",
            "Train Epoch: 4 [3615/3978 (91%)]\tLoss: 0.252346\n",
            "Train Epoch: 4 [3620/3978 (91%)]\tLoss: 0.212264\n",
            "Train Epoch: 4 [3625/3978 (91%)]\tLoss: 0.318096\n",
            "Train Epoch: 4 [3630/3978 (91%)]\tLoss: 0.121405\n",
            "Train Epoch: 4 [3635/3978 (91%)]\tLoss: 0.315859\n",
            "Train Epoch: 4 [3640/3978 (91%)]\tLoss: 0.276152\n",
            "Train Epoch: 4 [3645/3978 (92%)]\tLoss: 0.205357\n",
            "Train Epoch: 4 [3650/3978 (92%)]\tLoss: 0.276370\n",
            "Train Epoch: 4 [3655/3978 (92%)]\tLoss: 0.104517\n",
            "Train Epoch: 4 [3660/3978 (92%)]\tLoss: 0.274853\n",
            "Train Epoch: 4 [3665/3978 (92%)]\tLoss: 0.395943\n",
            "Train Epoch: 4 [3670/3978 (92%)]\tLoss: 0.187352\n",
            "Train Epoch: 4 [3675/3978 (92%)]\tLoss: 0.339418\n",
            "Train Epoch: 4 [3680/3978 (92%)]\tLoss: 0.316557\n",
            "Train Epoch: 4 [3685/3978 (93%)]\tLoss: 0.196325\n",
            "Train Epoch: 4 [3690/3978 (93%)]\tLoss: 0.207424\n",
            "Train Epoch: 4 [3695/3978 (93%)]\tLoss: 0.453828\n",
            "Train Epoch: 4 [3700/3978 (93%)]\tLoss: 0.054599\n",
            "Train Epoch: 4 [3705/3978 (93%)]\tLoss: 0.309544\n",
            "Train Epoch: 4 [3710/3978 (93%)]\tLoss: 0.303387\n",
            "Train Epoch: 4 [3715/3978 (93%)]\tLoss: 0.210591\n",
            "Train Epoch: 4 [3720/3978 (93%)]\tLoss: 0.370474\n",
            "Train Epoch: 4 [3725/3978 (94%)]\tLoss: 0.112831\n",
            "Train Epoch: 4 [3730/3978 (94%)]\tLoss: 0.264588\n",
            "Train Epoch: 4 [3735/3978 (94%)]\tLoss: 0.094518\n",
            "Train Epoch: 4 [3740/3978 (94%)]\tLoss: 0.774393\n",
            "Train Epoch: 4 [3745/3978 (94%)]\tLoss: 0.078156\n",
            "Train Epoch: 4 [3750/3978 (94%)]\tLoss: 0.676382\n",
            "Train Epoch: 4 [3755/3978 (94%)]\tLoss: 0.141750\n",
            "Train Epoch: 4 [3760/3978 (94%)]\tLoss: 0.104974\n",
            "Train Epoch: 4 [3765/3978 (95%)]\tLoss: 0.189184\n",
            "Train Epoch: 4 [3770/3978 (95%)]\tLoss: 0.124199\n",
            "Train Epoch: 4 [3775/3978 (95%)]\tLoss: 0.243145\n",
            "Train Epoch: 4 [3780/3978 (95%)]\tLoss: 0.072941\n",
            "Train Epoch: 4 [3785/3978 (95%)]\tLoss: 0.612161\n",
            "Train Epoch: 4 [3790/3978 (95%)]\tLoss: 0.296441\n",
            "Train Epoch: 4 [3795/3978 (95%)]\tLoss: 0.320385\n",
            "Train Epoch: 4 [3800/3978 (95%)]\tLoss: 0.208022\n",
            "Train Epoch: 4 [3805/3978 (96%)]\tLoss: 0.292562\n",
            "Train Epoch: 4 [3810/3978 (96%)]\tLoss: 0.095300\n",
            "Train Epoch: 4 [3815/3978 (96%)]\tLoss: 0.305677\n",
            "Train Epoch: 4 [3820/3978 (96%)]\tLoss: 0.140526\n",
            "Train Epoch: 4 [3825/3978 (96%)]\tLoss: 0.341428\n",
            "Train Epoch: 4 [3830/3978 (96%)]\tLoss: 0.171693\n",
            "Train Epoch: 4 [3835/3978 (96%)]\tLoss: 0.168523\n",
            "Train Epoch: 4 [3840/3978 (96%)]\tLoss: 0.273252\n",
            "Train Epoch: 4 [3845/3978 (97%)]\tLoss: 0.367503\n",
            "Train Epoch: 4 [3850/3978 (97%)]\tLoss: 0.097491\n",
            "Train Epoch: 4 [3855/3978 (97%)]\tLoss: 0.185135\n",
            "Train Epoch: 4 [3860/3978 (97%)]\tLoss: 0.263323\n",
            "Train Epoch: 4 [3865/3978 (97%)]\tLoss: 0.385652\n",
            "Train Epoch: 4 [3870/3978 (97%)]\tLoss: 0.282637\n",
            "Train Epoch: 4 [3875/3978 (97%)]\tLoss: 0.388209\n",
            "Train Epoch: 4 [3880/3978 (97%)]\tLoss: 0.135642\n",
            "Train Epoch: 4 [3885/3978 (98%)]\tLoss: 0.113301\n",
            "Train Epoch: 4 [3890/3978 (98%)]\tLoss: 0.101355\n",
            "Train Epoch: 4 [3895/3978 (98%)]\tLoss: 0.266582\n",
            "Train Epoch: 4 [3900/3978 (98%)]\tLoss: 0.087103\n",
            "Train Epoch: 4 [3905/3978 (98%)]\tLoss: 0.039294\n",
            "Train Epoch: 4 [3910/3978 (98%)]\tLoss: 0.114671\n",
            "Train Epoch: 4 [3915/3978 (98%)]\tLoss: 0.454389\n",
            "Train Epoch: 4 [3920/3978 (98%)]\tLoss: 0.508861\n",
            "Train Epoch: 4 [3925/3978 (99%)]\tLoss: 0.130874\n",
            "Train Epoch: 4 [3930/3978 (99%)]\tLoss: 0.384380\n",
            "Train Epoch: 4 [3935/3978 (99%)]\tLoss: 0.285592\n",
            "Train Epoch: 4 [3940/3978 (99%)]\tLoss: 0.085897\n",
            "Train Epoch: 4 [3945/3978 (99%)]\tLoss: 0.247071\n",
            "Train Epoch: 4 [3950/3978 (99%)]\tLoss: 0.385998\n",
            "Train Epoch: 4 [3955/3978 (99%)]\tLoss: 0.297341\n",
            "Train Epoch: 4 [3960/3978 (99%)]\tLoss: 0.320851\n",
            "Train Epoch: 4 [3965/3978 (100%)]\tLoss: 0.430444\n",
            "Train Epoch: 4 [3970/3978 (100%)]\tLoss: 0.235987\n",
            "Train Epoch: 4 [2385/3978 (100%)]\tLoss: 0.139794\n",
            "Epoch\n",
            "train/train_loss: 0.1397935301065445\n",
            "\n",
            "Train Loss: 0.140, Valid Loss: 0.309250, Accuracy: 0.36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='811.925 MB of 811.925 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50efaff24d9d47479b30bf029c23a951"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train/loss</td><td>▃▂▃▂▅▁▂▃▄█▃▂▃▂▂▂▂▇▁▃▂▃▃▁▁▁▂▁▂▃▂▃▂▂▁▂▁▂▃▃</td></tr><tr><td>validation/accuracy</td><td>▁██▁█</td></tr><tr><td>validation/loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/loss</td><td>0.13979</td></tr><tr><td>validation/accuracy</td><td>0.36494</td></tr><tr><td>validation/loss</td><td>0.30925</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">olive-sweep-5</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/mwj2226b' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/mwj2226b</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240829_192547-mwj2226b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.agent(sweep_id, function=lambda: train_agent(val_dataloader=val_loader,train_dataset=train_dataset), count=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aizE_9C61znY"
      },
      "source": [
        "## Run training on the best network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "sJYRRErD1-3r",
        "outputId": "f1b6208b-9284-420d-add4-a4fa2c935298"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240830_092247-70nmvld5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/uncategorized/runs/70nmvld5' target=\"_blank\">revived-sun-6</a></strong> to <a href='https://wandb.ai/cecca/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/uncategorized' target=\"_blank\">https://wandb.ai/cecca/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/uncategorized/runs/70nmvld5' target=\"_blank\">https://wandb.ai/cecca/uncategorized/runs/70nmvld5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact trained-model:v2, 135.32MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:11.3\n"
          ]
        }
      ],
      "source": [
        "# Initialize WandB\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('cecca/AdvancedTechniques/trained-model:v2', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "# Assuming your artifact contains a model file named 'model.pth'\n",
        "model_path = os.path.join(artifact_dir, 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjsBH0DffrsK"
      },
      "outputs": [],
      "source": [
        "# Now I can load the model using PyTorch\n",
        "model = SlowFusionNetVLAD(dropout=0.4)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpjN9oKM2Eaz"
      },
      "outputs": [],
      "source": [
        "train_dataloader =torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "XaN3Ynwm2Q9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34b369c4055d4ab0b092d350dbfb4a52",
            "48c8a970639945388dcbcb3ccc529f7e",
            "dcdb164b0b834d998b2797df0e3ef2a1",
            "3b85d3618b3c44b79e947bb889825a91",
            "effa492022514065a7fa1b23afd1f74c",
            "27f1e5cb58c14f7eb24a08aff76a768a",
            "05a3afc78501447c95fc2f94a3b622b5",
            "6bc4d1efaed74f93aea9f57eddb685db",
            "b8c7cf1c30384b299a1a13ea52fa541e",
            "19c5e7ee087a43f0a3df5b150d78d290",
            "f91857373c7d4cfaaafb4bdab3599f17",
            "2109ccea576c4e2a96856946d18e3445",
            "cf35cfb11a2a4de0a3254e9296e112f8",
            "78eef56438994dd5856af18b1197747b",
            "67367e6ba96348f885b7cdf4afb5fb79",
            "85e5b6d09abd45daab46dcf18bff6866"
          ]
        },
        "outputId": "5aec5b50-1d67-43c8-93b4-7211c85ba0fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:70nmvld5) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34b369c4055d4ab0b092d350dbfb4a52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">revived-sun-6</strong> at: <a href='https://wandb.ai/cecca/uncategorized/runs/70nmvld5' target=\"_blank\">https://wandb.ai/cecca/uncategorized/runs/70nmvld5</a><br/> View project at: <a href='https://wandb.ai/cecca/uncategorized' target=\"_blank\">https://wandb.ai/cecca/uncategorized</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240830_092247-70nmvld5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:70nmvld5). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240830_092307-3t02llmn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/3t02llmn' target=\"_blank\">copper-pyramid-30</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/3t02llmn' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/3t02llmn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train Epoch: 14 [1849/6845 (27%)]\tLoss: 1.608494\n",
            "Train Epoch: 14 [1850/6845 (27%)]\tLoss: 0.144758\n",
            "Train Epoch: 14 [1851/6845 (27%)]\tLoss: 0.179208\n",
            "Train Epoch: 14 [1852/6845 (27%)]\tLoss: 0.334754\n",
            "Train Epoch: 14 [1853/6845 (27%)]\tLoss: 0.728397\n",
            "Train Epoch: 14 [1854/6845 (27%)]\tLoss: 0.188477\n",
            "Train Epoch: 14 [1855/6845 (27%)]\tLoss: 0.623006\n",
            "Train Epoch: 14 [1856/6845 (27%)]\tLoss: 0.240187\n",
            "Train Epoch: 14 [1857/6845 (27%)]\tLoss: 0.177252\n",
            "Train Epoch: 14 [1858/6845 (27%)]\tLoss: 0.125323\n",
            "Train Epoch: 14 [1859/6845 (27%)]\tLoss: 0.128462\n",
            "Train Epoch: 14 [1860/6845 (27%)]\tLoss: 0.138286\n",
            "Train Epoch: 14 [1861/6845 (27%)]\tLoss: 0.172794\n",
            "Train Epoch: 14 [1862/6845 (27%)]\tLoss: 0.156471\n",
            "Train Epoch: 14 [1863/6845 (27%)]\tLoss: 0.310452\n",
            "Train Epoch: 14 [1864/6845 (27%)]\tLoss: 0.265721\n",
            "Train Epoch: 14 [1865/6845 (27%)]\tLoss: 0.123472\n",
            "Train Epoch: 14 [1866/6845 (27%)]\tLoss: 0.161429\n",
            "Train Epoch: 14 [1867/6845 (27%)]\tLoss: 0.800240\n",
            "Train Epoch: 14 [1868/6845 (27%)]\tLoss: 0.135226\n",
            "Train Epoch: 14 [1869/6845 (27%)]\tLoss: 0.094723\n",
            "Train Epoch: 14 [1870/6845 (27%)]\tLoss: 0.202303\n",
            "Train Epoch: 14 [1871/6845 (27%)]\tLoss: 1.264834\n",
            "Train Epoch: 14 [1872/6845 (27%)]\tLoss: 0.488936\n",
            "Train Epoch: 14 [1873/6845 (27%)]\tLoss: 0.129488\n",
            "Train Epoch: 14 [1874/6845 (27%)]\tLoss: 0.106032\n",
            "Train Epoch: 14 [1875/6845 (27%)]\tLoss: 0.105404\n",
            "Train Epoch: 14 [1876/6845 (27%)]\tLoss: 0.341558\n",
            "Train Epoch: 14 [1877/6845 (27%)]\tLoss: 0.526126\n",
            "Train Epoch: 14 [1878/6845 (27%)]\tLoss: 0.123307\n",
            "Train Epoch: 14 [1879/6845 (27%)]\tLoss: 0.107352\n",
            "Train Epoch: 14 [1880/6845 (27%)]\tLoss: 0.805164\n",
            "Train Epoch: 14 [1881/6845 (27%)]\tLoss: 0.127213\n",
            "Train Epoch: 14 [1882/6845 (27%)]\tLoss: 0.098128\n",
            "Train Epoch: 14 [1883/6845 (28%)]\tLoss: 0.685495\n",
            "Train Epoch: 14 [1884/6845 (28%)]\tLoss: 0.168053\n",
            "Train Epoch: 14 [1885/6845 (28%)]\tLoss: 0.103604\n",
            "Train Epoch: 14 [1886/6845 (28%)]\tLoss: 0.420514\n",
            "Train Epoch: 14 [1887/6845 (28%)]\tLoss: 0.471529\n",
            "Train Epoch: 14 [1888/6845 (28%)]\tLoss: 0.132931\n",
            "Train Epoch: 14 [1889/6845 (28%)]\tLoss: 0.555963\n",
            "Train Epoch: 14 [1890/6845 (28%)]\tLoss: 0.235989\n",
            "Train Epoch: 14 [1891/6845 (28%)]\tLoss: 0.336756\n",
            "Train Epoch: 14 [1892/6845 (28%)]\tLoss: 1.153310\n",
            "Train Epoch: 14 [1893/6845 (28%)]\tLoss: 0.088136\n",
            "Train Epoch: 14 [1894/6845 (28%)]\tLoss: 0.063797\n",
            "Train Epoch: 14 [1895/6845 (28%)]\tLoss: 0.095405\n",
            "Train Epoch: 14 [1896/6845 (28%)]\tLoss: 0.723691\n",
            "Train Epoch: 14 [1897/6845 (28%)]\tLoss: 0.185602\n",
            "Train Epoch: 14 [1898/6845 (28%)]\tLoss: 0.075725\n",
            "Train Epoch: 14 [1899/6845 (28%)]\tLoss: 0.487737\n",
            "Train Epoch: 14 [1900/6845 (28%)]\tLoss: 0.512637\n",
            "Train Epoch: 14 [1901/6845 (28%)]\tLoss: 0.146546\n",
            "Train Epoch: 14 [1902/6845 (28%)]\tLoss: 1.019860\n",
            "Train Epoch: 14 [1903/6845 (28%)]\tLoss: 0.063701\n",
            "Train Epoch: 14 [1904/6845 (28%)]\tLoss: 0.090964\n",
            "Train Epoch: 14 [1905/6845 (28%)]\tLoss: 0.071274\n",
            "Train Epoch: 14 [1906/6845 (28%)]\tLoss: 0.151919\n",
            "Train Epoch: 14 [1907/6845 (28%)]\tLoss: 0.054781\n",
            "Train Epoch: 14 [1908/6845 (28%)]\tLoss: 0.172945\n",
            "Train Epoch: 14 [1909/6845 (28%)]\tLoss: 0.076913\n",
            "Train Epoch: 14 [1910/6845 (28%)]\tLoss: 0.170228\n",
            "Train Epoch: 14 [1911/6845 (28%)]\tLoss: 0.101765\n",
            "Train Epoch: 14 [1912/6845 (28%)]\tLoss: 0.269929\n",
            "Train Epoch: 14 [1913/6845 (28%)]\tLoss: 0.165735\n",
            "Train Epoch: 14 [1914/6845 (28%)]\tLoss: 0.448129\n",
            "Train Epoch: 14 [1915/6845 (28%)]\tLoss: 0.401557\n",
            "Train Epoch: 14 [1916/6845 (28%)]\tLoss: 0.156297\n",
            "Train Epoch: 14 [1917/6845 (28%)]\tLoss: 0.158500\n",
            "Train Epoch: 14 [1918/6845 (28%)]\tLoss: 0.268052\n",
            "Train Epoch: 14 [1919/6845 (28%)]\tLoss: 0.146992\n",
            "Train Epoch: 14 [1920/6845 (28%)]\tLoss: 0.068925\n",
            "Train Epoch: 14 [1921/6845 (28%)]\tLoss: 0.654025\n",
            "Train Epoch: 14 [1922/6845 (28%)]\tLoss: 0.291610\n",
            "Train Epoch: 14 [1923/6845 (28%)]\tLoss: 0.308823\n",
            "Train Epoch: 14 [1924/6845 (28%)]\tLoss: 0.082010\n",
            "Train Epoch: 14 [1925/6845 (28%)]\tLoss: 0.082454\n",
            "Train Epoch: 14 [1926/6845 (28%)]\tLoss: 0.078977\n",
            "Train Epoch: 14 [1927/6845 (28%)]\tLoss: 0.303889\n",
            "Train Epoch: 14 [1928/6845 (28%)]\tLoss: 0.669353\n",
            "Train Epoch: 14 [1929/6845 (28%)]\tLoss: 0.302707\n",
            "Train Epoch: 14 [1930/6845 (28%)]\tLoss: 0.074108\n",
            "Train Epoch: 14 [1931/6845 (28%)]\tLoss: 0.105526\n",
            "Train Epoch: 14 [1932/6845 (28%)]\tLoss: 0.138390\n",
            "Train Epoch: 14 [1933/6845 (28%)]\tLoss: 0.113206\n",
            "Train Epoch: 14 [1934/6845 (28%)]\tLoss: 0.072050\n",
            "Train Epoch: 14 [1935/6845 (28%)]\tLoss: 0.119999\n",
            "Train Epoch: 14 [1936/6845 (28%)]\tLoss: 0.627509\n",
            "Train Epoch: 14 [1937/6845 (28%)]\tLoss: 0.477279\n",
            "Train Epoch: 14 [1938/6845 (28%)]\tLoss: 0.174489\n",
            "Train Epoch: 14 [1939/6845 (28%)]\tLoss: 0.196756\n",
            "Train Epoch: 14 [1940/6845 (28%)]\tLoss: 0.096010\n",
            "Train Epoch: 14 [1941/6845 (28%)]\tLoss: 0.911000\n",
            "Train Epoch: 14 [1942/6845 (28%)]\tLoss: 0.067984\n",
            "Train Epoch: 14 [1943/6845 (28%)]\tLoss: 0.194361\n",
            "Train Epoch: 14 [1944/6845 (28%)]\tLoss: 0.579423\n",
            "Train Epoch: 14 [1945/6845 (28%)]\tLoss: 0.102343\n",
            "Train Epoch: 14 [1946/6845 (28%)]\tLoss: 0.164326\n",
            "Train Epoch: 14 [1947/6845 (28%)]\tLoss: 0.065905\n",
            "Train Epoch: 14 [1948/6845 (28%)]\tLoss: 0.068104\n",
            "Train Epoch: 14 [1949/6845 (28%)]\tLoss: 0.262743\n",
            "Train Epoch: 14 [1950/6845 (28%)]\tLoss: 0.559703\n",
            "Train Epoch: 14 [1951/6845 (29%)]\tLoss: 0.228891\n",
            "Train Epoch: 14 [1952/6845 (29%)]\tLoss: 0.155576\n",
            "Train Epoch: 14 [1953/6845 (29%)]\tLoss: 0.066049\n",
            "Train Epoch: 14 [1954/6845 (29%)]\tLoss: 0.093993\n",
            "Train Epoch: 14 [1955/6845 (29%)]\tLoss: 0.129217\n",
            "Train Epoch: 14 [1956/6845 (29%)]\tLoss: 0.094070\n",
            "Train Epoch: 14 [1957/6845 (29%)]\tLoss: 0.397902\n",
            "Train Epoch: 14 [1958/6845 (29%)]\tLoss: 0.469098\n",
            "Train Epoch: 14 [1959/6845 (29%)]\tLoss: 0.854009\n",
            "Train Epoch: 14 [1960/6845 (29%)]\tLoss: 0.257036\n",
            "Train Epoch: 14 [1961/6845 (29%)]\tLoss: 0.105616\n",
            "Train Epoch: 14 [1962/6845 (29%)]\tLoss: 0.381343\n",
            "Train Epoch: 14 [1963/6845 (29%)]\tLoss: 0.255659\n",
            "Train Epoch: 14 [1964/6845 (29%)]\tLoss: 0.202339\n",
            "Train Epoch: 14 [1965/6845 (29%)]\tLoss: 0.086195\n",
            "Train Epoch: 14 [1966/6845 (29%)]\tLoss: 0.166974\n",
            "Train Epoch: 14 [1967/6845 (29%)]\tLoss: 0.733008\n",
            "Train Epoch: 14 [1968/6845 (29%)]\tLoss: 0.087089\n",
            "Train Epoch: 14 [1969/6845 (29%)]\tLoss: 0.125104\n",
            "Train Epoch: 14 [1970/6845 (29%)]\tLoss: 0.074274\n",
            "Train Epoch: 14 [1971/6845 (29%)]\tLoss: 0.071692\n",
            "Train Epoch: 14 [1972/6845 (29%)]\tLoss: 0.136513\n",
            "Train Epoch: 14 [1973/6845 (29%)]\tLoss: 0.101527\n",
            "Train Epoch: 14 [1974/6845 (29%)]\tLoss: 0.071064\n",
            "Train Epoch: 14 [1975/6845 (29%)]\tLoss: 0.075817\n",
            "Train Epoch: 14 [1976/6845 (29%)]\tLoss: 0.089239\n",
            "Train Epoch: 14 [1977/6845 (29%)]\tLoss: 0.220821\n",
            "Train Epoch: 14 [1978/6845 (29%)]\tLoss: 0.090281\n",
            "Train Epoch: 14 [1979/6845 (29%)]\tLoss: 0.713001\n",
            "Train Epoch: 14 [1980/6845 (29%)]\tLoss: 0.165805\n",
            "Train Epoch: 14 [1981/6845 (29%)]\tLoss: 0.117990\n",
            "Train Epoch: 14 [1982/6845 (29%)]\tLoss: 0.687351\n",
            "Train Epoch: 14 [1983/6845 (29%)]\tLoss: 0.091293\n",
            "Train Epoch: 14 [1984/6845 (29%)]\tLoss: 0.058303\n",
            "Train Epoch: 14 [1985/6845 (29%)]\tLoss: 0.571548\n",
            "Train Epoch: 14 [1986/6845 (29%)]\tLoss: 0.192163\n",
            "Train Epoch: 14 [1987/6845 (29%)]\tLoss: 0.108577\n",
            "Train Epoch: 14 [1988/6845 (29%)]\tLoss: 0.706440\n",
            "Train Epoch: 14 [1989/6845 (29%)]\tLoss: 0.469512\n",
            "Train Epoch: 14 [1990/6845 (29%)]\tLoss: 0.354037\n",
            "Train Epoch: 14 [1991/6845 (29%)]\tLoss: 0.071011\n",
            "Train Epoch: 14 [1992/6845 (29%)]\tLoss: 0.461436\n",
            "Train Epoch: 14 [1993/6845 (29%)]\tLoss: 0.078079\n",
            "Train Epoch: 14 [1994/6845 (29%)]\tLoss: 0.076777\n",
            "Train Epoch: 14 [1995/6845 (29%)]\tLoss: 0.137116\n",
            "Train Epoch: 14 [1996/6845 (29%)]\tLoss: 0.088458\n",
            "Train Epoch: 14 [1997/6845 (29%)]\tLoss: 0.165146\n",
            "Train Epoch: 14 [1998/6845 (29%)]\tLoss: 0.164181\n",
            "Train Epoch: 14 [1999/6845 (29%)]\tLoss: 0.635717\n",
            "Train Epoch: 14 [2000/6845 (29%)]\tLoss: 0.804188\n",
            "Train Epoch: 14 [2001/6845 (29%)]\tLoss: 0.067921\n",
            "Train Epoch: 14 [2002/6845 (29%)]\tLoss: 0.429759\n",
            "Train Epoch: 14 [2003/6845 (29%)]\tLoss: 0.558228\n",
            "Train Epoch: 14 [2004/6845 (29%)]\tLoss: 0.228426\n",
            "Train Epoch: 14 [2005/6845 (29%)]\tLoss: 0.384935\n",
            "Train Epoch: 14 [2006/6845 (29%)]\tLoss: 0.176801\n",
            "Train Epoch: 14 [2007/6845 (29%)]\tLoss: 0.161761\n",
            "Train Epoch: 14 [2008/6845 (29%)]\tLoss: 0.422744\n",
            "Train Epoch: 14 [2009/6845 (29%)]\tLoss: 0.115246\n",
            "Train Epoch: 14 [2010/6845 (29%)]\tLoss: 0.327807\n",
            "Train Epoch: 14 [2011/6845 (29%)]\tLoss: 0.411321\n",
            "Train Epoch: 14 [2012/6845 (29%)]\tLoss: 0.098222\n",
            "Train Epoch: 14 [2013/6845 (29%)]\tLoss: 0.218328\n",
            "Train Epoch: 14 [2014/6845 (29%)]\tLoss: 0.090133\n",
            "Train Epoch: 14 [2015/6845 (29%)]\tLoss: 0.067763\n",
            "Train Epoch: 14 [2016/6845 (29%)]\tLoss: 0.067964\n",
            "Train Epoch: 14 [2017/6845 (29%)]\tLoss: 0.466246\n",
            "Train Epoch: 14 [2018/6845 (29%)]\tLoss: 0.135786\n",
            "Train Epoch: 14 [2019/6845 (29%)]\tLoss: 0.190406\n",
            "Train Epoch: 14 [2020/6845 (30%)]\tLoss: 0.063708\n",
            "Train Epoch: 14 [2021/6845 (30%)]\tLoss: 0.131946\n",
            "Train Epoch: 14 [2022/6845 (30%)]\tLoss: 0.164986\n",
            "Train Epoch: 14 [2023/6845 (30%)]\tLoss: 0.205334\n",
            "Train Epoch: 14 [2024/6845 (30%)]\tLoss: 0.406398\n",
            "Train Epoch: 14 [2025/6845 (30%)]\tLoss: 0.706192\n",
            "Train Epoch: 14 [2026/6845 (30%)]\tLoss: 0.116524\n",
            "Train Epoch: 14 [2027/6845 (30%)]\tLoss: 0.122684\n",
            "Train Epoch: 14 [2028/6845 (30%)]\tLoss: 0.266450\n",
            "Train Epoch: 14 [2029/6845 (30%)]\tLoss: 0.056778\n",
            "Train Epoch: 14 [2030/6845 (30%)]\tLoss: 0.525738\n",
            "Train Epoch: 14 [2031/6845 (30%)]\tLoss: 0.130559\n",
            "Train Epoch: 14 [2032/6845 (30%)]\tLoss: 0.056287\n",
            "Train Epoch: 14 [2033/6845 (30%)]\tLoss: 0.115211\n",
            "Train Epoch: 14 [2034/6845 (30%)]\tLoss: 0.155216\n",
            "Train Epoch: 14 [2035/6845 (30%)]\tLoss: 0.170070\n",
            "Train Epoch: 14 [2036/6845 (30%)]\tLoss: 0.064354\n",
            "Train Epoch: 14 [2037/6845 (30%)]\tLoss: 0.086216\n",
            "Train Epoch: 14 [2038/6845 (30%)]\tLoss: 0.164208\n",
            "Train Epoch: 14 [2039/6845 (30%)]\tLoss: 0.157432\n",
            "Train Epoch: 14 [2040/6845 (30%)]\tLoss: 0.106125\n",
            "Train Epoch: 14 [2041/6845 (30%)]\tLoss: 0.206585\n",
            "Train Epoch: 14 [2042/6845 (30%)]\tLoss: 0.790956\n",
            "Train Epoch: 14 [2043/6845 (30%)]\tLoss: 0.211207\n",
            "Train Epoch: 14 [2044/6845 (30%)]\tLoss: 0.186909\n",
            "Train Epoch: 14 [2045/6845 (30%)]\tLoss: 0.621614\n",
            "Train Epoch: 14 [2046/6845 (30%)]\tLoss: 0.142166\n",
            "Train Epoch: 14 [2047/6845 (30%)]\tLoss: 0.109203\n",
            "Train Epoch: 14 [2048/6845 (30%)]\tLoss: 0.782683\n",
            "Train Epoch: 14 [2049/6845 (30%)]\tLoss: 0.533705\n",
            "Train Epoch: 14 [2050/6845 (30%)]\tLoss: 0.087809\n",
            "Train Epoch: 14 [2051/6845 (30%)]\tLoss: 0.117099\n",
            "Train Epoch: 14 [2052/6845 (30%)]\tLoss: 0.063182\n",
            "Train Epoch: 14 [2053/6845 (30%)]\tLoss: 0.074347\n",
            "Train Epoch: 14 [2054/6845 (30%)]\tLoss: 0.505096\n",
            "Train Epoch: 14 [2055/6845 (30%)]\tLoss: 0.075027\n",
            "Train Epoch: 14 [2056/6845 (30%)]\tLoss: 0.158589\n",
            "Train Epoch: 14 [2057/6845 (30%)]\tLoss: 1.115474\n",
            "Train Epoch: 14 [2058/6845 (30%)]\tLoss: 0.053716\n",
            "Train Epoch: 14 [2059/6845 (30%)]\tLoss: 0.662899\n",
            "Train Epoch: 14 [2060/6845 (30%)]\tLoss: 0.061777\n",
            "Train Epoch: 14 [2061/6845 (30%)]\tLoss: 0.052328\n",
            "Train Epoch: 14 [2062/6845 (30%)]\tLoss: 0.111152\n",
            "Train Epoch: 14 [2063/6845 (30%)]\tLoss: 0.326518\n",
            "Train Epoch: 14 [2064/6845 (30%)]\tLoss: 0.522696\n",
            "Train Epoch: 14 [2065/6845 (30%)]\tLoss: 0.061257\n",
            "Train Epoch: 14 [2066/6845 (30%)]\tLoss: 0.985845\n",
            "Train Epoch: 14 [2067/6845 (30%)]\tLoss: 0.056229\n",
            "Train Epoch: 14 [2068/6845 (30%)]\tLoss: 0.101079\n",
            "Train Epoch: 14 [2069/6845 (30%)]\tLoss: 0.697877\n",
            "Train Epoch: 14 [2070/6845 (30%)]\tLoss: 0.243560\n",
            "Train Epoch: 14 [2071/6845 (30%)]\tLoss: 0.303066\n",
            "Train Epoch: 14 [2072/6845 (30%)]\tLoss: 0.119654\n",
            "Train Epoch: 14 [2073/6845 (30%)]\tLoss: 0.567485\n",
            "Train Epoch: 14 [2074/6845 (30%)]\tLoss: 0.167270\n",
            "Train Epoch: 14 [2075/6845 (30%)]\tLoss: 0.529390\n",
            "Train Epoch: 14 [2076/6845 (30%)]\tLoss: 0.118790\n",
            "Train Epoch: 14 [2077/6845 (30%)]\tLoss: 0.505208\n",
            "Train Epoch: 14 [2078/6845 (30%)]\tLoss: 0.542619\n",
            "Train Epoch: 14 [2079/6845 (30%)]\tLoss: 0.166795\n",
            "Train Epoch: 14 [2080/6845 (30%)]\tLoss: 0.076485\n",
            "Train Epoch: 14 [2081/6845 (30%)]\tLoss: 0.531890\n",
            "Train Epoch: 14 [2082/6845 (30%)]\tLoss: 0.070780\n",
            "Train Epoch: 14 [2083/6845 (30%)]\tLoss: 0.152995\n",
            "Train Epoch: 14 [2084/6845 (30%)]\tLoss: 0.119013\n",
            "Train Epoch: 14 [2085/6845 (30%)]\tLoss: 0.496652\n",
            "Train Epoch: 14 [2086/6845 (30%)]\tLoss: 0.529130\n",
            "Train Epoch: 14 [2087/6845 (30%)]\tLoss: 0.137742\n",
            "Train Epoch: 14 [2088/6845 (31%)]\tLoss: 0.066323\n",
            "Train Epoch: 14 [2089/6845 (31%)]\tLoss: 0.068123\n",
            "Train Epoch: 14 [2090/6845 (31%)]\tLoss: 0.108382\n",
            "Train Epoch: 14 [2091/6845 (31%)]\tLoss: 0.128539\n",
            "Train Epoch: 14 [2092/6845 (31%)]\tLoss: 0.166882\n",
            "Train Epoch: 14 [2093/6845 (31%)]\tLoss: 0.143594\n",
            "Train Epoch: 14 [2094/6845 (31%)]\tLoss: 0.112304\n",
            "Train Epoch: 14 [2095/6845 (31%)]\tLoss: 0.683954\n",
            "Train Epoch: 14 [2096/6845 (31%)]\tLoss: 0.240186\n",
            "Train Epoch: 14 [2097/6845 (31%)]\tLoss: 0.072045\n",
            "Train Epoch: 14 [2098/6845 (31%)]\tLoss: 0.130409\n",
            "Train Epoch: 14 [2099/6845 (31%)]\tLoss: 0.218566\n",
            "Train Epoch: 14 [2100/6845 (31%)]\tLoss: 0.334305\n",
            "Train Epoch: 14 [2101/6845 (31%)]\tLoss: 0.135855\n",
            "Train Epoch: 14 [2102/6845 (31%)]\tLoss: 0.409035\n",
            "Train Epoch: 14 [2103/6845 (31%)]\tLoss: 0.631063\n",
            "Train Epoch: 14 [2104/6845 (31%)]\tLoss: 0.176612\n",
            "Train Epoch: 14 [2105/6845 (31%)]\tLoss: 0.098858\n",
            "Train Epoch: 14 [2106/6845 (31%)]\tLoss: 0.126682\n",
            "Train Epoch: 14 [2107/6845 (31%)]\tLoss: 1.671105\n",
            "Train Epoch: 14 [2108/6845 (31%)]\tLoss: 0.116702\n",
            "Train Epoch: 14 [2109/6845 (31%)]\tLoss: 0.075905\n",
            "Train Epoch: 14 [2110/6845 (31%)]\tLoss: 0.094125\n",
            "Train Epoch: 14 [2111/6845 (31%)]\tLoss: 0.077377\n",
            "Train Epoch: 14 [2112/6845 (31%)]\tLoss: 0.154411\n",
            "Train Epoch: 14 [2113/6845 (31%)]\tLoss: 0.103362\n",
            "Train Epoch: 14 [2114/6845 (31%)]\tLoss: 0.071299\n",
            "Train Epoch: 14 [2115/6845 (31%)]\tLoss: 0.118270\n",
            "Train Epoch: 14 [2116/6845 (31%)]\tLoss: 0.093681\n",
            "Train Epoch: 14 [2117/6845 (31%)]\tLoss: 0.120873\n",
            "Train Epoch: 14 [2118/6845 (31%)]\tLoss: 0.495521\n",
            "Train Epoch: 14 [2119/6845 (31%)]\tLoss: 0.097493\n",
            "Train Epoch: 14 [2120/6845 (31%)]\tLoss: 0.076509\n",
            "Train Epoch: 14 [2121/6845 (31%)]\tLoss: 0.740793\n",
            "Train Epoch: 14 [2122/6845 (31%)]\tLoss: 0.135414\n",
            "Train Epoch: 14 [2123/6845 (31%)]\tLoss: 0.091040\n",
            "Train Epoch: 14 [2124/6845 (31%)]\tLoss: 0.198974\n",
            "Train Epoch: 14 [2125/6845 (31%)]\tLoss: 0.239326\n",
            "Train Epoch: 14 [2126/6845 (31%)]\tLoss: 0.366641\n",
            "Train Epoch: 14 [2127/6845 (31%)]\tLoss: 0.117744\n",
            "Train Epoch: 14 [2128/6845 (31%)]\tLoss: 0.080798\n",
            "Train Epoch: 14 [2129/6845 (31%)]\tLoss: 0.435648\n",
            "Train Epoch: 14 [2130/6845 (31%)]\tLoss: 0.592008\n",
            "Train Epoch: 14 [2131/6845 (31%)]\tLoss: 0.151997\n",
            "Train Epoch: 14 [2132/6845 (31%)]\tLoss: 0.101420\n",
            "Train Epoch: 14 [2133/6845 (31%)]\tLoss: 0.071328\n",
            "Train Epoch: 14 [2134/6845 (31%)]\tLoss: 0.519847\n",
            "Train Epoch: 14 [2135/6845 (31%)]\tLoss: 0.562071\n",
            "Train Epoch: 14 [2136/6845 (31%)]\tLoss: 0.181122\n",
            "Train Epoch: 14 [2137/6845 (31%)]\tLoss: 0.182509\n",
            "Train Epoch: 14 [2138/6845 (31%)]\tLoss: 0.177682\n",
            "Train Epoch: 14 [2139/6845 (31%)]\tLoss: 0.139962\n",
            "Train Epoch: 14 [2140/6845 (31%)]\tLoss: 0.959132\n",
            "Train Epoch: 14 [2141/6845 (31%)]\tLoss: 0.831410\n",
            "Train Epoch: 14 [2142/6845 (31%)]\tLoss: 0.645545\n",
            "Train Epoch: 14 [2143/6845 (31%)]\tLoss: 0.100496\n",
            "Train Epoch: 14 [2144/6845 (31%)]\tLoss: 0.975935\n",
            "Train Epoch: 14 [2145/6845 (31%)]\tLoss: 0.128150\n",
            "Train Epoch: 14 [2146/6845 (31%)]\tLoss: 0.077819\n",
            "Train Epoch: 14 [2147/6845 (31%)]\tLoss: 0.078497\n",
            "Train Epoch: 14 [2148/6845 (31%)]\tLoss: 0.445553\n",
            "Train Epoch: 14 [2149/6845 (31%)]\tLoss: 0.101364\n",
            "Train Epoch: 14 [2150/6845 (31%)]\tLoss: 0.109666\n",
            "Train Epoch: 14 [2151/6845 (31%)]\tLoss: 0.682661\n",
            "Train Epoch: 14 [2152/6845 (31%)]\tLoss: 0.215163\n",
            "Train Epoch: 14 [2153/6845 (31%)]\tLoss: 0.086239\n",
            "Train Epoch: 14 [2154/6845 (31%)]\tLoss: 0.063440\n",
            "Train Epoch: 14 [2155/6845 (31%)]\tLoss: 0.513957\n",
            "Train Epoch: 14 [2156/6845 (31%)]\tLoss: 0.100350\n",
            "Train Epoch: 14 [2157/6845 (32%)]\tLoss: 0.266586\n",
            "Train Epoch: 14 [2158/6845 (32%)]\tLoss: 0.061251\n",
            "Train Epoch: 14 [2159/6845 (32%)]\tLoss: 0.089380\n",
            "Train Epoch: 14 [2160/6845 (32%)]\tLoss: 0.199093\n",
            "Train Epoch: 14 [2161/6845 (32%)]\tLoss: 0.132346\n",
            "Train Epoch: 14 [2162/6845 (32%)]\tLoss: 0.064069\n",
            "Train Epoch: 14 [2163/6845 (32%)]\tLoss: 0.534040\n",
            "Train Epoch: 14 [2164/6845 (32%)]\tLoss: 0.242640\n",
            "Train Epoch: 14 [2165/6845 (32%)]\tLoss: 0.057280\n",
            "Train Epoch: 14 [2166/6845 (32%)]\tLoss: 0.267621\n",
            "Train Epoch: 14 [2167/6845 (32%)]\tLoss: 0.209778\n",
            "Train Epoch: 14 [2168/6845 (32%)]\tLoss: 0.408797\n",
            "Train Epoch: 14 [2169/6845 (32%)]\tLoss: 0.125058\n",
            "Train Epoch: 14 [2170/6845 (32%)]\tLoss: 0.356211\n",
            "Train Epoch: 14 [2171/6845 (32%)]\tLoss: 0.081226\n",
            "Train Epoch: 14 [2172/6845 (32%)]\tLoss: 0.248174\n",
            "Train Epoch: 14 [2173/6845 (32%)]\tLoss: 0.189547\n",
            "Train Epoch: 14 [2174/6845 (32%)]\tLoss: 0.066018\n",
            "Train Epoch: 14 [2175/6845 (32%)]\tLoss: 0.071543\n",
            "Train Epoch: 14 [2176/6845 (32%)]\tLoss: 0.145008\n",
            "Train Epoch: 14 [2177/6845 (32%)]\tLoss: 0.157662\n",
            "Train Epoch: 14 [2178/6845 (32%)]\tLoss: 0.067559\n",
            "Train Epoch: 14 [2179/6845 (32%)]\tLoss: 0.086325\n",
            "Train Epoch: 14 [2180/6845 (32%)]\tLoss: 0.149991\n",
            "Train Epoch: 14 [2181/6845 (32%)]\tLoss: 0.153716\n",
            "Train Epoch: 14 [2182/6845 (32%)]\tLoss: 0.055824\n",
            "Train Epoch: 14 [2183/6845 (32%)]\tLoss: 0.166083\n",
            "Train Epoch: 14 [2184/6845 (32%)]\tLoss: 1.085868\n",
            "Train Epoch: 14 [2185/6845 (32%)]\tLoss: 0.058632\n",
            "Train Epoch: 14 [2186/6845 (32%)]\tLoss: 0.060800\n",
            "Train Epoch: 14 [2187/6845 (32%)]\tLoss: 0.130066\n",
            "Train Epoch: 14 [2188/6845 (32%)]\tLoss: 0.072782\n",
            "Train Epoch: 14 [2189/6845 (32%)]\tLoss: 0.067078\n",
            "Train Epoch: 14 [2190/6845 (32%)]\tLoss: 0.091576\n",
            "Train Epoch: 14 [2191/6845 (32%)]\tLoss: 0.068642\n",
            "Train Epoch: 14 [2192/6845 (32%)]\tLoss: 0.823582\n",
            "Train Epoch: 14 [2193/6845 (32%)]\tLoss: 0.198829\n",
            "Train Epoch: 14 [2194/6845 (32%)]\tLoss: 0.074207\n",
            "Train Epoch: 14 [2195/6845 (32%)]\tLoss: 0.060457\n",
            "Train Epoch: 14 [2196/6845 (32%)]\tLoss: 0.095892\n",
            "Train Epoch: 14 [2197/6845 (32%)]\tLoss: 0.084114\n",
            "Train Epoch: 14 [2198/6845 (32%)]\tLoss: 0.075169\n",
            "Train Epoch: 14 [2199/6845 (32%)]\tLoss: 0.169983\n",
            "Train Epoch: 14 [2200/6845 (32%)]\tLoss: 0.099246\n",
            "Train Epoch: 14 [2201/6845 (32%)]\tLoss: 0.458244\n",
            "Train Epoch: 14 [2202/6845 (32%)]\tLoss: 0.059077\n",
            "Train Epoch: 14 [2203/6845 (32%)]\tLoss: 0.166268\n",
            "Train Epoch: 14 [2204/6845 (32%)]\tLoss: 0.114537\n",
            "Train Epoch: 14 [2205/6845 (32%)]\tLoss: 0.060858\n",
            "Train Epoch: 14 [2206/6845 (32%)]\tLoss: 0.113962\n",
            "Train Epoch: 14 [2207/6845 (32%)]\tLoss: 0.074390\n",
            "Train Epoch: 14 [2208/6845 (32%)]\tLoss: 0.483933\n",
            "Train Epoch: 14 [2209/6845 (32%)]\tLoss: 0.159555\n",
            "Train Epoch: 14 [2210/6845 (32%)]\tLoss: 0.427589\n",
            "Train Epoch: 14 [2211/6845 (32%)]\tLoss: 0.591430\n",
            "Train Epoch: 14 [2212/6845 (32%)]\tLoss: 0.067078\n",
            "Train Epoch: 14 [2213/6845 (32%)]\tLoss: 0.065236\n",
            "Train Epoch: 14 [2214/6845 (32%)]\tLoss: 0.054946\n",
            "Train Epoch: 14 [2215/6845 (32%)]\tLoss: 0.111105\n",
            "Train Epoch: 14 [2216/6845 (32%)]\tLoss: 0.075051\n",
            "Train Epoch: 14 [2217/6845 (32%)]\tLoss: 0.101767\n",
            "Train Epoch: 14 [2218/6845 (32%)]\tLoss: 0.070366\n",
            "Train Epoch: 14 [2219/6845 (32%)]\tLoss: 0.090936\n",
            "Train Epoch: 14 [2220/6845 (32%)]\tLoss: 0.055366\n",
            "Train Epoch: 14 [2221/6845 (32%)]\tLoss: 0.670584\n",
            "Train Epoch: 14 [2222/6845 (32%)]\tLoss: 0.141346\n",
            "Train Epoch: 14 [2223/6845 (32%)]\tLoss: 0.507695\n",
            "Train Epoch: 14 [2224/6845 (32%)]\tLoss: 0.077864\n",
            "Train Epoch: 14 [2225/6845 (33%)]\tLoss: 0.101871\n",
            "Train Epoch: 14 [2226/6845 (33%)]\tLoss: 1.368883\n",
            "Train Epoch: 14 [2227/6845 (33%)]\tLoss: 1.324978\n",
            "Train Epoch: 14 [2228/6845 (33%)]\tLoss: 0.051911\n",
            "Train Epoch: 14 [2229/6845 (33%)]\tLoss: 0.497649\n",
            "Train Epoch: 14 [2230/6845 (33%)]\tLoss: 0.150179\n",
            "Train Epoch: 14 [2231/6845 (33%)]\tLoss: 0.085522\n",
            "Train Epoch: 14 [2232/6845 (33%)]\tLoss: 0.053508\n",
            "Train Epoch: 14 [2233/6845 (33%)]\tLoss: 0.145688\n",
            "Train Epoch: 14 [2234/6845 (33%)]\tLoss: 0.118680\n",
            "Train Epoch: 14 [2235/6845 (33%)]\tLoss: 0.058860\n",
            "Train Epoch: 14 [2236/6845 (33%)]\tLoss: 0.044137\n",
            "Train Epoch: 14 [2237/6845 (33%)]\tLoss: 0.152767\n",
            "Train Epoch: 14 [2238/6845 (33%)]\tLoss: 0.571434\n",
            "Train Epoch: 14 [2239/6845 (33%)]\tLoss: 0.188472\n",
            "Train Epoch: 14 [2240/6845 (33%)]\tLoss: 0.044278\n",
            "Train Epoch: 14 [2241/6845 (33%)]\tLoss: 0.110169\n",
            "Train Epoch: 14 [2242/6845 (33%)]\tLoss: 0.144671\n",
            "Train Epoch: 14 [2243/6845 (33%)]\tLoss: 0.345623\n",
            "Train Epoch: 14 [2244/6845 (33%)]\tLoss: 0.397922\n",
            "Train Epoch: 14 [2245/6845 (33%)]\tLoss: 0.081859\n",
            "Train Epoch: 14 [2246/6845 (33%)]\tLoss: 0.056915\n",
            "Train Epoch: 14 [2247/6845 (33%)]\tLoss: 0.124137\n",
            "Train Epoch: 14 [2248/6845 (33%)]\tLoss: 0.078391\n",
            "Train Epoch: 14 [2249/6845 (33%)]\tLoss: 0.202622\n",
            "Train Epoch: 14 [2250/6845 (33%)]\tLoss: 0.377783\n",
            "Train Epoch: 14 [2251/6845 (33%)]\tLoss: 0.195902\n",
            "Train Epoch: 14 [2252/6845 (33%)]\tLoss: 0.107487\n",
            "Train Epoch: 14 [2253/6845 (33%)]\tLoss: 0.168099\n",
            "Train Epoch: 14 [2254/6845 (33%)]\tLoss: 0.066646\n",
            "Train Epoch: 14 [2255/6845 (33%)]\tLoss: 0.140506\n",
            "Train Epoch: 14 [2256/6845 (33%)]\tLoss: 0.164584\n",
            "Train Epoch: 14 [2257/6845 (33%)]\tLoss: 0.159137\n",
            "Train Epoch: 14 [2258/6845 (33%)]\tLoss: 0.092717\n",
            "Train Epoch: 14 [2259/6845 (33%)]\tLoss: 0.136431\n",
            "Train Epoch: 14 [2260/6845 (33%)]\tLoss: 0.089839\n",
            "Train Epoch: 14 [2261/6845 (33%)]\tLoss: 0.168152\n",
            "Train Epoch: 14 [2262/6845 (33%)]\tLoss: 0.075043\n",
            "Train Epoch: 14 [2263/6845 (33%)]\tLoss: 0.164042\n",
            "Train Epoch: 14 [2264/6845 (33%)]\tLoss: 0.096870\n",
            "Train Epoch: 14 [2265/6845 (33%)]\tLoss: 0.094759\n",
            "Train Epoch: 14 [2266/6845 (33%)]\tLoss: 0.645153\n",
            "Train Epoch: 14 [2267/6845 (33%)]\tLoss: 0.097160\n",
            "Train Epoch: 14 [2268/6845 (33%)]\tLoss: 0.092386\n",
            "Train Epoch: 14 [2269/6845 (33%)]\tLoss: 0.161840\n",
            "Train Epoch: 14 [2270/6845 (33%)]\tLoss: 0.562778\n",
            "Train Epoch: 14 [2271/6845 (33%)]\tLoss: 0.107889\n",
            "Train Epoch: 14 [2272/6845 (33%)]\tLoss: 1.213255\n",
            "Train Epoch: 14 [2273/6845 (33%)]\tLoss: 0.702488\n",
            "Train Epoch: 14 [2274/6845 (33%)]\tLoss: 0.071027\n",
            "Train Epoch: 14 [2275/6845 (33%)]\tLoss: 0.152690\n",
            "Train Epoch: 14 [2276/6845 (33%)]\tLoss: 1.259133\n",
            "Train Epoch: 14 [2277/6845 (33%)]\tLoss: 0.097398\n",
            "Train Epoch: 14 [2278/6845 (33%)]\tLoss: 0.120463\n",
            "Train Epoch: 14 [2279/6845 (33%)]\tLoss: 0.109489\n",
            "Train Epoch: 14 [2280/6845 (33%)]\tLoss: 0.081265\n",
            "Train Epoch: 14 [2281/6845 (33%)]\tLoss: 0.100367\n",
            "Train Epoch: 14 [2282/6845 (33%)]\tLoss: 0.124472\n",
            "Train Epoch: 14 [2283/6845 (33%)]\tLoss: 0.957047\n",
            "Train Epoch: 14 [2284/6845 (33%)]\tLoss: 0.456947\n",
            "Train Epoch: 14 [2285/6845 (33%)]\tLoss: 0.056949\n",
            "Train Epoch: 14 [2286/6845 (33%)]\tLoss: 0.098093\n",
            "Train Epoch: 14 [2287/6845 (33%)]\tLoss: 0.091838\n",
            "Train Epoch: 14 [2288/6845 (33%)]\tLoss: 0.076584\n",
            "Train Epoch: 14 [2289/6845 (33%)]\tLoss: 1.083439\n",
            "Train Epoch: 14 [2290/6845 (33%)]\tLoss: 0.063369\n",
            "Train Epoch: 14 [2291/6845 (33%)]\tLoss: 0.052314\n",
            "Train Epoch: 14 [2292/6845 (33%)]\tLoss: 0.102632\n",
            "Train Epoch: 14 [2293/6845 (33%)]\tLoss: 0.058471\n",
            "Train Epoch: 14 [2294/6845 (34%)]\tLoss: 0.047694\n",
            "Train Epoch: 14 [2295/6845 (34%)]\tLoss: 0.093699\n",
            "Train Epoch: 14 [2296/6845 (34%)]\tLoss: 0.138744\n",
            "Train Epoch: 14 [2297/6845 (34%)]\tLoss: 0.147204\n",
            "Train Epoch: 14 [2298/6845 (34%)]\tLoss: 0.772990\n",
            "Train Epoch: 14 [2299/6845 (34%)]\tLoss: 0.107969\n",
            "Train Epoch: 14 [2300/6845 (34%)]\tLoss: 0.072476\n",
            "Train Epoch: 14 [2301/6845 (34%)]\tLoss: 0.081593\n",
            "Train Epoch: 14 [2302/6845 (34%)]\tLoss: 0.164917\n",
            "Train Epoch: 14 [2303/6845 (34%)]\tLoss: 0.117877\n",
            "Train Epoch: 14 [2304/6845 (34%)]\tLoss: 0.096165\n",
            "Train Epoch: 14 [2305/6845 (34%)]\tLoss: 0.116903\n",
            "Train Epoch: 14 [2306/6845 (34%)]\tLoss: 0.615992\n",
            "Train Epoch: 14 [2307/6845 (34%)]\tLoss: 0.070525\n",
            "Train Epoch: 14 [2308/6845 (34%)]\tLoss: 0.054751\n",
            "Train Epoch: 14 [2309/6845 (34%)]\tLoss: 0.804287\n",
            "Train Epoch: 14 [2310/6845 (34%)]\tLoss: 0.125931\n",
            "Train Epoch: 14 [2311/6845 (34%)]\tLoss: 0.076589\n",
            "Train Epoch: 14 [2312/6845 (34%)]\tLoss: 0.133758\n",
            "Train Epoch: 14 [2313/6845 (34%)]\tLoss: 0.119859\n",
            "Train Epoch: 14 [2314/6845 (34%)]\tLoss: 0.101366\n",
            "Train Epoch: 14 [2315/6845 (34%)]\tLoss: 0.096805\n",
            "Train Epoch: 14 [2316/6845 (34%)]\tLoss: 0.610586\n",
            "Train Epoch: 14 [2317/6845 (34%)]\tLoss: 0.068995\n",
            "Train Epoch: 14 [2318/6845 (34%)]\tLoss: 0.084889\n",
            "Train Epoch: 14 [2319/6845 (34%)]\tLoss: 0.531173\n",
            "Train Epoch: 14 [2320/6845 (34%)]\tLoss: 0.180935\n",
            "Train Epoch: 14 [2321/6845 (34%)]\tLoss: 0.161153\n",
            "Train Epoch: 14 [2322/6845 (34%)]\tLoss: 0.568536\n",
            "Train Epoch: 14 [2323/6845 (34%)]\tLoss: 0.062233\n",
            "Train Epoch: 14 [2324/6845 (34%)]\tLoss: 0.490631\n",
            "Train Epoch: 14 [2325/6845 (34%)]\tLoss: 0.521214\n",
            "Train Epoch: 14 [2326/6845 (34%)]\tLoss: 0.067113\n",
            "Train Epoch: 14 [2327/6845 (34%)]\tLoss: 0.088449\n",
            "Train Epoch: 14 [2328/6845 (34%)]\tLoss: 0.802058\n",
            "Train Epoch: 14 [2329/6845 (34%)]\tLoss: 0.597254\n",
            "Train Epoch: 14 [2330/6845 (34%)]\tLoss: 0.678030\n",
            "Train Epoch: 14 [2331/6845 (34%)]\tLoss: 0.103015\n",
            "Train Epoch: 14 [2332/6845 (34%)]\tLoss: 0.108841\n",
            "Train Epoch: 14 [2333/6845 (34%)]\tLoss: 0.968423\n",
            "Train Epoch: 14 [2334/6845 (34%)]\tLoss: 0.095833\n",
            "Train Epoch: 14 [2335/6845 (34%)]\tLoss: 0.119402\n",
            "Train Epoch: 14 [2336/6845 (34%)]\tLoss: 0.065893\n",
            "Train Epoch: 14 [2337/6845 (34%)]\tLoss: 0.125324\n",
            "Train Epoch: 14 [2338/6845 (34%)]\tLoss: 0.056796\n",
            "Train Epoch: 14 [2339/6845 (34%)]\tLoss: 0.085786\n",
            "Train Epoch: 14 [2340/6845 (34%)]\tLoss: 0.084308\n",
            "Train Epoch: 14 [2341/6845 (34%)]\tLoss: 0.075630\n",
            "Train Epoch: 14 [2342/6845 (34%)]\tLoss: 0.154231\n",
            "Train Epoch: 14 [2343/6845 (34%)]\tLoss: 0.186440\n",
            "Train Epoch: 14 [2344/6845 (34%)]\tLoss: 0.762497\n",
            "Train Epoch: 14 [2345/6845 (34%)]\tLoss: 0.489655\n",
            "Train Epoch: 14 [2346/6845 (34%)]\tLoss: 0.080473\n",
            "Train Epoch: 14 [2347/6845 (34%)]\tLoss: 0.164556\n",
            "Train Epoch: 14 [2348/6845 (34%)]\tLoss: 0.628728\n",
            "Train Epoch: 14 [2349/6845 (34%)]\tLoss: 0.448018\n",
            "Train Epoch: 14 [2350/6845 (34%)]\tLoss: 0.131110\n",
            "Train Epoch: 14 [2351/6845 (34%)]\tLoss: 0.560171\n",
            "Train Epoch: 14 [2352/6845 (34%)]\tLoss: 0.080962\n",
            "Train Epoch: 14 [2353/6845 (34%)]\tLoss: 0.072855\n",
            "Train Epoch: 14 [2354/6845 (34%)]\tLoss: 0.086056\n",
            "Train Epoch: 14 [2355/6845 (34%)]\tLoss: 0.069898\n",
            "Train Epoch: 14 [2356/6845 (34%)]\tLoss: 0.199965\n",
            "Train Epoch: 14 [2357/6845 (34%)]\tLoss: 0.092870\n",
            "Train Epoch: 14 [2358/6845 (34%)]\tLoss: 0.070022\n",
            "Train Epoch: 14 [2359/6845 (34%)]\tLoss: 0.083430\n",
            "Train Epoch: 14 [2360/6845 (34%)]\tLoss: 0.197373\n",
            "Train Epoch: 14 [2361/6845 (34%)]\tLoss: 0.102973\n",
            "Train Epoch: 14 [2362/6845 (35%)]\tLoss: 0.133759\n",
            "Train Epoch: 14 [2363/6845 (35%)]\tLoss: 0.105461\n",
            "Train Epoch: 14 [2364/6845 (35%)]\tLoss: 0.094142\n",
            "Train Epoch: 14 [2365/6845 (35%)]\tLoss: 0.065535\n",
            "Train Epoch: 14 [2366/6845 (35%)]\tLoss: 0.059487\n",
            "Train Epoch: 14 [2367/6845 (35%)]\tLoss: 0.073640\n",
            "Train Epoch: 14 [2368/6845 (35%)]\tLoss: 0.064050\n",
            "Train Epoch: 14 [2369/6845 (35%)]\tLoss: 0.793283\n",
            "Train Epoch: 14 [2370/6845 (35%)]\tLoss: 0.105575\n",
            "Train Epoch: 14 [2371/6845 (35%)]\tLoss: 0.108528\n",
            "Train Epoch: 14 [2372/6845 (35%)]\tLoss: 0.502553\n",
            "Train Epoch: 14 [2373/6845 (35%)]\tLoss: 0.126044\n",
            "Train Epoch: 14 [2374/6845 (35%)]\tLoss: 0.071987\n",
            "Train Epoch: 14 [2375/6845 (35%)]\tLoss: 0.704816\n",
            "Train Epoch: 14 [2376/6845 (35%)]\tLoss: 0.145709\n",
            "Train Epoch: 14 [2377/6845 (35%)]\tLoss: 0.082549\n",
            "Train Epoch: 14 [2378/6845 (35%)]\tLoss: 0.147684\n",
            "Train Epoch: 14 [2379/6845 (35%)]\tLoss: 0.105986\n",
            "Train Epoch: 14 [2380/6845 (35%)]\tLoss: 0.071914\n",
            "Train Epoch: 14 [2381/6845 (35%)]\tLoss: 0.063101\n",
            "Train Epoch: 14 [2382/6845 (35%)]\tLoss: 0.886343\n",
            "Train Epoch: 14 [2383/6845 (35%)]\tLoss: 0.108452\n",
            "Train Epoch: 14 [2384/6845 (35%)]\tLoss: 0.059765\n",
            "Train Epoch: 14 [2385/6845 (35%)]\tLoss: 0.444772\n",
            "Train Epoch: 14 [2386/6845 (35%)]\tLoss: 0.053974\n",
            "Train Epoch: 14 [2387/6845 (35%)]\tLoss: 0.048021\n",
            "Train Epoch: 14 [2388/6845 (35%)]\tLoss: 0.878557\n",
            "Train Epoch: 14 [2389/6845 (35%)]\tLoss: 0.138393\n",
            "Train Epoch: 14 [2390/6845 (35%)]\tLoss: 0.080748\n",
            "Train Epoch: 14 [2391/6845 (35%)]\tLoss: 0.157974\n",
            "Train Epoch: 14 [2392/6845 (35%)]\tLoss: 0.085018\n",
            "Train Epoch: 14 [2393/6845 (35%)]\tLoss: 0.156709\n",
            "Train Epoch: 14 [2394/6845 (35%)]\tLoss: 0.663813\n",
            "Train Epoch: 14 [2395/6845 (35%)]\tLoss: 1.156661\n",
            "Train Epoch: 14 [2396/6845 (35%)]\tLoss: 0.066078\n",
            "Train Epoch: 14 [2397/6845 (35%)]\tLoss: 0.649338\n",
            "Train Epoch: 14 [2398/6845 (35%)]\tLoss: 0.038734\n",
            "Train Epoch: 14 [2399/6845 (35%)]\tLoss: 0.227149\n",
            "Train Epoch: 14 [2400/6845 (35%)]\tLoss: 0.132620\n",
            "Train Epoch: 14 [2401/6845 (35%)]\tLoss: 0.687285\n",
            "Train Epoch: 14 [2402/6845 (35%)]\tLoss: 0.213393\n",
            "Train Epoch: 14 [2403/6845 (35%)]\tLoss: 0.103627\n",
            "Train Epoch: 14 [2404/6845 (35%)]\tLoss: 0.061980\n",
            "Train Epoch: 14 [2405/6845 (35%)]\tLoss: 0.169563\n",
            "Train Epoch: 14 [2406/6845 (35%)]\tLoss: 1.511567\n",
            "Train Epoch: 14 [2407/6845 (35%)]\tLoss: 0.215105\n",
            "Train Epoch: 14 [2408/6845 (35%)]\tLoss: 0.045746\n",
            "Train Epoch: 14 [2409/6845 (35%)]\tLoss: 0.113008\n",
            "Train Epoch: 14 [2410/6845 (35%)]\tLoss: 0.954078\n",
            "Train Epoch: 14 [2411/6845 (35%)]\tLoss: 0.048927\n",
            "Train Epoch: 14 [2412/6845 (35%)]\tLoss: 0.122944\n",
            "Train Epoch: 14 [2413/6845 (35%)]\tLoss: 0.777974\n",
            "Train Epoch: 14 [2414/6845 (35%)]\tLoss: 0.164438\n",
            "Train Epoch: 14 [2415/6845 (35%)]\tLoss: 0.052219\n",
            "Train Epoch: 14 [2416/6845 (35%)]\tLoss: 0.096122\n",
            "Train Epoch: 14 [2417/6845 (35%)]\tLoss: 0.208772\n",
            "Train Epoch: 14 [2418/6845 (35%)]\tLoss: 0.063904\n",
            "Train Epoch: 14 [2419/6845 (35%)]\tLoss: 0.128179\n",
            "Train Epoch: 14 [2420/6845 (35%)]\tLoss: 0.126532\n",
            "Train Epoch: 14 [2421/6845 (35%)]\tLoss: 0.067833\n",
            "Train Epoch: 14 [2422/6845 (35%)]\tLoss: 0.593615\n",
            "Train Epoch: 14 [2423/6845 (35%)]\tLoss: 0.470904\n",
            "Train Epoch: 14 [2424/6845 (35%)]\tLoss: 0.086134\n",
            "Train Epoch: 14 [2425/6845 (35%)]\tLoss: 0.965556\n",
            "Train Epoch: 14 [2426/6845 (35%)]\tLoss: 0.058691\n",
            "Train Epoch: 14 [2427/6845 (35%)]\tLoss: 0.406210\n",
            "Train Epoch: 14 [2428/6845 (35%)]\tLoss: 0.176709\n",
            "Train Epoch: 14 [2429/6845 (35%)]\tLoss: 0.470701\n",
            "Train Epoch: 14 [2430/6845 (36%)]\tLoss: 0.120710\n",
            "Train Epoch: 14 [2431/6845 (36%)]\tLoss: 0.972336\n",
            "Train Epoch: 14 [2432/6845 (36%)]\tLoss: 0.621251\n",
            "Train Epoch: 14 [2433/6845 (36%)]\tLoss: 0.395165\n",
            "Train Epoch: 14 [2434/6845 (36%)]\tLoss: 0.099386\n",
            "Train Epoch: 14 [2435/6845 (36%)]\tLoss: 1.068291\n",
            "Train Epoch: 14 [2436/6845 (36%)]\tLoss: 0.509352\n",
            "Train Epoch: 14 [2437/6845 (36%)]\tLoss: 0.396390\n",
            "Train Epoch: 14 [2438/6845 (36%)]\tLoss: 0.077958\n",
            "Train Epoch: 14 [2439/6845 (36%)]\tLoss: 0.123713\n",
            "Train Epoch: 14 [2440/6845 (36%)]\tLoss: 0.414132\n",
            "Train Epoch: 14 [2441/6845 (36%)]\tLoss: 0.077935\n",
            "Train Epoch: 14 [2442/6845 (36%)]\tLoss: 0.214651\n",
            "Train Epoch: 14 [2443/6845 (36%)]\tLoss: 0.212179\n",
            "Train Epoch: 14 [2444/6845 (36%)]\tLoss: 0.070369\n",
            "Train Epoch: 14 [2445/6845 (36%)]\tLoss: 0.136579\n",
            "Train Epoch: 14 [2446/6845 (36%)]\tLoss: 0.158222\n",
            "Train Epoch: 14 [2447/6845 (36%)]\tLoss: 0.128484\n",
            "Train Epoch: 14 [2448/6845 (36%)]\tLoss: 0.149119\n",
            "Train Epoch: 14 [2449/6845 (36%)]\tLoss: 0.704468\n",
            "Train Epoch: 14 [2450/6845 (36%)]\tLoss: 0.216528\n",
            "Train Epoch: 14 [2451/6845 (36%)]\tLoss: 0.113980\n",
            "Train Epoch: 14 [2452/6845 (36%)]\tLoss: 0.122155\n",
            "Train Epoch: 14 [2453/6845 (36%)]\tLoss: 0.214615\n",
            "Train Epoch: 14 [2454/6845 (36%)]\tLoss: 0.161726\n",
            "Train Epoch: 14 [2455/6845 (36%)]\tLoss: 0.463065\n",
            "Train Epoch: 14 [2456/6845 (36%)]\tLoss: 0.593274\n",
            "Train Epoch: 14 [2457/6845 (36%)]\tLoss: 0.114883\n",
            "Train Epoch: 14 [2458/6845 (36%)]\tLoss: 0.161891\n",
            "Train Epoch: 14 [2459/6845 (36%)]\tLoss: 0.069233\n",
            "Train Epoch: 14 [2460/6845 (36%)]\tLoss: 0.111150\n",
            "Train Epoch: 14 [2461/6845 (36%)]\tLoss: 0.673394\n",
            "Train Epoch: 14 [2462/6845 (36%)]\tLoss: 0.103126\n",
            "Train Epoch: 14 [2463/6845 (36%)]\tLoss: 0.389375\n",
            "Train Epoch: 14 [2464/6845 (36%)]\tLoss: 0.843404\n",
            "Train Epoch: 14 [2465/6845 (36%)]\tLoss: 0.865062\n",
            "Train Epoch: 14 [2466/6845 (36%)]\tLoss: 0.108397\n",
            "Train Epoch: 14 [2467/6845 (36%)]\tLoss: 0.302891\n",
            "Train Epoch: 14 [2468/6845 (36%)]\tLoss: 0.186919\n",
            "Train Epoch: 14 [2469/6845 (36%)]\tLoss: 0.217571\n",
            "Train Epoch: 14 [2470/6845 (36%)]\tLoss: 0.600489\n",
            "Train Epoch: 14 [2471/6845 (36%)]\tLoss: 0.112518\n",
            "Train Epoch: 14 [2472/6845 (36%)]\tLoss: 0.459179\n",
            "Train Epoch: 14 [2473/6845 (36%)]\tLoss: 0.101304\n",
            "Train Epoch: 14 [2474/6845 (36%)]\tLoss: 0.202223\n",
            "Train Epoch: 14 [2475/6845 (36%)]\tLoss: 0.585435\n",
            "Train Epoch: 14 [2476/6845 (36%)]\tLoss: 0.700387\n",
            "Train Epoch: 14 [2477/6845 (36%)]\tLoss: 0.103148\n",
            "Train Epoch: 14 [2478/6845 (36%)]\tLoss: 0.163199\n",
            "Train Epoch: 14 [2479/6845 (36%)]\tLoss: 0.171477\n",
            "Train Epoch: 14 [2480/6845 (36%)]\tLoss: 0.127785\n",
            "Train Epoch: 14 [2481/6845 (36%)]\tLoss: 0.228799\n",
            "Train Epoch: 14 [2482/6845 (36%)]\tLoss: 0.115761\n",
            "Train Epoch: 14 [2483/6845 (36%)]\tLoss: 0.143838\n",
            "Train Epoch: 14 [2484/6845 (36%)]\tLoss: 0.179496\n",
            "Train Epoch: 14 [2485/6845 (36%)]\tLoss: 0.164300\n",
            "Train Epoch: 14 [2486/6845 (36%)]\tLoss: 0.147604\n",
            "Train Epoch: 14 [2487/6845 (36%)]\tLoss: 0.108458\n",
            "Train Epoch: 14 [2488/6845 (36%)]\tLoss: 0.113825\n",
            "Train Epoch: 14 [2489/6845 (36%)]\tLoss: 0.070334\n",
            "Train Epoch: 14 [2490/6845 (36%)]\tLoss: 0.170977\n",
            "Train Epoch: 14 [2491/6845 (36%)]\tLoss: 0.580931\n",
            "Train Epoch: 14 [2492/6845 (36%)]\tLoss: 0.097525\n",
            "Train Epoch: 14 [2493/6845 (36%)]\tLoss: 0.664621\n",
            "Train Epoch: 14 [2494/6845 (36%)]\tLoss: 0.736244\n",
            "Train Epoch: 14 [2495/6845 (36%)]\tLoss: 0.106788\n",
            "Train Epoch: 14 [2496/6845 (36%)]\tLoss: 0.593628\n",
            "Train Epoch: 14 [2497/6845 (36%)]\tLoss: 0.185346\n",
            "Train Epoch: 14 [2498/6845 (36%)]\tLoss: 0.103907\n",
            "Train Epoch: 14 [2499/6845 (37%)]\tLoss: 0.095026\n",
            "Train Epoch: 14 [2500/6845 (37%)]\tLoss: 0.095456\n",
            "Train Epoch: 14 [2501/6845 (37%)]\tLoss: 0.054903\n",
            "Train Epoch: 14 [2502/6845 (37%)]\tLoss: 0.053674\n",
            "Train Epoch: 14 [2503/6845 (37%)]\tLoss: 0.153937\n",
            "Train Epoch: 14 [2504/6845 (37%)]\tLoss: 0.099275\n",
            "Train Epoch: 14 [2505/6845 (37%)]\tLoss: 0.140241\n",
            "Train Epoch: 14 [2506/6845 (37%)]\tLoss: 0.143159\n",
            "Train Epoch: 14 [2507/6845 (37%)]\tLoss: 0.172742\n",
            "Train Epoch: 14 [2508/6845 (37%)]\tLoss: 0.622475\n",
            "Train Epoch: 14 [2509/6845 (37%)]\tLoss: 0.082556\n",
            "Train Epoch: 14 [2510/6845 (37%)]\tLoss: 0.920513\n",
            "Train Epoch: 14 [2511/6845 (37%)]\tLoss: 0.062304\n",
            "Train Epoch: 14 [2512/6845 (37%)]\tLoss: 0.081249\n",
            "Train Epoch: 14 [2513/6845 (37%)]\tLoss: 0.080204\n",
            "Train Epoch: 14 [2514/6845 (37%)]\tLoss: 0.607900\n",
            "Train Epoch: 14 [2515/6845 (37%)]\tLoss: 0.059634\n",
            "Train Epoch: 14 [2516/6845 (37%)]\tLoss: 0.066432\n",
            "Train Epoch: 14 [2517/6845 (37%)]\tLoss: 0.107661\n",
            "Train Epoch: 14 [2518/6845 (37%)]\tLoss: 0.573959\n",
            "Train Epoch: 14 [2519/6845 (37%)]\tLoss: 0.079866\n",
            "Train Epoch: 14 [2520/6845 (37%)]\tLoss: 0.539949\n",
            "Train Epoch: 14 [2521/6845 (37%)]\tLoss: 0.403391\n",
            "Train Epoch: 14 [2522/6845 (37%)]\tLoss: 0.056783\n",
            "Train Epoch: 14 [2523/6845 (37%)]\tLoss: 0.564109\n",
            "Train Epoch: 14 [2524/6845 (37%)]\tLoss: 1.514059\n",
            "Train Epoch: 14 [2525/6845 (37%)]\tLoss: 0.123243\n",
            "Train Epoch: 14 [2526/6845 (37%)]\tLoss: 0.125384\n",
            "Train Epoch: 14 [2527/6845 (37%)]\tLoss: 0.132805\n",
            "Train Epoch: 14 [2528/6845 (37%)]\tLoss: 0.058789\n",
            "Train Epoch: 14 [2529/6845 (37%)]\tLoss: 0.680982\n",
            "Train Epoch: 14 [2530/6845 (37%)]\tLoss: 0.191291\n",
            "Train Epoch: 14 [2531/6845 (37%)]\tLoss: 0.059235\n",
            "Train Epoch: 14 [2532/6845 (37%)]\tLoss: 0.150401\n",
            "Train Epoch: 14 [2533/6845 (37%)]\tLoss: 0.079826\n",
            "Train Epoch: 14 [2534/6845 (37%)]\tLoss: 1.016025\n",
            "Train Epoch: 14 [2535/6845 (37%)]\tLoss: 0.804362\n",
            "Train Epoch: 14 [2536/6845 (37%)]\tLoss: 0.498721\n",
            "Train Epoch: 14 [2537/6845 (37%)]\tLoss: 0.062134\n",
            "Train Epoch: 14 [2538/6845 (37%)]\tLoss: 0.040281\n",
            "Train Epoch: 14 [2539/6845 (37%)]\tLoss: 0.062699\n",
            "Train Epoch: 14 [2540/6845 (37%)]\tLoss: 0.591357\n",
            "Train Epoch: 14 [2541/6845 (37%)]\tLoss: 0.046922\n",
            "Train Epoch: 14 [2542/6845 (37%)]\tLoss: 0.038238\n",
            "Train Epoch: 14 [2543/6845 (37%)]\tLoss: 0.146567\n",
            "Train Epoch: 14 [2544/6845 (37%)]\tLoss: 0.054990\n",
            "Train Epoch: 14 [2545/6845 (37%)]\tLoss: 0.550983\n",
            "Train Epoch: 14 [2546/6845 (37%)]\tLoss: 0.189860\n",
            "Train Epoch: 14 [2547/6845 (37%)]\tLoss: 0.449846\n",
            "Train Epoch: 14 [2548/6845 (37%)]\tLoss: 0.147935\n",
            "Train Epoch: 14 [2549/6845 (37%)]\tLoss: 0.083724\n",
            "Train Epoch: 14 [2550/6845 (37%)]\tLoss: 0.420599\n",
            "Train Epoch: 14 [2551/6845 (37%)]\tLoss: 0.994243\n",
            "Train Epoch: 14 [2552/6845 (37%)]\tLoss: 0.284627\n",
            "Train Epoch: 14 [2553/6845 (37%)]\tLoss: 0.251674\n",
            "Train Epoch: 14 [2554/6845 (37%)]\tLoss: 0.167122\n",
            "Train Epoch: 14 [2555/6845 (37%)]\tLoss: 0.141651\n",
            "Train Epoch: 14 [2556/6845 (37%)]\tLoss: 0.519054\n",
            "Train Epoch: 14 [2557/6845 (37%)]\tLoss: 0.184097\n",
            "Train Epoch: 14 [2558/6845 (37%)]\tLoss: 0.512345\n",
            "Train Epoch: 14 [2559/6845 (37%)]\tLoss: 0.230786\n",
            "Train Epoch: 14 [2560/6845 (37%)]\tLoss: 0.646297\n",
            "Train Epoch: 14 [2561/6845 (37%)]\tLoss: 0.152716\n",
            "Train Epoch: 14 [2562/6845 (37%)]\tLoss: 0.656486\n",
            "Train Epoch: 14 [2563/6845 (37%)]\tLoss: 0.511543\n",
            "Train Epoch: 14 [2564/6845 (37%)]\tLoss: 0.082067\n",
            "Train Epoch: 14 [2565/6845 (37%)]\tLoss: 0.112692\n",
            "Train Epoch: 14 [2566/6845 (37%)]\tLoss: 0.403073\n",
            "Train Epoch: 14 [2567/6845 (38%)]\tLoss: 0.066284\n",
            "Train Epoch: 14 [2568/6845 (38%)]\tLoss: 0.365717\n",
            "Train Epoch: 14 [2569/6845 (38%)]\tLoss: 0.238086\n",
            "Train Epoch: 14 [2570/6845 (38%)]\tLoss: 0.102418\n",
            "Train Epoch: 14 [2571/6845 (38%)]\tLoss: 0.094194\n",
            "Train Epoch: 14 [2572/6845 (38%)]\tLoss: 0.235377\n",
            "Train Epoch: 14 [2573/6845 (38%)]\tLoss: 0.128221\n",
            "Train Epoch: 14 [2574/6845 (38%)]\tLoss: 0.510166\n",
            "Train Epoch: 14 [2575/6845 (38%)]\tLoss: 0.251524\n",
            "Train Epoch: 14 [2576/6845 (38%)]\tLoss: 0.090611\n",
            "Train Epoch: 14 [2577/6845 (38%)]\tLoss: 0.233340\n",
            "Train Epoch: 14 [2578/6845 (38%)]\tLoss: 0.533998\n",
            "Train Epoch: 14 [2579/6845 (38%)]\tLoss: 0.202141\n",
            "Train Epoch: 14 [2580/6845 (38%)]\tLoss: 0.611659\n",
            "Train Epoch: 14 [2581/6845 (38%)]\tLoss: 0.667745\n",
            "Train Epoch: 14 [2582/6845 (38%)]\tLoss: 0.091352\n",
            "Train Epoch: 14 [2583/6845 (38%)]\tLoss: 0.493790\n",
            "Train Epoch: 14 [2584/6845 (38%)]\tLoss: 0.829156\n",
            "Train Epoch: 14 [2585/6845 (38%)]\tLoss: 0.136049\n",
            "Train Epoch: 14 [2586/6845 (38%)]\tLoss: 0.093119\n",
            "Train Epoch: 14 [2587/6845 (38%)]\tLoss: 0.442469\n",
            "Train Epoch: 14 [2588/6845 (38%)]\tLoss: 0.097673\n",
            "Train Epoch: 14 [2589/6845 (38%)]\tLoss: 0.162735\n",
            "Train Epoch: 14 [2590/6845 (38%)]\tLoss: 0.236317\n",
            "Train Epoch: 14 [2591/6845 (38%)]\tLoss: 0.251703\n",
            "Train Epoch: 14 [2592/6845 (38%)]\tLoss: 0.791805\n",
            "Train Epoch: 14 [2593/6845 (38%)]\tLoss: 0.227712\n",
            "Train Epoch: 14 [2594/6845 (38%)]\tLoss: 0.198804\n",
            "Train Epoch: 14 [2595/6845 (38%)]\tLoss: 0.158054\n",
            "Train Epoch: 14 [2596/6845 (38%)]\tLoss: 0.080355\n",
            "Train Epoch: 14 [2597/6845 (38%)]\tLoss: 0.157371\n",
            "Train Epoch: 14 [2598/6845 (38%)]\tLoss: 0.245359\n",
            "Train Epoch: 14 [2599/6845 (38%)]\tLoss: 0.578921\n",
            "Train Epoch: 14 [2600/6845 (38%)]\tLoss: 0.163775\n",
            "Train Epoch: 14 [2601/6845 (38%)]\tLoss: 0.558596\n",
            "Train Epoch: 14 [2602/6845 (38%)]\tLoss: 0.062062\n",
            "Train Epoch: 14 [2603/6845 (38%)]\tLoss: 0.145746\n",
            "Train Epoch: 14 [2604/6845 (38%)]\tLoss: 0.108961\n",
            "Train Epoch: 14 [2605/6845 (38%)]\tLoss: 0.094034\n",
            "Train Epoch: 14 [2606/6845 (38%)]\tLoss: 0.087690\n",
            "Train Epoch: 14 [2607/6845 (38%)]\tLoss: 0.094824\n",
            "Train Epoch: 14 [2608/6845 (38%)]\tLoss: 0.122320\n",
            "Train Epoch: 14 [2609/6845 (38%)]\tLoss: 0.637888\n",
            "Train Epoch: 14 [2610/6845 (38%)]\tLoss: 0.465880\n",
            "Train Epoch: 14 [2611/6845 (38%)]\tLoss: 0.594910\n",
            "Train Epoch: 14 [2612/6845 (38%)]\tLoss: 0.518660\n",
            "Train Epoch: 14 [2613/6845 (38%)]\tLoss: 0.480157\n",
            "Train Epoch: 14 [2614/6845 (38%)]\tLoss: 0.939833\n",
            "Train Epoch: 14 [2615/6845 (38%)]\tLoss: 0.102180\n",
            "Train Epoch: 14 [2616/6845 (38%)]\tLoss: 0.133447\n",
            "Train Epoch: 14 [2617/6845 (38%)]\tLoss: 0.071749\n",
            "Train Epoch: 14 [2618/6845 (38%)]\tLoss: 0.685194\n",
            "Train Epoch: 14 [2619/6845 (38%)]\tLoss: 0.616017\n",
            "Train Epoch: 14 [2620/6845 (38%)]\tLoss: 0.511656\n",
            "Train Epoch: 14 [2621/6845 (38%)]\tLoss: 0.541441\n",
            "Train Epoch: 14 [2622/6845 (38%)]\tLoss: 0.107287\n",
            "Train Epoch: 14 [2623/6845 (38%)]\tLoss: 0.264579\n",
            "Train Epoch: 14 [2624/6845 (38%)]\tLoss: 0.117593\n",
            "Train Epoch: 14 [2625/6845 (38%)]\tLoss: 0.076909\n",
            "Train Epoch: 14 [2626/6845 (38%)]\tLoss: 0.692693\n",
            "Train Epoch: 14 [2627/6845 (38%)]\tLoss: 0.083371\n",
            "Train Epoch: 14 [2628/6845 (38%)]\tLoss: 0.105782\n",
            "Train Epoch: 14 [2629/6845 (38%)]\tLoss: 0.458662\n",
            "Train Epoch: 14 [2630/6845 (38%)]\tLoss: 0.094307\n",
            "Train Epoch: 14 [2631/6845 (38%)]\tLoss: 0.667310\n",
            "Train Epoch: 14 [2632/6845 (38%)]\tLoss: 0.506989\n",
            "Train Epoch: 14 [2633/6845 (38%)]\tLoss: 0.099922\n",
            "Train Epoch: 14 [2634/6845 (38%)]\tLoss: 0.140979\n",
            "Train Epoch: 14 [2635/6845 (38%)]\tLoss: 0.075765\n",
            "Train Epoch: 14 [2636/6845 (39%)]\tLoss: 0.079016\n",
            "Train Epoch: 14 [2637/6845 (39%)]\tLoss: 0.278921\n",
            "Train Epoch: 14 [2638/6845 (39%)]\tLoss: 0.159684\n",
            "Train Epoch: 14 [2639/6845 (39%)]\tLoss: 0.087987\n",
            "Train Epoch: 14 [2640/6845 (39%)]\tLoss: 0.068396\n",
            "Train Epoch: 14 [2641/6845 (39%)]\tLoss: 0.104889\n",
            "Train Epoch: 14 [2642/6845 (39%)]\tLoss: 0.455135\n",
            "Train Epoch: 14 [2643/6845 (39%)]\tLoss: 0.293403\n",
            "Train Epoch: 14 [2644/6845 (39%)]\tLoss: 0.161938\n",
            "Train Epoch: 14 [2645/6845 (39%)]\tLoss: 0.070595\n",
            "Train Epoch: 14 [2646/6845 (39%)]\tLoss: 0.279068\n",
            "Train Epoch: 14 [2647/6845 (39%)]\tLoss: 0.165002\n",
            "Train Epoch: 14 [2648/6845 (39%)]\tLoss: 0.145829\n",
            "Train Epoch: 14 [2649/6845 (39%)]\tLoss: 0.312732\n",
            "Train Epoch: 14 [2650/6845 (39%)]\tLoss: 0.077604\n",
            "Train Epoch: 14 [2651/6845 (39%)]\tLoss: 0.065803\n",
            "Train Epoch: 14 [2652/6845 (39%)]\tLoss: 0.130466\n",
            "Train Epoch: 14 [2653/6845 (39%)]\tLoss: 0.140011\n",
            "Train Epoch: 14 [2654/6845 (39%)]\tLoss: 0.185461\n",
            "Train Epoch: 14 [2655/6845 (39%)]\tLoss: 0.151098\n",
            "Train Epoch: 14 [2656/6845 (39%)]\tLoss: 0.177843\n",
            "Train Epoch: 14 [2657/6845 (39%)]\tLoss: 0.122493\n",
            "Train Epoch: 14 [2658/6845 (39%)]\tLoss: 0.062693\n",
            "Train Epoch: 14 [2659/6845 (39%)]\tLoss: 0.582267\n",
            "Train Epoch: 14 [2660/6845 (39%)]\tLoss: 0.807691\n",
            "Train Epoch: 14 [2661/6845 (39%)]\tLoss: 0.640408\n",
            "Train Epoch: 14 [2662/6845 (39%)]\tLoss: 0.063710\n",
            "Train Epoch: 14 [2663/6845 (39%)]\tLoss: 0.119826\n",
            "Train Epoch: 14 [2664/6845 (39%)]\tLoss: 0.767145\n",
            "Train Epoch: 14 [2665/6845 (39%)]\tLoss: 0.130314\n",
            "Train Epoch: 14 [2666/6845 (39%)]\tLoss: 0.230685\n",
            "Train Epoch: 14 [2667/6845 (39%)]\tLoss: 0.236631\n",
            "Train Epoch: 14 [2668/6845 (39%)]\tLoss: 0.674810\n",
            "Train Epoch: 14 [2669/6845 (39%)]\tLoss: 0.195138\n",
            "Train Epoch: 14 [2670/6845 (39%)]\tLoss: 0.100259\n",
            "Train Epoch: 14 [2671/6845 (39%)]\tLoss: 0.575818\n",
            "Train Epoch: 14 [2672/6845 (39%)]\tLoss: 0.305975\n",
            "Train Epoch: 14 [2673/6845 (39%)]\tLoss: 0.078122\n",
            "Train Epoch: 14 [2674/6845 (39%)]\tLoss: 0.078204\n",
            "Train Epoch: 14 [2675/6845 (39%)]\tLoss: 0.083536\n",
            "Train Epoch: 14 [2676/6845 (39%)]\tLoss: 0.316240\n",
            "Train Epoch: 14 [2677/6845 (39%)]\tLoss: 0.129020\n",
            "Train Epoch: 14 [2678/6845 (39%)]\tLoss: 0.772703\n",
            "Train Epoch: 14 [2679/6845 (39%)]\tLoss: 0.144171\n",
            "Train Epoch: 14 [2680/6845 (39%)]\tLoss: 0.216925\n",
            "Train Epoch: 14 [2681/6845 (39%)]\tLoss: 0.060996\n",
            "Train Epoch: 14 [2682/6845 (39%)]\tLoss: 0.073162\n",
            "Train Epoch: 14 [2683/6845 (39%)]\tLoss: 0.265615\n",
            "Train Epoch: 14 [2684/6845 (39%)]\tLoss: 0.762222\n",
            "Train Epoch: 14 [2685/6845 (39%)]\tLoss: 0.111545\n",
            "Train Epoch: 14 [2686/6845 (39%)]\tLoss: 0.058043\n",
            "Train Epoch: 14 [2687/6845 (39%)]\tLoss: 0.282676\n",
            "Train Epoch: 14 [2688/6845 (39%)]\tLoss: 0.165205\n",
            "Train Epoch: 14 [2689/6845 (39%)]\tLoss: 0.078089\n",
            "Train Epoch: 14 [2690/6845 (39%)]\tLoss: 0.114048\n",
            "Train Epoch: 14 [2691/6845 (39%)]\tLoss: 0.053327\n",
            "Train Epoch: 14 [2692/6845 (39%)]\tLoss: 0.102324\n",
            "Train Epoch: 14 [2693/6845 (39%)]\tLoss: 0.049015\n",
            "Train Epoch: 14 [2694/6845 (39%)]\tLoss: 0.294703\n",
            "Train Epoch: 14 [2695/6845 (39%)]\tLoss: 0.074927\n",
            "Train Epoch: 14 [2696/6845 (39%)]\tLoss: 0.253715\n",
            "Train Epoch: 14 [2697/6845 (39%)]\tLoss: 0.054879\n",
            "Train Epoch: 14 [2698/6845 (39%)]\tLoss: 0.193657\n",
            "Train Epoch: 14 [2699/6845 (39%)]\tLoss: 0.055427\n",
            "Train Epoch: 14 [2700/6845 (39%)]\tLoss: 0.207128\n",
            "Train Epoch: 14 [2701/6845 (39%)]\tLoss: 0.241682\n",
            "Train Epoch: 14 [2702/6845 (39%)]\tLoss: 0.140796\n",
            "Train Epoch: 14 [2703/6845 (39%)]\tLoss: 0.109521\n",
            "Train Epoch: 14 [2704/6845 (40%)]\tLoss: 0.289702\n",
            "Train Epoch: 14 [2705/6845 (40%)]\tLoss: 0.048798\n",
            "Train Epoch: 14 [2706/6845 (40%)]\tLoss: 0.183289\n",
            "Train Epoch: 14 [2707/6845 (40%)]\tLoss: 0.796550\n",
            "Train Epoch: 14 [2708/6845 (40%)]\tLoss: 0.076769\n",
            "Train Epoch: 14 [2709/6845 (40%)]\tLoss: 0.061618\n",
            "Train Epoch: 14 [2710/6845 (40%)]\tLoss: 0.366624\n",
            "Train Epoch: 14 [2711/6845 (40%)]\tLoss: 0.090252\n",
            "Train Epoch: 14 [2712/6845 (40%)]\tLoss: 0.179060\n",
            "Train Epoch: 14 [2713/6845 (40%)]\tLoss: 0.304685\n",
            "Train Epoch: 14 [2714/6845 (40%)]\tLoss: 0.065876\n",
            "Train Epoch: 14 [2715/6845 (40%)]\tLoss: 0.146188\n",
            "Train Epoch: 14 [2716/6845 (40%)]\tLoss: 0.221652\n",
            "Train Epoch: 14 [2717/6845 (40%)]\tLoss: 0.206806\n",
            "Train Epoch: 14 [2718/6845 (40%)]\tLoss: 0.109690\n",
            "Train Epoch: 14 [2719/6845 (40%)]\tLoss: 0.350756\n",
            "Train Epoch: 14 [2720/6845 (40%)]\tLoss: 0.101848\n",
            "Train Epoch: 14 [2721/6845 (40%)]\tLoss: 0.494281\n",
            "Train Epoch: 14 [2722/6845 (40%)]\tLoss: 0.908840\n",
            "Train Epoch: 14 [2723/6845 (40%)]\tLoss: 0.172683\n",
            "Train Epoch: 14 [2724/6845 (40%)]\tLoss: 0.067621\n",
            "Train Epoch: 14 [2725/6845 (40%)]\tLoss: 0.194157\n",
            "Train Epoch: 14 [2726/6845 (40%)]\tLoss: 0.058538\n",
            "Train Epoch: 14 [2727/6845 (40%)]\tLoss: 0.076796\n",
            "Train Epoch: 14 [2728/6845 (40%)]\tLoss: 0.079797\n",
            "Train Epoch: 14 [2729/6845 (40%)]\tLoss: 0.093181\n",
            "Train Epoch: 14 [2730/6845 (40%)]\tLoss: 0.587240\n",
            "Train Epoch: 14 [2731/6845 (40%)]\tLoss: 0.201801\n",
            "Train Epoch: 14 [2732/6845 (40%)]\tLoss: 0.137765\n",
            "Train Epoch: 14 [2733/6845 (40%)]\tLoss: 0.056449\n",
            "Train Epoch: 14 [2734/6845 (40%)]\tLoss: 0.091540\n",
            "Train Epoch: 14 [2735/6845 (40%)]\tLoss: 0.636756\n",
            "Train Epoch: 14 [2736/6845 (40%)]\tLoss: 0.053205\n",
            "Train Epoch: 14 [2737/6845 (40%)]\tLoss: 0.152182\n",
            "Train Epoch: 14 [2738/6845 (40%)]\tLoss: 0.090972\n",
            "Train Epoch: 14 [2739/6845 (40%)]\tLoss: 0.140283\n",
            "Train Epoch: 14 [2740/6845 (40%)]\tLoss: 0.177117\n",
            "Train Epoch: 14 [2741/6845 (40%)]\tLoss: 0.122885\n",
            "Train Epoch: 14 [2742/6845 (40%)]\tLoss: 0.094900\n",
            "Train Epoch: 14 [2743/6845 (40%)]\tLoss: 0.161316\n",
            "Train Epoch: 14 [2744/6845 (40%)]\tLoss: 0.124251\n",
            "Train Epoch: 14 [2745/6845 (40%)]\tLoss: 0.091046\n",
            "Train Epoch: 14 [2746/6845 (40%)]\tLoss: 0.047293\n",
            "Train Epoch: 14 [2747/6845 (40%)]\tLoss: 0.120016\n",
            "Train Epoch: 14 [2748/6845 (40%)]\tLoss: 0.805397\n",
            "Train Epoch: 14 [2749/6845 (40%)]\tLoss: 0.624221\n",
            "Train Epoch: 14 [2750/6845 (40%)]\tLoss: 0.129171\n",
            "Train Epoch: 14 [2751/6845 (40%)]\tLoss: 0.052381\n",
            "Train Epoch: 14 [2752/6845 (40%)]\tLoss: 0.327965\n",
            "Train Epoch: 14 [2753/6845 (40%)]\tLoss: 0.046931\n",
            "Train Epoch: 14 [2754/6845 (40%)]\tLoss: 0.812160\n",
            "Train Epoch: 14 [2755/6845 (40%)]\tLoss: 0.047290\n",
            "Train Epoch: 14 [2756/6845 (40%)]\tLoss: 0.128187\n",
            "Train Epoch: 14 [2757/6845 (40%)]\tLoss: 0.043767\n",
            "Train Epoch: 14 [2758/6845 (40%)]\tLoss: 0.107347\n",
            "Train Epoch: 14 [2759/6845 (40%)]\tLoss: 0.047933\n",
            "Train Epoch: 14 [2760/6845 (40%)]\tLoss: 0.055098\n",
            "Train Epoch: 14 [2761/6845 (40%)]\tLoss: 0.056451\n",
            "Train Epoch: 14 [2762/6845 (40%)]\tLoss: 1.039343\n",
            "Train Epoch: 14 [2763/6845 (40%)]\tLoss: 0.434909\n",
            "Train Epoch: 14 [2764/6845 (40%)]\tLoss: 0.037890\n",
            "Train Epoch: 14 [2765/6845 (40%)]\tLoss: 0.142507\n",
            "Train Epoch: 14 [2766/6845 (40%)]\tLoss: 0.080838\n",
            "Train Epoch: 14 [2767/6845 (40%)]\tLoss: 0.081711\n",
            "Train Epoch: 14 [2768/6845 (40%)]\tLoss: 0.156681\n",
            "Train Epoch: 14 [2769/6845 (40%)]\tLoss: 0.041823\n",
            "Train Epoch: 14 [2770/6845 (40%)]\tLoss: 0.124427\n",
            "Train Epoch: 14 [2771/6845 (40%)]\tLoss: 0.063980\n",
            "Train Epoch: 14 [2772/6845 (40%)]\tLoss: 0.931765\n",
            "Train Epoch: 14 [2773/6845 (41%)]\tLoss: 0.793708\n",
            "Train Epoch: 14 [2774/6845 (41%)]\tLoss: 0.054067\n",
            "Train Epoch: 14 [2775/6845 (41%)]\tLoss: 0.072370\n",
            "Train Epoch: 14 [2776/6845 (41%)]\tLoss: 0.108075\n",
            "Train Epoch: 14 [2777/6845 (41%)]\tLoss: 0.034369\n",
            "Train Epoch: 14 [2778/6845 (41%)]\tLoss: 0.094035\n",
            "Train Epoch: 14 [2779/6845 (41%)]\tLoss: 0.151329\n",
            "Train Epoch: 14 [2780/6845 (41%)]\tLoss: 0.564810\n",
            "Train Epoch: 14 [2781/6845 (41%)]\tLoss: 0.571207\n",
            "Train Epoch: 14 [2782/6845 (41%)]\tLoss: 0.102196\n",
            "Train Epoch: 14 [2783/6845 (41%)]\tLoss: 0.036820\n",
            "Train Epoch: 14 [2784/6845 (41%)]\tLoss: 0.160479\n",
            "Train Epoch: 14 [2785/6845 (41%)]\tLoss: 0.731210\n",
            "Train Epoch: 14 [2786/6845 (41%)]\tLoss: 0.066772\n",
            "Train Epoch: 14 [2787/6845 (41%)]\tLoss: 0.055378\n",
            "Train Epoch: 14 [2788/6845 (41%)]\tLoss: 0.094937\n",
            "Train Epoch: 14 [2789/6845 (41%)]\tLoss: 0.090304\n",
            "Train Epoch: 14 [2790/6845 (41%)]\tLoss: 0.569113\n",
            "Train Epoch: 14 [2791/6845 (41%)]\tLoss: 0.090811\n",
            "Train Epoch: 14 [2792/6845 (41%)]\tLoss: 0.164132\n",
            "Train Epoch: 14 [2793/6845 (41%)]\tLoss: 0.095080\n",
            "Train Epoch: 14 [2794/6845 (41%)]\tLoss: 0.196696\n",
            "Train Epoch: 14 [2795/6845 (41%)]\tLoss: 0.090014\n",
            "Train Epoch: 14 [2796/6845 (41%)]\tLoss: 0.062452\n",
            "Train Epoch: 14 [2797/6845 (41%)]\tLoss: 0.149215\n",
            "Train Epoch: 14 [2798/6845 (41%)]\tLoss: 0.126443\n",
            "Train Epoch: 14 [2799/6845 (41%)]\tLoss: 0.122216\n",
            "Train Epoch: 14 [2800/6845 (41%)]\tLoss: 0.094617\n",
            "Train Epoch: 14 [2801/6845 (41%)]\tLoss: 0.186588\n",
            "Train Epoch: 14 [2802/6845 (41%)]\tLoss: 0.064732\n",
            "Train Epoch: 14 [2803/6845 (41%)]\tLoss: 0.071432\n",
            "Train Epoch: 14 [2804/6845 (41%)]\tLoss: 0.087143\n",
            "Train Epoch: 14 [2805/6845 (41%)]\tLoss: 0.873900\n",
            "Train Epoch: 14 [2806/6845 (41%)]\tLoss: 0.065343\n",
            "Train Epoch: 14 [2807/6845 (41%)]\tLoss: 0.064697\n",
            "Train Epoch: 14 [2808/6845 (41%)]\tLoss: 0.121160\n",
            "Train Epoch: 14 [2809/6845 (41%)]\tLoss: 0.112060\n",
            "Train Epoch: 14 [2810/6845 (41%)]\tLoss: 0.049694\n",
            "Train Epoch: 14 [2811/6845 (41%)]\tLoss: 0.074310\n",
            "Train Epoch: 14 [2812/6845 (41%)]\tLoss: 0.057231\n",
            "Train Epoch: 14 [2813/6845 (41%)]\tLoss: 0.065508\n",
            "Train Epoch: 14 [2814/6845 (41%)]\tLoss: 0.105698\n",
            "Train Epoch: 14 [2815/6845 (41%)]\tLoss: 0.054364\n",
            "Train Epoch: 14 [2816/6845 (41%)]\tLoss: 1.465544\n",
            "Train Epoch: 14 [2817/6845 (41%)]\tLoss: 0.857243\n",
            "Train Epoch: 14 [2818/6845 (41%)]\tLoss: 0.129344\n",
            "Train Epoch: 14 [2819/6845 (41%)]\tLoss: 0.130551\n",
            "Train Epoch: 14 [2820/6845 (41%)]\tLoss: 0.103188\n",
            "Train Epoch: 14 [2821/6845 (41%)]\tLoss: 0.040750\n",
            "Train Epoch: 14 [2822/6845 (41%)]\tLoss: 0.094972\n",
            "Train Epoch: 14 [2823/6845 (41%)]\tLoss: 0.087884\n",
            "Train Epoch: 14 [2824/6845 (41%)]\tLoss: 0.059939\n",
            "Train Epoch: 14 [2825/6845 (41%)]\tLoss: 0.078391\n",
            "Train Epoch: 14 [2826/6845 (41%)]\tLoss: 0.728540\n",
            "Train Epoch: 14 [2827/6845 (41%)]\tLoss: 0.049066\n",
            "Train Epoch: 14 [2828/6845 (41%)]\tLoss: 0.052445\n",
            "Train Epoch: 14 [2829/6845 (41%)]\tLoss: 0.056263\n",
            "Train Epoch: 14 [2830/6845 (41%)]\tLoss: 0.107653\n",
            "Train Epoch: 14 [2831/6845 (41%)]\tLoss: 0.088216\n",
            "Train Epoch: 14 [2832/6845 (41%)]\tLoss: 0.149529\n",
            "Train Epoch: 14 [2833/6845 (41%)]\tLoss: 0.042240\n",
            "Train Epoch: 14 [2834/6845 (41%)]\tLoss: 0.078266\n",
            "Train Epoch: 14 [2835/6845 (41%)]\tLoss: 0.568883\n",
            "Train Epoch: 14 [2836/6845 (41%)]\tLoss: 0.142966\n",
            "Train Epoch: 14 [2837/6845 (41%)]\tLoss: 0.199522\n",
            "Train Epoch: 14 [2838/6845 (41%)]\tLoss: 0.083482\n",
            "Train Epoch: 14 [2839/6845 (41%)]\tLoss: 0.091405\n",
            "Train Epoch: 14 [2840/6845 (41%)]\tLoss: 0.445974\n",
            "Train Epoch: 14 [2841/6845 (42%)]\tLoss: 0.137566\n",
            "Train Epoch: 14 [2842/6845 (42%)]\tLoss: 0.070776\n",
            "Train Epoch: 14 [2843/6845 (42%)]\tLoss: 0.100986\n",
            "Train Epoch: 14 [2844/6845 (42%)]\tLoss: 0.578806\n",
            "Train Epoch: 14 [2845/6845 (42%)]\tLoss: 1.186989\n",
            "Train Epoch: 14 [2846/6845 (42%)]\tLoss: 0.098395\n",
            "Train Epoch: 14 [2847/6845 (42%)]\tLoss: 0.438035\n",
            "Train Epoch: 14 [2848/6845 (42%)]\tLoss: 0.089057\n",
            "Train Epoch: 14 [2849/6845 (42%)]\tLoss: 0.083280\n",
            "Train Epoch: 14 [2850/6845 (42%)]\tLoss: 0.065275\n",
            "Train Epoch: 14 [2851/6845 (42%)]\tLoss: 0.080732\n",
            "Train Epoch: 14 [2852/6845 (42%)]\tLoss: 0.085823\n",
            "Train Epoch: 14 [2853/6845 (42%)]\tLoss: 1.241903\n",
            "Train Epoch: 14 [2854/6845 (42%)]\tLoss: 0.095033\n",
            "Train Epoch: 14 [2855/6845 (42%)]\tLoss: 0.611445\n",
            "Train Epoch: 14 [2856/6845 (42%)]\tLoss: 0.054537\n",
            "Train Epoch: 14 [2857/6845 (42%)]\tLoss: 0.065026\n",
            "Train Epoch: 14 [2858/6845 (42%)]\tLoss: 0.669025\n",
            "Train Epoch: 14 [2859/6845 (42%)]\tLoss: 0.675245\n",
            "Train Epoch: 14 [2860/6845 (42%)]\tLoss: 0.180164\n",
            "Train Epoch: 14 [2861/6845 (42%)]\tLoss: 0.626156\n",
            "Train Epoch: 14 [2862/6845 (42%)]\tLoss: 0.061445\n",
            "Train Epoch: 14 [2863/6845 (42%)]\tLoss: 0.147785\n",
            "Train Epoch: 14 [2864/6845 (42%)]\tLoss: 0.162374\n",
            "Train Epoch: 14 [2865/6845 (42%)]\tLoss: 0.571416\n",
            "Train Epoch: 14 [2866/6845 (42%)]\tLoss: 0.125564\n",
            "Train Epoch: 14 [2867/6845 (42%)]\tLoss: 0.788029\n",
            "Train Epoch: 14 [2868/6845 (42%)]\tLoss: 0.068900\n",
            "Train Epoch: 14 [2869/6845 (42%)]\tLoss: 1.137996\n",
            "Train Epoch: 14 [2870/6845 (42%)]\tLoss: 0.067017\n",
            "Train Epoch: 14 [2871/6845 (42%)]\tLoss: 0.647016\n",
            "Train Epoch: 14 [2872/6845 (42%)]\tLoss: 0.071726\n",
            "Train Epoch: 14 [2873/6845 (42%)]\tLoss: 0.182918\n",
            "Train Epoch: 14 [2874/6845 (42%)]\tLoss: 0.075223\n",
            "Train Epoch: 14 [2875/6845 (42%)]\tLoss: 0.685402\n",
            "Train Epoch: 14 [2876/6845 (42%)]\tLoss: 0.178144\n",
            "Train Epoch: 14 [2877/6845 (42%)]\tLoss: 0.476072\n",
            "Train Epoch: 14 [2878/6845 (42%)]\tLoss: 0.148211\n",
            "Train Epoch: 14 [2879/6845 (42%)]\tLoss: 0.627959\n",
            "Train Epoch: 14 [2880/6845 (42%)]\tLoss: 0.089277\n",
            "Train Epoch: 14 [2881/6845 (42%)]\tLoss: 0.578161\n",
            "Train Epoch: 14 [2882/6845 (42%)]\tLoss: 0.943705\n",
            "Train Epoch: 14 [2883/6845 (42%)]\tLoss: 0.072203\n",
            "Train Epoch: 14 [2884/6845 (42%)]\tLoss: 0.078471\n",
            "Train Epoch: 14 [2885/6845 (42%)]\tLoss: 0.231061\n",
            "Train Epoch: 14 [2886/6845 (42%)]\tLoss: 0.617921\n",
            "Train Epoch: 14 [2887/6845 (42%)]\tLoss: 0.527369\n",
            "Train Epoch: 14 [2888/6845 (42%)]\tLoss: 0.087596\n",
            "Train Epoch: 14 [2889/6845 (42%)]\tLoss: 0.066503\n",
            "Train Epoch: 14 [2890/6845 (42%)]\tLoss: 0.081850\n",
            "Train Epoch: 14 [2891/6845 (42%)]\tLoss: 0.071052\n",
            "Train Epoch: 14 [2892/6845 (42%)]\tLoss: 0.068901\n",
            "Train Epoch: 14 [2893/6845 (42%)]\tLoss: 0.059630\n",
            "Train Epoch: 14 [2894/6845 (42%)]\tLoss: 0.061380\n",
            "Train Epoch: 14 [2895/6845 (42%)]\tLoss: 0.101023\n",
            "Train Epoch: 14 [2896/6845 (42%)]\tLoss: 0.086946\n",
            "Train Epoch: 14 [2897/6845 (42%)]\tLoss: 0.517253\n",
            "Train Epoch: 14 [2898/6845 (42%)]\tLoss: 0.065032\n",
            "Train Epoch: 14 [2899/6845 (42%)]\tLoss: 0.117754\n",
            "Train Epoch: 14 [2900/6845 (42%)]\tLoss: 0.056889\n",
            "Train Epoch: 14 [2901/6845 (42%)]\tLoss: 0.064209\n",
            "Train Epoch: 14 [2902/6845 (42%)]\tLoss: 0.064928\n",
            "Train Epoch: 14 [2903/6845 (42%)]\tLoss: 0.116556\n",
            "Train Epoch: 14 [2904/6845 (42%)]\tLoss: 0.138340\n",
            "Train Epoch: 14 [2905/6845 (42%)]\tLoss: 0.056844\n",
            "Train Epoch: 14 [2906/6845 (42%)]\tLoss: 0.079311\n",
            "Train Epoch: 14 [2907/6845 (42%)]\tLoss: 0.280770\n",
            "Train Epoch: 14 [2908/6845 (42%)]\tLoss: 0.085138\n",
            "Train Epoch: 14 [2909/6845 (42%)]\tLoss: 0.127432\n",
            "Train Epoch: 14 [2910/6845 (43%)]\tLoss: 0.043018\n",
            "Train Epoch: 14 [2911/6845 (43%)]\tLoss: 0.174142\n",
            "Train Epoch: 14 [2912/6845 (43%)]\tLoss: 0.077036\n",
            "Train Epoch: 14 [2913/6845 (43%)]\tLoss: 0.253277\n",
            "Train Epoch: 14 [2914/6845 (43%)]\tLoss: 0.084805\n",
            "Train Epoch: 14 [2915/6845 (43%)]\tLoss: 0.108250\n",
            "Train Epoch: 14 [2916/6845 (43%)]\tLoss: 0.052898\n",
            "Train Epoch: 14 [2917/6845 (43%)]\tLoss: 0.489364\n",
            "Train Epoch: 14 [2918/6845 (43%)]\tLoss: 0.146590\n",
            "Train Epoch: 14 [2919/6845 (43%)]\tLoss: 0.135777\n",
            "Train Epoch: 14 [2920/6845 (43%)]\tLoss: 0.942491\n",
            "Train Epoch: 14 [2921/6845 (43%)]\tLoss: 0.520308\n",
            "Train Epoch: 14 [2922/6845 (43%)]\tLoss: 0.720230\n",
            "Train Epoch: 14 [2923/6845 (43%)]\tLoss: 0.155913\n",
            "Train Epoch: 14 [2924/6845 (43%)]\tLoss: 0.050820\n",
            "Train Epoch: 14 [2925/6845 (43%)]\tLoss: 0.056258\n",
            "Train Epoch: 14 [2926/6845 (43%)]\tLoss: 0.202602\n",
            "Train Epoch: 14 [2927/6845 (43%)]\tLoss: 0.132480\n",
            "Train Epoch: 14 [2928/6845 (43%)]\tLoss: 0.159729\n",
            "Train Epoch: 14 [2929/6845 (43%)]\tLoss: 0.064962\n",
            "Train Epoch: 14 [2930/6845 (43%)]\tLoss: 0.094530\n",
            "Train Epoch: 14 [2931/6845 (43%)]\tLoss: 0.724656\n",
            "Train Epoch: 14 [2932/6845 (43%)]\tLoss: 0.113817\n",
            "Train Epoch: 14 [2933/6845 (43%)]\tLoss: 0.059311\n",
            "Train Epoch: 14 [2934/6845 (43%)]\tLoss: 0.046190\n",
            "Train Epoch: 14 [2935/6845 (43%)]\tLoss: 0.138879\n",
            "Train Epoch: 14 [2936/6845 (43%)]\tLoss: 1.178236\n",
            "Train Epoch: 14 [2937/6845 (43%)]\tLoss: 0.085883\n",
            "Train Epoch: 14 [2938/6845 (43%)]\tLoss: 0.080090\n",
            "Train Epoch: 14 [2939/6845 (43%)]\tLoss: 0.093278\n",
            "Train Epoch: 14 [2940/6845 (43%)]\tLoss: 0.419343\n",
            "Train Epoch: 14 [2941/6845 (43%)]\tLoss: 0.981679\n",
            "Train Epoch: 14 [2942/6845 (43%)]\tLoss: 0.065131\n",
            "Train Epoch: 14 [2943/6845 (43%)]\tLoss: 0.046673\n",
            "Train Epoch: 14 [2944/6845 (43%)]\tLoss: 0.089379\n",
            "Train Epoch: 14 [2945/6845 (43%)]\tLoss: 0.096323\n",
            "Train Epoch: 14 [2946/6845 (43%)]\tLoss: 0.531328\n",
            "Train Epoch: 14 [2947/6845 (43%)]\tLoss: 0.148994\n",
            "Train Epoch: 14 [2948/6845 (43%)]\tLoss: 0.097286\n",
            "Train Epoch: 14 [2949/6845 (43%)]\tLoss: 0.082059\n",
            "Train Epoch: 14 [2950/6845 (43%)]\tLoss: 0.074046\n",
            "Train Epoch: 14 [2951/6845 (43%)]\tLoss: 0.086168\n",
            "Train Epoch: 14 [2952/6845 (43%)]\tLoss: 0.165126\n",
            "Train Epoch: 14 [2953/6845 (43%)]\tLoss: 0.089007\n",
            "Train Epoch: 14 [2954/6845 (43%)]\tLoss: 0.061695\n",
            "Train Epoch: 14 [2955/6845 (43%)]\tLoss: 0.493521\n",
            "Train Epoch: 14 [2956/6845 (43%)]\tLoss: 1.197430\n",
            "Train Epoch: 14 [2957/6845 (43%)]\tLoss: 0.071086\n",
            "Train Epoch: 14 [2958/6845 (43%)]\tLoss: 0.064539\n",
            "Train Epoch: 14 [2959/6845 (43%)]\tLoss: 0.092669\n",
            "Train Epoch: 14 [2960/6845 (43%)]\tLoss: 0.086206\n",
            "Train Epoch: 14 [2961/6845 (43%)]\tLoss: 0.766753\n",
            "Train Epoch: 14 [2962/6845 (43%)]\tLoss: 0.113909\n",
            "Train Epoch: 14 [2963/6845 (43%)]\tLoss: 0.133669\n",
            "Train Epoch: 14 [2964/6845 (43%)]\tLoss: 0.609183\n",
            "Train Epoch: 14 [2965/6845 (43%)]\tLoss: 0.095910\n",
            "Train Epoch: 14 [2966/6845 (43%)]\tLoss: 0.087477\n",
            "Train Epoch: 14 [2967/6845 (43%)]\tLoss: 0.462364\n",
            "Train Epoch: 14 [2968/6845 (43%)]\tLoss: 0.166661\n",
            "Train Epoch: 14 [2969/6845 (43%)]\tLoss: 0.120391\n",
            "Train Epoch: 14 [2970/6845 (43%)]\tLoss: 0.440872\n",
            "Train Epoch: 14 [2971/6845 (43%)]\tLoss: 0.090833\n",
            "Train Epoch: 14 [2972/6845 (43%)]\tLoss: 0.563272\n",
            "Train Epoch: 14 [2973/6845 (43%)]\tLoss: 0.051632\n",
            "Train Epoch: 14 [2974/6845 (43%)]\tLoss: 0.443163\n",
            "Train Epoch: 14 [2975/6845 (43%)]\tLoss: 0.142116\n",
            "Train Epoch: 14 [2976/6845 (43%)]\tLoss: 0.234313\n",
            "Train Epoch: 14 [2977/6845 (43%)]\tLoss: 0.186600\n",
            "Train Epoch: 14 [2978/6845 (44%)]\tLoss: 0.832735\n",
            "Train Epoch: 14 [2979/6845 (44%)]\tLoss: 1.639528\n",
            "Train Epoch: 14 [2980/6845 (44%)]\tLoss: 0.128070\n",
            "Train Epoch: 14 [2981/6845 (44%)]\tLoss: 0.711881\n",
            "Train Epoch: 14 [2982/6845 (44%)]\tLoss: 0.061962\n",
            "Train Epoch: 14 [2983/6845 (44%)]\tLoss: 0.045722\n",
            "Train Epoch: 14 [2984/6845 (44%)]\tLoss: 0.124163\n",
            "Train Epoch: 14 [2985/6845 (44%)]\tLoss: 0.173985\n",
            "Train Epoch: 14 [2986/6845 (44%)]\tLoss: 0.140124\n",
            "Train Epoch: 14 [2987/6845 (44%)]\tLoss: 0.167191\n",
            "Train Epoch: 14 [2988/6845 (44%)]\tLoss: 0.040322\n",
            "Train Epoch: 14 [2989/6845 (44%)]\tLoss: 0.155843\n",
            "Train Epoch: 14 [2990/6845 (44%)]\tLoss: 0.091182\n",
            "Train Epoch: 14 [2991/6845 (44%)]\tLoss: 0.039898\n",
            "Train Epoch: 14 [2992/6845 (44%)]\tLoss: 0.614603\n",
            "Train Epoch: 14 [2993/6845 (44%)]\tLoss: 0.127674\n",
            "Train Epoch: 14 [2994/6845 (44%)]\tLoss: 0.792279\n",
            "Train Epoch: 14 [2995/6845 (44%)]\tLoss: 0.121447\n",
            "Train Epoch: 14 [2996/6845 (44%)]\tLoss: 0.143440\n",
            "Train Epoch: 14 [2997/6845 (44%)]\tLoss: 0.151531\n",
            "Train Epoch: 14 [2998/6845 (44%)]\tLoss: 0.863637\n",
            "Train Epoch: 14 [2999/6845 (44%)]\tLoss: 0.182391\n",
            "Train Epoch: 14 [3000/6845 (44%)]\tLoss: 0.574919\n",
            "Train Epoch: 14 [3001/6845 (44%)]\tLoss: 0.176793\n",
            "Train Epoch: 14 [3002/6845 (44%)]\tLoss: 0.191553\n",
            "Train Epoch: 14 [3003/6845 (44%)]\tLoss: 0.725033\n",
            "Train Epoch: 14 [3004/6845 (44%)]\tLoss: 0.146986\n",
            "Train Epoch: 14 [3005/6845 (44%)]\tLoss: 0.095050\n",
            "Train Epoch: 14 [3006/6845 (44%)]\tLoss: 0.593452\n",
            "Train Epoch: 14 [3007/6845 (44%)]\tLoss: 0.188534\n",
            "Train Epoch: 14 [3008/6845 (44%)]\tLoss: 0.186496\n",
            "Train Epoch: 14 [3009/6845 (44%)]\tLoss: 0.690984\n",
            "Train Epoch: 14 [3010/6845 (44%)]\tLoss: 0.044040\n",
            "Train Epoch: 14 [3011/6845 (44%)]\tLoss: 0.252003\n",
            "Train Epoch: 14 [3012/6845 (44%)]\tLoss: 0.525766\n",
            "Train Epoch: 14 [3013/6845 (44%)]\tLoss: 0.051242\n",
            "Train Epoch: 14 [3014/6845 (44%)]\tLoss: 0.105993\n",
            "Train Epoch: 14 [3015/6845 (44%)]\tLoss: 0.095301\n",
            "Train Epoch: 14 [3016/6845 (44%)]\tLoss: 0.043327\n",
            "Train Epoch: 14 [3017/6845 (44%)]\tLoss: 0.139089\n",
            "Train Epoch: 14 [3018/6845 (44%)]\tLoss: 0.138791\n",
            "Train Epoch: 14 [3019/6845 (44%)]\tLoss: 0.150211\n",
            "Train Epoch: 14 [3020/6845 (44%)]\tLoss: 0.136810\n",
            "Train Epoch: 14 [3021/6845 (44%)]\tLoss: 0.048626\n",
            "Train Epoch: 14 [3022/6845 (44%)]\tLoss: 0.915632\n",
            "Train Epoch: 14 [3023/6845 (44%)]\tLoss: 0.133975\n",
            "Train Epoch: 14 [3024/6845 (44%)]\tLoss: 0.588041\n",
            "Train Epoch: 14 [3025/6845 (44%)]\tLoss: 0.728713\n",
            "Train Epoch: 14 [3026/6845 (44%)]\tLoss: 0.140930\n",
            "Train Epoch: 14 [3027/6845 (44%)]\tLoss: 0.050429\n",
            "Train Epoch: 14 [3028/6845 (44%)]\tLoss: 0.734156\n",
            "Train Epoch: 14 [3029/6845 (44%)]\tLoss: 0.051901\n",
            "Train Epoch: 14 [3030/6845 (44%)]\tLoss: 0.044856\n",
            "Train Epoch: 14 [3031/6845 (44%)]\tLoss: 0.219441\n",
            "Train Epoch: 14 [3032/6845 (44%)]\tLoss: 0.088209\n",
            "Train Epoch: 14 [3033/6845 (44%)]\tLoss: 0.149011\n",
            "Train Epoch: 14 [3034/6845 (44%)]\tLoss: 0.099253\n",
            "Train Epoch: 14 [3035/6845 (44%)]\tLoss: 0.127551\n",
            "Train Epoch: 14 [3036/6845 (44%)]\tLoss: 0.110952\n",
            "Train Epoch: 14 [3037/6845 (44%)]\tLoss: 0.678604\n",
            "Train Epoch: 14 [3038/6845 (44%)]\tLoss: 0.101136\n",
            "Train Epoch: 14 [3039/6845 (44%)]\tLoss: 0.088838\n",
            "Train Epoch: 14 [3040/6845 (44%)]\tLoss: 0.778139\n",
            "Train Epoch: 14 [3041/6845 (44%)]\tLoss: 0.072460\n",
            "Train Epoch: 14 [3042/6845 (44%)]\tLoss: 0.080679\n",
            "Train Epoch: 14 [3043/6845 (44%)]\tLoss: 0.065323\n",
            "Train Epoch: 14 [3044/6845 (44%)]\tLoss: 0.108058\n",
            "Train Epoch: 14 [3045/6845 (44%)]\tLoss: 0.064192\n",
            "Train Epoch: 14 [3046/6845 (44%)]\tLoss: 0.078083\n",
            "Train Epoch: 14 [3047/6845 (45%)]\tLoss: 0.634335\n",
            "Train Epoch: 14 [3048/6845 (45%)]\tLoss: 0.168140\n",
            "Train Epoch: 14 [3049/6845 (45%)]\tLoss: 0.116576\n",
            "Train Epoch: 14 [3050/6845 (45%)]\tLoss: 0.074745\n",
            "Train Epoch: 14 [3051/6845 (45%)]\tLoss: 0.667972\n",
            "Train Epoch: 14 [3052/6845 (45%)]\tLoss: 0.151278\n",
            "Train Epoch: 14 [3053/6845 (45%)]\tLoss: 0.115387\n",
            "Train Epoch: 14 [3054/6845 (45%)]\tLoss: 0.071387\n",
            "Train Epoch: 14 [3055/6845 (45%)]\tLoss: 0.093332\n",
            "Train Epoch: 14 [3056/6845 (45%)]\tLoss: 0.073714\n",
            "Train Epoch: 14 [3057/6845 (45%)]\tLoss: 0.211541\n",
            "Train Epoch: 14 [3058/6845 (45%)]\tLoss: 0.090148\n",
            "Train Epoch: 14 [3059/6845 (45%)]\tLoss: 0.077992\n",
            "Train Epoch: 14 [3060/6845 (45%)]\tLoss: 0.068688\n",
            "Train Epoch: 14 [3061/6845 (45%)]\tLoss: 0.171194\n",
            "Train Epoch: 14 [3062/6845 (45%)]\tLoss: 0.184464\n",
            "Train Epoch: 14 [3063/6845 (45%)]\tLoss: 0.066340\n",
            "Train Epoch: 14 [3064/6845 (45%)]\tLoss: 0.128085\n",
            "Train Epoch: 14 [3065/6845 (45%)]\tLoss: 0.077741\n",
            "Train Epoch: 14 [3066/6845 (45%)]\tLoss: 0.071966\n",
            "Train Epoch: 14 [3067/6845 (45%)]\tLoss: 0.062190\n",
            "Train Epoch: 14 [3068/6845 (45%)]\tLoss: 0.655599\n",
            "Train Epoch: 14 [3069/6845 (45%)]\tLoss: 0.064098\n",
            "Train Epoch: 14 [3070/6845 (45%)]\tLoss: 0.057813\n",
            "Train Epoch: 14 [3071/6845 (45%)]\tLoss: 0.066672\n",
            "Train Epoch: 14 [3072/6845 (45%)]\tLoss: 0.090333\n",
            "Train Epoch: 14 [3073/6845 (45%)]\tLoss: 0.085627\n",
            "Train Epoch: 14 [3074/6845 (45%)]\tLoss: 0.086802\n",
            "Train Epoch: 14 [3075/6845 (45%)]\tLoss: 0.078225\n",
            "Train Epoch: 14 [3076/6845 (45%)]\tLoss: 0.577463\n",
            "Train Epoch: 14 [3077/6845 (45%)]\tLoss: 0.068908\n",
            "Train Epoch: 14 [3078/6845 (45%)]\tLoss: 0.084894\n",
            "Train Epoch: 14 [3079/6845 (45%)]\tLoss: 0.091613\n",
            "Train Epoch: 14 [3080/6845 (45%)]\tLoss: 0.075608\n",
            "Train Epoch: 14 [3081/6845 (45%)]\tLoss: 0.054381\n",
            "Train Epoch: 14 [3082/6845 (45%)]\tLoss: 0.527464\n",
            "Train Epoch: 14 [3083/6845 (45%)]\tLoss: 0.098523\n",
            "Train Epoch: 14 [3084/6845 (45%)]\tLoss: 0.066802\n",
            "Train Epoch: 14 [3085/6845 (45%)]\tLoss: 0.067382\n",
            "Train Epoch: 14 [3086/6845 (45%)]\tLoss: 0.112017\n",
            "Train Epoch: 14 [3087/6845 (45%)]\tLoss: 0.457286\n",
            "Train Epoch: 14 [3088/6845 (45%)]\tLoss: 0.076205\n",
            "Train Epoch: 14 [3089/6845 (45%)]\tLoss: 0.066792\n",
            "Train Epoch: 14 [3090/6845 (45%)]\tLoss: 0.057124\n",
            "Train Epoch: 14 [3091/6845 (45%)]\tLoss: 0.064937\n",
            "Train Epoch: 14 [3092/6845 (45%)]\tLoss: 0.092026\n",
            "Train Epoch: 14 [3093/6845 (45%)]\tLoss: 0.079996\n",
            "Train Epoch: 14 [3094/6845 (45%)]\tLoss: 0.046820\n",
            "Train Epoch: 14 [3095/6845 (45%)]\tLoss: 0.113978\n",
            "Train Epoch: 14 [3096/6845 (45%)]\tLoss: 0.087373\n",
            "Train Epoch: 14 [3097/6845 (45%)]\tLoss: 0.063492\n",
            "Train Epoch: 14 [3098/6845 (45%)]\tLoss: 0.100025\n",
            "Train Epoch: 14 [3099/6845 (45%)]\tLoss: 1.538596\n",
            "Train Epoch: 14 [3100/6845 (45%)]\tLoss: 0.042146\n",
            "Train Epoch: 14 [3101/6845 (45%)]\tLoss: 0.119997\n",
            "Train Epoch: 14 [3102/6845 (45%)]\tLoss: 0.548714\n",
            "Train Epoch: 14 [3103/6845 (45%)]\tLoss: 0.488463\n",
            "Train Epoch: 14 [3104/6845 (45%)]\tLoss: 0.054247\n",
            "Train Epoch: 14 [3105/6845 (45%)]\tLoss: 0.204867\n",
            "Train Epoch: 14 [3106/6845 (45%)]\tLoss: 1.001866\n",
            "Train Epoch: 14 [3107/6845 (45%)]\tLoss: 0.106895\n",
            "Train Epoch: 14 [3108/6845 (45%)]\tLoss: 0.067585\n",
            "Train Epoch: 14 [3109/6845 (45%)]\tLoss: 0.058129\n",
            "Train Epoch: 14 [3110/6845 (45%)]\tLoss: 0.043983\n",
            "Train Epoch: 14 [3111/6845 (45%)]\tLoss: 0.049751\n",
            "Train Epoch: 14 [3112/6845 (45%)]\tLoss: 0.047452\n",
            "Train Epoch: 14 [3113/6845 (45%)]\tLoss: 0.151106\n",
            "Train Epoch: 14 [3114/6845 (45%)]\tLoss: 0.581400\n",
            "Train Epoch: 14 [3115/6845 (46%)]\tLoss: 0.036318\n",
            "Train Epoch: 14 [3116/6845 (46%)]\tLoss: 0.147805\n",
            "Train Epoch: 14 [3117/6845 (46%)]\tLoss: 0.650768\n",
            "Train Epoch: 14 [3118/6845 (46%)]\tLoss: 0.166995\n",
            "Train Epoch: 14 [3119/6845 (46%)]\tLoss: 0.040348\n",
            "Train Epoch: 14 [3120/6845 (46%)]\tLoss: 0.095218\n",
            "Train Epoch: 14 [3121/6845 (46%)]\tLoss: 0.540942\n",
            "Train Epoch: 14 [3122/6845 (46%)]\tLoss: 0.778054\n",
            "Train Epoch: 14 [3123/6845 (46%)]\tLoss: 0.701686\n",
            "Train Epoch: 14 [3124/6845 (46%)]\tLoss: 0.462800\n",
            "Train Epoch: 14 [3125/6845 (46%)]\tLoss: 0.064169\n",
            "Train Epoch: 14 [3126/6845 (46%)]\tLoss: 0.088903\n",
            "Train Epoch: 14 [3127/6845 (46%)]\tLoss: 0.052910\n",
            "Train Epoch: 14 [3128/6845 (46%)]\tLoss: 0.050276\n",
            "Train Epoch: 14 [3129/6845 (46%)]\tLoss: 0.207935\n",
            "Train Epoch: 14 [3130/6845 (46%)]\tLoss: 0.094101\n",
            "Train Epoch: 14 [3131/6845 (46%)]\tLoss: 0.046283\n",
            "Train Epoch: 14 [3132/6845 (46%)]\tLoss: 0.162535\n",
            "Train Epoch: 14 [3133/6845 (46%)]\tLoss: 0.101133\n",
            "Train Epoch: 14 [3134/6845 (46%)]\tLoss: 0.089683\n",
            "Train Epoch: 14 [3135/6845 (46%)]\tLoss: 0.049657\n",
            "Train Epoch: 14 [3136/6845 (46%)]\tLoss: 0.087517\n",
            "Train Epoch: 14 [3137/6845 (46%)]\tLoss: 0.066661\n",
            "Train Epoch: 14 [3138/6845 (46%)]\tLoss: 0.169976\n",
            "Train Epoch: 14 [3139/6845 (46%)]\tLoss: 0.070165\n",
            "Train Epoch: 14 [3140/6845 (46%)]\tLoss: 0.093522\n",
            "Train Epoch: 14 [3141/6845 (46%)]\tLoss: 0.604520\n",
            "Train Epoch: 14 [3142/6845 (46%)]\tLoss: 0.804200\n",
            "Train Epoch: 14 [3143/6845 (46%)]\tLoss: 0.438556\n",
            "Train Epoch: 14 [3144/6845 (46%)]\tLoss: 0.195679\n",
            "Train Epoch: 14 [3145/6845 (46%)]\tLoss: 0.091067\n",
            "Train Epoch: 14 [3146/6845 (46%)]\tLoss: 0.044739\n",
            "Train Epoch: 14 [3147/6845 (46%)]\tLoss: 0.542007\n",
            "Train Epoch: 14 [3148/6845 (46%)]\tLoss: 0.419958\n",
            "Train Epoch: 14 [3149/6845 (46%)]\tLoss: 0.708313\n",
            "Train Epoch: 14 [3150/6845 (46%)]\tLoss: 0.117446\n",
            "Train Epoch: 14 [3151/6845 (46%)]\tLoss: 0.110093\n",
            "Train Epoch: 14 [3152/6845 (46%)]\tLoss: 1.039780\n",
            "Train Epoch: 14 [3153/6845 (46%)]\tLoss: 0.925829\n",
            "Train Epoch: 14 [3154/6845 (46%)]\tLoss: 2.058473\n",
            "Train Epoch: 14 [3155/6845 (46%)]\tLoss: 0.065081\n",
            "Train Epoch: 14 [3156/6845 (46%)]\tLoss: 0.137832\n",
            "Train Epoch: 14 [3157/6845 (46%)]\tLoss: 0.168855\n",
            "Train Epoch: 14 [3158/6845 (46%)]\tLoss: 0.065513\n",
            "Train Epoch: 14 [3159/6845 (46%)]\tLoss: 0.880966\n",
            "Train Epoch: 14 [3160/6845 (46%)]\tLoss: 0.094771\n",
            "Train Epoch: 14 [3161/6845 (46%)]\tLoss: 0.531685\n",
            "Train Epoch: 14 [3162/6845 (46%)]\tLoss: 0.127605\n",
            "Train Epoch: 14 [3163/6845 (46%)]\tLoss: 0.097101\n",
            "Train Epoch: 14 [3164/6845 (46%)]\tLoss: 0.117700\n",
            "Train Epoch: 14 [3165/6845 (46%)]\tLoss: 0.823191\n",
            "Train Epoch: 14 [3166/6845 (46%)]\tLoss: 0.069488\n",
            "Train Epoch: 14 [3167/6845 (46%)]\tLoss: 0.160458\n",
            "Train Epoch: 14 [3168/6845 (46%)]\tLoss: 0.430018\n",
            "Train Epoch: 14 [3169/6845 (46%)]\tLoss: 0.084159\n",
            "Train Epoch: 14 [3170/6845 (46%)]\tLoss: 0.073383\n",
            "Train Epoch: 14 [3171/6845 (46%)]\tLoss: 0.115554\n",
            "Train Epoch: 14 [3172/6845 (46%)]\tLoss: 0.103316\n",
            "Train Epoch: 14 [3173/6845 (46%)]\tLoss: 0.064319\n",
            "Train Epoch: 14 [3174/6845 (46%)]\tLoss: 0.071479\n",
            "Train Epoch: 14 [3175/6845 (46%)]\tLoss: 0.070269\n",
            "Train Epoch: 14 [3176/6845 (46%)]\tLoss: 0.089168\n",
            "Train Epoch: 14 [3177/6845 (46%)]\tLoss: 0.083437\n",
            "Train Epoch: 14 [3178/6845 (46%)]\tLoss: 0.448590\n",
            "Train Epoch: 14 [3179/6845 (46%)]\tLoss: 0.216955\n",
            "Train Epoch: 14 [3180/6845 (46%)]\tLoss: 0.110194\n",
            "Train Epoch: 14 [3181/6845 (46%)]\tLoss: 0.075744\n",
            "Train Epoch: 14 [3182/6845 (46%)]\tLoss: 0.063202\n",
            "Train Epoch: 14 [3183/6845 (47%)]\tLoss: 0.069333\n",
            "Train Epoch: 14 [3184/6845 (47%)]\tLoss: 0.999657\n",
            "Train Epoch: 14 [3185/6845 (47%)]\tLoss: 1.468074\n",
            "Train Epoch: 14 [3186/6845 (47%)]\tLoss: 0.516787\n",
            "Train Epoch: 14 [3187/6845 (47%)]\tLoss: 0.083397\n",
            "Train Epoch: 14 [3188/6845 (47%)]\tLoss: 0.072840\n",
            "Train Epoch: 14 [3189/6845 (47%)]\tLoss: 0.080559\n",
            "Train Epoch: 14 [3190/6845 (47%)]\tLoss: 0.077309\n",
            "Train Epoch: 14 [3191/6845 (47%)]\tLoss: 0.067119\n",
            "Train Epoch: 14 [3192/6845 (47%)]\tLoss: 0.493535\n",
            "Train Epoch: 14 [3193/6845 (47%)]\tLoss: 0.765677\n",
            "Train Epoch: 14 [3194/6845 (47%)]\tLoss: 0.518154\n",
            "Train Epoch: 14 [3195/6845 (47%)]\tLoss: 0.872381\n",
            "Train Epoch: 14 [3196/6845 (47%)]\tLoss: 0.521843\n",
            "Train Epoch: 14 [3197/6845 (47%)]\tLoss: 0.515528\n",
            "Train Epoch: 14 [3198/6845 (47%)]\tLoss: 0.079821\n",
            "Train Epoch: 14 [3199/6845 (47%)]\tLoss: 0.765923\n",
            "Train Epoch: 14 [3200/6845 (47%)]\tLoss: 0.073655\n",
            "Train Epoch: 14 [3201/6845 (47%)]\tLoss: 0.148489\n",
            "Train Epoch: 14 [3202/6845 (47%)]\tLoss: 0.791604\n",
            "Train Epoch: 14 [3203/6845 (47%)]\tLoss: 0.135176\n",
            "Train Epoch: 14 [3204/6845 (47%)]\tLoss: 0.079051\n",
            "Train Epoch: 14 [3205/6845 (47%)]\tLoss: 0.101584\n",
            "Train Epoch: 14 [3206/6845 (47%)]\tLoss: 0.097263\n",
            "Train Epoch: 14 [3207/6845 (47%)]\tLoss: 0.079711\n",
            "Train Epoch: 14 [3208/6845 (47%)]\tLoss: 0.124836\n",
            "Train Epoch: 14 [3209/6845 (47%)]\tLoss: 0.083811\n",
            "Train Epoch: 14 [3210/6845 (47%)]\tLoss: 0.237001\n",
            "Train Epoch: 14 [3211/6845 (47%)]\tLoss: 0.080297\n",
            "Train Epoch: 14 [3212/6845 (47%)]\tLoss: 0.251101\n",
            "Train Epoch: 14 [3213/6845 (47%)]\tLoss: 0.423839\n",
            "Train Epoch: 14 [3214/6845 (47%)]\tLoss: 0.092105\n",
            "Train Epoch: 14 [3215/6845 (47%)]\tLoss: 0.093910\n",
            "Train Epoch: 14 [3216/6845 (47%)]\tLoss: 0.082026\n",
            "Train Epoch: 14 [3217/6845 (47%)]\tLoss: 0.399951\n",
            "Train Epoch: 14 [3218/6845 (47%)]\tLoss: 0.126229\n",
            "Train Epoch: 14 [3219/6845 (47%)]\tLoss: 0.564293\n",
            "Train Epoch: 14 [3220/6845 (47%)]\tLoss: 0.088655\n",
            "Train Epoch: 14 [3221/6845 (47%)]\tLoss: 0.414357\n",
            "Train Epoch: 14 [3222/6845 (47%)]\tLoss: 0.085596\n",
            "Train Epoch: 14 [3223/6845 (47%)]\tLoss: 0.102905\n",
            "Train Epoch: 14 [3224/6845 (47%)]\tLoss: 0.094703\n",
            "Train Epoch: 14 [3225/6845 (47%)]\tLoss: 1.042796\n",
            "Train Epoch: 14 [3226/6845 (47%)]\tLoss: 0.624970\n",
            "Train Epoch: 14 [3227/6845 (47%)]\tLoss: 0.102137\n",
            "Train Epoch: 14 [3228/6845 (47%)]\tLoss: 0.112289\n",
            "Train Epoch: 14 [3229/6845 (47%)]\tLoss: 0.485608\n",
            "Train Epoch: 14 [3230/6845 (47%)]\tLoss: 0.791881\n",
            "Train Epoch: 14 [3231/6845 (47%)]\tLoss: 0.109209\n",
            "Train Epoch: 14 [3232/6845 (47%)]\tLoss: 0.108445\n",
            "Train Epoch: 14 [3233/6845 (47%)]\tLoss: 0.528024\n",
            "Train Epoch: 14 [3234/6845 (47%)]\tLoss: 0.117323\n",
            "Train Epoch: 14 [3235/6845 (47%)]\tLoss: 0.281126\n",
            "Train Epoch: 14 [3236/6845 (47%)]\tLoss: 0.098504\n",
            "Train Epoch: 14 [3237/6845 (47%)]\tLoss: 0.530388\n",
            "Train Epoch: 14 [3238/6845 (47%)]\tLoss: 0.067194\n",
            "Train Epoch: 14 [3239/6845 (47%)]\tLoss: 0.062113\n",
            "Train Epoch: 14 [3240/6845 (47%)]\tLoss: 0.169535\n",
            "Train Epoch: 14 [3241/6845 (47%)]\tLoss: 0.381685\n",
            "Train Epoch: 14 [3242/6845 (47%)]\tLoss: 0.065865\n",
            "Train Epoch: 14 [3243/6845 (47%)]\tLoss: 0.112868\n",
            "Train Epoch: 14 [3244/6845 (47%)]\tLoss: 0.107261\n",
            "Train Epoch: 14 [3245/6845 (47%)]\tLoss: 0.169996\n",
            "Train Epoch: 14 [3246/6845 (47%)]\tLoss: 0.666390\n",
            "Train Epoch: 14 [3247/6845 (47%)]\tLoss: 0.181449\n",
            "Train Epoch: 14 [3248/6845 (47%)]\tLoss: 0.121027\n",
            "Train Epoch: 14 [3249/6845 (47%)]\tLoss: 0.098064\n",
            "Train Epoch: 14 [3250/6845 (47%)]\tLoss: 0.088771\n",
            "Train Epoch: 14 [3251/6845 (47%)]\tLoss: 0.066334\n",
            "Train Epoch: 14 [3252/6845 (48%)]\tLoss: 0.110316\n",
            "Train Epoch: 14 [3253/6845 (48%)]\tLoss: 0.079701\n",
            "Train Epoch: 14 [3254/6845 (48%)]\tLoss: 0.091980\n",
            "Train Epoch: 14 [3255/6845 (48%)]\tLoss: 0.075603\n",
            "Train Epoch: 14 [3256/6845 (48%)]\tLoss: 0.094705\n",
            "Train Epoch: 14 [3257/6845 (48%)]\tLoss: 0.104437\n",
            "Train Epoch: 14 [3258/6845 (48%)]\tLoss: 0.084973\n",
            "Train Epoch: 14 [3259/6845 (48%)]\tLoss: 0.108413\n",
            "Train Epoch: 14 [3260/6845 (48%)]\tLoss: 0.237218\n",
            "Train Epoch: 14 [3261/6845 (48%)]\tLoss: 0.553903\n",
            "Train Epoch: 14 [3262/6845 (48%)]\tLoss: 1.018406\n",
            "Train Epoch: 14 [3263/6845 (48%)]\tLoss: 0.518458\n",
            "Train Epoch: 14 [3264/6845 (48%)]\tLoss: 0.086777\n",
            "Train Epoch: 14 [3265/6845 (48%)]\tLoss: 0.087638\n",
            "Train Epoch: 14 [3266/6845 (48%)]\tLoss: 0.234592\n",
            "Train Epoch: 14 [3267/6845 (48%)]\tLoss: 0.084035\n",
            "Train Epoch: 14 [3268/6845 (48%)]\tLoss: 0.252787\n",
            "Train Epoch: 14 [3269/6845 (48%)]\tLoss: 0.064370\n",
            "Train Epoch: 14 [3270/6845 (48%)]\tLoss: 0.088877\n",
            "Train Epoch: 14 [3271/6845 (48%)]\tLoss: 0.072344\n",
            "Train Epoch: 14 [3272/6845 (48%)]\tLoss: 0.238444\n",
            "Train Epoch: 14 [3273/6845 (48%)]\tLoss: 0.253100\n",
            "Train Epoch: 14 [3274/6845 (48%)]\tLoss: 0.110926\n",
            "Train Epoch: 14 [3275/6845 (48%)]\tLoss: 0.084322\n",
            "Train Epoch: 14 [3276/6845 (48%)]\tLoss: 0.167532\n",
            "Train Epoch: 14 [3277/6845 (48%)]\tLoss: 0.557890\n",
            "Train Epoch: 14 [3278/6845 (48%)]\tLoss: 0.148991\n",
            "Train Epoch: 14 [3279/6845 (48%)]\tLoss: 0.149654\n",
            "Train Epoch: 14 [3280/6845 (48%)]\tLoss: 0.709800\n",
            "Train Epoch: 14 [3281/6845 (48%)]\tLoss: 0.087647\n",
            "Train Epoch: 14 [3282/6845 (48%)]\tLoss: 0.093836\n",
            "Train Epoch: 14 [3283/6845 (48%)]\tLoss: 0.643670\n",
            "Train Epoch: 14 [3284/6845 (48%)]\tLoss: 0.206445\n",
            "Train Epoch: 14 [3285/6845 (48%)]\tLoss: 0.124286\n",
            "Train Epoch: 14 [3286/6845 (48%)]\tLoss: 0.114382\n",
            "Train Epoch: 14 [3287/6845 (48%)]\tLoss: 0.490908\n",
            "Train Epoch: 14 [3288/6845 (48%)]\tLoss: 0.773354\n",
            "Train Epoch: 14 [3289/6845 (48%)]\tLoss: 0.113531\n",
            "Train Epoch: 14 [3290/6845 (48%)]\tLoss: 0.108272\n",
            "Train Epoch: 14 [3291/6845 (48%)]\tLoss: 0.789521\n",
            "Train Epoch: 14 [3292/6845 (48%)]\tLoss: 0.765598\n",
            "Train Epoch: 14 [3293/6845 (48%)]\tLoss: 0.090295\n",
            "Train Epoch: 14 [3294/6845 (48%)]\tLoss: 0.551741\n",
            "Train Epoch: 14 [3295/6845 (48%)]\tLoss: 0.205773\n",
            "Train Epoch: 14 [3296/6845 (48%)]\tLoss: 0.491718\n",
            "Train Epoch: 14 [3297/6845 (48%)]\tLoss: 0.109815\n",
            "Train Epoch: 14 [3298/6845 (48%)]\tLoss: 0.075068\n",
            "Train Epoch: 14 [3299/6845 (48%)]\tLoss: 0.885950\n",
            "Train Epoch: 14 [3300/6845 (48%)]\tLoss: 0.126822\n",
            "Train Epoch: 14 [3301/6845 (48%)]\tLoss: 0.216106\n",
            "Train Epoch: 14 [3302/6845 (48%)]\tLoss: 0.647953\n",
            "Train Epoch: 14 [3303/6845 (48%)]\tLoss: 0.076383\n",
            "Train Epoch: 14 [3304/6845 (48%)]\tLoss: 0.071129\n",
            "Train Epoch: 14 [3305/6845 (48%)]\tLoss: 0.076487\n",
            "Train Epoch: 14 [3306/6845 (48%)]\tLoss: 0.079031\n",
            "Train Epoch: 14 [3307/6845 (48%)]\tLoss: 0.066121\n",
            "Train Epoch: 14 [3308/6845 (48%)]\tLoss: 0.201498\n",
            "Train Epoch: 14 [3309/6845 (48%)]\tLoss: 0.097502\n",
            "Train Epoch: 14 [3310/6845 (48%)]\tLoss: 0.125650\n",
            "Train Epoch: 14 [3311/6845 (48%)]\tLoss: 0.191216\n",
            "Train Epoch: 14 [3312/6845 (48%)]\tLoss: 0.170163\n",
            "Train Epoch: 14 [3313/6845 (48%)]\tLoss: 0.094131\n",
            "Train Epoch: 14 [3314/6845 (48%)]\tLoss: 0.242446\n",
            "Train Epoch: 14 [3315/6845 (48%)]\tLoss: 0.059930\n",
            "Train Epoch: 14 [3316/6845 (48%)]\tLoss: 0.055505\n",
            "Train Epoch: 14 [3317/6845 (48%)]\tLoss: 0.059074\n",
            "Train Epoch: 14 [3318/6845 (48%)]\tLoss: 0.078539\n",
            "Train Epoch: 14 [3319/6845 (48%)]\tLoss: 0.239738\n",
            "Train Epoch: 14 [3320/6845 (49%)]\tLoss: 0.046453\n",
            "Train Epoch: 14 [3321/6845 (49%)]\tLoss: 0.122776\n",
            "Train Epoch: 14 [3322/6845 (49%)]\tLoss: 0.096024\n",
            "Train Epoch: 14 [3323/6845 (49%)]\tLoss: 0.161487\n",
            "Train Epoch: 14 [3324/6845 (49%)]\tLoss: 0.063226\n",
            "Train Epoch: 14 [3325/6845 (49%)]\tLoss: 0.087682\n",
            "Train Epoch: 14 [3326/6845 (49%)]\tLoss: 0.084196\n",
            "Train Epoch: 14 [3327/6845 (49%)]\tLoss: 0.645095\n",
            "Train Epoch: 14 [3328/6845 (49%)]\tLoss: 0.617699\n",
            "Train Epoch: 14 [3329/6845 (49%)]\tLoss: 0.164681\n",
            "Train Epoch: 14 [3330/6845 (49%)]\tLoss: 0.090493\n",
            "Train Epoch: 14 [3331/6845 (49%)]\tLoss: 0.441950\n",
            "Train Epoch: 14 [3332/6845 (49%)]\tLoss: 0.045782\n",
            "Train Epoch: 14 [3333/6845 (49%)]\tLoss: 0.758291\n",
            "Train Epoch: 14 [3334/6845 (49%)]\tLoss: 0.485937\n",
            "Train Epoch: 14 [3335/6845 (49%)]\tLoss: 0.083271\n",
            "Train Epoch: 14 [3336/6845 (49%)]\tLoss: 0.835147\n",
            "Train Epoch: 14 [3337/6845 (49%)]\tLoss: 0.102797\n",
            "Train Epoch: 14 [3338/6845 (49%)]\tLoss: 0.087353\n",
            "Train Epoch: 14 [3339/6845 (49%)]\tLoss: 0.184142\n",
            "Train Epoch: 14 [3340/6845 (49%)]\tLoss: 0.592448\n",
            "Train Epoch: 14 [3341/6845 (49%)]\tLoss: 0.064571\n",
            "Train Epoch: 14 [3342/6845 (49%)]\tLoss: 0.072855\n",
            "Train Epoch: 14 [3343/6845 (49%)]\tLoss: 0.410516\n",
            "Train Epoch: 14 [3344/6845 (49%)]\tLoss: 0.095642\n",
            "Train Epoch: 14 [3345/6845 (49%)]\tLoss: 0.197632\n",
            "Train Epoch: 14 [3346/6845 (49%)]\tLoss: 0.206376\n",
            "Train Epoch: 14 [3347/6845 (49%)]\tLoss: 0.172092\n",
            "Train Epoch: 14 [3348/6845 (49%)]\tLoss: 0.147457\n",
            "Train Epoch: 14 [3349/6845 (49%)]\tLoss: 0.072850\n",
            "Train Epoch: 14 [3350/6845 (49%)]\tLoss: 0.095105\n",
            "Train Epoch: 14 [3351/6845 (49%)]\tLoss: 0.077919\n",
            "Train Epoch: 14 [3352/6845 (49%)]\tLoss: 0.181621\n",
            "Train Epoch: 14 [3353/6845 (49%)]\tLoss: 0.120461\n",
            "Train Epoch: 14 [3354/6845 (49%)]\tLoss: 0.114497\n",
            "Train Epoch: 14 [3355/6845 (49%)]\tLoss: 0.066280\n",
            "Train Epoch: 14 [3356/6845 (49%)]\tLoss: 0.072761\n",
            "Train Epoch: 14 [3357/6845 (49%)]\tLoss: 0.199935\n",
            "Train Epoch: 14 [3358/6845 (49%)]\tLoss: 0.640552\n",
            "Train Epoch: 14 [3359/6845 (49%)]\tLoss: 0.069584\n",
            "Train Epoch: 14 [3360/6845 (49%)]\tLoss: 0.112242\n",
            "Train Epoch: 14 [3361/6845 (49%)]\tLoss: 0.164596\n",
            "Train Epoch: 14 [3362/6845 (49%)]\tLoss: 0.128202\n",
            "Train Epoch: 14 [3363/6845 (49%)]\tLoss: 0.088230\n",
            "Train Epoch: 14 [3364/6845 (49%)]\tLoss: 0.082011\n",
            "Train Epoch: 14 [3365/6845 (49%)]\tLoss: 0.075850\n",
            "Train Epoch: 14 [3366/6845 (49%)]\tLoss: 0.631235\n",
            "Train Epoch: 14 [3367/6845 (49%)]\tLoss: 0.697947\n",
            "Train Epoch: 14 [3368/6845 (49%)]\tLoss: 0.201861\n",
            "Train Epoch: 14 [3369/6845 (49%)]\tLoss: 0.060111\n",
            "Train Epoch: 14 [3370/6845 (49%)]\tLoss: 0.128164\n",
            "Train Epoch: 14 [3371/6845 (49%)]\tLoss: 0.054621\n",
            "Train Epoch: 14 [3372/6845 (49%)]\tLoss: 0.056946\n",
            "Train Epoch: 14 [3373/6845 (49%)]\tLoss: 0.072738\n",
            "Train Epoch: 14 [3374/6845 (49%)]\tLoss: 0.206650\n",
            "Train Epoch: 14 [3375/6845 (49%)]\tLoss: 0.144252\n",
            "Train Epoch: 14 [3376/6845 (49%)]\tLoss: 0.061513\n",
            "Train Epoch: 14 [3377/6845 (49%)]\tLoss: 0.104559\n",
            "Train Epoch: 14 [3378/6845 (49%)]\tLoss: 0.090991\n",
            "Train Epoch: 14 [3379/6845 (49%)]\tLoss: 0.042033\n",
            "Train Epoch: 14 [3380/6845 (49%)]\tLoss: 0.101835\n",
            "Train Epoch: 14 [3381/6845 (49%)]\tLoss: 0.047032\n",
            "Train Epoch: 14 [3382/6845 (49%)]\tLoss: 0.619032\n",
            "Train Epoch: 14 [3383/6845 (49%)]\tLoss: 0.501869\n",
            "Train Epoch: 14 [3384/6845 (49%)]\tLoss: 0.051225\n",
            "Train Epoch: 14 [3385/6845 (49%)]\tLoss: 0.066438\n",
            "Train Epoch: 14 [3386/6845 (49%)]\tLoss: 0.667059\n",
            "Train Epoch: 14 [3387/6845 (49%)]\tLoss: 0.071828\n",
            "Train Epoch: 14 [3388/6845 (49%)]\tLoss: 0.755536\n",
            "Train Epoch: 14 [3389/6845 (50%)]\tLoss: 0.080024\n",
            "Train Epoch: 14 [3390/6845 (50%)]\tLoss: 0.090168\n",
            "Train Epoch: 14 [3391/6845 (50%)]\tLoss: 0.070106\n",
            "Train Epoch: 14 [3392/6845 (50%)]\tLoss: 0.054641\n",
            "Train Epoch: 14 [3393/6845 (50%)]\tLoss: 0.160814\n",
            "Train Epoch: 14 [3394/6845 (50%)]\tLoss: 0.061002\n",
            "Train Epoch: 14 [3395/6845 (50%)]\tLoss: 0.075251\n",
            "Train Epoch: 14 [3396/6845 (50%)]\tLoss: 0.630103\n",
            "Train Epoch: 14 [3397/6845 (50%)]\tLoss: 0.553162\n",
            "Train Epoch: 14 [3398/6845 (50%)]\tLoss: 0.093750\n",
            "Train Epoch: 14 [3399/6845 (50%)]\tLoss: 0.807530\n",
            "Train Epoch: 14 [3400/6845 (50%)]\tLoss: 0.628048\n",
            "Train Epoch: 14 [3401/6845 (50%)]\tLoss: 0.052358\n",
            "Train Epoch: 14 [3402/6845 (50%)]\tLoss: 1.279292\n",
            "Train Epoch: 14 [3403/6845 (50%)]\tLoss: 0.084069\n",
            "Train Epoch: 14 [3404/6845 (50%)]\tLoss: 0.061973\n",
            "Train Epoch: 14 [3405/6845 (50%)]\tLoss: 0.485388\n",
            "Train Epoch: 14 [3406/6845 (50%)]\tLoss: 0.609527\n",
            "Train Epoch: 14 [3407/6845 (50%)]\tLoss: 0.071215\n",
            "Train Epoch: 14 [3408/6845 (50%)]\tLoss: 0.088565\n",
            "Train Epoch: 14 [3409/6845 (50%)]\tLoss: 0.118655\n",
            "Train Epoch: 14 [3410/6845 (50%)]\tLoss: 0.079980\n",
            "Train Epoch: 14 [3411/6845 (50%)]\tLoss: 0.064268\n",
            "Train Epoch: 14 [3412/6845 (50%)]\tLoss: 0.064908\n",
            "Train Epoch: 14 [3413/6845 (50%)]\tLoss: 0.073235\n",
            "Train Epoch: 14 [3414/6845 (50%)]\tLoss: 0.465734\n",
            "Train Epoch: 14 [3415/6845 (50%)]\tLoss: 0.058941\n",
            "Train Epoch: 14 [3416/6845 (50%)]\tLoss: 0.082749\n",
            "Train Epoch: 14 [3417/6845 (50%)]\tLoss: 0.138607\n",
            "Train Epoch: 14 [3418/6845 (50%)]\tLoss: 0.096406\n",
            "Train Epoch: 14 [3419/6845 (50%)]\tLoss: 1.455097\n",
            "Train Epoch: 14 [3420/6845 (50%)]\tLoss: 0.079847\n",
            "Train Epoch: 14 [3421/6845 (50%)]\tLoss: 0.207246\n",
            "Train Epoch: 14 [3422/6845 (50%)]\tLoss: 0.497181\n",
            "Train Epoch: 14 [3423/6845 (50%)]\tLoss: 0.063527\n",
            "Train Epoch: 14 [3424/6845 (50%)]\tLoss: 0.173999\n",
            "Train Epoch: 14 [3425/6845 (50%)]\tLoss: 0.727301\n",
            "Train Epoch: 14 [3426/6845 (50%)]\tLoss: 0.117406\n",
            "Train Epoch: 14 [3427/6845 (50%)]\tLoss: 0.065924\n",
            "Train Epoch: 14 [3428/6845 (50%)]\tLoss: 0.416424\n",
            "Train Epoch: 14 [3429/6845 (50%)]\tLoss: 0.538954\n",
            "Train Epoch: 14 [3430/6845 (50%)]\tLoss: 0.087381\n",
            "Train Epoch: 14 [3431/6845 (50%)]\tLoss: 0.076705\n",
            "Train Epoch: 14 [3432/6845 (50%)]\tLoss: 0.070809\n",
            "Train Epoch: 14 [3433/6845 (50%)]\tLoss: 0.392395\n",
            "Train Epoch: 14 [3434/6845 (50%)]\tLoss: 0.081767\n",
            "Train Epoch: 14 [3435/6845 (50%)]\tLoss: 0.064806\n",
            "Train Epoch: 14 [3436/6845 (50%)]\tLoss: 0.063374\n",
            "Train Epoch: 14 [3437/6845 (50%)]\tLoss: 0.077795\n",
            "Train Epoch: 14 [3438/6845 (50%)]\tLoss: 1.077252\n",
            "Train Epoch: 14 [3439/6845 (50%)]\tLoss: 0.109050\n",
            "Train Epoch: 14 [3440/6845 (50%)]\tLoss: 1.074056\n",
            "Train Epoch: 14 [3441/6845 (50%)]\tLoss: 0.421313\n",
            "Train Epoch: 14 [3442/6845 (50%)]\tLoss: 0.069636\n",
            "Train Epoch: 14 [3443/6845 (50%)]\tLoss: 0.100297\n",
            "Train Epoch: 14 [3444/6845 (50%)]\tLoss: 0.246306\n",
            "Train Epoch: 14 [3445/6845 (50%)]\tLoss: 0.059009\n",
            "Train Epoch: 14 [3446/6845 (50%)]\tLoss: 0.104640\n",
            "Train Epoch: 14 [3447/6845 (50%)]\tLoss: 0.192549\n",
            "Train Epoch: 14 [3448/6845 (50%)]\tLoss: 0.186213\n",
            "Train Epoch: 14 [3449/6845 (50%)]\tLoss: 0.062155\n",
            "Train Epoch: 14 [3450/6845 (50%)]\tLoss: 0.096374\n",
            "Train Epoch: 14 [3451/6845 (50%)]\tLoss: 0.048391\n",
            "Train Epoch: 14 [3452/6845 (50%)]\tLoss: 0.414614\n",
            "Train Epoch: 14 [3453/6845 (50%)]\tLoss: 0.118838\n",
            "Train Epoch: 14 [3454/6845 (50%)]\tLoss: 0.893636\n",
            "Train Epoch: 14 [3455/6845 (50%)]\tLoss: 0.392988\n",
            "Train Epoch: 14 [3456/6845 (50%)]\tLoss: 0.123127\n",
            "Train Epoch: 14 [3457/6845 (51%)]\tLoss: 0.144313\n",
            "Train Epoch: 14 [3458/6845 (51%)]\tLoss: 0.108631\n",
            "Train Epoch: 14 [3459/6845 (51%)]\tLoss: 0.065159\n",
            "Train Epoch: 14 [3460/6845 (51%)]\tLoss: 0.106738\n",
            "Train Epoch: 14 [3461/6845 (51%)]\tLoss: 0.216907\n",
            "Train Epoch: 14 [3462/6845 (51%)]\tLoss: 0.101025\n",
            "Train Epoch: 14 [3463/6845 (51%)]\tLoss: 0.481831\n",
            "Train Epoch: 14 [3464/6845 (51%)]\tLoss: 0.817187\n",
            "Train Epoch: 14 [3465/6845 (51%)]\tLoss: 0.117718\n",
            "Train Epoch: 14 [3466/6845 (51%)]\tLoss: 0.065172\n",
            "Train Epoch: 14 [3467/6845 (51%)]\tLoss: 0.217377\n",
            "Train Epoch: 14 [3468/6845 (51%)]\tLoss: 0.058700\n",
            "Train Epoch: 14 [3469/6845 (51%)]\tLoss: 0.136297\n",
            "Train Epoch: 14 [3470/6845 (51%)]\tLoss: 0.061540\n",
            "Train Epoch: 14 [3471/6845 (51%)]\tLoss: 0.218369\n",
            "Train Epoch: 14 [3472/6845 (51%)]\tLoss: 0.728444\n",
            "Train Epoch: 14 [3473/6845 (51%)]\tLoss: 0.552814\n",
            "Train Epoch: 14 [3474/6845 (51%)]\tLoss: 0.220687\n",
            "Train Epoch: 14 [3475/6845 (51%)]\tLoss: 0.059374\n",
            "Train Epoch: 14 [3476/6845 (51%)]\tLoss: 1.100306\n",
            "Train Epoch: 14 [3477/6845 (51%)]\tLoss: 0.653565\n",
            "Train Epoch: 14 [3478/6845 (51%)]\tLoss: 0.988263\n",
            "Train Epoch: 14 [3479/6845 (51%)]\tLoss: 0.060489\n",
            "Train Epoch: 14 [3480/6845 (51%)]\tLoss: 0.816594\n",
            "Train Epoch: 14 [3481/6845 (51%)]\tLoss: 0.353721\n",
            "Train Epoch: 14 [3482/6845 (51%)]\tLoss: 0.116563\n",
            "Train Epoch: 14 [3483/6845 (51%)]\tLoss: 0.072376\n",
            "Train Epoch: 14 [3484/6845 (51%)]\tLoss: 0.513289\n",
            "Train Epoch: 14 [3485/6845 (51%)]\tLoss: 0.066330\n",
            "Train Epoch: 14 [3486/6845 (51%)]\tLoss: 0.082524\n",
            "Train Epoch: 14 [3487/6845 (51%)]\tLoss: 0.191243\n",
            "Train Epoch: 14 [3488/6845 (51%)]\tLoss: 0.167563\n",
            "Train Epoch: 14 [3489/6845 (51%)]\tLoss: 0.124201\n",
            "Train Epoch: 14 [3490/6845 (51%)]\tLoss: 0.197049\n",
            "Train Epoch: 14 [3491/6845 (51%)]\tLoss: 0.134654\n",
            "Train Epoch: 14 [3492/6845 (51%)]\tLoss: 0.526687\n",
            "Train Epoch: 14 [3493/6845 (51%)]\tLoss: 0.065234\n",
            "Train Epoch: 14 [3494/6845 (51%)]\tLoss: 0.594266\n",
            "Train Epoch: 14 [3495/6845 (51%)]\tLoss: 0.191490\n",
            "Train Epoch: 14 [3496/6845 (51%)]\tLoss: 0.231215\n",
            "Train Epoch: 14 [3497/6845 (51%)]\tLoss: 0.043518\n",
            "Train Epoch: 14 [3498/6845 (51%)]\tLoss: 0.073313\n",
            "Train Epoch: 14 [3499/6845 (51%)]\tLoss: 0.139896\n",
            "Train Epoch: 14 [3500/6845 (51%)]\tLoss: 0.057445\n",
            "Train Epoch: 14 [3501/6845 (51%)]\tLoss: 0.159442\n",
            "Train Epoch: 14 [3502/6845 (51%)]\tLoss: 0.723752\n",
            "Train Epoch: 14 [3503/6845 (51%)]\tLoss: 0.037878\n",
            "Train Epoch: 14 [3504/6845 (51%)]\tLoss: 0.160203\n",
            "Train Epoch: 14 [3505/6845 (51%)]\tLoss: 0.281411\n",
            "Train Epoch: 14 [3506/6845 (51%)]\tLoss: 1.412921\n",
            "Train Epoch: 14 [3507/6845 (51%)]\tLoss: 0.041164\n",
            "Train Epoch: 14 [3508/6845 (51%)]\tLoss: 0.147759\n",
            "Train Epoch: 14 [3509/6845 (51%)]\tLoss: 0.738167\n",
            "Train Epoch: 14 [3510/6845 (51%)]\tLoss: 0.129222\n",
            "Train Epoch: 14 [3511/6845 (51%)]\tLoss: 0.610004\n",
            "Train Epoch: 14 [3512/6845 (51%)]\tLoss: 0.261565\n",
            "Train Epoch: 14 [3513/6845 (51%)]\tLoss: 0.341015\n",
            "Train Epoch: 14 [3514/6845 (51%)]\tLoss: 0.211721\n",
            "Train Epoch: 14 [3515/6845 (51%)]\tLoss: 0.108628\n",
            "Train Epoch: 14 [3516/6845 (51%)]\tLoss: 0.275121\n",
            "Train Epoch: 14 [3517/6845 (51%)]\tLoss: 0.576684\n",
            "Train Epoch: 14 [3518/6845 (51%)]\tLoss: 0.096156\n",
            "Train Epoch: 14 [3519/6845 (51%)]\tLoss: 0.218347\n",
            "Train Epoch: 14 [3520/6845 (51%)]\tLoss: 0.257709\n",
            "Train Epoch: 14 [3521/6845 (51%)]\tLoss: 0.662932\n",
            "Train Epoch: 14 [3522/6845 (51%)]\tLoss: 0.490438\n",
            "Train Epoch: 14 [3523/6845 (51%)]\tLoss: 0.664207\n",
            "Train Epoch: 14 [3524/6845 (51%)]\tLoss: 0.086587\n",
            "Train Epoch: 14 [3525/6845 (51%)]\tLoss: 0.070312\n",
            "Train Epoch: 14 [3526/6845 (52%)]\tLoss: 0.064982\n",
            "Train Epoch: 14 [3527/6845 (52%)]\tLoss: 0.221415\n",
            "Train Epoch: 14 [3528/6845 (52%)]\tLoss: 0.095450\n",
            "Train Epoch: 14 [3529/6845 (52%)]\tLoss: 0.077964\n",
            "Train Epoch: 14 [3530/6845 (52%)]\tLoss: 0.697968\n",
            "Train Epoch: 14 [3531/6845 (52%)]\tLoss: 0.138796\n",
            "Train Epoch: 14 [3532/6845 (52%)]\tLoss: 0.506111\n",
            "Train Epoch: 14 [3533/6845 (52%)]\tLoss: 0.184922\n",
            "Train Epoch: 14 [3534/6845 (52%)]\tLoss: 0.481752\n",
            "Train Epoch: 14 [3535/6845 (52%)]\tLoss: 0.062355\n",
            "Train Epoch: 14 [3536/6845 (52%)]\tLoss: 0.053795\n",
            "Train Epoch: 14 [3537/6845 (52%)]\tLoss: 0.090363\n",
            "Train Epoch: 14 [3538/6845 (52%)]\tLoss: 0.117239\n",
            "Train Epoch: 14 [3539/6845 (52%)]\tLoss: 0.138498\n",
            "Train Epoch: 14 [3540/6845 (52%)]\tLoss: 0.051075\n",
            "Train Epoch: 14 [3541/6845 (52%)]\tLoss: 0.223118\n",
            "Train Epoch: 14 [3542/6845 (52%)]\tLoss: 0.137333\n",
            "Train Epoch: 14 [3543/6845 (52%)]\tLoss: 0.047866\n",
            "Train Epoch: 14 [3544/6845 (52%)]\tLoss: 0.049841\n",
            "Train Epoch: 14 [3545/6845 (52%)]\tLoss: 0.135559\n",
            "Train Epoch: 14 [3546/6845 (52%)]\tLoss: 0.043653\n",
            "Train Epoch: 14 [3547/6845 (52%)]\tLoss: 0.669380\n",
            "Train Epoch: 14 [3548/6845 (52%)]\tLoss: 0.642984\n",
            "Train Epoch: 14 [3549/6845 (52%)]\tLoss: 0.093607\n",
            "Train Epoch: 14 [3550/6845 (52%)]\tLoss: 0.121338\n",
            "Train Epoch: 14 [3551/6845 (52%)]\tLoss: 0.118036\n",
            "Train Epoch: 14 [3552/6845 (52%)]\tLoss: 0.149700\n",
            "Train Epoch: 14 [3553/6845 (52%)]\tLoss: 0.106051\n",
            "Train Epoch: 14 [3554/6845 (52%)]\tLoss: 0.183229\n",
            "Train Epoch: 14 [3555/6845 (52%)]\tLoss: 0.041025\n",
            "Train Epoch: 14 [3556/6845 (52%)]\tLoss: 0.137895\n",
            "Train Epoch: 14 [3557/6845 (52%)]\tLoss: 0.045658\n",
            "Train Epoch: 14 [3558/6845 (52%)]\tLoss: 0.041642\n",
            "Train Epoch: 14 [3559/6845 (52%)]\tLoss: 0.628942\n",
            "Train Epoch: 14 [3560/6845 (52%)]\tLoss: 0.272603\n",
            "Train Epoch: 14 [3561/6845 (52%)]\tLoss: 0.535378\n",
            "Train Epoch: 14 [3562/6845 (52%)]\tLoss: 0.043792\n",
            "Train Epoch: 14 [3563/6845 (52%)]\tLoss: 0.823492\n",
            "Train Epoch: 14 [3564/6845 (52%)]\tLoss: 0.100505\n",
            "Train Epoch: 14 [3565/6845 (52%)]\tLoss: 0.421512\n",
            "Train Epoch: 14 [3566/6845 (52%)]\tLoss: 0.141176\n",
            "Train Epoch: 14 [3567/6845 (52%)]\tLoss: 0.607831\n",
            "Train Epoch: 14 [3568/6845 (52%)]\tLoss: 0.094633\n",
            "Train Epoch: 14 [3569/6845 (52%)]\tLoss: 0.230782\n",
            "Train Epoch: 14 [3570/6845 (52%)]\tLoss: 0.104217\n",
            "Train Epoch: 14 [3571/6845 (52%)]\tLoss: 0.169887\n",
            "Train Epoch: 14 [3572/6845 (52%)]\tLoss: 0.121945\n",
            "Train Epoch: 14 [3573/6845 (52%)]\tLoss: 0.152595\n",
            "Train Epoch: 14 [3574/6845 (52%)]\tLoss: 0.124105\n",
            "Train Epoch: 14 [3575/6845 (52%)]\tLoss: 0.232784\n",
            "Train Epoch: 14 [3576/6845 (52%)]\tLoss: 0.340710\n",
            "Train Epoch: 14 [3577/6845 (52%)]\tLoss: 0.059762\n",
            "Train Epoch: 14 [3578/6845 (52%)]\tLoss: 0.122607\n",
            "Train Epoch: 14 [3579/6845 (52%)]\tLoss: 0.079315\n",
            "Train Epoch: 14 [3580/6845 (52%)]\tLoss: 0.213176\n",
            "Train Epoch: 14 [3581/6845 (52%)]\tLoss: 0.067634\n",
            "Train Epoch: 14 [3582/6845 (52%)]\tLoss: 0.562878\n",
            "Train Epoch: 14 [3583/6845 (52%)]\tLoss: 0.845728\n",
            "Train Epoch: 14 [3584/6845 (52%)]\tLoss: 0.083128\n",
            "Train Epoch: 14 [3585/6845 (52%)]\tLoss: 0.060245\n",
            "Train Epoch: 14 [3586/6845 (52%)]\tLoss: 0.059284\n",
            "Train Epoch: 14 [3587/6845 (52%)]\tLoss: 1.497152\n",
            "Train Epoch: 14 [3588/6845 (52%)]\tLoss: 0.052016\n",
            "Train Epoch: 14 [3589/6845 (52%)]\tLoss: 0.329973\n",
            "Train Epoch: 14 [3590/6845 (52%)]\tLoss: 0.090791\n",
            "Train Epoch: 14 [3591/6845 (52%)]\tLoss: 0.077806\n",
            "Train Epoch: 14 [3592/6845 (52%)]\tLoss: 0.046934\n",
            "Train Epoch: 14 [3593/6845 (52%)]\tLoss: 0.057450\n",
            "Train Epoch: 14 [3594/6845 (53%)]\tLoss: 0.422534\n",
            "Train Epoch: 14 [3595/6845 (53%)]\tLoss: 0.377169\n",
            "Train Epoch: 14 [3596/6845 (53%)]\tLoss: 0.224794\n",
            "Train Epoch: 14 [3597/6845 (53%)]\tLoss: 0.557335\n",
            "Train Epoch: 14 [3598/6845 (53%)]\tLoss: 0.059857\n",
            "Train Epoch: 14 [3599/6845 (53%)]\tLoss: 0.926838\n",
            "Train Epoch: 14 [3600/6845 (53%)]\tLoss: 0.071346\n",
            "Train Epoch: 14 [3601/6845 (53%)]\tLoss: 0.070577\n",
            "Train Epoch: 14 [3602/6845 (53%)]\tLoss: 0.190772\n",
            "Train Epoch: 14 [3603/6845 (53%)]\tLoss: 0.048741\n",
            "Train Epoch: 14 [3604/6845 (53%)]\tLoss: 0.047135\n",
            "Train Epoch: 14 [3605/6845 (53%)]\tLoss: 0.109552\n",
            "Train Epoch: 14 [3606/6845 (53%)]\tLoss: 0.046172\n",
            "Train Epoch: 14 [3607/6845 (53%)]\tLoss: 0.168044\n",
            "Train Epoch: 14 [3608/6845 (53%)]\tLoss: 0.112082\n",
            "Train Epoch: 14 [3609/6845 (53%)]\tLoss: 0.118826\n",
            "Train Epoch: 14 [3610/6845 (53%)]\tLoss: 0.069089\n",
            "Train Epoch: 14 [3611/6845 (53%)]\tLoss: 0.141665\n",
            "Train Epoch: 14 [3612/6845 (53%)]\tLoss: 0.167703\n",
            "Train Epoch: 14 [3613/6845 (53%)]\tLoss: 0.567615\n",
            "Train Epoch: 14 [3614/6845 (53%)]\tLoss: 0.520516\n",
            "Train Epoch: 14 [3615/6845 (53%)]\tLoss: 0.266998\n",
            "Train Epoch: 14 [3616/6845 (53%)]\tLoss: 0.050527\n",
            "Train Epoch: 14 [3617/6845 (53%)]\tLoss: 0.200542\n",
            "Train Epoch: 14 [3618/6845 (53%)]\tLoss: 0.177676\n",
            "Train Epoch: 14 [3619/6845 (53%)]\tLoss: 0.291770\n",
            "Train Epoch: 14 [3620/6845 (53%)]\tLoss: 0.085389\n",
            "Train Epoch: 14 [3621/6845 (53%)]\tLoss: 0.076247\n",
            "Train Epoch: 14 [3622/6845 (53%)]\tLoss: 0.699812\n",
            "Train Epoch: 14 [3623/6845 (53%)]\tLoss: 0.052937\n",
            "Train Epoch: 14 [3624/6845 (53%)]\tLoss: 0.050647\n",
            "Train Epoch: 14 [3625/6845 (53%)]\tLoss: 0.558745\n",
            "Train Epoch: 14 [3626/6845 (53%)]\tLoss: 0.094748\n",
            "Train Epoch: 14 [3627/6845 (53%)]\tLoss: 0.086201\n",
            "Train Epoch: 14 [3628/6845 (53%)]\tLoss: 0.147875\n",
            "Train Epoch: 14 [3629/6845 (53%)]\tLoss: 0.051457\n",
            "Train Epoch: 14 [3630/6845 (53%)]\tLoss: 0.138395\n",
            "Train Epoch: 14 [3631/6845 (53%)]\tLoss: 0.249996\n",
            "Train Epoch: 14 [3632/6845 (53%)]\tLoss: 0.174694\n",
            "Train Epoch: 14 [3633/6845 (53%)]\tLoss: 0.317251\n",
            "Train Epoch: 14 [3634/6845 (53%)]\tLoss: 0.050479\n",
            "Train Epoch: 14 [3635/6845 (53%)]\tLoss: 0.704329\n",
            "Train Epoch: 14 [3636/6845 (53%)]\tLoss: 0.065642\n",
            "Train Epoch: 14 [3637/6845 (53%)]\tLoss: 0.171224\n",
            "Train Epoch: 14 [3638/6845 (53%)]\tLoss: 0.212999\n",
            "Train Epoch: 14 [3639/6845 (53%)]\tLoss: 0.057404\n",
            "Train Epoch: 14 [3640/6845 (53%)]\tLoss: 0.636341\n",
            "Train Epoch: 14 [3641/6845 (53%)]\tLoss: 0.603171\n",
            "Train Epoch: 14 [3642/6845 (53%)]\tLoss: 0.068015\n",
            "Train Epoch: 14 [3643/6845 (53%)]\tLoss: 0.096730\n",
            "Train Epoch: 14 [3644/6845 (53%)]\tLoss: 0.081417\n",
            "Train Epoch: 14 [3645/6845 (53%)]\tLoss: 0.073870\n",
            "Train Epoch: 14 [3646/6845 (53%)]\tLoss: 0.057194\n",
            "Train Epoch: 14 [3647/6845 (53%)]\tLoss: 0.107420\n",
            "Train Epoch: 14 [3648/6845 (53%)]\tLoss: 0.099080\n",
            "Train Epoch: 14 [3649/6845 (53%)]\tLoss: 0.069959\n",
            "Train Epoch: 14 [3650/6845 (53%)]\tLoss: 0.038849\n",
            "Train Epoch: 14 [3651/6845 (53%)]\tLoss: 0.100599\n",
            "Train Epoch: 14 [3652/6845 (53%)]\tLoss: 1.058973\n",
            "Train Epoch: 14 [3653/6845 (53%)]\tLoss: 1.170812\n",
            "Train Epoch: 14 [3654/6845 (53%)]\tLoss: 0.068126\n",
            "Train Epoch: 14 [3655/6845 (53%)]\tLoss: 0.178618\n",
            "Train Epoch: 14 [3656/6845 (53%)]\tLoss: 0.047282\n",
            "Train Epoch: 14 [3657/6845 (53%)]\tLoss: 0.155549\n",
            "Train Epoch: 14 [3658/6845 (53%)]\tLoss: 0.668197\n",
            "Train Epoch: 14 [3659/6845 (53%)]\tLoss: 0.040067\n",
            "Train Epoch: 14 [3660/6845 (53%)]\tLoss: 0.200392\n",
            "Train Epoch: 14 [3661/6845 (53%)]\tLoss: 0.159285\n",
            "Train Epoch: 14 [3662/6845 (53%)]\tLoss: 0.048838\n",
            "Train Epoch: 14 [3663/6845 (54%)]\tLoss: 0.135177\n",
            "Train Epoch: 14 [3664/6845 (54%)]\tLoss: 0.143448\n",
            "Train Epoch: 14 [3665/6845 (54%)]\tLoss: 0.205765\n",
            "Train Epoch: 14 [3666/6845 (54%)]\tLoss: 0.097837\n",
            "Train Epoch: 14 [3667/6845 (54%)]\tLoss: 0.119254\n",
            "Train Epoch: 14 [3668/6845 (54%)]\tLoss: 0.161731\n",
            "Train Epoch: 14 [3669/6845 (54%)]\tLoss: 0.044584\n",
            "Train Epoch: 14 [3670/6845 (54%)]\tLoss: 0.097339\n",
            "Train Epoch: 14 [3671/6845 (54%)]\tLoss: 0.112513\n",
            "Train Epoch: 14 [3672/6845 (54%)]\tLoss: 0.079731\n",
            "Train Epoch: 14 [3673/6845 (54%)]\tLoss: 0.087239\n",
            "Train Epoch: 14 [3674/6845 (54%)]\tLoss: 0.112371\n",
            "Train Epoch: 14 [3675/6845 (54%)]\tLoss: 0.334110\n",
            "Train Epoch: 14 [3676/6845 (54%)]\tLoss: 0.137651\n",
            "Train Epoch: 14 [3677/6845 (54%)]\tLoss: 0.058919\n",
            "Train Epoch: 14 [3678/6845 (54%)]\tLoss: 0.575940\n",
            "Train Epoch: 14 [3679/6845 (54%)]\tLoss: 0.616316\n",
            "Train Epoch: 14 [3680/6845 (54%)]\tLoss: 0.116654\n",
            "Train Epoch: 14 [3681/6845 (54%)]\tLoss: 0.172447\n",
            "Train Epoch: 14 [3682/6845 (54%)]\tLoss: 0.197012\n",
            "Train Epoch: 14 [3683/6845 (54%)]\tLoss: 0.172034\n",
            "Train Epoch: 14 [3684/6845 (54%)]\tLoss: 0.097918\n",
            "Train Epoch: 14 [3685/6845 (54%)]\tLoss: 0.209428\n",
            "Train Epoch: 14 [3686/6845 (54%)]\tLoss: 0.099752\n",
            "Train Epoch: 14 [3687/6845 (54%)]\tLoss: 0.086785\n",
            "Train Epoch: 14 [3688/6845 (54%)]\tLoss: 0.052132\n",
            "Train Epoch: 14 [3689/6845 (54%)]\tLoss: 0.913670\n",
            "Train Epoch: 14 [3690/6845 (54%)]\tLoss: 0.123739\n",
            "Train Epoch: 14 [3691/6845 (54%)]\tLoss: 0.926233\n",
            "Train Epoch: 14 [3692/6845 (54%)]\tLoss: 0.069993\n",
            "Train Epoch: 14 [3693/6845 (54%)]\tLoss: 0.054909\n",
            "Train Epoch: 14 [3694/6845 (54%)]\tLoss: 0.114214\n",
            "Train Epoch: 14 [3695/6845 (54%)]\tLoss: 0.151841\n",
            "Train Epoch: 14 [3696/6845 (54%)]\tLoss: 0.058362\n",
            "Train Epoch: 14 [3697/6845 (54%)]\tLoss: 0.116128\n",
            "Train Epoch: 14 [3698/6845 (54%)]\tLoss: 0.124115\n",
            "Train Epoch: 14 [3699/6845 (54%)]\tLoss: 0.112471\n",
            "Train Epoch: 14 [3700/6845 (54%)]\tLoss: 0.053588\n",
            "Train Epoch: 14 [3701/6845 (54%)]\tLoss: 0.058395\n",
            "Train Epoch: 14 [3702/6845 (54%)]\tLoss: 0.060273\n",
            "Train Epoch: 14 [3703/6845 (54%)]\tLoss: 0.089850\n",
            "Train Epoch: 14 [3704/6845 (54%)]\tLoss: 0.169007\n",
            "Train Epoch: 14 [3705/6845 (54%)]\tLoss: 0.167492\n",
            "Train Epoch: 14 [3706/6845 (54%)]\tLoss: 0.066495\n",
            "Train Epoch: 14 [3707/6845 (54%)]\tLoss: 0.092459\n",
            "Train Epoch: 14 [3708/6845 (54%)]\tLoss: 0.065201\n",
            "Train Epoch: 14 [3709/6845 (54%)]\tLoss: 0.041619\n",
            "Train Epoch: 14 [3710/6845 (54%)]\tLoss: 0.147452\n",
            "Train Epoch: 14 [3711/6845 (54%)]\tLoss: 0.063317\n",
            "Train Epoch: 14 [3712/6845 (54%)]\tLoss: 0.596108\n",
            "Train Epoch: 14 [3713/6845 (54%)]\tLoss: 0.050152\n",
            "Train Epoch: 14 [3714/6845 (54%)]\tLoss: 0.684912\n",
            "Train Epoch: 14 [3715/6845 (54%)]\tLoss: 0.051724\n",
            "Train Epoch: 14 [3716/6845 (54%)]\tLoss: 0.176866\n",
            "Train Epoch: 14 [3717/6845 (54%)]\tLoss: 0.486556\n",
            "Train Epoch: 14 [3718/6845 (54%)]\tLoss: 0.080608\n",
            "Train Epoch: 14 [3719/6845 (54%)]\tLoss: 0.113564\n",
            "Train Epoch: 14 [3720/6845 (54%)]\tLoss: 0.165903\n",
            "Train Epoch: 14 [3721/6845 (54%)]\tLoss: 0.028920\n",
            "Train Epoch: 14 [3722/6845 (54%)]\tLoss: 0.040082\n",
            "Train Epoch: 14 [3723/6845 (54%)]\tLoss: 0.029297\n",
            "Train Epoch: 14 [3724/6845 (54%)]\tLoss: 0.704861\n",
            "Train Epoch: 14 [3725/6845 (54%)]\tLoss: 0.713079\n",
            "Train Epoch: 14 [3726/6845 (54%)]\tLoss: 0.024855\n",
            "Train Epoch: 14 [3727/6845 (54%)]\tLoss: 0.896701\n",
            "Train Epoch: 14 [3728/6845 (54%)]\tLoss: 0.118931\n",
            "Train Epoch: 14 [3729/6845 (54%)]\tLoss: 0.097006\n",
            "Train Epoch: 14 [3730/6845 (54%)]\tLoss: 0.054849\n",
            "Train Epoch: 14 [3731/6845 (55%)]\tLoss: 0.095085\n",
            "Train Epoch: 14 [3732/6845 (55%)]\tLoss: 0.083784\n",
            "Train Epoch: 14 [3733/6845 (55%)]\tLoss: 0.715856\n",
            "Train Epoch: 14 [3734/6845 (55%)]\tLoss: 0.400405\n",
            "Train Epoch: 14 [3735/6845 (55%)]\tLoss: 0.604870\n",
            "Train Epoch: 14 [3736/6845 (55%)]\tLoss: 0.378796\n",
            "Train Epoch: 14 [3737/6845 (55%)]\tLoss: 0.045988\n",
            "Train Epoch: 14 [3738/6845 (55%)]\tLoss: 0.562869\n",
            "Train Epoch: 14 [3739/6845 (55%)]\tLoss: 0.857773\n",
            "Train Epoch: 14 [3740/6845 (55%)]\tLoss: 0.109939\n",
            "Train Epoch: 14 [3741/6845 (55%)]\tLoss: 0.113227\n",
            "Train Epoch: 14 [3742/6845 (55%)]\tLoss: 0.088037\n",
            "Train Epoch: 14 [3743/6845 (55%)]\tLoss: 0.062152\n",
            "Train Epoch: 14 [3744/6845 (55%)]\tLoss: 0.059482\n",
            "Train Epoch: 14 [3745/6845 (55%)]\tLoss: 0.146428\n",
            "Train Epoch: 14 [3746/6845 (55%)]\tLoss: 0.166506\n",
            "Train Epoch: 14 [3747/6845 (55%)]\tLoss: 0.186244\n",
            "Train Epoch: 14 [3748/6845 (55%)]\tLoss: 0.040400\n",
            "Train Epoch: 14 [3749/6845 (55%)]\tLoss: 0.558864\n",
            "Train Epoch: 14 [3750/6845 (55%)]\tLoss: 0.039439\n",
            "Train Epoch: 14 [3751/6845 (55%)]\tLoss: 0.043407\n",
            "Train Epoch: 14 [3752/6845 (55%)]\tLoss: 0.922415\n",
            "Train Epoch: 14 [3753/6845 (55%)]\tLoss: 0.564579\n",
            "Train Epoch: 14 [3754/6845 (55%)]\tLoss: 0.092868\n",
            "Train Epoch: 14 [3755/6845 (55%)]\tLoss: 0.036789\n",
            "Train Epoch: 14 [3756/6845 (55%)]\tLoss: 0.070295\n",
            "Train Epoch: 14 [3757/6845 (55%)]\tLoss: 0.118062\n",
            "Train Epoch: 14 [3758/6845 (55%)]\tLoss: 0.401303\n",
            "Train Epoch: 14 [3759/6845 (55%)]\tLoss: 0.053264\n",
            "Train Epoch: 14 [3760/6845 (55%)]\tLoss: 0.098446\n",
            "Train Epoch: 14 [3761/6845 (55%)]\tLoss: 0.118992\n",
            "Train Epoch: 14 [3762/6845 (55%)]\tLoss: 0.161282\n",
            "Train Epoch: 14 [3763/6845 (55%)]\tLoss: 0.112145\n",
            "Train Epoch: 14 [3764/6845 (55%)]\tLoss: 0.115702\n",
            "Train Epoch: 14 [3765/6845 (55%)]\tLoss: 0.195958\n",
            "Train Epoch: 14 [3766/6845 (55%)]\tLoss: 0.569325\n",
            "Train Epoch: 14 [3767/6845 (55%)]\tLoss: 0.150307\n",
            "Train Epoch: 14 [3768/6845 (55%)]\tLoss: 0.110681\n",
            "Train Epoch: 14 [3769/6845 (55%)]\tLoss: 0.164675\n",
            "Train Epoch: 14 [3770/6845 (55%)]\tLoss: 0.511863\n",
            "Train Epoch: 14 [3771/6845 (55%)]\tLoss: 0.811365\n",
            "Train Epoch: 14 [3772/6845 (55%)]\tLoss: 0.684973\n",
            "Train Epoch: 14 [3773/6845 (55%)]\tLoss: 0.504562\n",
            "Train Epoch: 14 [3774/6845 (55%)]\tLoss: 0.343694\n",
            "Train Epoch: 14 [3775/6845 (55%)]\tLoss: 0.083071\n",
            "Train Epoch: 14 [3776/6845 (55%)]\tLoss: 0.380933\n",
            "Train Epoch: 14 [3777/6845 (55%)]\tLoss: 0.105279\n",
            "Train Epoch: 14 [3778/6845 (55%)]\tLoss: 0.592728\n",
            "Train Epoch: 14 [3779/6845 (55%)]\tLoss: 0.465580\n",
            "Train Epoch: 14 [3780/6845 (55%)]\tLoss: 0.243027\n",
            "Train Epoch: 14 [3781/6845 (55%)]\tLoss: 0.091540\n",
            "Train Epoch: 14 [3782/6845 (55%)]\tLoss: 0.180447\n",
            "Train Epoch: 14 [3783/6845 (55%)]\tLoss: 0.757794\n",
            "Train Epoch: 14 [3784/6845 (55%)]\tLoss: 0.359088\n",
            "Train Epoch: 14 [3785/6845 (55%)]\tLoss: 0.082569\n",
            "Train Epoch: 14 [3786/6845 (55%)]\tLoss: 0.145845\n",
            "Train Epoch: 14 [3787/6845 (55%)]\tLoss: 0.233944\n",
            "Train Epoch: 14 [3788/6845 (55%)]\tLoss: 0.267956\n",
            "Train Epoch: 14 [3789/6845 (55%)]\tLoss: 0.714998\n",
            "Train Epoch: 14 [3790/6845 (55%)]\tLoss: 0.085505\n",
            "Train Epoch: 14 [3791/6845 (55%)]\tLoss: 0.075683\n",
            "Train Epoch: 14 [3792/6845 (55%)]\tLoss: 0.415634\n",
            "Train Epoch: 14 [3793/6845 (55%)]\tLoss: 0.116861\n",
            "Train Epoch: 14 [3794/6845 (55%)]\tLoss: 0.070060\n",
            "Train Epoch: 14 [3795/6845 (55%)]\tLoss: 0.152288\n",
            "Train Epoch: 14 [3796/6845 (55%)]\tLoss: 0.112983\n",
            "Train Epoch: 14 [3797/6845 (55%)]\tLoss: 0.681751\n",
            "Train Epoch: 14 [3798/6845 (55%)]\tLoss: 0.186761\n",
            "Train Epoch: 14 [3799/6845 (56%)]\tLoss: 0.183319\n",
            "Train Epoch: 14 [3800/6845 (56%)]\tLoss: 0.126778\n",
            "Train Epoch: 14 [3801/6845 (56%)]\tLoss: 0.196630\n",
            "Train Epoch: 14 [3802/6845 (56%)]\tLoss: 0.100191\n",
            "Train Epoch: 14 [3803/6845 (56%)]\tLoss: 0.099734\n",
            "Train Epoch: 14 [3804/6845 (56%)]\tLoss: 0.300364\n",
            "Train Epoch: 14 [3805/6845 (56%)]\tLoss: 0.076870\n",
            "Train Epoch: 14 [3806/6845 (56%)]\tLoss: 0.641015\n",
            "Train Epoch: 14 [3807/6845 (56%)]\tLoss: 0.184545\n",
            "Train Epoch: 14 [3808/6845 (56%)]\tLoss: 0.270254\n",
            "Train Epoch: 14 [3809/6845 (56%)]\tLoss: 0.106282\n",
            "Train Epoch: 14 [3810/6845 (56%)]\tLoss: 0.127829\n",
            "Train Epoch: 14 [3811/6845 (56%)]\tLoss: 0.077636\n",
            "Train Epoch: 14 [3812/6845 (56%)]\tLoss: 1.414003\n",
            "Train Epoch: 14 [3813/6845 (56%)]\tLoss: 0.109282\n",
            "Train Epoch: 14 [3814/6845 (56%)]\tLoss: 0.084073\n",
            "Train Epoch: 14 [3815/6845 (56%)]\tLoss: 0.256610\n",
            "Train Epoch: 14 [3816/6845 (56%)]\tLoss: 0.096425\n",
            "Train Epoch: 14 [3817/6845 (56%)]\tLoss: 0.714701\n",
            "Train Epoch: 14 [3818/6845 (56%)]\tLoss: 1.040663\n",
            "Train Epoch: 14 [3819/6845 (56%)]\tLoss: 0.151535\n",
            "Train Epoch: 14 [3820/6845 (56%)]\tLoss: 0.094589\n",
            "Train Epoch: 14 [3821/6845 (56%)]\tLoss: 0.459258\n",
            "Train Epoch: 14 [3822/6845 (56%)]\tLoss: 0.147552\n",
            "Train Epoch: 14 [3823/6845 (56%)]\tLoss: 0.091312\n",
            "Train Epoch: 14 [3824/6845 (56%)]\tLoss: 0.081462\n",
            "Train Epoch: 14 [3825/6845 (56%)]\tLoss: 0.094618\n",
            "Train Epoch: 14 [3826/6845 (56%)]\tLoss: 0.116761\n",
            "Train Epoch: 14 [3827/6845 (56%)]\tLoss: 0.062757\n",
            "Train Epoch: 14 [3828/6845 (56%)]\tLoss: 0.101191\n",
            "Train Epoch: 14 [3829/6845 (56%)]\tLoss: 0.279221\n",
            "Train Epoch: 14 [3830/6845 (56%)]\tLoss: 0.541382\n",
            "Train Epoch: 14 [3831/6845 (56%)]\tLoss: 0.559016\n",
            "Train Epoch: 14 [3832/6845 (56%)]\tLoss: 0.110646\n",
            "Train Epoch: 14 [3833/6845 (56%)]\tLoss: 0.053565\n",
            "Train Epoch: 14 [3834/6845 (56%)]\tLoss: 0.060656\n",
            "Train Epoch: 14 [3835/6845 (56%)]\tLoss: 0.059884\n",
            "Train Epoch: 14 [3836/6845 (56%)]\tLoss: 0.611446\n",
            "Train Epoch: 14 [3837/6845 (56%)]\tLoss: 0.106723\n",
            "Train Epoch: 14 [3838/6845 (56%)]\tLoss: 0.124405\n",
            "Train Epoch: 14 [3839/6845 (56%)]\tLoss: 0.272036\n",
            "Train Epoch: 14 [3840/6845 (56%)]\tLoss: 0.058814\n",
            "Train Epoch: 14 [3841/6845 (56%)]\tLoss: 0.057462\n",
            "Train Epoch: 14 [3842/6845 (56%)]\tLoss: 0.107931\n",
            "Train Epoch: 14 [3843/6845 (56%)]\tLoss: 0.858120\n",
            "Train Epoch: 14 [3844/6845 (56%)]\tLoss: 0.100923\n",
            "Train Epoch: 14 [3845/6845 (56%)]\tLoss: 0.165938\n",
            "Train Epoch: 14 [3846/6845 (56%)]\tLoss: 0.120810\n",
            "Train Epoch: 14 [3847/6845 (56%)]\tLoss: 0.425263\n",
            "Train Epoch: 14 [3848/6845 (56%)]\tLoss: 0.106718\n",
            "Train Epoch: 14 [3849/6845 (56%)]\tLoss: 0.164559\n",
            "Train Epoch: 14 [3850/6845 (56%)]\tLoss: 0.103414\n",
            "Train Epoch: 14 [3851/6845 (56%)]\tLoss: 0.192020\n",
            "Train Epoch: 14 [3852/6845 (56%)]\tLoss: 0.053585\n",
            "Train Epoch: 14 [3853/6845 (56%)]\tLoss: 0.261396\n",
            "Train Epoch: 14 [3854/6845 (56%)]\tLoss: 0.094302\n",
            "Train Epoch: 14 [3855/6845 (56%)]\tLoss: 0.502762\n",
            "Train Epoch: 14 [3856/6845 (56%)]\tLoss: 0.108094\n",
            "Train Epoch: 14 [3857/6845 (56%)]\tLoss: 0.095884\n",
            "Train Epoch: 14 [3858/6845 (56%)]\tLoss: 0.598423\n",
            "Train Epoch: 14 [3859/6845 (56%)]\tLoss: 0.143842\n",
            "Train Epoch: 14 [3860/6845 (56%)]\tLoss: 0.137018\n",
            "Train Epoch: 14 [3861/6845 (56%)]\tLoss: 0.110934\n",
            "Train Epoch: 14 [3862/6845 (56%)]\tLoss: 0.106953\n",
            "Train Epoch: 14 [3863/6845 (56%)]\tLoss: 0.640538\n",
            "Train Epoch: 14 [3864/6845 (56%)]\tLoss: 0.149022\n",
            "Train Epoch: 14 [3865/6845 (56%)]\tLoss: 0.081063\n",
            "Train Epoch: 14 [3866/6845 (56%)]\tLoss: 0.052305\n",
            "Train Epoch: 14 [3867/6845 (56%)]\tLoss: 0.088062\n",
            "Train Epoch: 14 [3868/6845 (57%)]\tLoss: 0.101018\n",
            "Train Epoch: 14 [3869/6845 (57%)]\tLoss: 0.248592\n",
            "Train Epoch: 14 [3870/6845 (57%)]\tLoss: 0.156501\n",
            "Train Epoch: 14 [3871/6845 (57%)]\tLoss: 0.143987\n",
            "Train Epoch: 14 [3872/6845 (57%)]\tLoss: 0.101508\n",
            "Train Epoch: 14 [3873/6845 (57%)]\tLoss: 0.114939\n",
            "Train Epoch: 14 [3874/6845 (57%)]\tLoss: 0.093354\n",
            "Train Epoch: 14 [3875/6845 (57%)]\tLoss: 0.430062\n",
            "Train Epoch: 14 [3876/6845 (57%)]\tLoss: 0.114020\n",
            "Train Epoch: 14 [3877/6845 (57%)]\tLoss: 0.074373\n",
            "Train Epoch: 14 [3878/6845 (57%)]\tLoss: 0.143460\n",
            "Train Epoch: 14 [3879/6845 (57%)]\tLoss: 0.053164\n",
            "Train Epoch: 14 [3880/6845 (57%)]\tLoss: 0.087269\n",
            "Train Epoch: 14 [3881/6845 (57%)]\tLoss: 0.041528\n",
            "Train Epoch: 14 [3882/6845 (57%)]\tLoss: 0.037995\n",
            "Train Epoch: 14 [3883/6845 (57%)]\tLoss: 0.101284\n",
            "Train Epoch: 14 [3884/6845 (57%)]\tLoss: 0.181882\n",
            "Train Epoch: 14 [3885/6845 (57%)]\tLoss: 0.038513\n",
            "Train Epoch: 14 [3886/6845 (57%)]\tLoss: 0.066585\n",
            "Train Epoch: 14 [3887/6845 (57%)]\tLoss: 0.176496\n",
            "Train Epoch: 14 [3888/6845 (57%)]\tLoss: 0.192874\n",
            "Train Epoch: 14 [3889/6845 (57%)]\tLoss: 0.060098\n",
            "Train Epoch: 14 [3890/6845 (57%)]\tLoss: 0.430950\n",
            "Train Epoch: 14 [3891/6845 (57%)]\tLoss: 0.102912\n",
            "Train Epoch: 14 [3892/6845 (57%)]\tLoss: 0.108936\n",
            "Train Epoch: 14 [3893/6845 (57%)]\tLoss: 0.097372\n",
            "Train Epoch: 14 [3894/6845 (57%)]\tLoss: 0.426561\n",
            "Train Epoch: 14 [3895/6845 (57%)]\tLoss: 0.033469\n",
            "Train Epoch: 14 [3896/6845 (57%)]\tLoss: 0.037567\n",
            "Train Epoch: 14 [3897/6845 (57%)]\tLoss: 0.031994\n",
            "Train Epoch: 14 [3898/6845 (57%)]\tLoss: 0.423401\n",
            "Train Epoch: 14 [3899/6845 (57%)]\tLoss: 0.036096\n",
            "Train Epoch: 14 [3900/6845 (57%)]\tLoss: 0.828662\n",
            "Train Epoch: 14 [3901/6845 (57%)]\tLoss: 0.464166\n",
            "Train Epoch: 14 [3902/6845 (57%)]\tLoss: 0.159957\n",
            "Train Epoch: 14 [3903/6845 (57%)]\tLoss: 0.244516\n",
            "Train Epoch: 14 [3904/6845 (57%)]\tLoss: 0.024037\n",
            "Train Epoch: 14 [3905/6845 (57%)]\tLoss: 0.124214\n",
            "Train Epoch: 14 [3906/6845 (57%)]\tLoss: 0.132854\n",
            "Train Epoch: 14 [3907/6845 (57%)]\tLoss: 0.091242\n",
            "Train Epoch: 14 [3908/6845 (57%)]\tLoss: 0.193403\n",
            "Train Epoch: 14 [3909/6845 (57%)]\tLoss: 0.104687\n",
            "Train Epoch: 14 [3910/6845 (57%)]\tLoss: 0.046174\n",
            "Train Epoch: 14 [3911/6845 (57%)]\tLoss: 0.043816\n",
            "Train Epoch: 14 [3912/6845 (57%)]\tLoss: 0.029925\n",
            "Train Epoch: 14 [3913/6845 (57%)]\tLoss: 0.143151\n",
            "Train Epoch: 14 [3914/6845 (57%)]\tLoss: 0.026100\n",
            "Train Epoch: 14 [3915/6845 (57%)]\tLoss: 0.724463\n",
            "Train Epoch: 14 [3916/6845 (57%)]\tLoss: 0.050783\n",
            "Train Epoch: 14 [3917/6845 (57%)]\tLoss: 0.038882\n",
            "Train Epoch: 14 [3918/6845 (57%)]\tLoss: 0.028751\n",
            "Train Epoch: 14 [3919/6845 (57%)]\tLoss: 0.192622\n",
            "Train Epoch: 14 [3920/6845 (57%)]\tLoss: 0.689523\n",
            "Train Epoch: 14 [3921/6845 (57%)]\tLoss: 0.141326\n",
            "Train Epoch: 14 [3922/6845 (57%)]\tLoss: 0.067329\n",
            "Train Epoch: 14 [3923/6845 (57%)]\tLoss: 0.166245\n",
            "Train Epoch: 14 [3924/6845 (57%)]\tLoss: 0.754333\n",
            "Train Epoch: 14 [3925/6845 (57%)]\tLoss: 0.990214\n",
            "Train Epoch: 14 [3926/6845 (57%)]\tLoss: 0.697875\n",
            "Train Epoch: 14 [3927/6845 (57%)]\tLoss: 0.136275\n",
            "Train Epoch: 14 [3928/6845 (57%)]\tLoss: 1.553597\n",
            "Train Epoch: 14 [3929/6845 (57%)]\tLoss: 0.103086\n",
            "Train Epoch: 14 [3930/6845 (57%)]\tLoss: 0.148508\n",
            "Train Epoch: 14 [3931/6845 (57%)]\tLoss: 0.156314\n",
            "Train Epoch: 14 [3932/6845 (57%)]\tLoss: 0.089690\n",
            "Train Epoch: 14 [3933/6845 (57%)]\tLoss: 0.070527\n",
            "Train Epoch: 14 [3934/6845 (57%)]\tLoss: 0.147237\n",
            "Train Epoch: 14 [3935/6845 (57%)]\tLoss: 0.075858\n",
            "Train Epoch: 14 [3936/6845 (58%)]\tLoss: 0.185568\n",
            "Train Epoch: 14 [3937/6845 (58%)]\tLoss: 0.073968\n",
            "Train Epoch: 14 [3938/6845 (58%)]\tLoss: 0.073911\n",
            "Train Epoch: 14 [3939/6845 (58%)]\tLoss: 1.393595\n",
            "Train Epoch: 14 [3940/6845 (58%)]\tLoss: 0.108701\n",
            "Train Epoch: 14 [3941/6845 (58%)]\tLoss: 0.145387\n",
            "Train Epoch: 14 [3942/6845 (58%)]\tLoss: 0.103911\n",
            "Train Epoch: 14 [3943/6845 (58%)]\tLoss: 0.072772\n",
            "Train Epoch: 14 [3944/6845 (58%)]\tLoss: 0.054228\n",
            "Train Epoch: 14 [3945/6845 (58%)]\tLoss: 0.593807\n",
            "Train Epoch: 14 [3946/6845 (58%)]\tLoss: 0.056276\n",
            "Train Epoch: 14 [3947/6845 (58%)]\tLoss: 0.652261\n",
            "Train Epoch: 14 [3948/6845 (58%)]\tLoss: 0.544012\n",
            "Train Epoch: 14 [3949/6845 (58%)]\tLoss: 0.071296\n",
            "Train Epoch: 14 [3950/6845 (58%)]\tLoss: 0.982497\n",
            "Train Epoch: 14 [3951/6845 (58%)]\tLoss: 0.598043\n",
            "Train Epoch: 14 [3952/6845 (58%)]\tLoss: 0.187384\n",
            "Train Epoch: 14 [3953/6845 (58%)]\tLoss: 0.103257\n",
            "Train Epoch: 14 [3954/6845 (58%)]\tLoss: 0.153643\n",
            "Train Epoch: 14 [3955/6845 (58%)]\tLoss: 0.909116\n",
            "Train Epoch: 14 [3956/6845 (58%)]\tLoss: 0.076283\n",
            "Train Epoch: 14 [3957/6845 (58%)]\tLoss: 0.065278\n",
            "Train Epoch: 14 [3958/6845 (58%)]\tLoss: 0.141406\n",
            "Train Epoch: 14 [3959/6845 (58%)]\tLoss: 1.021528\n",
            "Train Epoch: 14 [3960/6845 (58%)]\tLoss: 0.053825\n",
            "Train Epoch: 14 [3961/6845 (58%)]\tLoss: 0.161399\n",
            "Train Epoch: 14 [3962/6845 (58%)]\tLoss: 0.129186\n",
            "Train Epoch: 14 [3963/6845 (58%)]\tLoss: 0.074207\n",
            "Train Epoch: 14 [3964/6845 (58%)]\tLoss: 0.074802\n",
            "Train Epoch: 14 [3965/6845 (58%)]\tLoss: 0.436159\n",
            "Train Epoch: 14 [3966/6845 (58%)]\tLoss: 0.083272\n",
            "Train Epoch: 14 [3967/6845 (58%)]\tLoss: 0.075318\n",
            "Train Epoch: 14 [3968/6845 (58%)]\tLoss: 0.160780\n",
            "Train Epoch: 14 [3969/6845 (58%)]\tLoss: 0.149465\n",
            "Train Epoch: 14 [3970/6845 (58%)]\tLoss: 0.453845\n",
            "Train Epoch: 14 [3971/6845 (58%)]\tLoss: 0.131363\n",
            "Train Epoch: 14 [3972/6845 (58%)]\tLoss: 0.084088\n",
            "Train Epoch: 14 [3973/6845 (58%)]\tLoss: 0.066881\n",
            "Train Epoch: 14 [3974/6845 (58%)]\tLoss: 0.393412\n",
            "Train Epoch: 14 [3975/6845 (58%)]\tLoss: 0.073543\n",
            "Train Epoch: 14 [3976/6845 (58%)]\tLoss: 0.475036\n",
            "Train Epoch: 14 [3977/6845 (58%)]\tLoss: 0.060121\n",
            "Train Epoch: 14 [3978/6845 (58%)]\tLoss: 0.122674\n",
            "Train Epoch: 14 [3979/6845 (58%)]\tLoss: 0.119410\n",
            "Train Epoch: 14 [3980/6845 (58%)]\tLoss: 0.059497\n",
            "Train Epoch: 14 [3981/6845 (58%)]\tLoss: 0.132954\n",
            "Train Epoch: 14 [3982/6845 (58%)]\tLoss: 0.137224\n",
            "Train Epoch: 14 [3983/6845 (58%)]\tLoss: 0.467586\n",
            "Train Epoch: 14 [3984/6845 (58%)]\tLoss: 0.144177\n",
            "Train Epoch: 14 [3985/6845 (58%)]\tLoss: 0.455688\n",
            "Train Epoch: 14 [3986/6845 (58%)]\tLoss: 0.119608\n",
            "Train Epoch: 14 [3987/6845 (58%)]\tLoss: 0.344170\n",
            "Train Epoch: 14 [3988/6845 (58%)]\tLoss: 0.115070\n",
            "Train Epoch: 14 [3989/6845 (58%)]\tLoss: 0.086480\n",
            "Train Epoch: 14 [3990/6845 (58%)]\tLoss: 1.393062\n",
            "Train Epoch: 14 [3991/6845 (58%)]\tLoss: 0.072335\n",
            "Train Epoch: 14 [3992/6845 (58%)]\tLoss: 0.723043\n",
            "Train Epoch: 14 [3993/6845 (58%)]\tLoss: 0.496313\n",
            "Train Epoch: 14 [3994/6845 (58%)]\tLoss: 0.571344\n",
            "Train Epoch: 14 [3995/6845 (58%)]\tLoss: 0.082284\n",
            "Train Epoch: 14 [3996/6845 (58%)]\tLoss: 0.174818\n",
            "Train Epoch: 14 [3997/6845 (58%)]\tLoss: 0.175285\n",
            "Train Epoch: 14 [3998/6845 (58%)]\tLoss: 0.089302\n",
            "Train Epoch: 14 [3999/6845 (58%)]\tLoss: 0.126354\n",
            "Train Epoch: 14 [4000/6845 (58%)]\tLoss: 0.090989\n",
            "Train Epoch: 14 [4001/6845 (58%)]\tLoss: 0.089852\n",
            "Train Epoch: 14 [4002/6845 (58%)]\tLoss: 0.147449\n",
            "Train Epoch: 14 [4003/6845 (58%)]\tLoss: 0.170115\n",
            "Train Epoch: 14 [4004/6845 (58%)]\tLoss: 0.107455\n",
            "Train Epoch: 14 [4005/6845 (59%)]\tLoss: 0.177904\n",
            "Train Epoch: 14 [4006/6845 (59%)]\tLoss: 0.170358\n",
            "Train Epoch: 14 [4007/6845 (59%)]\tLoss: 0.147803\n",
            "Train Epoch: 14 [4008/6845 (59%)]\tLoss: 0.834576\n",
            "Train Epoch: 14 [4009/6845 (59%)]\tLoss: 1.225700\n",
            "Train Epoch: 14 [4010/6845 (59%)]\tLoss: 0.101613\n",
            "Train Epoch: 14 [4011/6845 (59%)]\tLoss: 0.432330\n",
            "Train Epoch: 14 [4012/6845 (59%)]\tLoss: 0.130526\n",
            "Train Epoch: 14 [4013/6845 (59%)]\tLoss: 0.139056\n",
            "Train Epoch: 14 [4014/6845 (59%)]\tLoss: 0.178103\n",
            "Train Epoch: 14 [4015/6845 (59%)]\tLoss: 0.065138\n",
            "Train Epoch: 14 [4016/6845 (59%)]\tLoss: 0.161814\n",
            "Train Epoch: 14 [4017/6845 (59%)]\tLoss: 0.142209\n",
            "Train Epoch: 14 [4018/6845 (59%)]\tLoss: 0.437423\n",
            "Train Epoch: 14 [4019/6845 (59%)]\tLoss: 0.099163\n",
            "Train Epoch: 14 [4020/6845 (59%)]\tLoss: 0.067490\n",
            "Train Epoch: 14 [4021/6845 (59%)]\tLoss: 0.140639\n",
            "Train Epoch: 14 [4022/6845 (59%)]\tLoss: 0.084677\n",
            "Train Epoch: 14 [4023/6845 (59%)]\tLoss: 0.111814\n",
            "Train Epoch: 14 [4024/6845 (59%)]\tLoss: 0.075411\n",
            "Train Epoch: 14 [4025/6845 (59%)]\tLoss: 0.093740\n",
            "Train Epoch: 14 [4026/6845 (59%)]\tLoss: 0.078655\n",
            "Train Epoch: 14 [4027/6845 (59%)]\tLoss: 0.419891\n",
            "Train Epoch: 14 [4028/6845 (59%)]\tLoss: 0.142234\n",
            "Train Epoch: 14 [4029/6845 (59%)]\tLoss: 0.083027\n",
            "Train Epoch: 14 [4030/6845 (59%)]\tLoss: 0.142914\n",
            "Train Epoch: 14 [4031/6845 (59%)]\tLoss: 0.152047\n",
            "Train Epoch: 14 [4032/6845 (59%)]\tLoss: 0.610417\n",
            "Train Epoch: 14 [4033/6845 (59%)]\tLoss: 0.080902\n",
            "Train Epoch: 14 [4034/6845 (59%)]\tLoss: 0.061172\n",
            "Train Epoch: 14 [4035/6845 (59%)]\tLoss: 0.073145\n",
            "Train Epoch: 14 [4036/6845 (59%)]\tLoss: 0.093291\n",
            "Train Epoch: 14 [4037/6845 (59%)]\tLoss: 1.291122\n",
            "Train Epoch: 14 [4038/6845 (59%)]\tLoss: 0.077405\n",
            "Train Epoch: 14 [4039/6845 (59%)]\tLoss: 0.077968\n",
            "Train Epoch: 14 [4040/6845 (59%)]\tLoss: 0.069360\n",
            "Train Epoch: 14 [4041/6845 (59%)]\tLoss: 0.823514\n",
            "Train Epoch: 14 [4042/6845 (59%)]\tLoss: 0.509795\n",
            "Train Epoch: 14 [4043/6845 (59%)]\tLoss: 0.069753\n",
            "Train Epoch: 14 [4044/6845 (59%)]\tLoss: 0.073461\n",
            "Train Epoch: 14 [4045/6845 (59%)]\tLoss: 0.065457\n",
            "Train Epoch: 14 [4046/6845 (59%)]\tLoss: 0.705974\n",
            "Train Epoch: 14 [4047/6845 (59%)]\tLoss: 0.502177\n",
            "Train Epoch: 14 [4048/6845 (59%)]\tLoss: 0.052914\n",
            "Train Epoch: 14 [4049/6845 (59%)]\tLoss: 0.089651\n",
            "Train Epoch: 14 [4050/6845 (59%)]\tLoss: 0.079227\n",
            "Train Epoch: 14 [4051/6845 (59%)]\tLoss: 0.072555\n",
            "Train Epoch: 14 [4052/6845 (59%)]\tLoss: 0.073529\n",
            "Train Epoch: 14 [4053/6845 (59%)]\tLoss: 0.064348\n",
            "Train Epoch: 14 [4054/6845 (59%)]\tLoss: 0.057688\n",
            "Train Epoch: 14 [4055/6845 (59%)]\tLoss: 0.136622\n",
            "Train Epoch: 14 [4056/6845 (59%)]\tLoss: 0.601571\n",
            "Train Epoch: 14 [4057/6845 (59%)]\tLoss: 0.084816\n",
            "Train Epoch: 14 [4058/6845 (59%)]\tLoss: 0.100457\n",
            "Train Epoch: 14 [4059/6845 (59%)]\tLoss: 0.511465\n",
            "Train Epoch: 14 [4060/6845 (59%)]\tLoss: 0.047720\n",
            "Train Epoch: 14 [4061/6845 (59%)]\tLoss: 0.047235\n",
            "Train Epoch: 14 [4062/6845 (59%)]\tLoss: 0.793308\n",
            "Train Epoch: 14 [4063/6845 (59%)]\tLoss: 0.115938\n",
            "Train Epoch: 14 [4064/6845 (59%)]\tLoss: 0.090484\n",
            "Train Epoch: 14 [4065/6845 (59%)]\tLoss: 0.044601\n",
            "Train Epoch: 14 [4066/6845 (59%)]\tLoss: 0.853279\n",
            "Train Epoch: 14 [4067/6845 (59%)]\tLoss: 0.073354\n",
            "Train Epoch: 14 [4068/6845 (59%)]\tLoss: 0.455109\n",
            "Train Epoch: 14 [4069/6845 (59%)]\tLoss: 0.132916\n",
            "Train Epoch: 14 [4070/6845 (59%)]\tLoss: 0.111577\n",
            "Train Epoch: 14 [4071/6845 (59%)]\tLoss: 0.429061\n",
            "Train Epoch: 14 [4072/6845 (59%)]\tLoss: 0.405534\n",
            "Train Epoch: 14 [4073/6845 (60%)]\tLoss: 0.128582\n",
            "Train Epoch: 14 [4074/6845 (60%)]\tLoss: 0.642159\n",
            "Train Epoch: 14 [4075/6845 (60%)]\tLoss: 0.049741\n",
            "Train Epoch: 14 [4076/6845 (60%)]\tLoss: 0.051706\n",
            "Train Epoch: 14 [4077/6845 (60%)]\tLoss: 0.129324\n",
            "Train Epoch: 14 [4078/6845 (60%)]\tLoss: 0.094878\n",
            "Train Epoch: 14 [4079/6845 (60%)]\tLoss: 0.107290\n",
            "Train Epoch: 14 [4080/6845 (60%)]\tLoss: 0.142724\n",
            "Train Epoch: 14 [4081/6845 (60%)]\tLoss: 0.108596\n",
            "Train Epoch: 14 [4082/6845 (60%)]\tLoss: 0.048667\n",
            "Train Epoch: 14 [4083/6845 (60%)]\tLoss: 0.155310\n",
            "Train Epoch: 14 [4084/6845 (60%)]\tLoss: 0.166653\n",
            "Train Epoch: 14 [4085/6845 (60%)]\tLoss: 0.144244\n",
            "Train Epoch: 14 [4086/6845 (60%)]\tLoss: 0.366036\n",
            "Train Epoch: 14 [4087/6845 (60%)]\tLoss: 0.489629\n",
            "Train Epoch: 14 [4088/6845 (60%)]\tLoss: 0.130729\n",
            "Train Epoch: 14 [4089/6845 (60%)]\tLoss: 0.150208\n",
            "Train Epoch: 14 [4090/6845 (60%)]\tLoss: 0.071208\n",
            "Train Epoch: 14 [4091/6845 (60%)]\tLoss: 0.135805\n",
            "Train Epoch: 14 [4092/6845 (60%)]\tLoss: 0.126690\n",
            "Train Epoch: 14 [4093/6845 (60%)]\tLoss: 0.076881\n",
            "Train Epoch: 14 [4094/6845 (60%)]\tLoss: 0.068692\n",
            "Train Epoch: 14 [4095/6845 (60%)]\tLoss: 0.123369\n",
            "Train Epoch: 14 [4096/6845 (60%)]\tLoss: 0.073082\n",
            "Train Epoch: 14 [4097/6845 (60%)]\tLoss: 0.427501\n",
            "Train Epoch: 14 [4098/6845 (60%)]\tLoss: 0.092607\n",
            "Train Epoch: 14 [4099/6845 (60%)]\tLoss: 0.696784\n",
            "Train Epoch: 14 [4100/6845 (60%)]\tLoss: 0.165509\n",
            "Train Epoch: 14 [4101/6845 (60%)]\tLoss: 0.171965\n",
            "Train Epoch: 14 [4102/6845 (60%)]\tLoss: 0.066106\n",
            "Train Epoch: 14 [4103/6845 (60%)]\tLoss: 0.100728\n",
            "Train Epoch: 14 [4104/6845 (60%)]\tLoss: 0.222290\n",
            "Train Epoch: 14 [4105/6845 (60%)]\tLoss: 0.120185\n",
            "Train Epoch: 14 [4106/6845 (60%)]\tLoss: 0.077877\n",
            "Train Epoch: 14 [4107/6845 (60%)]\tLoss: 0.106835\n",
            "Train Epoch: 14 [4108/6845 (60%)]\tLoss: 0.714243\n",
            "Train Epoch: 14 [4109/6845 (60%)]\tLoss: 0.548630\n",
            "Train Epoch: 14 [4110/6845 (60%)]\tLoss: 0.073615\n",
            "Train Epoch: 14 [4111/6845 (60%)]\tLoss: 0.099070\n",
            "Train Epoch: 14 [4112/6845 (60%)]\tLoss: 0.082402\n",
            "Train Epoch: 14 [4113/6845 (60%)]\tLoss: 0.081788\n",
            "Train Epoch: 14 [4114/6845 (60%)]\tLoss: 0.143704\n",
            "Train Epoch: 14 [4115/6845 (60%)]\tLoss: 0.152183\n",
            "Train Epoch: 14 [4116/6845 (60%)]\tLoss: 0.087279\n",
            "Train Epoch: 14 [4117/6845 (60%)]\tLoss: 0.167955\n",
            "Train Epoch: 14 [4118/6845 (60%)]\tLoss: 0.401054\n",
            "Train Epoch: 14 [4119/6845 (60%)]\tLoss: 0.123915\n",
            "Train Epoch: 14 [4120/6845 (60%)]\tLoss: 0.388800\n",
            "Train Epoch: 14 [4121/6845 (60%)]\tLoss: 0.089205\n",
            "Train Epoch: 14 [4122/6845 (60%)]\tLoss: 0.172491\n",
            "Train Epoch: 14 [4123/6845 (60%)]\tLoss: 0.081376\n",
            "Train Epoch: 14 [4124/6845 (60%)]\tLoss: 0.046761\n",
            "Train Epoch: 14 [4125/6845 (60%)]\tLoss: 0.108637\n",
            "Train Epoch: 14 [4126/6845 (60%)]\tLoss: 0.107183\n",
            "Train Epoch: 14 [4127/6845 (60%)]\tLoss: 0.057937\n",
            "Train Epoch: 14 [4128/6845 (60%)]\tLoss: 0.131130\n",
            "Train Epoch: 14 [4129/6845 (60%)]\tLoss: 0.044786\n",
            "Train Epoch: 14 [4130/6845 (60%)]\tLoss: 0.639002\n",
            "Train Epoch: 14 [4131/6845 (60%)]\tLoss: 0.044157\n",
            "Train Epoch: 14 [4132/6845 (60%)]\tLoss: 0.116226\n",
            "Train Epoch: 14 [4133/6845 (60%)]\tLoss: 0.651011\n",
            "Train Epoch: 14 [4134/6845 (60%)]\tLoss: 0.072800\n",
            "Train Epoch: 14 [4135/6845 (60%)]\tLoss: 0.044097\n",
            "Train Epoch: 14 [4136/6845 (60%)]\tLoss: 0.131768\n",
            "Train Epoch: 14 [4137/6845 (60%)]\tLoss: 0.099251\n",
            "Train Epoch: 14 [4138/6845 (60%)]\tLoss: 0.197845\n",
            "Train Epoch: 14 [4139/6845 (60%)]\tLoss: 0.099793\n",
            "Train Epoch: 14 [4140/6845 (60%)]\tLoss: 0.043796\n",
            "Train Epoch: 14 [4141/6845 (60%)]\tLoss: 0.088539\n",
            "Train Epoch: 14 [4142/6845 (61%)]\tLoss: 0.170843\n",
            "Train Epoch: 14 [4143/6845 (61%)]\tLoss: 0.091850\n",
            "Train Epoch: 14 [4144/6845 (61%)]\tLoss: 0.069221\n",
            "Train Epoch: 14 [4145/6845 (61%)]\tLoss: 0.056490\n",
            "Train Epoch: 14 [4146/6845 (61%)]\tLoss: 0.914733\n",
            "Train Epoch: 14 [4147/6845 (61%)]\tLoss: 0.452865\n",
            "Train Epoch: 14 [4148/6845 (61%)]\tLoss: 0.048867\n",
            "Train Epoch: 14 [4149/6845 (61%)]\tLoss: 0.089993\n",
            "Train Epoch: 14 [4150/6845 (61%)]\tLoss: 0.090005\n",
            "Train Epoch: 14 [4151/6845 (61%)]\tLoss: 0.094452\n",
            "Train Epoch: 14 [4152/6845 (61%)]\tLoss: 0.100475\n",
            "Train Epoch: 14 [4153/6845 (61%)]\tLoss: 0.115857\n",
            "Train Epoch: 14 [4154/6845 (61%)]\tLoss: 0.190296\n",
            "Train Epoch: 14 [4155/6845 (61%)]\tLoss: 0.642412\n",
            "Train Epoch: 14 [4156/6845 (61%)]\tLoss: 0.051814\n",
            "Train Epoch: 14 [4157/6845 (61%)]\tLoss: 0.054087\n",
            "Train Epoch: 14 [4158/6845 (61%)]\tLoss: 0.099059\n",
            "Train Epoch: 14 [4159/6845 (61%)]\tLoss: 1.002255\n",
            "Train Epoch: 14 [4160/6845 (61%)]\tLoss: 0.713921\n",
            "Train Epoch: 14 [4161/6845 (61%)]\tLoss: 0.476125\n",
            "Train Epoch: 14 [4162/6845 (61%)]\tLoss: 0.191386\n",
            "Train Epoch: 14 [4163/6845 (61%)]\tLoss: 0.559171\n",
            "Train Epoch: 14 [4164/6845 (61%)]\tLoss: 0.059047\n",
            "Train Epoch: 14 [4165/6845 (61%)]\tLoss: 0.109632\n",
            "Train Epoch: 14 [4166/6845 (61%)]\tLoss: 0.931866\n",
            "Train Epoch: 14 [4167/6845 (61%)]\tLoss: 0.386772\n",
            "Train Epoch: 14 [4168/6845 (61%)]\tLoss: 0.570961\n",
            "Train Epoch: 14 [4169/6845 (61%)]\tLoss: 0.115244\n",
            "Train Epoch: 14 [4170/6845 (61%)]\tLoss: 1.062913\n",
            "Train Epoch: 14 [4171/6845 (61%)]\tLoss: 0.874523\n",
            "Train Epoch: 14 [4172/6845 (61%)]\tLoss: 0.123500\n",
            "Train Epoch: 14 [4173/6845 (61%)]\tLoss: 0.652836\n",
            "Train Epoch: 14 [4174/6845 (61%)]\tLoss: 0.103531\n",
            "Train Epoch: 14 [4175/6845 (61%)]\tLoss: 0.466482\n",
            "Train Epoch: 14 [4176/6845 (61%)]\tLoss: 0.076501\n",
            "Train Epoch: 14 [4177/6845 (61%)]\tLoss: 0.090859\n",
            "Train Epoch: 14 [4178/6845 (61%)]\tLoss: 0.522211\n",
            "Train Epoch: 14 [4179/6845 (61%)]\tLoss: 0.099545\n",
            "Train Epoch: 14 [4180/6845 (61%)]\tLoss: 0.114361\n",
            "Train Epoch: 14 [4181/6845 (61%)]\tLoss: 0.156772\n",
            "Train Epoch: 14 [4182/6845 (61%)]\tLoss: 0.154222\n",
            "Train Epoch: 14 [4183/6845 (61%)]\tLoss: 0.292961\n",
            "Train Epoch: 14 [4184/6845 (61%)]\tLoss: 0.123018\n",
            "Train Epoch: 14 [4185/6845 (61%)]\tLoss: 0.115283\n",
            "Train Epoch: 14 [4186/6845 (61%)]\tLoss: 0.135257\n",
            "Train Epoch: 14 [4187/6845 (61%)]\tLoss: 1.314164\n",
            "Train Epoch: 14 [4188/6845 (61%)]\tLoss: 0.107042\n",
            "Train Epoch: 14 [4189/6845 (61%)]\tLoss: 0.070670\n",
            "Train Epoch: 14 [4190/6845 (61%)]\tLoss: 0.658978\n",
            "Train Epoch: 14 [4191/6845 (61%)]\tLoss: 0.095628\n",
            "Train Epoch: 14 [4192/6845 (61%)]\tLoss: 0.571543\n",
            "Train Epoch: 14 [4193/6845 (61%)]\tLoss: 0.090932\n",
            "Train Epoch: 14 [4194/6845 (61%)]\tLoss: 1.148542\n",
            "Train Epoch: 14 [4195/6845 (61%)]\tLoss: 0.632137\n",
            "Train Epoch: 14 [4196/6845 (61%)]\tLoss: 0.077915\n",
            "Train Epoch: 14 [4197/6845 (61%)]\tLoss: 0.548789\n",
            "Train Epoch: 14 [4198/6845 (61%)]\tLoss: 0.140483\n",
            "Train Epoch: 14 [4199/6845 (61%)]\tLoss: 0.102705\n",
            "Train Epoch: 14 [4200/6845 (61%)]\tLoss: 0.349720\n",
            "Train Epoch: 14 [4201/6845 (61%)]\tLoss: 0.131660\n",
            "Train Epoch: 14 [4202/6845 (61%)]\tLoss: 0.263355\n",
            "Train Epoch: 14 [4203/6845 (61%)]\tLoss: 0.096917\n",
            "Train Epoch: 14 [4204/6845 (61%)]\tLoss: 0.107462\n",
            "Train Epoch: 14 [4205/6845 (61%)]\tLoss: 0.087020\n",
            "Train Epoch: 14 [4206/6845 (61%)]\tLoss: 0.101601\n",
            "Train Epoch: 14 [4207/6845 (61%)]\tLoss: 0.139575\n",
            "Train Epoch: 14 [4208/6845 (61%)]\tLoss: 0.194878\n",
            "Train Epoch: 14 [4209/6845 (61%)]\tLoss: 0.237536\n",
            "Train Epoch: 14 [4210/6845 (62%)]\tLoss: 0.070605\n",
            "Train Epoch: 14 [4211/6845 (62%)]\tLoss: 0.259356\n",
            "Train Epoch: 14 [4212/6845 (62%)]\tLoss: 0.083375\n",
            "Train Epoch: 14 [4213/6845 (62%)]\tLoss: 0.208684\n",
            "Train Epoch: 14 [4214/6845 (62%)]\tLoss: 0.131332\n",
            "Train Epoch: 14 [4215/6845 (62%)]\tLoss: 0.504751\n",
            "Train Epoch: 14 [4216/6845 (62%)]\tLoss: 0.424883\n",
            "Train Epoch: 14 [4217/6845 (62%)]\tLoss: 0.205359\n",
            "Train Epoch: 14 [4218/6845 (62%)]\tLoss: 0.170957\n",
            "Train Epoch: 14 [4219/6845 (62%)]\tLoss: 0.104314\n",
            "Train Epoch: 14 [4220/6845 (62%)]\tLoss: 0.502822\n",
            "Train Epoch: 14 [4221/6845 (62%)]\tLoss: 0.150453\n",
            "Train Epoch: 14 [4222/6845 (62%)]\tLoss: 0.127429\n",
            "Train Epoch: 14 [4223/6845 (62%)]\tLoss: 0.149017\n",
            "Train Epoch: 14 [4224/6845 (62%)]\tLoss: 0.071241\n",
            "Train Epoch: 14 [4225/6845 (62%)]\tLoss: 0.687306\n",
            "Train Epoch: 14 [4226/6845 (62%)]\tLoss: 0.057234\n",
            "Train Epoch: 14 [4227/6845 (62%)]\tLoss: 0.768075\n",
            "Train Epoch: 14 [4228/6845 (62%)]\tLoss: 0.077723\n",
            "Train Epoch: 14 [4229/6845 (62%)]\tLoss: 0.112362\n",
            "Train Epoch: 14 [4230/6845 (62%)]\tLoss: 0.050856\n",
            "Train Epoch: 14 [4231/6845 (62%)]\tLoss: 0.128872\n",
            "Train Epoch: 14 [4232/6845 (62%)]\tLoss: 0.200846\n",
            "Train Epoch: 14 [4233/6845 (62%)]\tLoss: 0.105971\n",
            "Train Epoch: 14 [4234/6845 (62%)]\tLoss: 0.169171\n",
            "Train Epoch: 14 [4235/6845 (62%)]\tLoss: 0.407270\n",
            "Train Epoch: 14 [4236/6845 (62%)]\tLoss: 0.096691\n",
            "Train Epoch: 14 [4237/6845 (62%)]\tLoss: 0.112092\n",
            "Train Epoch: 14 [4238/6845 (62%)]\tLoss: 0.447801\n",
            "Train Epoch: 14 [4239/6845 (62%)]\tLoss: 0.657096\n",
            "Train Epoch: 14 [4240/6845 (62%)]\tLoss: 0.402368\n",
            "Train Epoch: 14 [4241/6845 (62%)]\tLoss: 0.254378\n",
            "Train Epoch: 14 [4242/6845 (62%)]\tLoss: 0.108348\n",
            "Train Epoch: 14 [4243/6845 (62%)]\tLoss: 0.837141\n",
            "Train Epoch: 14 [4244/6845 (62%)]\tLoss: 0.412657\n",
            "Train Epoch: 14 [4245/6845 (62%)]\tLoss: 0.112058\n",
            "Train Epoch: 14 [4246/6845 (62%)]\tLoss: 0.099850\n",
            "Train Epoch: 14 [4247/6845 (62%)]\tLoss: 0.095128\n",
            "Train Epoch: 14 [4248/6845 (62%)]\tLoss: 0.866533\n",
            "Train Epoch: 14 [4249/6845 (62%)]\tLoss: 0.095115\n",
            "Train Epoch: 14 [4250/6845 (62%)]\tLoss: 0.072230\n",
            "Train Epoch: 14 [4251/6845 (62%)]\tLoss: 0.105394\n",
            "Train Epoch: 14 [4252/6845 (62%)]\tLoss: 0.190177\n",
            "Train Epoch: 14 [4253/6845 (62%)]\tLoss: 0.854981\n",
            "Train Epoch: 14 [4254/6845 (62%)]\tLoss: 0.089869\n",
            "Train Epoch: 14 [4255/6845 (62%)]\tLoss: 0.158835\n",
            "Train Epoch: 14 [4256/6845 (62%)]\tLoss: 0.073778\n",
            "Train Epoch: 14 [4257/6845 (62%)]\tLoss: 0.867228\n",
            "Train Epoch: 14 [4258/6845 (62%)]\tLoss: 0.408003\n",
            "Train Epoch: 14 [4259/6845 (62%)]\tLoss: 0.086285\n",
            "Train Epoch: 14 [4260/6845 (62%)]\tLoss: 0.402879\n",
            "Train Epoch: 14 [4261/6845 (62%)]\tLoss: 0.188822\n",
            "Train Epoch: 14 [4262/6845 (62%)]\tLoss: 0.100798\n",
            "Train Epoch: 14 [4263/6845 (62%)]\tLoss: 0.120578\n",
            "Train Epoch: 14 [4264/6845 (62%)]\tLoss: 0.181571\n",
            "Train Epoch: 14 [4265/6845 (62%)]\tLoss: 0.068893\n",
            "Train Epoch: 14 [4266/6845 (62%)]\tLoss: 0.100630\n",
            "Train Epoch: 14 [4267/6845 (62%)]\tLoss: 0.077925\n",
            "Train Epoch: 14 [4268/6845 (62%)]\tLoss: 0.411528\n",
            "Train Epoch: 14 [4269/6845 (62%)]\tLoss: 0.418761\n",
            "Train Epoch: 14 [4270/6845 (62%)]\tLoss: 0.163219\n",
            "Train Epoch: 14 [4271/6845 (62%)]\tLoss: 0.118619\n",
            "Train Epoch: 14 [4272/6845 (62%)]\tLoss: 0.098372\n",
            "Train Epoch: 14 [4273/6845 (62%)]\tLoss: 0.162961\n",
            "Train Epoch: 14 [4274/6845 (62%)]\tLoss: 0.083366\n",
            "Train Epoch: 14 [4275/6845 (62%)]\tLoss: 0.099445\n",
            "Train Epoch: 14 [4276/6845 (62%)]\tLoss: 0.264925\n",
            "Train Epoch: 14 [4277/6845 (62%)]\tLoss: 0.130421\n",
            "Train Epoch: 14 [4278/6845 (62%)]\tLoss: 0.445375\n",
            "Train Epoch: 14 [4279/6845 (63%)]\tLoss: 0.111129\n",
            "Train Epoch: 14 [4280/6845 (63%)]\tLoss: 0.112873\n",
            "Train Epoch: 14 [4281/6845 (63%)]\tLoss: 0.999634\n",
            "Train Epoch: 14 [4282/6845 (63%)]\tLoss: 0.155286\n",
            "Train Epoch: 14 [4283/6845 (63%)]\tLoss: 0.417963\n",
            "Train Epoch: 14 [4284/6845 (63%)]\tLoss: 0.226015\n",
            "Train Epoch: 14 [4285/6845 (63%)]\tLoss: 0.057826\n",
            "Train Epoch: 14 [4286/6845 (63%)]\tLoss: 0.056367\n",
            "Train Epoch: 14 [4287/6845 (63%)]\tLoss: 0.073637\n",
            "Train Epoch: 14 [4288/6845 (63%)]\tLoss: 0.147852\n",
            "Train Epoch: 14 [4289/6845 (63%)]\tLoss: 0.120515\n",
            "Train Epoch: 14 [4290/6845 (63%)]\tLoss: 0.057629\n",
            "Train Epoch: 14 [4291/6845 (63%)]\tLoss: 0.169051\n",
            "Train Epoch: 14 [4292/6845 (63%)]\tLoss: 0.878375\n",
            "Train Epoch: 14 [4293/6845 (63%)]\tLoss: 1.391331\n",
            "Train Epoch: 14 [4294/6845 (63%)]\tLoss: 0.074980\n",
            "Train Epoch: 14 [4295/6845 (63%)]\tLoss: 0.098357\n",
            "Train Epoch: 14 [4296/6845 (63%)]\tLoss: 0.122692\n",
            "Train Epoch: 14 [4297/6845 (63%)]\tLoss: 0.967449\n",
            "Train Epoch: 14 [4298/6845 (63%)]\tLoss: 0.078433\n",
            "Train Epoch: 14 [4299/6845 (63%)]\tLoss: 0.073159\n",
            "Train Epoch: 14 [4300/6845 (63%)]\tLoss: 0.657539\n",
            "Train Epoch: 14 [4301/6845 (63%)]\tLoss: 0.548952\n",
            "Train Epoch: 14 [4302/6845 (63%)]\tLoss: 0.111110\n",
            "Train Epoch: 14 [4303/6845 (63%)]\tLoss: 0.450136\n",
            "Train Epoch: 14 [4304/6845 (63%)]\tLoss: 0.111547\n",
            "Train Epoch: 14 [4305/6845 (63%)]\tLoss: 0.067951\n",
            "Train Epoch: 14 [4306/6845 (63%)]\tLoss: 0.085639\n",
            "Train Epoch: 14 [4307/6845 (63%)]\tLoss: 0.087571\n",
            "Train Epoch: 14 [4308/6845 (63%)]\tLoss: 0.701734\n",
            "Train Epoch: 14 [4309/6845 (63%)]\tLoss: 0.466554\n",
            "Train Epoch: 14 [4310/6845 (63%)]\tLoss: 0.613571\n",
            "Train Epoch: 14 [4311/6845 (63%)]\tLoss: 0.439664\n",
            "Train Epoch: 14 [4312/6845 (63%)]\tLoss: 0.061243\n",
            "Train Epoch: 14 [4313/6845 (63%)]\tLoss: 0.210337\n",
            "Train Epoch: 14 [4314/6845 (63%)]\tLoss: 0.064149\n",
            "Train Epoch: 14 [4315/6845 (63%)]\tLoss: 0.096509\n",
            "Train Epoch: 14 [4316/6845 (63%)]\tLoss: 0.095889\n",
            "Train Epoch: 14 [4317/6845 (63%)]\tLoss: 0.138544\n",
            "Train Epoch: 14 [4318/6845 (63%)]\tLoss: 0.135433\n",
            "Train Epoch: 14 [4319/6845 (63%)]\tLoss: 0.601322\n",
            "Train Epoch: 14 [4320/6845 (63%)]\tLoss: 0.423678\n",
            "Train Epoch: 14 [4321/6845 (63%)]\tLoss: 0.147495\n",
            "Train Epoch: 14 [4322/6845 (63%)]\tLoss: 0.398371\n",
            "Train Epoch: 14 [4323/6845 (63%)]\tLoss: 0.507657\n",
            "Train Epoch: 14 [4324/6845 (63%)]\tLoss: 0.070624\n",
            "Train Epoch: 14 [4325/6845 (63%)]\tLoss: 0.113863\n",
            "Train Epoch: 14 [4326/6845 (63%)]\tLoss: 0.385965\n",
            "Train Epoch: 14 [4327/6845 (63%)]\tLoss: 0.146831\n",
            "Train Epoch: 14 [4328/6845 (63%)]\tLoss: 0.076498\n",
            "Train Epoch: 14 [4329/6845 (63%)]\tLoss: 0.981892\n",
            "Train Epoch: 14 [4330/6845 (63%)]\tLoss: 0.109030\n",
            "Train Epoch: 14 [4331/6845 (63%)]\tLoss: 0.767869\n",
            "Train Epoch: 14 [4332/6845 (63%)]\tLoss: 0.075423\n",
            "Train Epoch: 14 [4333/6845 (63%)]\tLoss: 0.272200\n",
            "Train Epoch: 14 [4334/6845 (63%)]\tLoss: 0.274477\n",
            "Train Epoch: 14 [4335/6845 (63%)]\tLoss: 0.638451\n",
            "Train Epoch: 14 [4336/6845 (63%)]\tLoss: 0.100799\n",
            "Train Epoch: 14 [4337/6845 (63%)]\tLoss: 0.339211\n",
            "Train Epoch: 14 [4338/6845 (63%)]\tLoss: 0.194834\n",
            "Train Epoch: 14 [4339/6845 (63%)]\tLoss: 0.857515\n",
            "Train Epoch: 14 [4340/6845 (63%)]\tLoss: 0.266393\n",
            "Train Epoch: 14 [4341/6845 (63%)]\tLoss: 0.331538\n",
            "Train Epoch: 14 [4342/6845 (63%)]\tLoss: 0.125247\n",
            "Train Epoch: 14 [4343/6845 (63%)]\tLoss: 0.092006\n",
            "Train Epoch: 14 [4344/6845 (63%)]\tLoss: 0.103697\n",
            "Train Epoch: 14 [4345/6845 (63%)]\tLoss: 0.126261\n",
            "Train Epoch: 14 [4346/6845 (63%)]\tLoss: 0.180477\n",
            "Train Epoch: 14 [4347/6845 (64%)]\tLoss: 0.166717\n",
            "Train Epoch: 14 [4348/6845 (64%)]\tLoss: 0.105332\n",
            "Train Epoch: 14 [4349/6845 (64%)]\tLoss: 0.126342\n",
            "Train Epoch: 14 [4350/6845 (64%)]\tLoss: 0.646457\n",
            "Train Epoch: 14 [4351/6845 (64%)]\tLoss: 0.137138\n",
            "Train Epoch: 14 [4352/6845 (64%)]\tLoss: 0.087152\n",
            "Train Epoch: 14 [4353/6845 (64%)]\tLoss: 0.081711\n",
            "Train Epoch: 14 [4354/6845 (64%)]\tLoss: 0.238209\n",
            "Train Epoch: 14 [4355/6845 (64%)]\tLoss: 0.589158\n",
            "Train Epoch: 14 [4356/6845 (64%)]\tLoss: 0.043988\n",
            "Train Epoch: 14 [4357/6845 (64%)]\tLoss: 0.138201\n",
            "Train Epoch: 14 [4358/6845 (64%)]\tLoss: 0.090400\n",
            "Train Epoch: 14 [4359/6845 (64%)]\tLoss: 0.061208\n",
            "Train Epoch: 14 [4360/6845 (64%)]\tLoss: 0.175756\n",
            "Train Epoch: 14 [4361/6845 (64%)]\tLoss: 0.232663\n",
            "Train Epoch: 14 [4362/6845 (64%)]\tLoss: 0.145274\n",
            "Train Epoch: 14 [4363/6845 (64%)]\tLoss: 0.089105\n",
            "Train Epoch: 14 [4364/6845 (64%)]\tLoss: 0.081706\n",
            "Train Epoch: 14 [4365/6845 (64%)]\tLoss: 0.723307\n",
            "Train Epoch: 14 [4366/6845 (64%)]\tLoss: 0.042713\n",
            "Train Epoch: 14 [4367/6845 (64%)]\tLoss: 0.145176\n",
            "Train Epoch: 14 [4368/6845 (64%)]\tLoss: 0.671459\n",
            "Train Epoch: 14 [4369/6845 (64%)]\tLoss: 0.431794\n",
            "Train Epoch: 14 [4370/6845 (64%)]\tLoss: 0.209913\n",
            "Train Epoch: 14 [4371/6845 (64%)]\tLoss: 0.040767\n",
            "Train Epoch: 14 [4372/6845 (64%)]\tLoss: 0.556883\n",
            "Train Epoch: 14 [4373/6845 (64%)]\tLoss: 0.072254\n",
            "Train Epoch: 14 [4374/6845 (64%)]\tLoss: 0.051322\n",
            "Train Epoch: 14 [4375/6845 (64%)]\tLoss: 0.140065\n",
            "Train Epoch: 14 [4376/6845 (64%)]\tLoss: 0.239794\n",
            "Train Epoch: 14 [4377/6845 (64%)]\tLoss: 0.888898\n",
            "Train Epoch: 14 [4378/6845 (64%)]\tLoss: 0.597311\n",
            "Train Epoch: 14 [4379/6845 (64%)]\tLoss: 0.059179\n",
            "Train Epoch: 14 [4380/6845 (64%)]\tLoss: 0.298571\n",
            "Train Epoch: 14 [4381/6845 (64%)]\tLoss: 0.126790\n",
            "Train Epoch: 14 [4382/6845 (64%)]\tLoss: 0.132165\n",
            "Train Epoch: 14 [4383/6845 (64%)]\tLoss: 0.116568\n",
            "Train Epoch: 14 [4384/6845 (64%)]\tLoss: 0.782485\n",
            "Train Epoch: 14 [4385/6845 (64%)]\tLoss: 0.138031\n",
            "Train Epoch: 14 [4386/6845 (64%)]\tLoss: 0.685587\n",
            "Train Epoch: 14 [4387/6845 (64%)]\tLoss: 0.059882\n",
            "Train Epoch: 14 [4388/6845 (64%)]\tLoss: 0.324010\n",
            "Train Epoch: 14 [4389/6845 (64%)]\tLoss: 0.100564\n",
            "Train Epoch: 14 [4390/6845 (64%)]\tLoss: 0.188125\n",
            "Train Epoch: 14 [4391/6845 (64%)]\tLoss: 0.603814\n",
            "Train Epoch: 14 [4392/6845 (64%)]\tLoss: 0.886970\n",
            "Train Epoch: 14 [4393/6845 (64%)]\tLoss: 0.554001\n",
            "Train Epoch: 14 [4394/6845 (64%)]\tLoss: 0.539108\n",
            "Train Epoch: 14 [4395/6845 (64%)]\tLoss: 0.111672\n",
            "Train Epoch: 14 [4396/6845 (64%)]\tLoss: 0.075393\n",
            "Train Epoch: 14 [4397/6845 (64%)]\tLoss: 0.159263\n",
            "Train Epoch: 14 [4398/6845 (64%)]\tLoss: 0.067780\n",
            "Train Epoch: 14 [4399/6845 (64%)]\tLoss: 0.098109\n",
            "Train Epoch: 14 [4400/6845 (64%)]\tLoss: 0.238659\n",
            "Train Epoch: 14 [4401/6845 (64%)]\tLoss: 0.161665\n",
            "Train Epoch: 14 [4402/6845 (64%)]\tLoss: 0.074431\n",
            "Train Epoch: 14 [4403/6845 (64%)]\tLoss: 0.079255\n",
            "Train Epoch: 14 [4404/6845 (64%)]\tLoss: 0.096330\n",
            "Train Epoch: 14 [4405/6845 (64%)]\tLoss: 0.266930\n",
            "Train Epoch: 14 [4406/6845 (64%)]\tLoss: 0.172284\n",
            "Train Epoch: 14 [4407/6845 (64%)]\tLoss: 0.072577\n",
            "Train Epoch: 14 [4408/6845 (64%)]\tLoss: 0.069527\n",
            "Train Epoch: 14 [4409/6845 (64%)]\tLoss: 0.097998\n",
            "Train Epoch: 14 [4410/6845 (64%)]\tLoss: 0.083419\n",
            "Train Epoch: 14 [4411/6845 (64%)]\tLoss: 0.087618\n",
            "Train Epoch: 14 [4412/6845 (64%)]\tLoss: 0.131207\n",
            "Train Epoch: 14 [4413/6845 (64%)]\tLoss: 0.068635\n",
            "Train Epoch: 14 [4414/6845 (64%)]\tLoss: 0.156037\n",
            "Train Epoch: 14 [4415/6845 (64%)]\tLoss: 0.075539\n",
            "Train Epoch: 14 [4416/6845 (65%)]\tLoss: 0.568021\n",
            "Train Epoch: 14 [4417/6845 (65%)]\tLoss: 0.446080\n",
            "Train Epoch: 14 [4418/6845 (65%)]\tLoss: 0.100772\n",
            "Train Epoch: 14 [4419/6845 (65%)]\tLoss: 0.066025\n",
            "Train Epoch: 14 [4420/6845 (65%)]\tLoss: 0.746131\n",
            "Train Epoch: 14 [4421/6845 (65%)]\tLoss: 0.711765\n",
            "Train Epoch: 14 [4422/6845 (65%)]\tLoss: 0.458529\n",
            "Train Epoch: 14 [4423/6845 (65%)]\tLoss: 0.501972\n",
            "Train Epoch: 14 [4424/6845 (65%)]\tLoss: 0.723201\n",
            "Train Epoch: 14 [4425/6845 (65%)]\tLoss: 0.554500\n",
            "Train Epoch: 14 [4426/6845 (65%)]\tLoss: 0.079235\n",
            "Train Epoch: 14 [4427/6845 (65%)]\tLoss: 0.458460\n",
            "Train Epoch: 14 [4428/6845 (65%)]\tLoss: 1.038028\n",
            "Train Epoch: 14 [4429/6845 (65%)]\tLoss: 0.084342\n",
            "Train Epoch: 14 [4430/6845 (65%)]\tLoss: 0.080554\n",
            "Train Epoch: 14 [4431/6845 (65%)]\tLoss: 0.237692\n",
            "Train Epoch: 14 [4432/6845 (65%)]\tLoss: 0.110607\n",
            "Train Epoch: 14 [4433/6845 (65%)]\tLoss: 0.227957\n",
            "Train Epoch: 14 [4434/6845 (65%)]\tLoss: 0.247195\n",
            "Train Epoch: 14 [4435/6845 (65%)]\tLoss: 0.933920\n",
            "Train Epoch: 14 [4436/6845 (65%)]\tLoss: 0.403453\n",
            "Train Epoch: 14 [4437/6845 (65%)]\tLoss: 0.453648\n",
            "Train Epoch: 14 [4438/6845 (65%)]\tLoss: 0.103687\n",
            "Train Epoch: 14 [4439/6845 (65%)]\tLoss: 0.146737\n",
            "Train Epoch: 14 [4440/6845 (65%)]\tLoss: 0.125903\n",
            "Train Epoch: 14 [4441/6845 (65%)]\tLoss: 0.263247\n",
            "Train Epoch: 14 [4442/6845 (65%)]\tLoss: 0.196978\n",
            "Train Epoch: 14 [4443/6845 (65%)]\tLoss: 0.249812\n",
            "Train Epoch: 14 [4444/6845 (65%)]\tLoss: 0.569415\n",
            "Train Epoch: 14 [4445/6845 (65%)]\tLoss: 0.160830\n",
            "Train Epoch: 14 [4446/6845 (65%)]\tLoss: 0.084699\n",
            "Train Epoch: 14 [4447/6845 (65%)]\tLoss: 0.144909\n",
            "Train Epoch: 14 [4448/6845 (65%)]\tLoss: 0.151355\n",
            "Train Epoch: 14 [4449/6845 (65%)]\tLoss: 0.151359\n",
            "Train Epoch: 14 [4450/6845 (65%)]\tLoss: 0.625047\n",
            "Train Epoch: 14 [4451/6845 (65%)]\tLoss: 0.304610\n",
            "Train Epoch: 14 [4452/6845 (65%)]\tLoss: 0.298850\n",
            "Train Epoch: 14 [4453/6845 (65%)]\tLoss: 0.146460\n",
            "Train Epoch: 14 [4454/6845 (65%)]\tLoss: 0.088159\n",
            "Train Epoch: 14 [4455/6845 (65%)]\tLoss: 0.198608\n",
            "Train Epoch: 14 [4456/6845 (65%)]\tLoss: 0.186319\n",
            "Train Epoch: 14 [4457/6845 (65%)]\tLoss: 0.133002\n",
            "Train Epoch: 14 [4458/6845 (65%)]\tLoss: 0.104915\n",
            "Train Epoch: 14 [4459/6845 (65%)]\tLoss: 0.108103\n",
            "Train Epoch: 14 [4460/6845 (65%)]\tLoss: 0.168456\n",
            "Train Epoch: 14 [4461/6845 (65%)]\tLoss: 0.113109\n",
            "Train Epoch: 14 [4462/6845 (65%)]\tLoss: 0.084987\n",
            "Train Epoch: 14 [4463/6845 (65%)]\tLoss: 0.086255\n",
            "Train Epoch: 14 [4464/6845 (65%)]\tLoss: 0.258983\n",
            "Train Epoch: 14 [4465/6845 (65%)]\tLoss: 0.104228\n",
            "Train Epoch: 14 [4466/6845 (65%)]\tLoss: 0.273455\n",
            "Train Epoch: 14 [4467/6845 (65%)]\tLoss: 0.312910\n",
            "Train Epoch: 14 [4468/6845 (65%)]\tLoss: 0.122166\n",
            "Train Epoch: 14 [4469/6845 (65%)]\tLoss: 0.112694\n",
            "Train Epoch: 14 [4470/6845 (65%)]\tLoss: 0.079028\n",
            "Train Epoch: 14 [4471/6845 (65%)]\tLoss: 0.077707\n",
            "Train Epoch: 14 [4472/6845 (65%)]\tLoss: 1.463611\n",
            "Train Epoch: 14 [4473/6845 (65%)]\tLoss: 0.111759\n",
            "Train Epoch: 14 [4474/6845 (65%)]\tLoss: 0.240301\n",
            "Train Epoch: 14 [4475/6845 (65%)]\tLoss: 0.175699\n",
            "Train Epoch: 14 [4476/6845 (65%)]\tLoss: 0.160606\n",
            "Train Epoch: 14 [4477/6845 (65%)]\tLoss: 0.258546\n",
            "Train Epoch: 14 [4478/6845 (65%)]\tLoss: 0.505001\n",
            "Train Epoch: 14 [4479/6845 (65%)]\tLoss: 0.719206\n",
            "Train Epoch: 14 [4480/6845 (65%)]\tLoss: 0.246233\n",
            "Train Epoch: 14 [4481/6845 (65%)]\tLoss: 0.459781\n",
            "Train Epoch: 14 [4482/6845 (65%)]\tLoss: 0.200941\n",
            "Train Epoch: 14 [4483/6845 (65%)]\tLoss: 0.096340\n",
            "Train Epoch: 14 [4484/6845 (66%)]\tLoss: 0.104493\n",
            "Train Epoch: 14 [4485/6845 (66%)]\tLoss: 1.102411\n",
            "Train Epoch: 14 [4486/6845 (66%)]\tLoss: 0.084298\n",
            "Train Epoch: 14 [4487/6845 (66%)]\tLoss: 0.101105\n",
            "Train Epoch: 14 [4488/6845 (66%)]\tLoss: 0.091514\n",
            "Train Epoch: 14 [4489/6845 (66%)]\tLoss: 0.091032\n",
            "Train Epoch: 14 [4490/6845 (66%)]\tLoss: 0.108004\n",
            "Train Epoch: 14 [4491/6845 (66%)]\tLoss: 0.108498\n",
            "Train Epoch: 14 [4492/6845 (66%)]\tLoss: 0.083807\n",
            "Train Epoch: 14 [4493/6845 (66%)]\tLoss: 0.594266\n",
            "Train Epoch: 14 [4494/6845 (66%)]\tLoss: 0.072116\n",
            "Train Epoch: 14 [4495/6845 (66%)]\tLoss: 0.130399\n",
            "Train Epoch: 14 [4496/6845 (66%)]\tLoss: 0.224507\n",
            "Train Epoch: 14 [4497/6845 (66%)]\tLoss: 0.145956\n",
            "Train Epoch: 14 [4498/6845 (66%)]\tLoss: 0.415950\n",
            "Train Epoch: 14 [4499/6845 (66%)]\tLoss: 0.090209\n",
            "Train Epoch: 14 [4500/6845 (66%)]\tLoss: 0.869928\n",
            "Train Epoch: 14 [4501/6845 (66%)]\tLoss: 0.090821\n",
            "Train Epoch: 14 [4502/6845 (66%)]\tLoss: 1.031670\n",
            "Train Epoch: 14 [4503/6845 (66%)]\tLoss: 0.092685\n",
            "Train Epoch: 14 [4504/6845 (66%)]\tLoss: 0.104434\n",
            "Train Epoch: 14 [4505/6845 (66%)]\tLoss: 0.193754\n",
            "Train Epoch: 14 [4506/6845 (66%)]\tLoss: 1.071974\n",
            "Train Epoch: 14 [4507/6845 (66%)]\tLoss: 0.116702\n",
            "Train Epoch: 14 [4508/6845 (66%)]\tLoss: 0.091874\n",
            "Train Epoch: 14 [4509/6845 (66%)]\tLoss: 0.092929\n",
            "Train Epoch: 14 [4510/6845 (66%)]\tLoss: 0.076096\n",
            "Train Epoch: 14 [4511/6845 (66%)]\tLoss: 0.082766\n",
            "Train Epoch: 14 [4512/6845 (66%)]\tLoss: 0.097695\n",
            "Train Epoch: 14 [4513/6845 (66%)]\tLoss: 2.073612\n",
            "Train Epoch: 14 [4514/6845 (66%)]\tLoss: 0.464277\n",
            "Train Epoch: 14 [4515/6845 (66%)]\tLoss: 0.105113\n",
            "Train Epoch: 14 [4516/6845 (66%)]\tLoss: 0.099978\n",
            "Train Epoch: 14 [4517/6845 (66%)]\tLoss: 0.092830\n",
            "Train Epoch: 14 [4518/6845 (66%)]\tLoss: 0.064165\n",
            "Train Epoch: 14 [4519/6845 (66%)]\tLoss: 0.523530\n",
            "Train Epoch: 14 [4520/6845 (66%)]\tLoss: 0.222788\n",
            "Train Epoch: 14 [4521/6845 (66%)]\tLoss: 0.647742\n",
            "Train Epoch: 14 [4522/6845 (66%)]\tLoss: 0.051963\n",
            "Train Epoch: 14 [4523/6845 (66%)]\tLoss: 0.061972\n",
            "Train Epoch: 14 [4524/6845 (66%)]\tLoss: 0.141797\n",
            "Train Epoch: 14 [4525/6845 (66%)]\tLoss: 0.144016\n",
            "Train Epoch: 14 [4526/6845 (66%)]\tLoss: 0.862378\n",
            "Train Epoch: 14 [4527/6845 (66%)]\tLoss: 0.317310\n",
            "Train Epoch: 14 [4528/6845 (66%)]\tLoss: 0.689951\n",
            "Train Epoch: 14 [4529/6845 (66%)]\tLoss: 0.106767\n",
            "Train Epoch: 14 [4530/6845 (66%)]\tLoss: 0.105309\n",
            "Train Epoch: 14 [4531/6845 (66%)]\tLoss: 0.107207\n",
            "Train Epoch: 14 [4532/6845 (66%)]\tLoss: 0.436446\n",
            "Train Epoch: 14 [4533/6845 (66%)]\tLoss: 0.057060\n",
            "Train Epoch: 14 [4534/6845 (66%)]\tLoss: 0.060257\n",
            "Train Epoch: 14 [4535/6845 (66%)]\tLoss: 0.062064\n",
            "Train Epoch: 14 [4536/6845 (66%)]\tLoss: 0.461137\n",
            "Train Epoch: 14 [4537/6845 (66%)]\tLoss: 0.095287\n",
            "Train Epoch: 14 [4538/6845 (66%)]\tLoss: 0.061904\n",
            "Train Epoch: 14 [4539/6845 (66%)]\tLoss: 0.057747\n",
            "Train Epoch: 14 [4540/6845 (66%)]\tLoss: 0.059507\n",
            "Train Epoch: 14 [4541/6845 (66%)]\tLoss: 0.096742\n",
            "Train Epoch: 14 [4542/6845 (66%)]\tLoss: 0.133283\n",
            "Train Epoch: 14 [4543/6845 (66%)]\tLoss: 0.056799\n",
            "Train Epoch: 14 [4544/6845 (66%)]\tLoss: 0.054160\n",
            "Train Epoch: 14 [4545/6845 (66%)]\tLoss: 0.642299\n",
            "Train Epoch: 14 [4546/6845 (66%)]\tLoss: 0.666464\n",
            "Train Epoch: 14 [4547/6845 (66%)]\tLoss: 1.006732\n",
            "Train Epoch: 14 [4548/6845 (66%)]\tLoss: 0.133270\n",
            "Train Epoch: 14 [4549/6845 (66%)]\tLoss: 0.468933\n",
            "Train Epoch: 14 [4550/6845 (66%)]\tLoss: 0.043970\n",
            "Train Epoch: 14 [4551/6845 (66%)]\tLoss: 0.591362\n",
            "Train Epoch: 14 [4552/6845 (67%)]\tLoss: 0.142605\n",
            "Train Epoch: 14 [4553/6845 (67%)]\tLoss: 0.483309\n",
            "Train Epoch: 14 [4554/6845 (67%)]\tLoss: 0.938721\n",
            "Train Epoch: 14 [4555/6845 (67%)]\tLoss: 0.240303\n",
            "Train Epoch: 14 [4556/6845 (67%)]\tLoss: 0.646599\n",
            "Train Epoch: 14 [4557/6845 (67%)]\tLoss: 0.048457\n",
            "Train Epoch: 14 [4558/6845 (67%)]\tLoss: 0.176284\n",
            "Train Epoch: 14 [4559/6845 (67%)]\tLoss: 0.330263\n",
            "Train Epoch: 14 [4560/6845 (67%)]\tLoss: 0.568600\n",
            "Train Epoch: 14 [4561/6845 (67%)]\tLoss: 0.141752\n",
            "Train Epoch: 14 [4562/6845 (67%)]\tLoss: 0.255725\n",
            "Train Epoch: 14 [4563/6845 (67%)]\tLoss: 0.527246\n",
            "Train Epoch: 14 [4564/6845 (67%)]\tLoss: 0.582689\n",
            "Train Epoch: 14 [4565/6845 (67%)]\tLoss: 0.202023\n",
            "Train Epoch: 14 [4566/6845 (67%)]\tLoss: 0.112572\n",
            "Train Epoch: 14 [4567/6845 (67%)]\tLoss: 0.070109\n",
            "Train Epoch: 14 [4568/6845 (67%)]\tLoss: 0.114536\n",
            "Train Epoch: 14 [4569/6845 (67%)]\tLoss: 0.093635\n",
            "Train Epoch: 14 [4570/6845 (67%)]\tLoss: 0.121951\n",
            "Train Epoch: 14 [4571/6845 (67%)]\tLoss: 0.097825\n",
            "Train Epoch: 14 [4572/6845 (67%)]\tLoss: 0.542964\n",
            "Train Epoch: 14 [4573/6845 (67%)]\tLoss: 0.250162\n",
            "Train Epoch: 14 [4574/6845 (67%)]\tLoss: 0.106597\n",
            "Train Epoch: 14 [4575/6845 (67%)]\tLoss: 0.148822\n",
            "Train Epoch: 14 [4576/6845 (67%)]\tLoss: 0.118787\n",
            "Train Epoch: 14 [4577/6845 (67%)]\tLoss: 0.176383\n",
            "Train Epoch: 14 [4578/6845 (67%)]\tLoss: 0.285521\n",
            "Train Epoch: 14 [4579/6845 (67%)]\tLoss: 0.076028\n",
            "Train Epoch: 14 [4580/6845 (67%)]\tLoss: 1.060226\n",
            "Train Epoch: 14 [4581/6845 (67%)]\tLoss: 0.491540\n",
            "Train Epoch: 14 [4582/6845 (67%)]\tLoss: 0.136401\n",
            "Train Epoch: 14 [4583/6845 (67%)]\tLoss: 0.175753\n",
            "Train Epoch: 14 [4584/6845 (67%)]\tLoss: 0.593733\n",
            "Train Epoch: 14 [4585/6845 (67%)]\tLoss: 0.104093\n",
            "Train Epoch: 14 [4586/6845 (67%)]\tLoss: 0.428819\n",
            "Train Epoch: 14 [4587/6845 (67%)]\tLoss: 0.161287\n",
            "Train Epoch: 14 [4588/6845 (67%)]\tLoss: 0.499987\n",
            "Train Epoch: 14 [4589/6845 (67%)]\tLoss: 0.062135\n",
            "Train Epoch: 14 [4590/6845 (67%)]\tLoss: 0.108649\n",
            "Train Epoch: 14 [4591/6845 (67%)]\tLoss: 0.532111\n",
            "Train Epoch: 14 [4592/6845 (67%)]\tLoss: 0.228915\n",
            "Train Epoch: 14 [4593/6845 (67%)]\tLoss: 0.401038\n",
            "Train Epoch: 14 [4594/6845 (67%)]\tLoss: 0.086418\n",
            "Train Epoch: 14 [4595/6845 (67%)]\tLoss: 0.096351\n",
            "Train Epoch: 14 [4596/6845 (67%)]\tLoss: 0.106197\n",
            "Train Epoch: 14 [4597/6845 (67%)]\tLoss: 0.480188\n",
            "Train Epoch: 14 [4598/6845 (67%)]\tLoss: 0.128192\n",
            "Train Epoch: 14 [4599/6845 (67%)]\tLoss: 0.100858\n",
            "Train Epoch: 14 [4600/6845 (67%)]\tLoss: 0.255499\n",
            "Train Epoch: 14 [4601/6845 (67%)]\tLoss: 0.830243\n",
            "Train Epoch: 14 [4602/6845 (67%)]\tLoss: 0.074622\n",
            "Train Epoch: 14 [4603/6845 (67%)]\tLoss: 0.109839\n",
            "Train Epoch: 14 [4604/6845 (67%)]\tLoss: 0.231579\n",
            "Train Epoch: 14 [4605/6845 (67%)]\tLoss: 0.367522\n",
            "Train Epoch: 14 [4606/6845 (67%)]\tLoss: 0.084423\n",
            "Train Epoch: 14 [4607/6845 (67%)]\tLoss: 0.095044\n",
            "Train Epoch: 14 [4608/6845 (67%)]\tLoss: 0.233472\n",
            "Train Epoch: 14 [4609/6845 (67%)]\tLoss: 0.063270\n",
            "Train Epoch: 14 [4610/6845 (67%)]\tLoss: 0.124124\n",
            "Train Epoch: 14 [4611/6845 (67%)]\tLoss: 0.439285\n",
            "Train Epoch: 14 [4612/6845 (67%)]\tLoss: 0.087849\n",
            "Train Epoch: 14 [4613/6845 (67%)]\tLoss: 0.078330\n",
            "Train Epoch: 14 [4614/6845 (67%)]\tLoss: 0.136598\n",
            "Train Epoch: 14 [4615/6845 (67%)]\tLoss: 0.109552\n",
            "Train Epoch: 14 [4616/6845 (67%)]\tLoss: 0.087057\n",
            "Train Epoch: 14 [4617/6845 (67%)]\tLoss: 0.432640\n",
            "Train Epoch: 14 [4618/6845 (67%)]\tLoss: 0.656068\n",
            "Train Epoch: 14 [4619/6845 (67%)]\tLoss: 0.068814\n",
            "Train Epoch: 14 [4620/6845 (67%)]\tLoss: 0.109223\n",
            "Train Epoch: 14 [4621/6845 (68%)]\tLoss: 0.425061\n",
            "Train Epoch: 14 [4622/6845 (68%)]\tLoss: 0.067036\n",
            "Train Epoch: 14 [4623/6845 (68%)]\tLoss: 0.442270\n",
            "Train Epoch: 14 [4624/6845 (68%)]\tLoss: 0.085225\n",
            "Train Epoch: 14 [4625/6845 (68%)]\tLoss: 0.103125\n",
            "Train Epoch: 14 [4626/6845 (68%)]\tLoss: 0.598102\n",
            "Train Epoch: 14 [4627/6845 (68%)]\tLoss: 0.059569\n",
            "Train Epoch: 14 [4628/6845 (68%)]\tLoss: 0.089982\n",
            "Train Epoch: 14 [4629/6845 (68%)]\tLoss: 0.253391\n",
            "Train Epoch: 14 [4630/6845 (68%)]\tLoss: 0.140795\n",
            "Train Epoch: 14 [4631/6845 (68%)]\tLoss: 0.088683\n",
            "Train Epoch: 14 [4632/6845 (68%)]\tLoss: 0.138222\n",
            "Train Epoch: 14 [4633/6845 (68%)]\tLoss: 0.177310\n",
            "Train Epoch: 14 [4634/6845 (68%)]\tLoss: 0.071031\n",
            "Train Epoch: 14 [4635/6845 (68%)]\tLoss: 0.578561\n",
            "Train Epoch: 14 [4636/6845 (68%)]\tLoss: 0.118865\n",
            "Train Epoch: 14 [4637/6845 (68%)]\tLoss: 0.073873\n",
            "Train Epoch: 14 [4638/6845 (68%)]\tLoss: 0.064555\n",
            "Train Epoch: 14 [4639/6845 (68%)]\tLoss: 0.155536\n",
            "Train Epoch: 14 [4640/6845 (68%)]\tLoss: 0.092733\n",
            "Train Epoch: 14 [4641/6845 (68%)]\tLoss: 0.567999\n",
            "Train Epoch: 14 [4642/6845 (68%)]\tLoss: 0.064514\n",
            "Train Epoch: 14 [4643/6845 (68%)]\tLoss: 0.203035\n",
            "Train Epoch: 14 [4644/6845 (68%)]\tLoss: 0.074871\n",
            "Train Epoch: 14 [4645/6845 (68%)]\tLoss: 0.368955\n",
            "Train Epoch: 14 [4646/6845 (68%)]\tLoss: 0.563456\n",
            "Train Epoch: 14 [4647/6845 (68%)]\tLoss: 0.470541\n",
            "Train Epoch: 14 [4648/6845 (68%)]\tLoss: 0.099359\n",
            "Train Epoch: 14 [4649/6845 (68%)]\tLoss: 0.054865\n",
            "Train Epoch: 14 [4650/6845 (68%)]\tLoss: 0.213918\n",
            "Train Epoch: 14 [4651/6845 (68%)]\tLoss: 0.477433\n",
            "Train Epoch: 14 [4652/6845 (68%)]\tLoss: 0.054989\n",
            "Train Epoch: 14 [4653/6845 (68%)]\tLoss: 0.176905\n",
            "Train Epoch: 14 [4654/6845 (68%)]\tLoss: 0.092691\n",
            "Train Epoch: 14 [4655/6845 (68%)]\tLoss: 0.098510\n",
            "Train Epoch: 14 [4656/6845 (68%)]\tLoss: 0.735680\n",
            "Train Epoch: 14 [4657/6845 (68%)]\tLoss: 0.099892\n",
            "Train Epoch: 14 [4658/6845 (68%)]\tLoss: 0.243525\n",
            "Train Epoch: 14 [4659/6845 (68%)]\tLoss: 0.101529\n",
            "Train Epoch: 14 [4660/6845 (68%)]\tLoss: 0.082529\n",
            "Train Epoch: 14 [4661/6845 (68%)]\tLoss: 0.187098\n",
            "Train Epoch: 14 [4662/6845 (68%)]\tLoss: 0.098767\n",
            "Train Epoch: 14 [4663/6845 (68%)]\tLoss: 0.891217\n",
            "Train Epoch: 14 [4664/6845 (68%)]\tLoss: 0.471969\n",
            "Train Epoch: 14 [4665/6845 (68%)]\tLoss: 0.053056\n",
            "Train Epoch: 14 [4666/6845 (68%)]\tLoss: 0.109698\n",
            "Train Epoch: 14 [4667/6845 (68%)]\tLoss: 0.750350\n",
            "Train Epoch: 14 [4668/6845 (68%)]\tLoss: 0.798087\n",
            "Train Epoch: 14 [4669/6845 (68%)]\tLoss: 0.477399\n",
            "Train Epoch: 14 [4670/6845 (68%)]\tLoss: 0.235130\n",
            "Train Epoch: 14 [4671/6845 (68%)]\tLoss: 0.157134\n",
            "Train Epoch: 14 [4672/6845 (68%)]\tLoss: 0.475839\n",
            "Train Epoch: 14 [4673/6845 (68%)]\tLoss: 1.069243\n",
            "Train Epoch: 14 [4674/6845 (68%)]\tLoss: 0.064507\n",
            "Train Epoch: 14 [4675/6845 (68%)]\tLoss: 0.066156\n",
            "Train Epoch: 14 [4676/6845 (68%)]\tLoss: 0.405385\n",
            "Train Epoch: 14 [4677/6845 (68%)]\tLoss: 0.090333\n",
            "Train Epoch: 14 [4678/6845 (68%)]\tLoss: 0.145793\n",
            "Train Epoch: 14 [4679/6845 (68%)]\tLoss: 0.184269\n",
            "Train Epoch: 14 [4680/6845 (68%)]\tLoss: 0.101710\n",
            "Train Epoch: 14 [4681/6845 (68%)]\tLoss: 1.869024\n",
            "Train Epoch: 14 [4682/6845 (68%)]\tLoss: 0.068395\n",
            "Train Epoch: 14 [4683/6845 (68%)]\tLoss: 0.099994\n",
            "Train Epoch: 14 [4684/6845 (68%)]\tLoss: 0.383614\n",
            "Train Epoch: 14 [4685/6845 (68%)]\tLoss: 0.107329\n",
            "Train Epoch: 14 [4686/6845 (68%)]\tLoss: 0.065019\n",
            "Train Epoch: 14 [4687/6845 (68%)]\tLoss: 0.109796\n",
            "Train Epoch: 14 [4688/6845 (68%)]\tLoss: 0.075297\n",
            "Train Epoch: 14 [4689/6845 (69%)]\tLoss: 0.205799\n",
            "Train Epoch: 14 [4690/6845 (69%)]\tLoss: 0.095407\n",
            "Train Epoch: 14 [4691/6845 (69%)]\tLoss: 0.100731\n",
            "Train Epoch: 14 [4692/6845 (69%)]\tLoss: 0.104133\n",
            "Train Epoch: 14 [4693/6845 (69%)]\tLoss: 0.264623\n",
            "Train Epoch: 14 [4694/6845 (69%)]\tLoss: 0.264249\n",
            "Train Epoch: 14 [4695/6845 (69%)]\tLoss: 0.782937\n",
            "Train Epoch: 14 [4696/6845 (69%)]\tLoss: 0.793950\n",
            "Train Epoch: 14 [4697/6845 (69%)]\tLoss: 0.106233\n",
            "Train Epoch: 14 [4698/6845 (69%)]\tLoss: 0.127354\n",
            "Train Epoch: 14 [4699/6845 (69%)]\tLoss: 0.207658\n",
            "Train Epoch: 14 [4700/6845 (69%)]\tLoss: 0.112736\n",
            "Train Epoch: 14 [4701/6845 (69%)]\tLoss: 0.316875\n",
            "Train Epoch: 14 [4702/6845 (69%)]\tLoss: 0.073544\n",
            "Train Epoch: 14 [4703/6845 (69%)]\tLoss: 0.218203\n",
            "Train Epoch: 14 [4704/6845 (69%)]\tLoss: 0.655494\n",
            "Train Epoch: 14 [4705/6845 (69%)]\tLoss: 0.081433\n",
            "Train Epoch: 14 [4706/6845 (69%)]\tLoss: 0.081938\n",
            "Train Epoch: 14 [4707/6845 (69%)]\tLoss: 0.654838\n",
            "Train Epoch: 14 [4708/6845 (69%)]\tLoss: 0.108261\n",
            "Train Epoch: 14 [4709/6845 (69%)]\tLoss: 0.799138\n",
            "Train Epoch: 14 [4710/6845 (69%)]\tLoss: 0.230814\n",
            "Train Epoch: 14 [4711/6845 (69%)]\tLoss: 0.075668\n",
            "Train Epoch: 14 [4712/6845 (69%)]\tLoss: 0.114445\n",
            "Train Epoch: 14 [4713/6845 (69%)]\tLoss: 0.621947\n",
            "Train Epoch: 14 [4714/6845 (69%)]\tLoss: 0.073550\n",
            "Train Epoch: 14 [4715/6845 (69%)]\tLoss: 0.225145\n",
            "Train Epoch: 14 [4716/6845 (69%)]\tLoss: 0.120386\n",
            "Train Epoch: 14 [4717/6845 (69%)]\tLoss: 0.072956\n",
            "Train Epoch: 14 [4718/6845 (69%)]\tLoss: 0.099690\n",
            "Train Epoch: 14 [4719/6845 (69%)]\tLoss: 0.122893\n",
            "Train Epoch: 14 [4720/6845 (69%)]\tLoss: 0.520389\n",
            "Train Epoch: 14 [4721/6845 (69%)]\tLoss: 0.155879\n",
            "Train Epoch: 14 [4722/6845 (69%)]\tLoss: 0.105838\n",
            "Train Epoch: 14 [4723/6845 (69%)]\tLoss: 0.384906\n",
            "Train Epoch: 14 [4724/6845 (69%)]\tLoss: 0.114020\n",
            "Train Epoch: 14 [4725/6845 (69%)]\tLoss: 0.074061\n",
            "Train Epoch: 14 [4726/6845 (69%)]\tLoss: 0.106057\n",
            "Train Epoch: 14 [4727/6845 (69%)]\tLoss: 0.076923\n",
            "Train Epoch: 14 [4728/6845 (69%)]\tLoss: 0.082124\n",
            "Train Epoch: 14 [4729/6845 (69%)]\tLoss: 0.079979\n",
            "Train Epoch: 14 [4730/6845 (69%)]\tLoss: 0.221213\n",
            "Train Epoch: 14 [4731/6845 (69%)]\tLoss: 0.797693\n",
            "Train Epoch: 14 [4732/6845 (69%)]\tLoss: 0.070313\n",
            "Train Epoch: 14 [4733/6845 (69%)]\tLoss: 0.525291\n",
            "Train Epoch: 14 [4734/6845 (69%)]\tLoss: 0.066061\n",
            "Train Epoch: 14 [4735/6845 (69%)]\tLoss: 0.107948\n",
            "Train Epoch: 14 [4736/6845 (69%)]\tLoss: 0.187325\n",
            "Train Epoch: 14 [4737/6845 (69%)]\tLoss: 0.075603\n",
            "Train Epoch: 14 [4738/6845 (69%)]\tLoss: 0.147869\n",
            "Train Epoch: 14 [4739/6845 (69%)]\tLoss: 0.092622\n",
            "Train Epoch: 14 [4740/6845 (69%)]\tLoss: 0.422950\n",
            "Train Epoch: 14 [4741/6845 (69%)]\tLoss: 0.114595\n",
            "Train Epoch: 14 [4742/6845 (69%)]\tLoss: 0.201811\n",
            "Train Epoch: 14 [4743/6845 (69%)]\tLoss: 0.102861\n",
            "Train Epoch: 14 [4744/6845 (69%)]\tLoss: 0.068613\n",
            "Train Epoch: 14 [4745/6845 (69%)]\tLoss: 0.079612\n",
            "Train Epoch: 14 [4746/6845 (69%)]\tLoss: 0.205111\n",
            "Train Epoch: 14 [4747/6845 (69%)]\tLoss: 0.167467\n",
            "Train Epoch: 14 [4748/6845 (69%)]\tLoss: 0.126490\n",
            "Train Epoch: 14 [4749/6845 (69%)]\tLoss: 0.056904\n",
            "Train Epoch: 14 [4750/6845 (69%)]\tLoss: 0.616982\n",
            "Train Epoch: 14 [4751/6845 (69%)]\tLoss: 0.084631\n",
            "Train Epoch: 14 [4752/6845 (69%)]\tLoss: 0.083365\n",
            "Train Epoch: 14 [4753/6845 (69%)]\tLoss: 0.087247\n",
            "Train Epoch: 14 [4754/6845 (69%)]\tLoss: 0.751188\n",
            "Train Epoch: 14 [4755/6845 (69%)]\tLoss: 0.063379\n",
            "Train Epoch: 14 [4756/6845 (69%)]\tLoss: 0.066396\n",
            "Train Epoch: 14 [4757/6845 (69%)]\tLoss: 0.729965\n",
            "Train Epoch: 14 [4758/6845 (70%)]\tLoss: 0.063120\n",
            "Train Epoch: 14 [4759/6845 (70%)]\tLoss: 0.185178\n",
            "Train Epoch: 14 [4760/6845 (70%)]\tLoss: 0.112515\n",
            "Train Epoch: 14 [4761/6845 (70%)]\tLoss: 0.488781\n",
            "Train Epoch: 14 [4762/6845 (70%)]\tLoss: 1.086983\n",
            "Train Epoch: 14 [4763/6845 (70%)]\tLoss: 0.830801\n",
            "Train Epoch: 14 [4764/6845 (70%)]\tLoss: 0.558787\n",
            "Train Epoch: 14 [4765/6845 (70%)]\tLoss: 0.387855\n",
            "Train Epoch: 14 [4766/6845 (70%)]\tLoss: 0.099718\n",
            "Train Epoch: 14 [4767/6845 (70%)]\tLoss: 0.075779\n",
            "Train Epoch: 14 [4768/6845 (70%)]\tLoss: 0.207089\n",
            "Train Epoch: 14 [4769/6845 (70%)]\tLoss: 0.062631\n",
            "Train Epoch: 14 [4770/6845 (70%)]\tLoss: 0.778085\n",
            "Train Epoch: 14 [4771/6845 (70%)]\tLoss: 0.813318\n",
            "Train Epoch: 14 [4772/6845 (70%)]\tLoss: 0.070262\n",
            "Train Epoch: 14 [4773/6845 (70%)]\tLoss: 0.623578\n",
            "Train Epoch: 14 [4774/6845 (70%)]\tLoss: 0.132224\n",
            "Train Epoch: 14 [4775/6845 (70%)]\tLoss: 0.160667\n",
            "Train Epoch: 14 [4776/6845 (70%)]\tLoss: 0.063750\n",
            "Train Epoch: 14 [4777/6845 (70%)]\tLoss: 0.075458\n",
            "Train Epoch: 14 [4778/6845 (70%)]\tLoss: 0.088818\n",
            "Train Epoch: 14 [4779/6845 (70%)]\tLoss: 0.179243\n",
            "Train Epoch: 14 [4780/6845 (70%)]\tLoss: 0.170959\n",
            "Train Epoch: 14 [4781/6845 (70%)]\tLoss: 0.154723\n",
            "Train Epoch: 14 [4782/6845 (70%)]\tLoss: 0.138583\n",
            "Train Epoch: 14 [4783/6845 (70%)]\tLoss: 0.113771\n",
            "Train Epoch: 14 [4784/6845 (70%)]\tLoss: 0.073302\n",
            "Train Epoch: 14 [4785/6845 (70%)]\tLoss: 0.066214\n",
            "Train Epoch: 14 [4786/6845 (70%)]\tLoss: 0.073837\n",
            "Train Epoch: 14 [4787/6845 (70%)]\tLoss: 0.124944\n",
            "Train Epoch: 14 [4788/6845 (70%)]\tLoss: 0.089762\n",
            "Train Epoch: 14 [4789/6845 (70%)]\tLoss: 0.205359\n",
            "Train Epoch: 14 [4790/6845 (70%)]\tLoss: 0.142545\n",
            "Train Epoch: 14 [4791/6845 (70%)]\tLoss: 0.079418\n",
            "Train Epoch: 14 [4792/6845 (70%)]\tLoss: 0.076243\n",
            "Train Epoch: 14 [4793/6845 (70%)]\tLoss: 1.078962\n",
            "Train Epoch: 14 [4794/6845 (70%)]\tLoss: 0.666192\n",
            "Train Epoch: 14 [4795/6845 (70%)]\tLoss: 0.540135\n",
            "Train Epoch: 14 [4796/6845 (70%)]\tLoss: 0.097378\n",
            "Train Epoch: 14 [4797/6845 (70%)]\tLoss: 0.147964\n",
            "Train Epoch: 14 [4798/6845 (70%)]\tLoss: 0.073509\n",
            "Train Epoch: 14 [4799/6845 (70%)]\tLoss: 0.053135\n",
            "Train Epoch: 14 [4800/6845 (70%)]\tLoss: 0.517742\n",
            "Train Epoch: 14 [4801/6845 (70%)]\tLoss: 0.480424\n",
            "Train Epoch: 14 [4802/6845 (70%)]\tLoss: 0.222988\n",
            "Train Epoch: 14 [4803/6845 (70%)]\tLoss: 0.197975\n",
            "Train Epoch: 14 [4804/6845 (70%)]\tLoss: 0.126841\n",
            "Train Epoch: 14 [4805/6845 (70%)]\tLoss: 0.748382\n",
            "Train Epoch: 14 [4806/6845 (70%)]\tLoss: 0.079041\n",
            "Train Epoch: 14 [4807/6845 (70%)]\tLoss: 0.397729\n",
            "Train Epoch: 14 [4808/6845 (70%)]\tLoss: 0.061459\n",
            "Train Epoch: 14 [4809/6845 (70%)]\tLoss: 0.102891\n",
            "Train Epoch: 14 [4810/6845 (70%)]\tLoss: 0.143487\n",
            "Train Epoch: 14 [4811/6845 (70%)]\tLoss: 0.100818\n",
            "Train Epoch: 14 [4812/6845 (70%)]\tLoss: 0.074888\n",
            "Train Epoch: 14 [4813/6845 (70%)]\tLoss: 0.053329\n",
            "Train Epoch: 14 [4814/6845 (70%)]\tLoss: 0.063364\n",
            "Train Epoch: 14 [4815/6845 (70%)]\tLoss: 1.206884\n",
            "Train Epoch: 14 [4816/6845 (70%)]\tLoss: 0.066277\n",
            "Train Epoch: 14 [4817/6845 (70%)]\tLoss: 0.126857\n",
            "Train Epoch: 14 [4818/6845 (70%)]\tLoss: 0.410420\n",
            "Train Epoch: 14 [4819/6845 (70%)]\tLoss: 0.793169\n",
            "Train Epoch: 14 [4820/6845 (70%)]\tLoss: 0.177078\n",
            "Train Epoch: 14 [4821/6845 (70%)]\tLoss: 0.853064\n",
            "Train Epoch: 14 [4822/6845 (70%)]\tLoss: 0.066092\n",
            "Train Epoch: 14 [4823/6845 (70%)]\tLoss: 0.053351\n",
            "Train Epoch: 14 [4824/6845 (70%)]\tLoss: 0.103953\n",
            "Train Epoch: 14 [4825/6845 (70%)]\tLoss: 0.143087\n",
            "Train Epoch: 14 [4826/6845 (71%)]\tLoss: 0.088957\n",
            "Train Epoch: 14 [4827/6845 (71%)]\tLoss: 0.607482\n",
            "Train Epoch: 14 [4828/6845 (71%)]\tLoss: 0.388910\n",
            "Train Epoch: 14 [4829/6845 (71%)]\tLoss: 0.949064\n",
            "Train Epoch: 14 [4830/6845 (71%)]\tLoss: 0.064889\n",
            "Train Epoch: 14 [4831/6845 (71%)]\tLoss: 0.198959\n",
            "Train Epoch: 14 [4832/6845 (71%)]\tLoss: 0.088207\n",
            "Train Epoch: 14 [4833/6845 (71%)]\tLoss: 0.201488\n",
            "Train Epoch: 14 [4834/6845 (71%)]\tLoss: 0.112173\n",
            "Train Epoch: 14 [4835/6845 (71%)]\tLoss: 0.389940\n",
            "Train Epoch: 14 [4836/6845 (71%)]\tLoss: 0.192776\n",
            "Train Epoch: 14 [4837/6845 (71%)]\tLoss: 0.215763\n",
            "Train Epoch: 14 [4838/6845 (71%)]\tLoss: 0.651438\n",
            "Train Epoch: 14 [4839/6845 (71%)]\tLoss: 0.083786\n",
            "Train Epoch: 14 [4840/6845 (71%)]\tLoss: 0.486660\n",
            "Train Epoch: 14 [4841/6845 (71%)]\tLoss: 0.712428\n",
            "Train Epoch: 14 [4842/6845 (71%)]\tLoss: 0.050538\n",
            "Train Epoch: 14 [4843/6845 (71%)]\tLoss: 0.088819\n",
            "Train Epoch: 14 [4844/6845 (71%)]\tLoss: 0.375968\n",
            "Train Epoch: 14 [4845/6845 (71%)]\tLoss: 0.074307\n",
            "Train Epoch: 14 [4846/6845 (71%)]\tLoss: 0.156000\n",
            "Train Epoch: 14 [4847/6845 (71%)]\tLoss: 0.061603\n",
            "Train Epoch: 14 [4848/6845 (71%)]\tLoss: 0.088310\n",
            "Train Epoch: 14 [4849/6845 (71%)]\tLoss: 0.564840\n",
            "Train Epoch: 14 [4850/6845 (71%)]\tLoss: 0.105203\n",
            "Train Epoch: 14 [4851/6845 (71%)]\tLoss: 0.086536\n",
            "Train Epoch: 14 [4852/6845 (71%)]\tLoss: 0.057654\n",
            "Train Epoch: 14 [4853/6845 (71%)]\tLoss: 0.113808\n",
            "Train Epoch: 14 [4854/6845 (71%)]\tLoss: 0.692559\n",
            "Train Epoch: 14 [4855/6845 (71%)]\tLoss: 0.058831\n",
            "Train Epoch: 14 [4856/6845 (71%)]\tLoss: 0.332763\n",
            "Train Epoch: 14 [4857/6845 (71%)]\tLoss: 0.066026\n",
            "Train Epoch: 14 [4858/6845 (71%)]\tLoss: 0.752902\n",
            "Train Epoch: 14 [4859/6845 (71%)]\tLoss: 0.702188\n",
            "Train Epoch: 14 [4860/6845 (71%)]\tLoss: 0.328300\n",
            "Train Epoch: 14 [4861/6845 (71%)]\tLoss: 0.123607\n",
            "Train Epoch: 14 [4862/6845 (71%)]\tLoss: 0.121668\n",
            "Train Epoch: 14 [4863/6845 (71%)]\tLoss: 0.145794\n",
            "Train Epoch: 14 [4864/6845 (71%)]\tLoss: 0.181781\n",
            "Train Epoch: 14 [4865/6845 (71%)]\tLoss: 0.105111\n",
            "Train Epoch: 14 [4866/6845 (71%)]\tLoss: 0.269479\n",
            "Train Epoch: 14 [4867/6845 (71%)]\tLoss: 0.063182\n",
            "Train Epoch: 14 [4868/6845 (71%)]\tLoss: 0.676357\n",
            "Train Epoch: 14 [4869/6845 (71%)]\tLoss: 0.062314\n",
            "Train Epoch: 14 [4870/6845 (71%)]\tLoss: 0.079915\n",
            "Train Epoch: 14 [4871/6845 (71%)]\tLoss: 0.076685\n",
            "Train Epoch: 14 [4872/6845 (71%)]\tLoss: 0.076696\n",
            "Train Epoch: 14 [4873/6845 (71%)]\tLoss: 0.097682\n",
            "Train Epoch: 14 [4874/6845 (71%)]\tLoss: 0.846879\n",
            "Train Epoch: 14 [4875/6845 (71%)]\tLoss: 0.902456\n",
            "Train Epoch: 14 [4876/6845 (71%)]\tLoss: 0.066674\n",
            "Train Epoch: 14 [4877/6845 (71%)]\tLoss: 0.063074\n",
            "Train Epoch: 14 [4878/6845 (71%)]\tLoss: 0.061851\n",
            "Train Epoch: 14 [4879/6845 (71%)]\tLoss: 0.095143\n",
            "Train Epoch: 14 [4880/6845 (71%)]\tLoss: 0.472538\n",
            "Train Epoch: 14 [4881/6845 (71%)]\tLoss: 0.091676\n",
            "Train Epoch: 14 [4882/6845 (71%)]\tLoss: 0.087699\n",
            "Train Epoch: 14 [4883/6845 (71%)]\tLoss: 0.669570\n",
            "Train Epoch: 14 [4884/6845 (71%)]\tLoss: 0.093460\n",
            "Train Epoch: 14 [4885/6845 (71%)]\tLoss: 0.100718\n",
            "Train Epoch: 14 [4886/6845 (71%)]\tLoss: 0.062044\n",
            "Train Epoch: 14 [4887/6845 (71%)]\tLoss: 0.557491\n",
            "Train Epoch: 14 [4888/6845 (71%)]\tLoss: 0.251091\n",
            "Train Epoch: 14 [4889/6845 (71%)]\tLoss: 0.158429\n",
            "Train Epoch: 14 [4890/6845 (71%)]\tLoss: 0.060340\n",
            "Train Epoch: 14 [4891/6845 (71%)]\tLoss: 0.118263\n",
            "Train Epoch: 14 [4892/6845 (71%)]\tLoss: 0.063615\n",
            "Train Epoch: 14 [4893/6845 (71%)]\tLoss: 0.107246\n",
            "Train Epoch: 14 [4894/6845 (71%)]\tLoss: 0.157749\n",
            "Train Epoch: 14 [4895/6845 (72%)]\tLoss: 0.081988\n",
            "Train Epoch: 14 [4896/6845 (72%)]\tLoss: 0.434440\n",
            "Train Epoch: 14 [4897/6845 (72%)]\tLoss: 0.443030\n",
            "Train Epoch: 14 [4898/6845 (72%)]\tLoss: 0.081867\n",
            "Train Epoch: 14 [4899/6845 (72%)]\tLoss: 0.152954\n",
            "Train Epoch: 14 [4900/6845 (72%)]\tLoss: 1.758672\n",
            "Train Epoch: 14 [4901/6845 (72%)]\tLoss: 0.250466\n",
            "Train Epoch: 14 [4902/6845 (72%)]\tLoss: 0.641064\n",
            "Train Epoch: 14 [4903/6845 (72%)]\tLoss: 0.210950\n",
            "Train Epoch: 14 [4904/6845 (72%)]\tLoss: 0.175554\n",
            "Train Epoch: 14 [4905/6845 (72%)]\tLoss: 0.541711\n",
            "Train Epoch: 14 [4906/6845 (72%)]\tLoss: 0.243522\n",
            "Train Epoch: 14 [4907/6845 (72%)]\tLoss: 0.407436\n",
            "Train Epoch: 14 [4908/6845 (72%)]\tLoss: 0.080492\n",
            "Train Epoch: 14 [4909/6845 (72%)]\tLoss: 0.091293\n",
            "Train Epoch: 14 [4910/6845 (72%)]\tLoss: 0.074848\n",
            "Train Epoch: 14 [4911/6845 (72%)]\tLoss: 0.575012\n",
            "Train Epoch: 14 [4912/6845 (72%)]\tLoss: 0.139246\n",
            "Train Epoch: 14 [4913/6845 (72%)]\tLoss: 0.087390\n",
            "Train Epoch: 14 [4914/6845 (72%)]\tLoss: 0.359554\n",
            "Train Epoch: 14 [4915/6845 (72%)]\tLoss: 0.059650\n",
            "Train Epoch: 14 [4916/6845 (72%)]\tLoss: 0.220978\n",
            "Train Epoch: 14 [4917/6845 (72%)]\tLoss: 0.222860\n",
            "Train Epoch: 14 [4918/6845 (72%)]\tLoss: 0.063497\n",
            "Train Epoch: 14 [4919/6845 (72%)]\tLoss: 0.077226\n",
            "Train Epoch: 14 [4920/6845 (72%)]\tLoss: 0.189789\n",
            "Train Epoch: 14 [4921/6845 (72%)]\tLoss: 0.066149\n",
            "Train Epoch: 14 [4922/6845 (72%)]\tLoss: 0.081358\n",
            "Train Epoch: 14 [4923/6845 (72%)]\tLoss: 0.229469\n",
            "Train Epoch: 14 [4924/6845 (72%)]\tLoss: 0.230522\n",
            "Train Epoch: 14 [4925/6845 (72%)]\tLoss: 0.149012\n",
            "Train Epoch: 14 [4926/6845 (72%)]\tLoss: 0.084483\n",
            "Train Epoch: 14 [4927/6845 (72%)]\tLoss: 0.072975\n",
            "Train Epoch: 14 [4928/6845 (72%)]\tLoss: 0.472596\n",
            "Train Epoch: 14 [4929/6845 (72%)]\tLoss: 0.071570\n",
            "Train Epoch: 14 [4930/6845 (72%)]\tLoss: 0.085086\n",
            "Train Epoch: 14 [4931/6845 (72%)]\tLoss: 0.790235\n",
            "Train Epoch: 14 [4932/6845 (72%)]\tLoss: 0.075276\n",
            "Train Epoch: 14 [4933/6845 (72%)]\tLoss: 0.111309\n",
            "Train Epoch: 14 [4934/6845 (72%)]\tLoss: 0.795526\n",
            "Train Epoch: 14 [4935/6845 (72%)]\tLoss: 0.573625\n",
            "Train Epoch: 14 [4936/6845 (72%)]\tLoss: 0.196794\n",
            "Train Epoch: 14 [4937/6845 (72%)]\tLoss: 0.122215\n",
            "Train Epoch: 14 [4938/6845 (72%)]\tLoss: 1.307529\n",
            "Train Epoch: 14 [4939/6845 (72%)]\tLoss: 0.089718\n",
            "Train Epoch: 14 [4940/6845 (72%)]\tLoss: 0.167589\n",
            "Train Epoch: 14 [4941/6845 (72%)]\tLoss: 0.110518\n",
            "Train Epoch: 14 [4942/6845 (72%)]\tLoss: 0.114254\n",
            "Train Epoch: 14 [4943/6845 (72%)]\tLoss: 0.217472\n",
            "Train Epoch: 14 [4944/6845 (72%)]\tLoss: 0.131092\n",
            "Train Epoch: 14 [4945/6845 (72%)]\tLoss: 0.722158\n",
            "Train Epoch: 14 [4946/6845 (72%)]\tLoss: 0.566090\n",
            "Train Epoch: 14 [4947/6845 (72%)]\tLoss: 0.081845\n",
            "Train Epoch: 14 [4948/6845 (72%)]\tLoss: 0.115965\n",
            "Train Epoch: 14 [4949/6845 (72%)]\tLoss: 0.109622\n",
            "Train Epoch: 14 [4950/6845 (72%)]\tLoss: 0.645979\n",
            "Train Epoch: 14 [4951/6845 (72%)]\tLoss: 0.180930\n",
            "Train Epoch: 14 [4952/6845 (72%)]\tLoss: 0.057287\n",
            "Train Epoch: 14 [4953/6845 (72%)]\tLoss: 0.067674\n",
            "Train Epoch: 14 [4954/6845 (72%)]\tLoss: 0.068581\n",
            "Train Epoch: 14 [4955/6845 (72%)]\tLoss: 0.101771\n",
            "Train Epoch: 14 [4956/6845 (72%)]\tLoss: 0.075199\n",
            "Train Epoch: 14 [4957/6845 (72%)]\tLoss: 0.073406\n",
            "Train Epoch: 14 [4958/6845 (72%)]\tLoss: 0.501367\n",
            "Train Epoch: 14 [4959/6845 (72%)]\tLoss: 0.073199\n",
            "Train Epoch: 14 [4960/6845 (72%)]\tLoss: 0.097339\n",
            "Train Epoch: 14 [4961/6845 (72%)]\tLoss: 0.157524\n",
            "Train Epoch: 14 [4962/6845 (72%)]\tLoss: 0.095280\n",
            "Train Epoch: 14 [4963/6845 (73%)]\tLoss: 0.083992\n",
            "Train Epoch: 14 [4964/6845 (73%)]\tLoss: 0.151716\n",
            "Train Epoch: 14 [4965/6845 (73%)]\tLoss: 0.090913\n",
            "Train Epoch: 14 [4966/6845 (73%)]\tLoss: 0.119954\n",
            "Train Epoch: 14 [4967/6845 (73%)]\tLoss: 0.089194\n",
            "Train Epoch: 14 [4968/6845 (73%)]\tLoss: 0.146287\n",
            "Train Epoch: 14 [4969/6845 (73%)]\tLoss: 0.116035\n",
            "Train Epoch: 14 [4970/6845 (73%)]\tLoss: 0.172688\n",
            "Train Epoch: 14 [4971/6845 (73%)]\tLoss: 0.046475\n",
            "Train Epoch: 14 [4972/6845 (73%)]\tLoss: 0.150271\n",
            "Train Epoch: 14 [4973/6845 (73%)]\tLoss: 0.040648\n",
            "Train Epoch: 14 [4974/6845 (73%)]\tLoss: 0.391452\n",
            "Train Epoch: 14 [4975/6845 (73%)]\tLoss: 0.086411\n",
            "Train Epoch: 14 [4976/6845 (73%)]\tLoss: 0.145652\n",
            "Train Epoch: 14 [4977/6845 (73%)]\tLoss: 0.104202\n",
            "Train Epoch: 14 [4978/6845 (73%)]\tLoss: 0.385798\n",
            "Train Epoch: 14 [4979/6845 (73%)]\tLoss: 0.043661\n",
            "Train Epoch: 14 [4980/6845 (73%)]\tLoss: 0.085536\n",
            "Train Epoch: 14 [4981/6845 (73%)]\tLoss: 0.047912\n",
            "Train Epoch: 14 [4982/6845 (73%)]\tLoss: 0.511030\n",
            "Train Epoch: 14 [4983/6845 (73%)]\tLoss: 0.826940\n",
            "Train Epoch: 14 [4984/6845 (73%)]\tLoss: 0.070093\n",
            "Train Epoch: 14 [4985/6845 (73%)]\tLoss: 0.088873\n",
            "Train Epoch: 14 [4986/6845 (73%)]\tLoss: 0.066545\n",
            "Train Epoch: 14 [4987/6845 (73%)]\tLoss: 0.614043\n",
            "Train Epoch: 14 [4988/6845 (73%)]\tLoss: 0.567514\n",
            "Train Epoch: 14 [4989/6845 (73%)]\tLoss: 0.810055\n",
            "Train Epoch: 14 [4990/6845 (73%)]\tLoss: 0.094577\n",
            "Train Epoch: 14 [4991/6845 (73%)]\tLoss: 0.162563\n",
            "Train Epoch: 14 [4992/6845 (73%)]\tLoss: 0.092785\n",
            "Train Epoch: 14 [4993/6845 (73%)]\tLoss: 0.358138\n",
            "Train Epoch: 14 [4994/6845 (73%)]\tLoss: 0.107775\n",
            "Train Epoch: 14 [4995/6845 (73%)]\tLoss: 0.374505\n",
            "Train Epoch: 14 [4996/6845 (73%)]\tLoss: 0.098562\n",
            "Train Epoch: 14 [4997/6845 (73%)]\tLoss: 0.058531\n",
            "Train Epoch: 14 [4998/6845 (73%)]\tLoss: 0.117678\n",
            "Train Epoch: 14 [4999/6845 (73%)]\tLoss: 0.123190\n",
            "Train Epoch: 14 [5000/6845 (73%)]\tLoss: 0.205157\n",
            "Train Epoch: 14 [5001/6845 (73%)]\tLoss: 0.066606\n",
            "Train Epoch: 14 [5002/6845 (73%)]\tLoss: 0.058691\n",
            "Train Epoch: 14 [5003/6845 (73%)]\tLoss: 0.098890\n",
            "Train Epoch: 14 [5004/6845 (73%)]\tLoss: 0.079610\n",
            "Train Epoch: 14 [5005/6845 (73%)]\tLoss: 0.117278\n",
            "Train Epoch: 14 [5006/6845 (73%)]\tLoss: 0.101854\n",
            "Train Epoch: 14 [5007/6845 (73%)]\tLoss: 0.174515\n",
            "Train Epoch: 14 [5008/6845 (73%)]\tLoss: 0.448687\n",
            "Train Epoch: 14 [5009/6845 (73%)]\tLoss: 0.131790\n",
            "Train Epoch: 14 [5010/6845 (73%)]\tLoss: 0.080035\n",
            "Train Epoch: 14 [5011/6845 (73%)]\tLoss: 0.177654\n",
            "Train Epoch: 14 [5012/6845 (73%)]\tLoss: 1.605713\n",
            "Train Epoch: 14 [5013/6845 (73%)]\tLoss: 0.756004\n",
            "Train Epoch: 14 [5014/6845 (73%)]\tLoss: 0.123209\n",
            "Train Epoch: 14 [5015/6845 (73%)]\tLoss: 0.208037\n",
            "Train Epoch: 14 [5016/6845 (73%)]\tLoss: 0.169314\n",
            "Train Epoch: 14 [5017/6845 (73%)]\tLoss: 0.072244\n",
            "Train Epoch: 14 [5018/6845 (73%)]\tLoss: 1.470678\n",
            "Train Epoch: 14 [5019/6845 (73%)]\tLoss: 0.108514\n",
            "Train Epoch: 14 [5020/6845 (73%)]\tLoss: 0.055238\n",
            "Train Epoch: 14 [5021/6845 (73%)]\tLoss: 0.067161\n",
            "Train Epoch: 14 [5022/6845 (73%)]\tLoss: 0.180560\n",
            "Train Epoch: 14 [5023/6845 (73%)]\tLoss: 0.523666\n",
            "Train Epoch: 14 [5024/6845 (73%)]\tLoss: 0.178138\n",
            "Train Epoch: 14 [5025/6845 (73%)]\tLoss: 0.564159\n",
            "Train Epoch: 14 [5026/6845 (73%)]\tLoss: 0.718338\n",
            "Train Epoch: 14 [5027/6845 (73%)]\tLoss: 0.118997\n",
            "Train Epoch: 14 [5028/6845 (73%)]\tLoss: 0.102436\n",
            "Train Epoch: 14 [5029/6845 (73%)]\tLoss: 0.104031\n",
            "Train Epoch: 14 [5030/6845 (73%)]\tLoss: 0.071988\n",
            "Train Epoch: 14 [5031/6845 (73%)]\tLoss: 1.092619\n",
            "Train Epoch: 14 [5032/6845 (74%)]\tLoss: 0.053997\n",
            "Train Epoch: 14 [5033/6845 (74%)]\tLoss: 0.097062\n",
            "Train Epoch: 14 [5034/6845 (74%)]\tLoss: 0.583704\n",
            "Train Epoch: 14 [5035/6845 (74%)]\tLoss: 0.094901\n",
            "Train Epoch: 14 [5036/6845 (74%)]\tLoss: 0.115932\n",
            "Train Epoch: 14 [5037/6845 (74%)]\tLoss: 0.465115\n",
            "Train Epoch: 14 [5038/6845 (74%)]\tLoss: 0.075597\n",
            "Train Epoch: 14 [5039/6845 (74%)]\tLoss: 0.128881\n",
            "Train Epoch: 14 [5040/6845 (74%)]\tLoss: 0.082352\n",
            "Train Epoch: 14 [5041/6845 (74%)]\tLoss: 0.094540\n",
            "Train Epoch: 14 [5042/6845 (74%)]\tLoss: 0.372401\n",
            "Train Epoch: 14 [5043/6845 (74%)]\tLoss: 0.052604\n",
            "Train Epoch: 14 [5044/6845 (74%)]\tLoss: 0.624911\n",
            "Train Epoch: 14 [5045/6845 (74%)]\tLoss: 0.502806\n",
            "Train Epoch: 14 [5046/6845 (74%)]\tLoss: 0.101684\n",
            "Train Epoch: 14 [5047/6845 (74%)]\tLoss: 1.128353\n",
            "Train Epoch: 14 [5048/6845 (74%)]\tLoss: 0.659184\n",
            "Train Epoch: 14 [5049/6845 (74%)]\tLoss: 0.081725\n",
            "Train Epoch: 14 [5050/6845 (74%)]\tLoss: 0.553925\n",
            "Train Epoch: 14 [5051/6845 (74%)]\tLoss: 0.083263\n",
            "Train Epoch: 14 [5052/6845 (74%)]\tLoss: 0.119653\n",
            "Train Epoch: 14 [5053/6845 (74%)]\tLoss: 0.121503\n",
            "Train Epoch: 14 [5054/6845 (74%)]\tLoss: 0.096335\n",
            "Train Epoch: 14 [5055/6845 (74%)]\tLoss: 1.136235\n",
            "Train Epoch: 14 [5056/6845 (74%)]\tLoss: 0.109888\n",
            "Train Epoch: 14 [5057/6845 (74%)]\tLoss: 0.375206\n",
            "Train Epoch: 14 [5058/6845 (74%)]\tLoss: 0.190520\n",
            "Train Epoch: 14 [5059/6845 (74%)]\tLoss: 0.070078\n",
            "Train Epoch: 14 [5060/6845 (74%)]\tLoss: 0.206720\n",
            "Train Epoch: 14 [5061/6845 (74%)]\tLoss: 0.732198\n",
            "Train Epoch: 14 [5062/6845 (74%)]\tLoss: 0.107633\n",
            "Train Epoch: 14 [5063/6845 (74%)]\tLoss: 0.259864\n",
            "Train Epoch: 14 [5064/6845 (74%)]\tLoss: 0.130303\n",
            "Train Epoch: 14 [5065/6845 (74%)]\tLoss: 0.348984\n",
            "Train Epoch: 14 [5066/6845 (74%)]\tLoss: 0.128104\n",
            "Train Epoch: 14 [5067/6845 (74%)]\tLoss: 0.586414\n",
            "Train Epoch: 14 [5068/6845 (74%)]\tLoss: 0.238031\n",
            "Train Epoch: 14 [5069/6845 (74%)]\tLoss: 0.533181\n",
            "Train Epoch: 14 [5070/6845 (74%)]\tLoss: 0.093363\n",
            "Train Epoch: 14 [5071/6845 (74%)]\tLoss: 0.095605\n",
            "Train Epoch: 14 [5072/6845 (74%)]\tLoss: 0.163956\n",
            "Train Epoch: 14 [5073/6845 (74%)]\tLoss: 0.082755\n",
            "Train Epoch: 14 [5074/6845 (74%)]\tLoss: 0.321788\n",
            "Train Epoch: 14 [5075/6845 (74%)]\tLoss: 0.204862\n",
            "Train Epoch: 14 [5076/6845 (74%)]\tLoss: 0.546923\n",
            "Train Epoch: 14 [5077/6845 (74%)]\tLoss: 0.084482\n",
            "Train Epoch: 14 [5078/6845 (74%)]\tLoss: 0.826073\n",
            "Train Epoch: 14 [5079/6845 (74%)]\tLoss: 0.500026\n",
            "Train Epoch: 14 [5080/6845 (74%)]\tLoss: 0.084076\n",
            "Train Epoch: 14 [5081/6845 (74%)]\tLoss: 0.277685\n",
            "Train Epoch: 14 [5082/6845 (74%)]\tLoss: 0.813632\n",
            "Train Epoch: 14 [5083/6845 (74%)]\tLoss: 0.122813\n",
            "Train Epoch: 14 [5084/6845 (74%)]\tLoss: 0.171447\n",
            "Train Epoch: 14 [5085/6845 (74%)]\tLoss: 0.404602\n",
            "Train Epoch: 14 [5086/6845 (74%)]\tLoss: 0.077442\n",
            "Train Epoch: 14 [5087/6845 (74%)]\tLoss: 0.129108\n",
            "Train Epoch: 14 [5088/6845 (74%)]\tLoss: 0.095661\n",
            "Train Epoch: 14 [5089/6845 (74%)]\tLoss: 0.080932\n",
            "Train Epoch: 14 [5090/6845 (74%)]\tLoss: 0.186167\n",
            "Train Epoch: 14 [5091/6845 (74%)]\tLoss: 0.104005\n",
            "Train Epoch: 14 [5092/6845 (74%)]\tLoss: 0.224640\n",
            "Train Epoch: 14 [5093/6845 (74%)]\tLoss: 0.249187\n",
            "Train Epoch: 14 [5094/6845 (74%)]\tLoss: 0.114338\n",
            "Train Epoch: 14 [5095/6845 (74%)]\tLoss: 1.121917\n",
            "Train Epoch: 14 [5096/6845 (74%)]\tLoss: 0.091595\n",
            "Train Epoch: 14 [5097/6845 (74%)]\tLoss: 0.091199\n",
            "Train Epoch: 14 [5098/6845 (74%)]\tLoss: 0.096894\n",
            "Train Epoch: 14 [5099/6845 (74%)]\tLoss: 0.601241\n",
            "Train Epoch: 14 [5100/6845 (75%)]\tLoss: 0.099152\n",
            "Train Epoch: 14 [5101/6845 (75%)]\tLoss: 0.210347\n",
            "Train Epoch: 14 [5102/6845 (75%)]\tLoss: 0.713864\n",
            "Train Epoch: 14 [5103/6845 (75%)]\tLoss: 0.859826\n",
            "Train Epoch: 14 [5104/6845 (75%)]\tLoss: 0.260288\n",
            "Train Epoch: 14 [5105/6845 (75%)]\tLoss: 0.089355\n",
            "Train Epoch: 14 [5106/6845 (75%)]\tLoss: 1.003321\n",
            "Train Epoch: 14 [5107/6845 (75%)]\tLoss: 0.087403\n",
            "Train Epoch: 14 [5108/6845 (75%)]\tLoss: 0.141901\n",
            "Train Epoch: 14 [5109/6845 (75%)]\tLoss: 0.450045\n",
            "Train Epoch: 14 [5110/6845 (75%)]\tLoss: 0.261520\n",
            "Train Epoch: 14 [5111/6845 (75%)]\tLoss: 0.118226\n",
            "Train Epoch: 14 [5112/6845 (75%)]\tLoss: 0.109150\n",
            "Train Epoch: 14 [5113/6845 (75%)]\tLoss: 0.112512\n",
            "Train Epoch: 14 [5114/6845 (75%)]\tLoss: 0.130530\n",
            "Train Epoch: 14 [5115/6845 (75%)]\tLoss: 0.128491\n",
            "Train Epoch: 14 [5116/6845 (75%)]\tLoss: 0.121274\n",
            "Train Epoch: 14 [5117/6845 (75%)]\tLoss: 0.133544\n",
            "Train Epoch: 14 [5118/6845 (75%)]\tLoss: 0.093720\n",
            "Train Epoch: 14 [5119/6845 (75%)]\tLoss: 0.212578\n",
            "Train Epoch: 14 [5120/6845 (75%)]\tLoss: 0.210204\n",
            "Train Epoch: 14 [5121/6845 (75%)]\tLoss: 0.097769\n",
            "Train Epoch: 14 [5122/6845 (75%)]\tLoss: 0.582094\n",
            "Train Epoch: 14 [5123/6845 (75%)]\tLoss: 0.845706\n",
            "Train Epoch: 14 [5124/6845 (75%)]\tLoss: 0.181188\n",
            "Train Epoch: 14 [5125/6845 (75%)]\tLoss: 0.223082\n",
            "Train Epoch: 14 [5126/6845 (75%)]\tLoss: 0.453675\n",
            "Train Epoch: 14 [5127/6845 (75%)]\tLoss: 0.552305\n",
            "Train Epoch: 14 [5128/6845 (75%)]\tLoss: 0.194652\n",
            "Train Epoch: 14 [5129/6845 (75%)]\tLoss: 0.292700\n",
            "Train Epoch: 14 [5130/6845 (75%)]\tLoss: 0.146424\n",
            "Train Epoch: 14 [5131/6845 (75%)]\tLoss: 0.637876\n",
            "Train Epoch: 14 [5132/6845 (75%)]\tLoss: 0.081777\n",
            "Train Epoch: 14 [5133/6845 (75%)]\tLoss: 0.462364\n",
            "Train Epoch: 14 [5134/6845 (75%)]\tLoss: 0.172678\n",
            "Train Epoch: 14 [5135/6845 (75%)]\tLoss: 0.078996\n",
            "Train Epoch: 14 [5136/6845 (75%)]\tLoss: 0.105354\n",
            "Train Epoch: 14 [5137/6845 (75%)]\tLoss: 0.116401\n",
            "Train Epoch: 14 [5138/6845 (75%)]\tLoss: 0.130560\n",
            "Train Epoch: 14 [5139/6845 (75%)]\tLoss: 0.137402\n",
            "Train Epoch: 14 [5140/6845 (75%)]\tLoss: 0.139048\n",
            "Train Epoch: 14 [5141/6845 (75%)]\tLoss: 0.081359\n",
            "Train Epoch: 14 [5142/6845 (75%)]\tLoss: 0.094145\n",
            "Train Epoch: 14 [5143/6845 (75%)]\tLoss: 0.075371\n",
            "Train Epoch: 14 [5144/6845 (75%)]\tLoss: 0.538325\n",
            "Train Epoch: 14 [5145/6845 (75%)]\tLoss: 0.492585\n",
            "Train Epoch: 14 [5146/6845 (75%)]\tLoss: 0.101672\n",
            "Train Epoch: 14 [5147/6845 (75%)]\tLoss: 0.410590\n",
            "Train Epoch: 14 [5148/6845 (75%)]\tLoss: 0.060842\n",
            "Train Epoch: 14 [5149/6845 (75%)]\tLoss: 0.118499\n",
            "Train Epoch: 14 [5150/6845 (75%)]\tLoss: 0.066956\n",
            "Train Epoch: 14 [5151/6845 (75%)]\tLoss: 0.071860\n",
            "Train Epoch: 14 [5152/6845 (75%)]\tLoss: 0.180553\n",
            "Train Epoch: 14 [5153/6845 (75%)]\tLoss: 0.097418\n",
            "Train Epoch: 14 [5154/6845 (75%)]\tLoss: 0.626861\n",
            "Train Epoch: 14 [5155/6845 (75%)]\tLoss: 0.668005\n",
            "Train Epoch: 14 [5156/6845 (75%)]\tLoss: 0.055385\n",
            "Train Epoch: 14 [5157/6845 (75%)]\tLoss: 0.858400\n",
            "Train Epoch: 14 [5158/6845 (75%)]\tLoss: 0.053591\n",
            "Train Epoch: 14 [5159/6845 (75%)]\tLoss: 0.402190\n",
            "Train Epoch: 14 [5160/6845 (75%)]\tLoss: 0.308778\n",
            "Train Epoch: 14 [5161/6845 (75%)]\tLoss: 0.182200\n",
            "Train Epoch: 14 [5162/6845 (75%)]\tLoss: 0.108621\n",
            "Train Epoch: 14 [5163/6845 (75%)]\tLoss: 0.194517\n",
            "Train Epoch: 14 [5164/6845 (75%)]\tLoss: 0.043699\n",
            "Train Epoch: 14 [5165/6845 (75%)]\tLoss: 0.157636\n",
            "Train Epoch: 14 [5166/6845 (75%)]\tLoss: 0.150853\n",
            "Train Epoch: 14 [5167/6845 (75%)]\tLoss: 0.067617\n",
            "Train Epoch: 14 [5168/6845 (76%)]\tLoss: 0.142318\n",
            "Train Epoch: 14 [5169/6845 (76%)]\tLoss: 0.250918\n",
            "Train Epoch: 14 [5170/6845 (76%)]\tLoss: 0.652492\n",
            "Train Epoch: 14 [5171/6845 (76%)]\tLoss: 0.111957\n",
            "Train Epoch: 14 [5172/6845 (76%)]\tLoss: 0.185259\n",
            "Train Epoch: 14 [5173/6845 (76%)]\tLoss: 0.106602\n",
            "Train Epoch: 14 [5174/6845 (76%)]\tLoss: 0.084317\n",
            "Train Epoch: 14 [5175/6845 (76%)]\tLoss: 0.095466\n",
            "Train Epoch: 14 [5176/6845 (76%)]\tLoss: 0.183297\n",
            "Train Epoch: 14 [5177/6845 (76%)]\tLoss: 0.043309\n",
            "Train Epoch: 14 [5178/6845 (76%)]\tLoss: 0.101565\n",
            "Train Epoch: 14 [5179/6845 (76%)]\tLoss: 0.582855\n",
            "Train Epoch: 14 [5180/6845 (76%)]\tLoss: 0.234724\n",
            "Train Epoch: 14 [5181/6845 (76%)]\tLoss: 0.044978\n",
            "Train Epoch: 14 [5182/6845 (76%)]\tLoss: 0.101934\n",
            "Train Epoch: 14 [5183/6845 (76%)]\tLoss: 0.182700\n",
            "Train Epoch: 14 [5184/6845 (76%)]\tLoss: 0.040111\n",
            "Train Epoch: 14 [5185/6845 (76%)]\tLoss: 0.112569\n",
            "Train Epoch: 14 [5186/6845 (76%)]\tLoss: 0.045969\n",
            "Train Epoch: 14 [5187/6845 (76%)]\tLoss: 0.040452\n",
            "Train Epoch: 14 [5188/6845 (76%)]\tLoss: 0.459179\n",
            "Train Epoch: 14 [5189/6845 (76%)]\tLoss: 0.158498\n",
            "Train Epoch: 14 [5190/6845 (76%)]\tLoss: 0.154019\n",
            "Train Epoch: 14 [5191/6845 (76%)]\tLoss: 0.042821\n",
            "Train Epoch: 14 [5192/6845 (76%)]\tLoss: 1.256202\n",
            "Train Epoch: 14 [5193/6845 (76%)]\tLoss: 0.135537\n",
            "Train Epoch: 14 [5194/6845 (76%)]\tLoss: 0.564286\n",
            "Train Epoch: 14 [5195/6845 (76%)]\tLoss: 0.141545\n",
            "Train Epoch: 14 [5196/6845 (76%)]\tLoss: 0.102886\n",
            "Train Epoch: 14 [5197/6845 (76%)]\tLoss: 0.083754\n",
            "Train Epoch: 14 [5198/6845 (76%)]\tLoss: 0.038449\n",
            "Train Epoch: 14 [5199/6845 (76%)]\tLoss: 0.118734\n",
            "Train Epoch: 14 [5200/6845 (76%)]\tLoss: 0.060817\n",
            "Train Epoch: 14 [5201/6845 (76%)]\tLoss: 0.158814\n",
            "Train Epoch: 14 [5202/6845 (76%)]\tLoss: 0.117193\n",
            "Train Epoch: 14 [5203/6845 (76%)]\tLoss: 0.181061\n",
            "Train Epoch: 14 [5204/6845 (76%)]\tLoss: 0.222103\n",
            "Train Epoch: 14 [5205/6845 (76%)]\tLoss: 0.076096\n",
            "Train Epoch: 14 [5206/6845 (76%)]\tLoss: 0.071763\n",
            "Train Epoch: 14 [5207/6845 (76%)]\tLoss: 0.076762\n",
            "Train Epoch: 14 [5208/6845 (76%)]\tLoss: 0.070090\n",
            "Train Epoch: 14 [5209/6845 (76%)]\tLoss: 0.207099\n",
            "Train Epoch: 14 [5210/6845 (76%)]\tLoss: 0.099251\n",
            "Train Epoch: 14 [5211/6845 (76%)]\tLoss: 0.517317\n",
            "Train Epoch: 14 [5212/6845 (76%)]\tLoss: 0.566360\n",
            "Train Epoch: 14 [5213/6845 (76%)]\tLoss: 0.529767\n",
            "Train Epoch: 14 [5214/6845 (76%)]\tLoss: 0.215720\n",
            "Train Epoch: 14 [5215/6845 (76%)]\tLoss: 0.101279\n",
            "Train Epoch: 14 [5216/6845 (76%)]\tLoss: 0.544418\n",
            "Train Epoch: 14 [5217/6845 (76%)]\tLoss: 0.066532\n",
            "Train Epoch: 14 [5218/6845 (76%)]\tLoss: 0.594796\n",
            "Train Epoch: 14 [5219/6845 (76%)]\tLoss: 0.147413\n",
            "Train Epoch: 14 [5220/6845 (76%)]\tLoss: 0.090097\n",
            "Train Epoch: 14 [5221/6845 (76%)]\tLoss: 0.081548\n",
            "Train Epoch: 14 [5222/6845 (76%)]\tLoss: 0.090768\n",
            "Train Epoch: 14 [5223/6845 (76%)]\tLoss: 0.653419\n",
            "Train Epoch: 14 [5224/6845 (76%)]\tLoss: 0.211890\n",
            "Train Epoch: 14 [5225/6845 (76%)]\tLoss: 0.051696\n",
            "Train Epoch: 14 [5226/6845 (76%)]\tLoss: 0.141777\n",
            "Train Epoch: 14 [5227/6845 (76%)]\tLoss: 0.077194\n",
            "Train Epoch: 14 [5228/6845 (76%)]\tLoss: 0.515133\n",
            "Train Epoch: 14 [5229/6845 (76%)]\tLoss: 0.081571\n",
            "Train Epoch: 14 [5230/6845 (76%)]\tLoss: 0.107814\n",
            "Train Epoch: 14 [5231/6845 (76%)]\tLoss: 0.077095\n",
            "Train Epoch: 14 [5232/6845 (76%)]\tLoss: 0.116201\n",
            "Train Epoch: 14 [5233/6845 (76%)]\tLoss: 0.070972\n",
            "Train Epoch: 14 [5234/6845 (76%)]\tLoss: 0.100013\n",
            "Train Epoch: 14 [5235/6845 (76%)]\tLoss: 0.081085\n",
            "Train Epoch: 14 [5236/6845 (76%)]\tLoss: 0.061373\n",
            "Train Epoch: 14 [5237/6845 (77%)]\tLoss: 0.071228\n",
            "Train Epoch: 14 [5238/6845 (77%)]\tLoss: 0.081386\n",
            "Train Epoch: 14 [5239/6845 (77%)]\tLoss: 0.066776\n",
            "Train Epoch: 14 [5240/6845 (77%)]\tLoss: 1.039350\n",
            "Train Epoch: 14 [5241/6845 (77%)]\tLoss: 0.173584\n",
            "Train Epoch: 14 [5242/6845 (77%)]\tLoss: 0.636118\n",
            "Train Epoch: 14 [5243/6845 (77%)]\tLoss: 0.108115\n",
            "Train Epoch: 14 [5244/6845 (77%)]\tLoss: 0.077521\n",
            "Train Epoch: 14 [5245/6845 (77%)]\tLoss: 0.087769\n",
            "Train Epoch: 14 [5246/6845 (77%)]\tLoss: 0.051901\n",
            "Train Epoch: 14 [5247/6845 (77%)]\tLoss: 0.101505\n",
            "Train Epoch: 14 [5248/6845 (77%)]\tLoss: 0.422081\n",
            "Train Epoch: 14 [5249/6845 (77%)]\tLoss: 0.137927\n",
            "Train Epoch: 14 [5250/6845 (77%)]\tLoss: 0.524540\n",
            "Train Epoch: 14 [5251/6845 (77%)]\tLoss: 0.113178\n",
            "Train Epoch: 14 [5252/6845 (77%)]\tLoss: 0.156719\n",
            "Train Epoch: 14 [5253/6845 (77%)]\tLoss: 0.540101\n",
            "Train Epoch: 14 [5254/6845 (77%)]\tLoss: 0.085369\n",
            "Train Epoch: 14 [5255/6845 (77%)]\tLoss: 0.158367\n",
            "Train Epoch: 14 [5256/6845 (77%)]\tLoss: 0.137796\n",
            "Train Epoch: 14 [5257/6845 (77%)]\tLoss: 0.060060\n",
            "Train Epoch: 14 [5258/6845 (77%)]\tLoss: 0.154225\n",
            "Train Epoch: 14 [5259/6845 (77%)]\tLoss: 0.379329\n",
            "Train Epoch: 14 [5260/6845 (77%)]\tLoss: 0.092929\n",
            "Train Epoch: 14 [5261/6845 (77%)]\tLoss: 0.115233\n",
            "Train Epoch: 14 [5262/6845 (77%)]\tLoss: 0.082352\n",
            "Train Epoch: 14 [5263/6845 (77%)]\tLoss: 0.092387\n",
            "Train Epoch: 14 [5264/6845 (77%)]\tLoss: 0.052233\n",
            "Train Epoch: 14 [5265/6845 (77%)]\tLoss: 0.067560\n",
            "Train Epoch: 14 [5266/6845 (77%)]\tLoss: 0.122377\n",
            "Train Epoch: 14 [5267/6845 (77%)]\tLoss: 0.182205\n",
            "Train Epoch: 14 [5268/6845 (77%)]\tLoss: 0.648090\n",
            "Train Epoch: 14 [5269/6845 (77%)]\tLoss: 0.078109\n",
            "Train Epoch: 14 [5270/6845 (77%)]\tLoss: 0.065441\n",
            "Train Epoch: 14 [5271/6845 (77%)]\tLoss: 0.432443\n",
            "Train Epoch: 14 [5272/6845 (77%)]\tLoss: 0.057634\n",
            "Train Epoch: 14 [5273/6845 (77%)]\tLoss: 0.071807\n",
            "Train Epoch: 14 [5274/6845 (77%)]\tLoss: 0.407765\n",
            "Train Epoch: 14 [5275/6845 (77%)]\tLoss: 0.072001\n",
            "Train Epoch: 14 [5276/6845 (77%)]\tLoss: 0.079580\n",
            "Train Epoch: 14 [5277/6845 (77%)]\tLoss: 0.075591\n",
            "Train Epoch: 14 [5278/6845 (77%)]\tLoss: 0.631490\n",
            "Train Epoch: 14 [5279/6845 (77%)]\tLoss: 0.076575\n",
            "Train Epoch: 14 [5280/6845 (77%)]\tLoss: 0.538137\n",
            "Train Epoch: 14 [5281/6845 (77%)]\tLoss: 0.055964\n",
            "Train Epoch: 14 [5282/6845 (77%)]\tLoss: 0.129312\n",
            "Train Epoch: 14 [5283/6845 (77%)]\tLoss: 0.083983\n",
            "Train Epoch: 14 [5284/6845 (77%)]\tLoss: 0.069412\n",
            "Train Epoch: 14 [5285/6845 (77%)]\tLoss: 0.141053\n",
            "Train Epoch: 14 [5286/6845 (77%)]\tLoss: 0.922235\n",
            "Train Epoch: 14 [5287/6845 (77%)]\tLoss: 0.128449\n",
            "Train Epoch: 14 [5288/6845 (77%)]\tLoss: 0.666391\n",
            "Train Epoch: 14 [5289/6845 (77%)]\tLoss: 0.414871\n",
            "Train Epoch: 14 [5290/6845 (77%)]\tLoss: 0.524602\n",
            "Train Epoch: 14 [5291/6845 (77%)]\tLoss: 0.517043\n",
            "Train Epoch: 14 [5292/6845 (77%)]\tLoss: 0.525492\n",
            "Train Epoch: 14 [5293/6845 (77%)]\tLoss: 0.106876\n",
            "Train Epoch: 14 [5294/6845 (77%)]\tLoss: 0.445006\n",
            "Train Epoch: 14 [5295/6845 (77%)]\tLoss: 0.132397\n",
            "Train Epoch: 14 [5296/6845 (77%)]\tLoss: 0.116746\n",
            "Train Epoch: 14 [5297/6845 (77%)]\tLoss: 0.147004\n",
            "Train Epoch: 14 [5298/6845 (77%)]\tLoss: 0.389796\n",
            "Train Epoch: 14 [5299/6845 (77%)]\tLoss: 0.165382\n",
            "Train Epoch: 14 [5300/6845 (77%)]\tLoss: 0.878616\n",
            "Train Epoch: 14 [5301/6845 (77%)]\tLoss: 0.333979\n",
            "Train Epoch: 14 [5302/6845 (77%)]\tLoss: 0.178615\n",
            "Train Epoch: 14 [5303/6845 (77%)]\tLoss: 0.109134\n",
            "Train Epoch: 14 [5304/6845 (77%)]\tLoss: 0.189466\n",
            "Train Epoch: 14 [5305/6845 (78%)]\tLoss: 0.372906\n",
            "Train Epoch: 14 [5306/6845 (78%)]\tLoss: 0.460874\n",
            "Train Epoch: 14 [5307/6845 (78%)]\tLoss: 0.104379\n",
            "Train Epoch: 14 [5308/6845 (78%)]\tLoss: 0.148182\n",
            "Train Epoch: 14 [5309/6845 (78%)]\tLoss: 0.735302\n",
            "Train Epoch: 14 [5310/6845 (78%)]\tLoss: 0.103564\n",
            "Train Epoch: 14 [5311/6845 (78%)]\tLoss: 0.244491\n",
            "Train Epoch: 14 [5312/6845 (78%)]\tLoss: 0.098194\n",
            "Train Epoch: 14 [5313/6845 (78%)]\tLoss: 0.182982\n",
            "Train Epoch: 14 [5314/6845 (78%)]\tLoss: 0.154254\n",
            "Train Epoch: 14 [5315/6845 (78%)]\tLoss: 0.579879\n",
            "Train Epoch: 14 [5316/6845 (78%)]\tLoss: 0.098206\n",
            "Train Epoch: 14 [5317/6845 (78%)]\tLoss: 0.148735\n",
            "Train Epoch: 14 [5318/6845 (78%)]\tLoss: 0.177324\n",
            "Train Epoch: 14 [5319/6845 (78%)]\tLoss: 0.833201\n",
            "Train Epoch: 14 [5320/6845 (78%)]\tLoss: 0.084038\n",
            "Train Epoch: 14 [5321/6845 (78%)]\tLoss: 0.077638\n",
            "Train Epoch: 14 [5322/6845 (78%)]\tLoss: 0.149100\n",
            "Train Epoch: 14 [5323/6845 (78%)]\tLoss: 0.569200\n",
            "Train Epoch: 14 [5324/6845 (78%)]\tLoss: 0.076066\n",
            "Train Epoch: 14 [5325/6845 (78%)]\tLoss: 0.123198\n",
            "Train Epoch: 14 [5326/6845 (78%)]\tLoss: 0.123047\n",
            "Train Epoch: 14 [5327/6845 (78%)]\tLoss: 0.092440\n",
            "Train Epoch: 14 [5328/6845 (78%)]\tLoss: 0.092416\n",
            "Train Epoch: 14 [5329/6845 (78%)]\tLoss: 0.207386\n",
            "Train Epoch: 14 [5330/6845 (78%)]\tLoss: 0.105996\n",
            "Train Epoch: 14 [5331/6845 (78%)]\tLoss: 0.122107\n",
            "Train Epoch: 14 [5332/6845 (78%)]\tLoss: 0.098435\n",
            "Train Epoch: 14 [5333/6845 (78%)]\tLoss: 1.599746\n",
            "Train Epoch: 14 [5334/6845 (78%)]\tLoss: 0.382937\n",
            "Train Epoch: 14 [5335/6845 (78%)]\tLoss: 0.387800\n",
            "Train Epoch: 14 [5336/6845 (78%)]\tLoss: 0.378968\n",
            "Train Epoch: 14 [5337/6845 (78%)]\tLoss: 0.049204\n",
            "Train Epoch: 14 [5338/6845 (78%)]\tLoss: 0.664249\n",
            "Train Epoch: 14 [5339/6845 (78%)]\tLoss: 0.161662\n",
            "Train Epoch: 14 [5340/6845 (78%)]\tLoss: 0.194204\n",
            "Train Epoch: 14 [5341/6845 (78%)]\tLoss: 0.683232\n",
            "Train Epoch: 14 [5342/6845 (78%)]\tLoss: 0.147224\n",
            "Train Epoch: 14 [5343/6845 (78%)]\tLoss: 0.199326\n",
            "Train Epoch: 14 [5344/6845 (78%)]\tLoss: 0.093483\n",
            "Train Epoch: 14 [5345/6845 (78%)]\tLoss: 0.068623\n",
            "Train Epoch: 14 [5346/6845 (78%)]\tLoss: 0.240111\n",
            "Train Epoch: 14 [5347/6845 (78%)]\tLoss: 0.157497\n",
            "Train Epoch: 14 [5348/6845 (78%)]\tLoss: 0.119792\n",
            "Train Epoch: 14 [5349/6845 (78%)]\tLoss: 0.113851\n",
            "Train Epoch: 14 [5350/6845 (78%)]\tLoss: 0.059455\n",
            "Train Epoch: 14 [5351/6845 (78%)]\tLoss: 0.092762\n",
            "Train Epoch: 14 [5352/6845 (78%)]\tLoss: 0.820988\n",
            "Train Epoch: 14 [5353/6845 (78%)]\tLoss: 0.067603\n",
            "Train Epoch: 14 [5354/6845 (78%)]\tLoss: 0.096202\n",
            "Train Epoch: 14 [5355/6845 (78%)]\tLoss: 0.179106\n",
            "Train Epoch: 14 [5356/6845 (78%)]\tLoss: 0.059799\n",
            "Train Epoch: 14 [5357/6845 (78%)]\tLoss: 0.159598\n",
            "Train Epoch: 14 [5358/6845 (78%)]\tLoss: 0.334856\n",
            "Train Epoch: 14 [5359/6845 (78%)]\tLoss: 0.070806\n",
            "Train Epoch: 14 [5360/6845 (78%)]\tLoss: 0.172980\n",
            "Train Epoch: 14 [5361/6845 (78%)]\tLoss: 0.078940\n",
            "Train Epoch: 14 [5362/6845 (78%)]\tLoss: 0.083864\n",
            "Train Epoch: 14 [5363/6845 (78%)]\tLoss: 0.131307\n",
            "Train Epoch: 14 [5364/6845 (78%)]\tLoss: 0.076387\n",
            "Train Epoch: 14 [5365/6845 (78%)]\tLoss: 0.052045\n",
            "Train Epoch: 14 [5366/6845 (78%)]\tLoss: 0.088107\n",
            "Train Epoch: 14 [5367/6845 (78%)]\tLoss: 0.118487\n",
            "Train Epoch: 14 [5368/6845 (78%)]\tLoss: 0.063431\n",
            "Train Epoch: 14 [5369/6845 (78%)]\tLoss: 0.451273\n",
            "Train Epoch: 14 [5370/6845 (78%)]\tLoss: 0.711736\n",
            "Train Epoch: 14 [5371/6845 (78%)]\tLoss: 0.104930\n",
            "Train Epoch: 14 [5372/6845 (78%)]\tLoss: 0.058482\n",
            "Train Epoch: 14 [5373/6845 (78%)]\tLoss: 1.381591\n",
            "Train Epoch: 14 [5374/6845 (79%)]\tLoss: 0.055700\n",
            "Train Epoch: 14 [5375/6845 (79%)]\tLoss: 0.469483\n",
            "Train Epoch: 14 [5376/6845 (79%)]\tLoss: 0.133191\n",
            "Train Epoch: 14 [5377/6845 (79%)]\tLoss: 1.012383\n",
            "Train Epoch: 14 [5378/6845 (79%)]\tLoss: 0.074813\n",
            "Train Epoch: 14 [5379/6845 (79%)]\tLoss: 0.079594\n",
            "Train Epoch: 14 [5380/6845 (79%)]\tLoss: 0.355479\n",
            "Train Epoch: 14 [5381/6845 (79%)]\tLoss: 0.356422\n",
            "Train Epoch: 14 [5382/6845 (79%)]\tLoss: 0.524761\n",
            "Train Epoch: 14 [5383/6845 (79%)]\tLoss: 0.110312\n",
            "Train Epoch: 14 [5384/6845 (79%)]\tLoss: 0.085661\n",
            "Train Epoch: 14 [5385/6845 (79%)]\tLoss: 0.187990\n",
            "Train Epoch: 14 [5386/6845 (79%)]\tLoss: 0.080275\n",
            "Train Epoch: 14 [5387/6845 (79%)]\tLoss: 0.095093\n",
            "Train Epoch: 14 [5388/6845 (79%)]\tLoss: 0.598011\n",
            "Train Epoch: 14 [5389/6845 (79%)]\tLoss: 0.459650\n",
            "Train Epoch: 14 [5390/6845 (79%)]\tLoss: 0.194105\n",
            "Train Epoch: 14 [5391/6845 (79%)]\tLoss: 0.562093\n",
            "Train Epoch: 14 [5392/6845 (79%)]\tLoss: 0.090890\n",
            "Train Epoch: 14 [5393/6845 (79%)]\tLoss: 0.077049\n",
            "Train Epoch: 14 [5394/6845 (79%)]\tLoss: 0.154729\n",
            "Train Epoch: 14 [5395/6845 (79%)]\tLoss: 0.083872\n",
            "Train Epoch: 14 [5396/6845 (79%)]\tLoss: 0.893346\n",
            "Train Epoch: 14 [5397/6845 (79%)]\tLoss: 0.789585\n",
            "Train Epoch: 14 [5398/6845 (79%)]\tLoss: 0.108652\n",
            "Train Epoch: 14 [5399/6845 (79%)]\tLoss: 0.090595\n",
            "Train Epoch: 14 [5400/6845 (79%)]\tLoss: 0.062688\n",
            "Train Epoch: 14 [5401/6845 (79%)]\tLoss: 0.091721\n",
            "Train Epoch: 14 [5402/6845 (79%)]\tLoss: 0.121924\n",
            "Train Epoch: 14 [5403/6845 (79%)]\tLoss: 1.042109\n",
            "Train Epoch: 14 [5404/6845 (79%)]\tLoss: 0.430473\n",
            "Train Epoch: 14 [5405/6845 (79%)]\tLoss: 0.107484\n",
            "Train Epoch: 14 [5406/6845 (79%)]\tLoss: 0.075622\n",
            "Train Epoch: 14 [5407/6845 (79%)]\tLoss: 0.061250\n",
            "Train Epoch: 14 [5408/6845 (79%)]\tLoss: 0.060046\n",
            "Train Epoch: 14 [5409/6845 (79%)]\tLoss: 0.100182\n",
            "Train Epoch: 14 [5410/6845 (79%)]\tLoss: 0.582121\n",
            "Train Epoch: 14 [5411/6845 (79%)]\tLoss: 0.121896\n",
            "Train Epoch: 14 [5412/6845 (79%)]\tLoss: 0.066813\n",
            "Train Epoch: 14 [5413/6845 (79%)]\tLoss: 0.160096\n",
            "Train Epoch: 14 [5414/6845 (79%)]\tLoss: 1.462770\n",
            "Train Epoch: 14 [5415/6845 (79%)]\tLoss: 0.055668\n",
            "Train Epoch: 14 [5416/6845 (79%)]\tLoss: 0.458043\n",
            "Train Epoch: 14 [5417/6845 (79%)]\tLoss: 0.054450\n",
            "Train Epoch: 14 [5418/6845 (79%)]\tLoss: 0.119331\n",
            "Train Epoch: 14 [5419/6845 (79%)]\tLoss: 0.130798\n",
            "Train Epoch: 14 [5420/6845 (79%)]\tLoss: 0.581032\n",
            "Train Epoch: 14 [5421/6845 (79%)]\tLoss: 0.108416\n",
            "Train Epoch: 14 [5422/6845 (79%)]\tLoss: 0.652800\n",
            "Train Epoch: 14 [5423/6845 (79%)]\tLoss: 0.075277\n",
            "Train Epoch: 14 [5424/6845 (79%)]\tLoss: 0.444318\n",
            "Train Epoch: 14 [5425/6845 (79%)]\tLoss: 0.130676\n",
            "Train Epoch: 14 [5426/6845 (79%)]\tLoss: 0.160175\n",
            "Train Epoch: 14 [5427/6845 (79%)]\tLoss: 0.201677\n",
            "Train Epoch: 14 [5428/6845 (79%)]\tLoss: 0.116664\n",
            "Train Epoch: 14 [5429/6845 (79%)]\tLoss: 0.166719\n",
            "Train Epoch: 14 [5430/6845 (79%)]\tLoss: 0.139254\n",
            "Train Epoch: 14 [5431/6845 (79%)]\tLoss: 0.161666\n",
            "Train Epoch: 14 [5432/6845 (79%)]\tLoss: 0.050937\n",
            "Train Epoch: 14 [5433/6845 (79%)]\tLoss: 0.619547\n",
            "Train Epoch: 14 [5434/6845 (79%)]\tLoss: 0.136491\n",
            "Train Epoch: 14 [5435/6845 (79%)]\tLoss: 1.001489\n",
            "Train Epoch: 14 [5436/6845 (79%)]\tLoss: 0.071654\n",
            "Train Epoch: 14 [5437/6845 (79%)]\tLoss: 0.496317\n",
            "Train Epoch: 14 [5438/6845 (79%)]\tLoss: 0.061392\n",
            "Train Epoch: 14 [5439/6845 (79%)]\tLoss: 1.478047\n",
            "Train Epoch: 14 [5440/6845 (79%)]\tLoss: 0.371972\n",
            "Train Epoch: 14 [5441/6845 (79%)]\tLoss: 0.033773\n",
            "Train Epoch: 14 [5442/6845 (80%)]\tLoss: 0.053430\n",
            "Train Epoch: 14 [5443/6845 (80%)]\tLoss: 0.423254\n",
            "Train Epoch: 14 [5444/6845 (80%)]\tLoss: 0.043600\n",
            "Train Epoch: 14 [5445/6845 (80%)]\tLoss: 0.214686\n",
            "Train Epoch: 14 [5446/6845 (80%)]\tLoss: 0.404070\n",
            "Train Epoch: 14 [5447/6845 (80%)]\tLoss: 0.694511\n",
            "Train Epoch: 14 [5448/6845 (80%)]\tLoss: 0.826928\n",
            "Train Epoch: 14 [5449/6845 (80%)]\tLoss: 0.152163\n",
            "Train Epoch: 14 [5450/6845 (80%)]\tLoss: 0.630551\n",
            "Train Epoch: 14 [5451/6845 (80%)]\tLoss: 0.146932\n",
            "Train Epoch: 14 [5452/6845 (80%)]\tLoss: 0.065205\n",
            "Train Epoch: 14 [5453/6845 (80%)]\tLoss: 0.697055\n",
            "Train Epoch: 14 [5454/6845 (80%)]\tLoss: 0.783114\n",
            "Train Epoch: 14 [5455/6845 (80%)]\tLoss: 0.191474\n",
            "Train Epoch: 14 [5456/6845 (80%)]\tLoss: 0.521438\n",
            "Train Epoch: 14 [5457/6845 (80%)]\tLoss: 0.350032\n",
            "Train Epoch: 14 [5458/6845 (80%)]\tLoss: 0.100615\n",
            "Train Epoch: 14 [5459/6845 (80%)]\tLoss: 0.059314\n",
            "Train Epoch: 14 [5460/6845 (80%)]\tLoss: 0.157682\n",
            "Train Epoch: 14 [5461/6845 (80%)]\tLoss: 0.074839\n",
            "Train Epoch: 14 [5462/6845 (80%)]\tLoss: 1.345746\n",
            "Train Epoch: 14 [5463/6845 (80%)]\tLoss: 1.073103\n",
            "Train Epoch: 14 [5464/6845 (80%)]\tLoss: 0.145800\n",
            "Train Epoch: 14 [5465/6845 (80%)]\tLoss: 0.079971\n",
            "Train Epoch: 14 [5466/6845 (80%)]\tLoss: 0.093549\n",
            "Train Epoch: 14 [5467/6845 (80%)]\tLoss: 0.440307\n",
            "Train Epoch: 14 [5468/6845 (80%)]\tLoss: 0.608785\n",
            "Train Epoch: 14 [5469/6845 (80%)]\tLoss: 0.577133\n",
            "Train Epoch: 14 [5470/6845 (80%)]\tLoss: 0.104304\n",
            "Train Epoch: 14 [5471/6845 (80%)]\tLoss: 0.376268\n",
            "Train Epoch: 14 [5472/6845 (80%)]\tLoss: 0.555862\n",
            "Train Epoch: 14 [5473/6845 (80%)]\tLoss: 0.371958\n",
            "Train Epoch: 14 [5474/6845 (80%)]\tLoss: 0.369869\n",
            "Train Epoch: 14 [5475/6845 (80%)]\tLoss: 0.455910\n",
            "Train Epoch: 14 [5476/6845 (80%)]\tLoss: 0.067906\n",
            "Train Epoch: 14 [5477/6845 (80%)]\tLoss: 0.249971\n",
            "Train Epoch: 14 [5478/6845 (80%)]\tLoss: 0.534665\n",
            "Train Epoch: 14 [5479/6845 (80%)]\tLoss: 0.149273\n",
            "Train Epoch: 14 [5480/6845 (80%)]\tLoss: 0.124387\n",
            "Train Epoch: 14 [5481/6845 (80%)]\tLoss: 0.147595\n",
            "Train Epoch: 14 [5482/6845 (80%)]\tLoss: 0.222537\n",
            "Train Epoch: 14 [5483/6845 (80%)]\tLoss: 0.181304\n",
            "Train Epoch: 14 [5484/6845 (80%)]\tLoss: 0.127639\n",
            "Train Epoch: 14 [5485/6845 (80%)]\tLoss: 0.128293\n",
            "Train Epoch: 14 [5486/6845 (80%)]\tLoss: 0.083454\n",
            "Train Epoch: 14 [5487/6845 (80%)]\tLoss: 0.073712\n",
            "Train Epoch: 14 [5488/6845 (80%)]\tLoss: 0.545137\n",
            "Train Epoch: 14 [5489/6845 (80%)]\tLoss: 0.109006\n",
            "Train Epoch: 14 [5490/6845 (80%)]\tLoss: 0.133154\n",
            "Train Epoch: 14 [5491/6845 (80%)]\tLoss: 0.079777\n",
            "Train Epoch: 14 [5492/6845 (80%)]\tLoss: 0.145108\n",
            "Train Epoch: 14 [5493/6845 (80%)]\tLoss: 0.198345\n",
            "Train Epoch: 14 [5494/6845 (80%)]\tLoss: 0.225363\n",
            "Train Epoch: 14 [5495/6845 (80%)]\tLoss: 0.068858\n",
            "Train Epoch: 14 [5496/6845 (80%)]\tLoss: 0.060772\n",
            "Train Epoch: 14 [5497/6845 (80%)]\tLoss: 0.660595\n",
            "Train Epoch: 14 [5498/6845 (80%)]\tLoss: 0.257979\n",
            "Train Epoch: 14 [5499/6845 (80%)]\tLoss: 0.185167\n",
            "Train Epoch: 14 [5500/6845 (80%)]\tLoss: 0.087072\n",
            "Train Epoch: 14 [5501/6845 (80%)]\tLoss: 0.151128\n",
            "Train Epoch: 14 [5502/6845 (80%)]\tLoss: 1.050263\n",
            "Train Epoch: 14 [5503/6845 (80%)]\tLoss: 0.088090\n",
            "Train Epoch: 14 [5504/6845 (80%)]\tLoss: 0.050901\n",
            "Train Epoch: 14 [5505/6845 (80%)]\tLoss: 0.346953\n",
            "Train Epoch: 14 [5506/6845 (80%)]\tLoss: 0.516361\n",
            "Train Epoch: 14 [5507/6845 (80%)]\tLoss: 0.752881\n",
            "Train Epoch: 14 [5508/6845 (80%)]\tLoss: 0.046615\n",
            "Train Epoch: 14 [5509/6845 (80%)]\tLoss: 0.138796\n",
            "Train Epoch: 14 [5510/6845 (80%)]\tLoss: 0.048509\n",
            "Train Epoch: 14 [5511/6845 (81%)]\tLoss: 0.188160\n",
            "Train Epoch: 14 [5512/6845 (81%)]\tLoss: 0.164183\n",
            "Train Epoch: 14 [5513/6845 (81%)]\tLoss: 0.111509\n",
            "Train Epoch: 14 [5514/6845 (81%)]\tLoss: 0.642743\n",
            "Train Epoch: 14 [5515/6845 (81%)]\tLoss: 0.076048\n",
            "Train Epoch: 14 [5516/6845 (81%)]\tLoss: 0.077039\n",
            "Train Epoch: 14 [5517/6845 (81%)]\tLoss: 0.161415\n",
            "Train Epoch: 14 [5518/6845 (81%)]\tLoss: 0.203740\n",
            "Train Epoch: 14 [5519/6845 (81%)]\tLoss: 0.204131\n",
            "Train Epoch: 14 [5520/6845 (81%)]\tLoss: 0.042423\n",
            "Train Epoch: 14 [5521/6845 (81%)]\tLoss: 0.745244\n",
            "Train Epoch: 14 [5522/6845 (81%)]\tLoss: 0.187853\n",
            "Train Epoch: 14 [5523/6845 (81%)]\tLoss: 0.038881\n",
            "Train Epoch: 14 [5524/6845 (81%)]\tLoss: 0.040989\n",
            "Train Epoch: 14 [5525/6845 (81%)]\tLoss: 0.790145\n",
            "Train Epoch: 14 [5526/6845 (81%)]\tLoss: 0.058179\n",
            "Train Epoch: 14 [5527/6845 (81%)]\tLoss: 0.119528\n",
            "Train Epoch: 14 [5528/6845 (81%)]\tLoss: 0.263415\n",
            "Train Epoch: 14 [5529/6845 (81%)]\tLoss: 0.672497\n",
            "Train Epoch: 14 [5530/6845 (81%)]\tLoss: 0.163240\n",
            "Train Epoch: 14 [5531/6845 (81%)]\tLoss: 0.569115\n",
            "Train Epoch: 14 [5532/6845 (81%)]\tLoss: 0.041643\n",
            "Train Epoch: 14 [5533/6845 (81%)]\tLoss: 0.553501\n",
            "Train Epoch: 14 [5534/6845 (81%)]\tLoss: 0.040167\n",
            "Train Epoch: 14 [5535/6845 (81%)]\tLoss: 0.686301\n",
            "Train Epoch: 14 [5536/6845 (81%)]\tLoss: 0.099220\n",
            "Train Epoch: 14 [5537/6845 (81%)]\tLoss: 0.274717\n",
            "Train Epoch: 14 [5538/6845 (81%)]\tLoss: 0.065953\n",
            "Train Epoch: 14 [5539/6845 (81%)]\tLoss: 0.391539\n",
            "Train Epoch: 14 [5540/6845 (81%)]\tLoss: 0.120799\n",
            "Train Epoch: 14 [5541/6845 (81%)]\tLoss: 0.547538\n",
            "Train Epoch: 14 [5542/6845 (81%)]\tLoss: 0.161804\n",
            "Train Epoch: 14 [5543/6845 (81%)]\tLoss: 0.151920\n",
            "Train Epoch: 14 [5544/6845 (81%)]\tLoss: 0.364600\n",
            "Train Epoch: 14 [5545/6845 (81%)]\tLoss: 0.129116\n",
            "Train Epoch: 14 [5546/6845 (81%)]\tLoss: 0.179872\n",
            "Train Epoch: 14 [5547/6845 (81%)]\tLoss: 0.116307\n",
            "Train Epoch: 14 [5548/6845 (81%)]\tLoss: 0.504526\n",
            "Train Epoch: 14 [5549/6845 (81%)]\tLoss: 0.056778\n",
            "Train Epoch: 14 [5550/6845 (81%)]\tLoss: 0.071458\n",
            "Train Epoch: 14 [5551/6845 (81%)]\tLoss: 0.691509\n",
            "Train Epoch: 14 [5552/6845 (81%)]\tLoss: 0.146871\n",
            "Train Epoch: 14 [5553/6845 (81%)]\tLoss: 0.118061\n",
            "Train Epoch: 14 [5554/6845 (81%)]\tLoss: 0.095124\n",
            "Train Epoch: 14 [5555/6845 (81%)]\tLoss: 0.150554\n",
            "Train Epoch: 14 [5556/6845 (81%)]\tLoss: 0.108137\n",
            "Train Epoch: 14 [5557/6845 (81%)]\tLoss: 0.114406\n",
            "Train Epoch: 14 [5558/6845 (81%)]\tLoss: 0.479802\n",
            "Train Epoch: 14 [5559/6845 (81%)]\tLoss: 0.083378\n",
            "Train Epoch: 14 [5560/6845 (81%)]\tLoss: 0.156121\n",
            "Train Epoch: 14 [5561/6845 (81%)]\tLoss: 0.536395\n",
            "Train Epoch: 14 [5562/6845 (81%)]\tLoss: 0.113068\n",
            "Train Epoch: 14 [5563/6845 (81%)]\tLoss: 0.668079\n",
            "Train Epoch: 14 [5564/6845 (81%)]\tLoss: 0.617921\n",
            "Train Epoch: 14 [5565/6845 (81%)]\tLoss: 1.040363\n",
            "Train Epoch: 14 [5566/6845 (81%)]\tLoss: 0.091922\n",
            "Train Epoch: 14 [5567/6845 (81%)]\tLoss: 0.566375\n",
            "Train Epoch: 14 [5568/6845 (81%)]\tLoss: 0.094626\n",
            "Train Epoch: 14 [5569/6845 (81%)]\tLoss: 0.119614\n",
            "Train Epoch: 14 [5570/6845 (81%)]\tLoss: 0.070686\n",
            "Train Epoch: 14 [5571/6845 (81%)]\tLoss: 0.096011\n",
            "Train Epoch: 14 [5572/6845 (81%)]\tLoss: 0.103342\n",
            "Train Epoch: 14 [5573/6845 (81%)]\tLoss: 0.112207\n",
            "Train Epoch: 14 [5574/6845 (81%)]\tLoss: 0.136337\n",
            "Train Epoch: 14 [5575/6845 (81%)]\tLoss: 0.528211\n",
            "Train Epoch: 14 [5576/6845 (81%)]\tLoss: 0.143729\n",
            "Train Epoch: 14 [5577/6845 (81%)]\tLoss: 0.469688\n",
            "Train Epoch: 14 [5578/6845 (81%)]\tLoss: 0.422319\n",
            "Train Epoch: 14 [5579/6845 (82%)]\tLoss: 0.552567\n",
            "Train Epoch: 14 [5580/6845 (82%)]\tLoss: 0.134839\n",
            "Train Epoch: 14 [5581/6845 (82%)]\tLoss: 0.109097\n",
            "Train Epoch: 14 [5582/6845 (82%)]\tLoss: 0.180823\n",
            "Train Epoch: 14 [5583/6845 (82%)]\tLoss: 0.649896\n",
            "Train Epoch: 14 [5584/6845 (82%)]\tLoss: 0.095377\n",
            "Train Epoch: 14 [5585/6845 (82%)]\tLoss: 0.107366\n",
            "Train Epoch: 14 [5586/6845 (82%)]\tLoss: 0.283483\n",
            "Train Epoch: 14 [5587/6845 (82%)]\tLoss: 0.201904\n",
            "Train Epoch: 14 [5588/6845 (82%)]\tLoss: 0.133304\n",
            "Train Epoch: 14 [5589/6845 (82%)]\tLoss: 0.107059\n",
            "Train Epoch: 14 [5590/6845 (82%)]\tLoss: 0.495587\n",
            "Train Epoch: 14 [5591/6845 (82%)]\tLoss: 0.077896\n",
            "Train Epoch: 14 [5592/6845 (82%)]\tLoss: 0.117351\n",
            "Train Epoch: 14 [5593/6845 (82%)]\tLoss: 0.072532\n",
            "Train Epoch: 14 [5594/6845 (82%)]\tLoss: 0.235870\n",
            "Train Epoch: 14 [5595/6845 (82%)]\tLoss: 0.761624\n",
            "Train Epoch: 14 [5596/6845 (82%)]\tLoss: 0.611088\n",
            "Train Epoch: 14 [5597/6845 (82%)]\tLoss: 0.100870\n",
            "Train Epoch: 14 [5598/6845 (82%)]\tLoss: 0.067907\n",
            "Train Epoch: 14 [5599/6845 (82%)]\tLoss: 0.274133\n",
            "Train Epoch: 14 [5600/6845 (82%)]\tLoss: 0.193626\n",
            "Train Epoch: 14 [5601/6845 (82%)]\tLoss: 0.070844\n",
            "Train Epoch: 14 [5602/6845 (82%)]\tLoss: 0.402629\n",
            "Train Epoch: 14 [5603/6845 (82%)]\tLoss: 0.087732\n",
            "Train Epoch: 14 [5604/6845 (82%)]\tLoss: 0.074347\n",
            "Train Epoch: 14 [5605/6845 (82%)]\tLoss: 0.144103\n",
            "Train Epoch: 14 [5606/6845 (82%)]\tLoss: 0.090787\n",
            "Train Epoch: 14 [5607/6845 (82%)]\tLoss: 0.071651\n",
            "Train Epoch: 14 [5608/6845 (82%)]\tLoss: 0.672532\n",
            "Train Epoch: 14 [5609/6845 (82%)]\tLoss: 0.577803\n",
            "Train Epoch: 14 [5610/6845 (82%)]\tLoss: 0.460509\n",
            "Train Epoch: 14 [5611/6845 (82%)]\tLoss: 0.219801\n",
            "Train Epoch: 14 [5612/6845 (82%)]\tLoss: 0.062932\n",
            "Train Epoch: 14 [5613/6845 (82%)]\tLoss: 0.105366\n",
            "Train Epoch: 14 [5614/6845 (82%)]\tLoss: 0.083725\n",
            "Train Epoch: 14 [5615/6845 (82%)]\tLoss: 0.687790\n",
            "Train Epoch: 14 [5616/6845 (82%)]\tLoss: 0.096178\n",
            "Train Epoch: 14 [5617/6845 (82%)]\tLoss: 0.091684\n",
            "Train Epoch: 14 [5618/6845 (82%)]\tLoss: 0.448392\n",
            "Train Epoch: 14 [5619/6845 (82%)]\tLoss: 0.307989\n",
            "Train Epoch: 14 [5620/6845 (82%)]\tLoss: 0.078545\n",
            "Train Epoch: 14 [5621/6845 (82%)]\tLoss: 0.707209\n",
            "Train Epoch: 14 [5622/6845 (82%)]\tLoss: 0.133892\n",
            "Train Epoch: 14 [5623/6845 (82%)]\tLoss: 0.125908\n",
            "Train Epoch: 14 [5624/6845 (82%)]\tLoss: 0.856396\n",
            "Train Epoch: 14 [5625/6845 (82%)]\tLoss: 0.092861\n",
            "Train Epoch: 14 [5626/6845 (82%)]\tLoss: 0.110340\n",
            "Train Epoch: 14 [5627/6845 (82%)]\tLoss: 0.245582\n",
            "Train Epoch: 14 [5628/6845 (82%)]\tLoss: 0.188960\n",
            "Train Epoch: 14 [5629/6845 (82%)]\tLoss: 0.099861\n",
            "Train Epoch: 14 [5630/6845 (82%)]\tLoss: 0.069278\n",
            "Train Epoch: 14 [5631/6845 (82%)]\tLoss: 0.105783\n",
            "Train Epoch: 14 [5632/6845 (82%)]\tLoss: 0.058318\n",
            "Train Epoch: 14 [5633/6845 (82%)]\tLoss: 0.752288\n",
            "Train Epoch: 14 [5634/6845 (82%)]\tLoss: 0.158104\n",
            "Train Epoch: 14 [5635/6845 (82%)]\tLoss: 0.128928\n",
            "Train Epoch: 14 [5636/6845 (82%)]\tLoss: 1.329308\n",
            "Train Epoch: 14 [5637/6845 (82%)]\tLoss: 0.062322\n",
            "Train Epoch: 14 [5638/6845 (82%)]\tLoss: 0.246804\n",
            "Train Epoch: 14 [5639/6845 (82%)]\tLoss: 0.914331\n",
            "Train Epoch: 14 [5640/6845 (82%)]\tLoss: 0.527753\n",
            "Train Epoch: 14 [5641/6845 (82%)]\tLoss: 0.103939\n",
            "Train Epoch: 14 [5642/6845 (82%)]\tLoss: 0.111375\n",
            "Train Epoch: 14 [5643/6845 (82%)]\tLoss: 0.455469\n",
            "Train Epoch: 14 [5644/6845 (82%)]\tLoss: 0.082121\n",
            "Train Epoch: 14 [5645/6845 (82%)]\tLoss: 0.341109\n",
            "Train Epoch: 14 [5646/6845 (82%)]\tLoss: 0.461140\n",
            "Train Epoch: 14 [5647/6845 (82%)]\tLoss: 0.270614\n",
            "Train Epoch: 14 [5648/6845 (83%)]\tLoss: 0.504808\n",
            "Train Epoch: 14 [5649/6845 (83%)]\tLoss: 0.510263\n",
            "Train Epoch: 14 [5650/6845 (83%)]\tLoss: 0.098739\n",
            "Train Epoch: 14 [5651/6845 (83%)]\tLoss: 0.087573\n",
            "Train Epoch: 14 [5652/6845 (83%)]\tLoss: 0.687335\n",
            "Train Epoch: 14 [5653/6845 (83%)]\tLoss: 0.110433\n",
            "Train Epoch: 14 [5654/6845 (83%)]\tLoss: 0.112692\n",
            "Train Epoch: 14 [5655/6845 (83%)]\tLoss: 0.564969\n",
            "Train Epoch: 14 [5656/6845 (83%)]\tLoss: 0.249977\n",
            "Train Epoch: 14 [5657/6845 (83%)]\tLoss: 0.469737\n",
            "Train Epoch: 14 [5658/6845 (83%)]\tLoss: 0.373454\n",
            "Train Epoch: 14 [5659/6845 (83%)]\tLoss: 0.635857\n",
            "Train Epoch: 14 [5660/6845 (83%)]\tLoss: 0.105246\n",
            "Train Epoch: 14 [5661/6845 (83%)]\tLoss: 0.469340\n",
            "Train Epoch: 14 [5662/6845 (83%)]\tLoss: 0.268515\n",
            "Train Epoch: 14 [5663/6845 (83%)]\tLoss: 0.248055\n",
            "Train Epoch: 14 [5664/6845 (83%)]\tLoss: 0.264701\n",
            "Train Epoch: 14 [5665/6845 (83%)]\tLoss: 0.103159\n",
            "Train Epoch: 14 [5666/6845 (83%)]\tLoss: 0.350129\n",
            "Train Epoch: 14 [5667/6845 (83%)]\tLoss: 0.098917\n",
            "Train Epoch: 14 [5668/6845 (83%)]\tLoss: 0.355857\n",
            "Train Epoch: 14 [5669/6845 (83%)]\tLoss: 0.176272\n",
            "Train Epoch: 14 [5670/6845 (83%)]\tLoss: 0.125752\n",
            "Train Epoch: 14 [5671/6845 (83%)]\tLoss: 0.150764\n",
            "Train Epoch: 14 [5672/6845 (83%)]\tLoss: 0.538068\n",
            "Train Epoch: 14 [5673/6845 (83%)]\tLoss: 0.245384\n",
            "Train Epoch: 14 [5674/6845 (83%)]\tLoss: 0.524326\n",
            "Train Epoch: 14 [5675/6845 (83%)]\tLoss: 0.467556\n",
            "Train Epoch: 14 [5676/6845 (83%)]\tLoss: 0.186970\n",
            "Train Epoch: 14 [5677/6845 (83%)]\tLoss: 0.138217\n",
            "Train Epoch: 14 [5678/6845 (83%)]\tLoss: 0.133659\n",
            "Train Epoch: 14 [5679/6845 (83%)]\tLoss: 0.089802\n",
            "Train Epoch: 14 [5680/6845 (83%)]\tLoss: 0.190633\n",
            "Train Epoch: 14 [5681/6845 (83%)]\tLoss: 0.535277\n",
            "Train Epoch: 14 [5682/6845 (83%)]\tLoss: 0.144063\n",
            "Train Epoch: 14 [5683/6845 (83%)]\tLoss: 0.430473\n",
            "Train Epoch: 14 [5684/6845 (83%)]\tLoss: 0.162318\n",
            "Train Epoch: 14 [5685/6845 (83%)]\tLoss: 0.094874\n",
            "Train Epoch: 14 [5686/6845 (83%)]\tLoss: 0.088955\n",
            "Train Epoch: 14 [5687/6845 (83%)]\tLoss: 0.136898\n",
            "Train Epoch: 14 [5688/6845 (83%)]\tLoss: 0.374149\n",
            "Train Epoch: 14 [5689/6845 (83%)]\tLoss: 0.134589\n",
            "Train Epoch: 14 [5690/6845 (83%)]\tLoss: 0.116885\n",
            "Train Epoch: 14 [5691/6845 (83%)]\tLoss: 0.347726\n",
            "Train Epoch: 14 [5692/6845 (83%)]\tLoss: 0.141445\n",
            "Train Epoch: 14 [5693/6845 (83%)]\tLoss: 0.448645\n",
            "Train Epoch: 14 [5694/6845 (83%)]\tLoss: 0.796947\n",
            "Train Epoch: 14 [5695/6845 (83%)]\tLoss: 0.101847\n",
            "Train Epoch: 14 [5696/6845 (83%)]\tLoss: 0.116364\n",
            "Train Epoch: 14 [5697/6845 (83%)]\tLoss: 0.099840\n",
            "Train Epoch: 14 [5698/6845 (83%)]\tLoss: 0.128806\n",
            "Train Epoch: 14 [5699/6845 (83%)]\tLoss: 0.335625\n",
            "Train Epoch: 14 [5700/6845 (83%)]\tLoss: 0.095736\n",
            "Train Epoch: 14 [5701/6845 (83%)]\tLoss: 0.094674\n",
            "Train Epoch: 14 [5702/6845 (83%)]\tLoss: 0.080148\n",
            "Train Epoch: 14 [5703/6845 (83%)]\tLoss: 0.153099\n",
            "Train Epoch: 14 [5704/6845 (83%)]\tLoss: 0.203084\n",
            "Train Epoch: 14 [5705/6845 (83%)]\tLoss: 0.321280\n",
            "Train Epoch: 14 [5706/6845 (83%)]\tLoss: 0.105732\n",
            "Train Epoch: 14 [5707/6845 (83%)]\tLoss: 0.145108\n",
            "Train Epoch: 14 [5708/6845 (83%)]\tLoss: 0.159892\n",
            "Train Epoch: 14 [5709/6845 (83%)]\tLoss: 0.093954\n",
            "Train Epoch: 14 [5710/6845 (83%)]\tLoss: 0.156772\n",
            "Train Epoch: 14 [5711/6845 (83%)]\tLoss: 0.111376\n",
            "Train Epoch: 14 [5712/6845 (83%)]\tLoss: 0.400342\n",
            "Train Epoch: 14 [5713/6845 (83%)]\tLoss: 0.066673\n",
            "Train Epoch: 14 [5714/6845 (83%)]\tLoss: 0.169491\n",
            "Train Epoch: 14 [5715/6845 (83%)]\tLoss: 0.107540\n",
            "Train Epoch: 14 [5716/6845 (84%)]\tLoss: 0.200710\n",
            "Train Epoch: 14 [5717/6845 (84%)]\tLoss: 0.059233\n",
            "Train Epoch: 14 [5718/6845 (84%)]\tLoss: 0.120364\n",
            "Train Epoch: 14 [5719/6845 (84%)]\tLoss: 0.131405\n",
            "Train Epoch: 14 [5720/6845 (84%)]\tLoss: 0.059156\n",
            "Train Epoch: 14 [5721/6845 (84%)]\tLoss: 0.206635\n",
            "Train Epoch: 14 [5722/6845 (84%)]\tLoss: 0.171611\n",
            "Train Epoch: 14 [5723/6845 (84%)]\tLoss: 0.323682\n",
            "Train Epoch: 14 [5724/6845 (84%)]\tLoss: 1.542642\n",
            "Train Epoch: 14 [5725/6845 (84%)]\tLoss: 0.114266\n",
            "Train Epoch: 14 [5726/6845 (84%)]\tLoss: 0.198745\n",
            "Train Epoch: 14 [5727/6845 (84%)]\tLoss: 0.108391\n",
            "Train Epoch: 14 [5728/6845 (84%)]\tLoss: 0.100328\n",
            "Train Epoch: 14 [5729/6845 (84%)]\tLoss: 0.115332\n",
            "Train Epoch: 14 [5730/6845 (84%)]\tLoss: 0.294759\n",
            "Train Epoch: 14 [5731/6845 (84%)]\tLoss: 0.172972\n",
            "Train Epoch: 14 [5732/6845 (84%)]\tLoss: 0.065327\n",
            "Train Epoch: 14 [5733/6845 (84%)]\tLoss: 0.594693\n",
            "Train Epoch: 14 [5734/6845 (84%)]\tLoss: 0.148792\n",
            "Train Epoch: 14 [5735/6845 (84%)]\tLoss: 0.156301\n",
            "Train Epoch: 14 [5736/6845 (84%)]\tLoss: 0.178053\n",
            "Train Epoch: 14 [5737/6845 (84%)]\tLoss: 0.095766\n",
            "Train Epoch: 14 [5738/6845 (84%)]\tLoss: 0.078867\n",
            "Train Epoch: 14 [5739/6845 (84%)]\tLoss: 0.495791\n",
            "Train Epoch: 14 [5740/6845 (84%)]\tLoss: 0.194847\n",
            "Train Epoch: 14 [5741/6845 (84%)]\tLoss: 0.076009\n",
            "Train Epoch: 14 [5742/6845 (84%)]\tLoss: 0.722960\n",
            "Train Epoch: 14 [5743/6845 (84%)]\tLoss: 0.080353\n",
            "Train Epoch: 14 [5744/6845 (84%)]\tLoss: 0.101238\n",
            "Train Epoch: 14 [5745/6845 (84%)]\tLoss: 0.172910\n",
            "Train Epoch: 14 [5746/6845 (84%)]\tLoss: 0.120919\n",
            "Train Epoch: 14 [5747/6845 (84%)]\tLoss: 0.082044\n",
            "Train Epoch: 14 [5748/6845 (84%)]\tLoss: 0.865646\n",
            "Train Epoch: 14 [5749/6845 (84%)]\tLoss: 0.754981\n",
            "Train Epoch: 14 [5750/6845 (84%)]\tLoss: 0.107315\n",
            "Train Epoch: 14 [5751/6845 (84%)]\tLoss: 0.428208\n",
            "Train Epoch: 14 [5752/6845 (84%)]\tLoss: 0.092582\n",
            "Train Epoch: 14 [5753/6845 (84%)]\tLoss: 0.069338\n",
            "Train Epoch: 14 [5754/6845 (84%)]\tLoss: 0.102471\n",
            "Train Epoch: 14 [5755/6845 (84%)]\tLoss: 1.180705\n",
            "Train Epoch: 14 [5756/6845 (84%)]\tLoss: 0.544361\n",
            "Train Epoch: 14 [5757/6845 (84%)]\tLoss: 0.070669\n",
            "Train Epoch: 14 [5758/6845 (84%)]\tLoss: 0.817935\n",
            "Train Epoch: 14 [5759/6845 (84%)]\tLoss: 0.278819\n",
            "Train Epoch: 14 [5760/6845 (84%)]\tLoss: 0.119848\n",
            "Train Epoch: 14 [5761/6845 (84%)]\tLoss: 1.392747\n",
            "Train Epoch: 14 [5762/6845 (84%)]\tLoss: 0.116964\n",
            "Train Epoch: 14 [5763/6845 (84%)]\tLoss: 0.128770\n",
            "Train Epoch: 14 [5764/6845 (84%)]\tLoss: 0.462768\n",
            "Train Epoch: 14 [5765/6845 (84%)]\tLoss: 0.219929\n",
            "Train Epoch: 14 [5766/6845 (84%)]\tLoss: 0.136244\n",
            "Train Epoch: 14 [5767/6845 (84%)]\tLoss: 0.661929\n",
            "Train Epoch: 14 [5768/6845 (84%)]\tLoss: 0.096606\n",
            "Train Epoch: 14 [5769/6845 (84%)]\tLoss: 0.233216\n",
            "Train Epoch: 14 [5770/6845 (84%)]\tLoss: 0.094828\n",
            "Train Epoch: 14 [5771/6845 (84%)]\tLoss: 0.089378\n",
            "Train Epoch: 14 [5772/6845 (84%)]\tLoss: 0.093160\n",
            "Train Epoch: 14 [5773/6845 (84%)]\tLoss: 0.127620\n",
            "Train Epoch: 14 [5774/6845 (84%)]\tLoss: 0.175175\n",
            "Train Epoch: 14 [5775/6845 (84%)]\tLoss: 0.095643\n",
            "Train Epoch: 14 [5776/6845 (84%)]\tLoss: 0.081324\n",
            "Train Epoch: 14 [5777/6845 (84%)]\tLoss: 0.653361\n",
            "Train Epoch: 14 [5778/6845 (84%)]\tLoss: 0.104657\n",
            "Train Epoch: 14 [5779/6845 (84%)]\tLoss: 0.114469\n",
            "Train Epoch: 14 [5780/6845 (84%)]\tLoss: 0.166371\n",
            "Train Epoch: 14 [5781/6845 (84%)]\tLoss: 0.057576\n",
            "Train Epoch: 14 [5782/6845 (84%)]\tLoss: 0.778485\n",
            "Train Epoch: 14 [5783/6845 (84%)]\tLoss: 0.056407\n",
            "Train Epoch: 14 [5784/6845 (84%)]\tLoss: 0.864119\n",
            "Train Epoch: 14 [5785/6845 (85%)]\tLoss: 0.115956\n",
            "Train Epoch: 14 [5786/6845 (85%)]\tLoss: 0.140891\n",
            "Train Epoch: 14 [5787/6845 (85%)]\tLoss: 0.071032\n",
            "Train Epoch: 14 [5788/6845 (85%)]\tLoss: 0.118054\n",
            "Train Epoch: 14 [5789/6845 (85%)]\tLoss: 0.259009\n",
            "Train Epoch: 14 [5790/6845 (85%)]\tLoss: 0.593000\n",
            "Train Epoch: 14 [5791/6845 (85%)]\tLoss: 0.051952\n",
            "Train Epoch: 14 [5792/6845 (85%)]\tLoss: 0.119581\n",
            "Train Epoch: 14 [5793/6845 (85%)]\tLoss: 0.626610\n",
            "Train Epoch: 14 [5794/6845 (85%)]\tLoss: 0.052925\n",
            "Train Epoch: 14 [5795/6845 (85%)]\tLoss: 0.932961\n",
            "Train Epoch: 14 [5796/6845 (85%)]\tLoss: 0.052770\n",
            "Train Epoch: 14 [5797/6845 (85%)]\tLoss: 0.111958\n",
            "Train Epoch: 14 [5798/6845 (85%)]\tLoss: 0.102073\n",
            "Train Epoch: 14 [5799/6845 (85%)]\tLoss: 0.117211\n",
            "Train Epoch: 14 [5800/6845 (85%)]\tLoss: 0.105472\n",
            "Train Epoch: 14 [5801/6845 (85%)]\tLoss: 0.095079\n",
            "Train Epoch: 14 [5802/6845 (85%)]\tLoss: 0.103009\n",
            "Train Epoch: 14 [5803/6845 (85%)]\tLoss: 0.117191\n",
            "Train Epoch: 14 [5804/6845 (85%)]\tLoss: 0.062948\n",
            "Train Epoch: 14 [5805/6845 (85%)]\tLoss: 0.151313\n",
            "Train Epoch: 14 [5806/6845 (85%)]\tLoss: 0.200577\n",
            "Train Epoch: 14 [5807/6845 (85%)]\tLoss: 0.444371\n",
            "Train Epoch: 14 [5808/6845 (85%)]\tLoss: 0.061369\n",
            "Train Epoch: 14 [5809/6845 (85%)]\tLoss: 0.088578\n",
            "Train Epoch: 14 [5810/6845 (85%)]\tLoss: 0.113829\n",
            "Train Epoch: 14 [5811/6845 (85%)]\tLoss: 0.071435\n",
            "Train Epoch: 14 [5812/6845 (85%)]\tLoss: 0.906351\n",
            "Train Epoch: 14 [5813/6845 (85%)]\tLoss: 0.438635\n",
            "Train Epoch: 14 [5814/6845 (85%)]\tLoss: 0.068373\n",
            "Train Epoch: 14 [5815/6845 (85%)]\tLoss: 0.094596\n",
            "Train Epoch: 14 [5816/6845 (85%)]\tLoss: 0.123650\n",
            "Train Epoch: 14 [5817/6845 (85%)]\tLoss: 0.085140\n",
            "Train Epoch: 14 [5818/6845 (85%)]\tLoss: 0.815376\n",
            "Train Epoch: 14 [5819/6845 (85%)]\tLoss: 0.775747\n",
            "Train Epoch: 14 [5820/6845 (85%)]\tLoss: 0.073741\n",
            "Train Epoch: 14 [5821/6845 (85%)]\tLoss: 0.070438\n",
            "Train Epoch: 14 [5822/6845 (85%)]\tLoss: 0.418122\n",
            "Train Epoch: 14 [5823/6845 (85%)]\tLoss: 0.424405\n",
            "Train Epoch: 14 [5824/6845 (85%)]\tLoss: 0.120934\n",
            "Train Epoch: 14 [5825/6845 (85%)]\tLoss: 0.356922\n",
            "Train Epoch: 14 [5826/6845 (85%)]\tLoss: 0.400208\n",
            "Train Epoch: 14 [5827/6845 (85%)]\tLoss: 0.120639\n",
            "Train Epoch: 14 [5828/6845 (85%)]\tLoss: 0.615552\n",
            "Train Epoch: 14 [5829/6845 (85%)]\tLoss: 0.595519\n",
            "Train Epoch: 14 [5830/6845 (85%)]\tLoss: 0.077278\n",
            "Train Epoch: 14 [5831/6845 (85%)]\tLoss: 0.550040\n",
            "Train Epoch: 14 [5832/6845 (85%)]\tLoss: 0.092275\n",
            "Train Epoch: 14 [5833/6845 (85%)]\tLoss: 0.075569\n",
            "Train Epoch: 14 [5834/6845 (85%)]\tLoss: 0.217489\n",
            "Train Epoch: 14 [5835/6845 (85%)]\tLoss: 0.077985\n",
            "Train Epoch: 14 [5836/6845 (85%)]\tLoss: 0.097414\n",
            "Train Epoch: 14 [5837/6845 (85%)]\tLoss: 0.064435\n",
            "Train Epoch: 14 [5838/6845 (85%)]\tLoss: 0.149363\n",
            "Train Epoch: 14 [5839/6845 (85%)]\tLoss: 0.111411\n",
            "Train Epoch: 14 [5840/6845 (85%)]\tLoss: 0.075618\n",
            "Train Epoch: 14 [5841/6845 (85%)]\tLoss: 0.202096\n",
            "Train Epoch: 14 [5842/6845 (85%)]\tLoss: 0.084756\n",
            "Train Epoch: 14 [5843/6845 (85%)]\tLoss: 0.057969\n",
            "Train Epoch: 14 [5844/6845 (85%)]\tLoss: 0.127390\n",
            "Train Epoch: 14 [5845/6845 (85%)]\tLoss: 0.509968\n",
            "Train Epoch: 14 [5846/6845 (85%)]\tLoss: 0.216481\n",
            "Train Epoch: 14 [5847/6845 (85%)]\tLoss: 0.178795\n",
            "Train Epoch: 14 [5848/6845 (85%)]\tLoss: 0.107830\n",
            "Train Epoch: 14 [5849/6845 (85%)]\tLoss: 0.053270\n",
            "Train Epoch: 14 [5850/6845 (85%)]\tLoss: 0.700264\n",
            "Train Epoch: 14 [5851/6845 (85%)]\tLoss: 0.086199\n",
            "Train Epoch: 14 [5852/6845 (85%)]\tLoss: 0.055094\n",
            "Train Epoch: 14 [5853/6845 (86%)]\tLoss: 0.056627\n",
            "Train Epoch: 14 [5854/6845 (86%)]\tLoss: 0.123278\n",
            "Train Epoch: 14 [5855/6845 (86%)]\tLoss: 0.120034\n",
            "Train Epoch: 14 [5856/6845 (86%)]\tLoss: 0.329581\n",
            "Train Epoch: 14 [5857/6845 (86%)]\tLoss: 0.890531\n",
            "Train Epoch: 14 [5858/6845 (86%)]\tLoss: 0.053309\n",
            "Train Epoch: 14 [5859/6845 (86%)]\tLoss: 0.114980\n",
            "Train Epoch: 14 [5860/6845 (86%)]\tLoss: 0.068775\n",
            "Train Epoch: 14 [5861/6845 (86%)]\tLoss: 0.713563\n",
            "Train Epoch: 14 [5862/6845 (86%)]\tLoss: 0.183805\n",
            "Train Epoch: 14 [5863/6845 (86%)]\tLoss: 0.549926\n",
            "Train Epoch: 14 [5864/6845 (86%)]\tLoss: 0.270538\n",
            "Train Epoch: 14 [5865/6845 (86%)]\tLoss: 0.269682\n",
            "Train Epoch: 14 [5866/6845 (86%)]\tLoss: 0.115844\n",
            "Train Epoch: 14 [5867/6845 (86%)]\tLoss: 0.207163\n",
            "Train Epoch: 14 [5868/6845 (86%)]\tLoss: 0.429298\n",
            "Train Epoch: 14 [5869/6845 (86%)]\tLoss: 0.070756\n",
            "Train Epoch: 14 [5870/6845 (86%)]\tLoss: 0.151278\n",
            "Train Epoch: 14 [5871/6845 (86%)]\tLoss: 0.242253\n",
            "Train Epoch: 14 [5872/6845 (86%)]\tLoss: 0.181528\n",
            "Train Epoch: 14 [5873/6845 (86%)]\tLoss: 0.550833\n",
            "Train Epoch: 14 [5874/6845 (86%)]\tLoss: 0.065444\n",
            "Train Epoch: 14 [5875/6845 (86%)]\tLoss: 0.068598\n",
            "Train Epoch: 14 [5876/6845 (86%)]\tLoss: 0.099250\n",
            "Train Epoch: 14 [5877/6845 (86%)]\tLoss: 0.066345\n",
            "Train Epoch: 14 [5878/6845 (86%)]\tLoss: 0.211293\n",
            "Train Epoch: 14 [5879/6845 (86%)]\tLoss: 0.537707\n",
            "Train Epoch: 14 [5880/6845 (86%)]\tLoss: 0.091271\n",
            "Train Epoch: 14 [5881/6845 (86%)]\tLoss: 0.464478\n",
            "Train Epoch: 14 [5882/6845 (86%)]\tLoss: 0.046879\n",
            "Train Epoch: 14 [5883/6845 (86%)]\tLoss: 0.503435\n",
            "Train Epoch: 14 [5884/6845 (86%)]\tLoss: 0.052536\n",
            "Train Epoch: 14 [5885/6845 (86%)]\tLoss: 0.177117\n",
            "Train Epoch: 14 [5886/6845 (86%)]\tLoss: 1.407644\n",
            "Train Epoch: 14 [5887/6845 (86%)]\tLoss: 0.044558\n",
            "Train Epoch: 14 [5888/6845 (86%)]\tLoss: 0.171971\n",
            "Train Epoch: 14 [5889/6845 (86%)]\tLoss: 0.561328\n",
            "Train Epoch: 14 [5890/6845 (86%)]\tLoss: 0.138371\n",
            "Train Epoch: 14 [5891/6845 (86%)]\tLoss: 0.041790\n",
            "Train Epoch: 14 [5892/6845 (86%)]\tLoss: 0.089723\n",
            "Train Epoch: 14 [5893/6845 (86%)]\tLoss: 0.160314\n",
            "Train Epoch: 14 [5894/6845 (86%)]\tLoss: 0.143404\n",
            "Train Epoch: 14 [5895/6845 (86%)]\tLoss: 0.167492\n",
            "Train Epoch: 14 [5896/6845 (86%)]\tLoss: 0.036346\n",
            "Train Epoch: 14 [5897/6845 (86%)]\tLoss: 0.033777\n",
            "Train Epoch: 14 [5898/6845 (86%)]\tLoss: 0.140002\n",
            "Train Epoch: 14 [5899/6845 (86%)]\tLoss: 0.126838\n",
            "Train Epoch: 14 [5900/6845 (86%)]\tLoss: 0.627873\n",
            "Train Epoch: 14 [5901/6845 (86%)]\tLoss: 0.598293\n",
            "Train Epoch: 14 [5902/6845 (86%)]\tLoss: 0.208689\n",
            "Train Epoch: 14 [5903/6845 (86%)]\tLoss: 0.032685\n",
            "Train Epoch: 14 [5904/6845 (86%)]\tLoss: 0.194928\n",
            "Train Epoch: 14 [5905/6845 (86%)]\tLoss: 0.577763\n",
            "Train Epoch: 14 [5906/6845 (86%)]\tLoss: 0.137517\n",
            "Train Epoch: 14 [5907/6845 (86%)]\tLoss: 0.770849\n",
            "Train Epoch: 14 [5908/6845 (86%)]\tLoss: 1.195180\n",
            "Train Epoch: 14 [5909/6845 (86%)]\tLoss: 0.067764\n",
            "Train Epoch: 14 [5910/6845 (86%)]\tLoss: 0.054848\n",
            "Train Epoch: 14 [5911/6845 (86%)]\tLoss: 0.181075\n",
            "Train Epoch: 14 [5912/6845 (86%)]\tLoss: 0.176848\n",
            "Train Epoch: 14 [5913/6845 (86%)]\tLoss: 0.103925\n",
            "Train Epoch: 14 [5914/6845 (86%)]\tLoss: 0.349874\n",
            "Train Epoch: 14 [5915/6845 (86%)]\tLoss: 1.126554\n",
            "Train Epoch: 14 [5916/6845 (86%)]\tLoss: 0.090121\n",
            "Train Epoch: 14 [5917/6845 (86%)]\tLoss: 0.127891\n",
            "Train Epoch: 14 [5918/6845 (86%)]\tLoss: 0.115527\n",
            "Train Epoch: 14 [5919/6845 (86%)]\tLoss: 0.109488\n",
            "Train Epoch: 14 [5920/6845 (86%)]\tLoss: 0.115455\n",
            "Train Epoch: 14 [5921/6845 (87%)]\tLoss: 0.204435\n",
            "Train Epoch: 14 [5922/6845 (87%)]\tLoss: 0.395478\n",
            "Train Epoch: 14 [5923/6845 (87%)]\tLoss: 0.541686\n",
            "Train Epoch: 14 [5924/6845 (87%)]\tLoss: 0.512842\n",
            "Train Epoch: 14 [5925/6845 (87%)]\tLoss: 0.597906\n",
            "Train Epoch: 14 [5926/6845 (87%)]\tLoss: 0.211541\n",
            "Train Epoch: 14 [5927/6845 (87%)]\tLoss: 0.207027\n",
            "Train Epoch: 14 [5928/6845 (87%)]\tLoss: 0.129284\n",
            "Train Epoch: 14 [5929/6845 (87%)]\tLoss: 0.733730\n",
            "Train Epoch: 14 [5930/6845 (87%)]\tLoss: 0.062975\n",
            "Train Epoch: 14 [5931/6845 (87%)]\tLoss: 0.239543\n",
            "Train Epoch: 14 [5932/6845 (87%)]\tLoss: 0.091383\n",
            "Train Epoch: 14 [5933/6845 (87%)]\tLoss: 0.229930\n",
            "Train Epoch: 14 [5934/6845 (87%)]\tLoss: 0.145416\n",
            "Train Epoch: 14 [5935/6845 (87%)]\tLoss: 0.461207\n",
            "Train Epoch: 14 [5936/6845 (87%)]\tLoss: 0.859693\n",
            "Train Epoch: 14 [5937/6845 (87%)]\tLoss: 0.444495\n",
            "Train Epoch: 14 [5938/6845 (87%)]\tLoss: 0.601027\n",
            "Train Epoch: 14 [5939/6845 (87%)]\tLoss: 0.240489\n",
            "Train Epoch: 14 [5940/6845 (87%)]\tLoss: 0.076294\n",
            "Train Epoch: 14 [5941/6845 (87%)]\tLoss: 0.131141\n",
            "Train Epoch: 14 [5942/6845 (87%)]\tLoss: 0.080575\n",
            "Train Epoch: 14 [5943/6845 (87%)]\tLoss: 0.083218\n",
            "Train Epoch: 14 [5944/6845 (87%)]\tLoss: 0.131963\n",
            "Train Epoch: 14 [5945/6845 (87%)]\tLoss: 0.101069\n",
            "Train Epoch: 14 [5946/6845 (87%)]\tLoss: 0.071890\n",
            "Train Epoch: 14 [5947/6845 (87%)]\tLoss: 0.331256\n",
            "Train Epoch: 14 [5948/6845 (87%)]\tLoss: 0.077130\n",
            "Train Epoch: 14 [5949/6845 (87%)]\tLoss: 0.426720\n",
            "Train Epoch: 14 [5950/6845 (87%)]\tLoss: 0.153983\n",
            "Train Epoch: 14 [5951/6845 (87%)]\tLoss: 0.550868\n",
            "Train Epoch: 14 [5952/6845 (87%)]\tLoss: 0.085259\n",
            "Train Epoch: 14 [5953/6845 (87%)]\tLoss: 0.096216\n",
            "Train Epoch: 14 [5954/6845 (87%)]\tLoss: 0.731619\n",
            "Train Epoch: 14 [5955/6845 (87%)]\tLoss: 0.173204\n",
            "Train Epoch: 14 [5956/6845 (87%)]\tLoss: 0.060308\n",
            "Train Epoch: 14 [5957/6845 (87%)]\tLoss: 0.150440\n",
            "Train Epoch: 14 [5958/6845 (87%)]\tLoss: 0.590283\n",
            "Train Epoch: 14 [5959/6845 (87%)]\tLoss: 0.480142\n",
            "Train Epoch: 14 [5960/6845 (87%)]\tLoss: 0.459973\n",
            "Train Epoch: 14 [5961/6845 (87%)]\tLoss: 0.128432\n",
            "Train Epoch: 14 [5962/6845 (87%)]\tLoss: 0.118312\n",
            "Train Epoch: 14 [5963/6845 (87%)]\tLoss: 1.379531\n",
            "Train Epoch: 14 [5964/6845 (87%)]\tLoss: 0.217338\n",
            "Train Epoch: 14 [5965/6845 (87%)]\tLoss: 0.122155\n",
            "Train Epoch: 14 [5966/6845 (87%)]\tLoss: 0.122941\n",
            "Train Epoch: 14 [5967/6845 (87%)]\tLoss: 0.066621\n",
            "Train Epoch: 14 [5968/6845 (87%)]\tLoss: 0.114353\n",
            "Train Epoch: 14 [5969/6845 (87%)]\tLoss: 0.132418\n",
            "Train Epoch: 14 [5970/6845 (87%)]\tLoss: 0.111162\n",
            "Train Epoch: 14 [5971/6845 (87%)]\tLoss: 0.330192\n",
            "Train Epoch: 14 [5972/6845 (87%)]\tLoss: 0.774805\n",
            "Train Epoch: 14 [5973/6845 (87%)]\tLoss: 0.105521\n",
            "Train Epoch: 14 [5974/6845 (87%)]\tLoss: 0.073131\n",
            "Train Epoch: 14 [5975/6845 (87%)]\tLoss: 0.197751\n",
            "Train Epoch: 14 [5976/6845 (87%)]\tLoss: 0.460459\n",
            "Train Epoch: 14 [5977/6845 (87%)]\tLoss: 0.167309\n",
            "Train Epoch: 14 [5978/6845 (87%)]\tLoss: 0.056779\n",
            "Train Epoch: 14 [5979/6845 (87%)]\tLoss: 0.163756\n",
            "Train Epoch: 14 [5980/6845 (87%)]\tLoss: 0.073014\n",
            "Train Epoch: 14 [5981/6845 (87%)]\tLoss: 0.198519\n",
            "Train Epoch: 14 [5982/6845 (87%)]\tLoss: 0.104583\n",
            "Train Epoch: 14 [5983/6845 (87%)]\tLoss: 0.058919\n",
            "Train Epoch: 14 [5984/6845 (87%)]\tLoss: 0.116567\n",
            "Train Epoch: 14 [5985/6845 (87%)]\tLoss: 0.099800\n",
            "Train Epoch: 14 [5986/6845 (87%)]\tLoss: 0.644076\n",
            "Train Epoch: 14 [5987/6845 (87%)]\tLoss: 0.081972\n",
            "Train Epoch: 14 [5988/6845 (87%)]\tLoss: 0.122815\n",
            "Train Epoch: 14 [5989/6845 (87%)]\tLoss: 0.445144\n",
            "Train Epoch: 14 [5990/6845 (88%)]\tLoss: 1.022298\n",
            "Train Epoch: 14 [5991/6845 (88%)]\tLoss: 0.478290\n",
            "Train Epoch: 14 [5992/6845 (88%)]\tLoss: 0.093423\n",
            "Train Epoch: 14 [5993/6845 (88%)]\tLoss: 0.126767\n",
            "Train Epoch: 14 [5994/6845 (88%)]\tLoss: 0.056567\n",
            "Train Epoch: 14 [5995/6845 (88%)]\tLoss: 0.109142\n",
            "Train Epoch: 14 [5996/6845 (88%)]\tLoss: 0.141697\n",
            "Train Epoch: 14 [5997/6845 (88%)]\tLoss: 0.232551\n",
            "Train Epoch: 14 [5998/6845 (88%)]\tLoss: 0.093957\n",
            "Train Epoch: 14 [5999/6845 (88%)]\tLoss: 0.064904\n",
            "Train Epoch: 14 [6000/6845 (88%)]\tLoss: 0.114142\n",
            "Train Epoch: 14 [6001/6845 (88%)]\tLoss: 0.484323\n",
            "Train Epoch: 14 [6002/6845 (88%)]\tLoss: 0.063469\n",
            "Train Epoch: 14 [6003/6845 (88%)]\tLoss: 0.963010\n",
            "Train Epoch: 14 [6004/6845 (88%)]\tLoss: 0.071274\n",
            "Train Epoch: 14 [6005/6845 (88%)]\tLoss: 0.126613\n",
            "Train Epoch: 14 [6006/6845 (88%)]\tLoss: 0.114235\n",
            "Train Epoch: 14 [6007/6845 (88%)]\tLoss: 0.454065\n",
            "Train Epoch: 14 [6008/6845 (88%)]\tLoss: 0.099339\n",
            "Train Epoch: 14 [6009/6845 (88%)]\tLoss: 0.640443\n",
            "Train Epoch: 14 [6010/6845 (88%)]\tLoss: 0.073472\n",
            "Train Epoch: 14 [6011/6845 (88%)]\tLoss: 0.905000\n",
            "Train Epoch: 14 [6012/6845 (88%)]\tLoss: 0.118810\n",
            "Train Epoch: 14 [6013/6845 (88%)]\tLoss: 0.163228\n",
            "Train Epoch: 14 [6014/6845 (88%)]\tLoss: 0.580068\n",
            "Train Epoch: 14 [6015/6845 (88%)]\tLoss: 0.074199\n",
            "Train Epoch: 14 [6016/6845 (88%)]\tLoss: 0.227241\n",
            "Train Epoch: 14 [6017/6845 (88%)]\tLoss: 0.800781\n",
            "Train Epoch: 14 [6018/6845 (88%)]\tLoss: 0.460579\n",
            "Train Epoch: 14 [6019/6845 (88%)]\tLoss: 0.167690\n",
            "Train Epoch: 14 [6020/6845 (88%)]\tLoss: 0.217850\n",
            "Train Epoch: 14 [6021/6845 (88%)]\tLoss: 0.069297\n",
            "Train Epoch: 14 [6022/6845 (88%)]\tLoss: 0.196742\n",
            "Train Epoch: 14 [6023/6845 (88%)]\tLoss: 0.249671\n",
            "Train Epoch: 14 [6024/6845 (88%)]\tLoss: 0.884046\n",
            "Train Epoch: 14 [6025/6845 (88%)]\tLoss: 0.076473\n",
            "Train Epoch: 14 [6026/6845 (88%)]\tLoss: 0.972987\n",
            "Train Epoch: 14 [6027/6845 (88%)]\tLoss: 0.082212\n",
            "Train Epoch: 14 [6028/6845 (88%)]\tLoss: 0.588376\n",
            "Train Epoch: 14 [6029/6845 (88%)]\tLoss: 0.106469\n",
            "Train Epoch: 14 [6030/6845 (88%)]\tLoss: 0.901566\n",
            "Train Epoch: 14 [6031/6845 (88%)]\tLoss: 0.086443\n",
            "Train Epoch: 14 [6032/6845 (88%)]\tLoss: 0.160190\n",
            "Train Epoch: 14 [6033/6845 (88%)]\tLoss: 0.078305\n",
            "Train Epoch: 14 [6034/6845 (88%)]\tLoss: 0.174971\n",
            "Train Epoch: 14 [6035/6845 (88%)]\tLoss: 0.679499\n",
            "Train Epoch: 14 [6036/6845 (88%)]\tLoss: 0.736988\n",
            "Train Epoch: 14 [6037/6845 (88%)]\tLoss: 0.226157\n",
            "Train Epoch: 14 [6038/6845 (88%)]\tLoss: 0.070639\n",
            "Train Epoch: 14 [6039/6845 (88%)]\tLoss: 0.134293\n",
            "Train Epoch: 14 [6040/6845 (88%)]\tLoss: 0.481560\n",
            "Train Epoch: 14 [6041/6845 (88%)]\tLoss: 0.118437\n",
            "Train Epoch: 14 [6042/6845 (88%)]\tLoss: 0.196943\n",
            "Train Epoch: 14 [6043/6845 (88%)]\tLoss: 0.073380\n",
            "Train Epoch: 14 [6044/6845 (88%)]\tLoss: 0.102339\n",
            "Train Epoch: 14 [6045/6845 (88%)]\tLoss: 0.433065\n",
            "Train Epoch: 14 [6046/6845 (88%)]\tLoss: 0.403111\n",
            "Train Epoch: 14 [6047/6845 (88%)]\tLoss: 0.094473\n",
            "Train Epoch: 14 [6048/6845 (88%)]\tLoss: 0.053212\n",
            "Train Epoch: 14 [6049/6845 (88%)]\tLoss: 0.107534\n",
            "Train Epoch: 14 [6050/6845 (88%)]\tLoss: 0.049798\n",
            "Train Epoch: 14 [6051/6845 (88%)]\tLoss: 0.482568\n",
            "Train Epoch: 14 [6052/6845 (88%)]\tLoss: 0.306159\n",
            "Train Epoch: 14 [6053/6845 (88%)]\tLoss: 0.173752\n",
            "Train Epoch: 14 [6054/6845 (88%)]\tLoss: 0.084883\n",
            "Train Epoch: 14 [6055/6845 (88%)]\tLoss: 0.072231\n",
            "Train Epoch: 14 [6056/6845 (88%)]\tLoss: 0.215810\n",
            "Train Epoch: 14 [6057/6845 (88%)]\tLoss: 0.064405\n",
            "Train Epoch: 14 [6058/6845 (89%)]\tLoss: 0.042396\n",
            "Train Epoch: 14 [6059/6845 (89%)]\tLoss: 0.250211\n",
            "Train Epoch: 14 [6060/6845 (89%)]\tLoss: 0.474899\n",
            "Train Epoch: 14 [6061/6845 (89%)]\tLoss: 0.380648\n",
            "Train Epoch: 14 [6062/6845 (89%)]\tLoss: 0.049675\n",
            "Train Epoch: 14 [6063/6845 (89%)]\tLoss: 0.470638\n",
            "Train Epoch: 14 [6064/6845 (89%)]\tLoss: 0.312977\n",
            "Train Epoch: 14 [6065/6845 (89%)]\tLoss: 0.163362\n",
            "Train Epoch: 14 [6066/6845 (89%)]\tLoss: 0.036330\n",
            "Train Epoch: 14 [6067/6845 (89%)]\tLoss: 0.535773\n",
            "Train Epoch: 14 [6068/6845 (89%)]\tLoss: 0.070466\n",
            "Train Epoch: 14 [6069/6845 (89%)]\tLoss: 0.346108\n",
            "Train Epoch: 14 [6070/6845 (89%)]\tLoss: 0.854009\n",
            "Train Epoch: 14 [6071/6845 (89%)]\tLoss: 0.125051\n",
            "Train Epoch: 14 [6072/6845 (89%)]\tLoss: 0.074084\n",
            "Train Epoch: 14 [6073/6845 (89%)]\tLoss: 0.163206\n",
            "Train Epoch: 14 [6074/6845 (89%)]\tLoss: 0.243874\n",
            "Train Epoch: 14 [6075/6845 (89%)]\tLoss: 0.475810\n",
            "Train Epoch: 14 [6076/6845 (89%)]\tLoss: 0.045840\n",
            "Train Epoch: 14 [6077/6845 (89%)]\tLoss: 0.169684\n",
            "Train Epoch: 14 [6078/6845 (89%)]\tLoss: 0.463256\n",
            "Train Epoch: 14 [6079/6845 (89%)]\tLoss: 0.087639\n",
            "Train Epoch: 14 [6080/6845 (89%)]\tLoss: 0.456990\n",
            "Train Epoch: 14 [6081/6845 (89%)]\tLoss: 0.420741\n",
            "Train Epoch: 14 [6082/6845 (89%)]\tLoss: 0.087398\n",
            "Train Epoch: 14 [6083/6845 (89%)]\tLoss: 0.560510\n",
            "Train Epoch: 14 [6084/6845 (89%)]\tLoss: 0.612843\n",
            "Train Epoch: 14 [6085/6845 (89%)]\tLoss: 0.139440\n",
            "Train Epoch: 14 [6086/6845 (89%)]\tLoss: 0.302023\n",
            "Train Epoch: 14 [6087/6845 (89%)]\tLoss: 0.174445\n",
            "Train Epoch: 14 [6088/6845 (89%)]\tLoss: 0.081592\n",
            "Train Epoch: 14 [6089/6845 (89%)]\tLoss: 0.061158\n",
            "Train Epoch: 14 [6090/6845 (89%)]\tLoss: 0.114752\n",
            "Train Epoch: 14 [6091/6845 (89%)]\tLoss: 0.113647\n",
            "Train Epoch: 14 [6092/6845 (89%)]\tLoss: 0.174447\n",
            "Train Epoch: 14 [6093/6845 (89%)]\tLoss: 0.193782\n",
            "Train Epoch: 14 [6094/6845 (89%)]\tLoss: 0.271075\n",
            "Train Epoch: 14 [6095/6845 (89%)]\tLoss: 0.117285\n",
            "Train Epoch: 14 [6096/6845 (89%)]\tLoss: 0.214282\n",
            "Train Epoch: 14 [6097/6845 (89%)]\tLoss: 0.082719\n",
            "Train Epoch: 14 [6098/6845 (89%)]\tLoss: 0.108341\n",
            "Train Epoch: 14 [6099/6845 (89%)]\tLoss: 0.143240\n",
            "Train Epoch: 14 [6100/6845 (89%)]\tLoss: 0.404164\n",
            "Train Epoch: 14 [6101/6845 (89%)]\tLoss: 0.078851\n",
            "Train Epoch: 14 [6102/6845 (89%)]\tLoss: 0.101602\n",
            "Train Epoch: 14 [6103/6845 (89%)]\tLoss: 0.143469\n",
            "Train Epoch: 14 [6104/6845 (89%)]\tLoss: 0.132136\n",
            "Train Epoch: 14 [6105/6845 (89%)]\tLoss: 0.179084\n",
            "Train Epoch: 14 [6106/6845 (89%)]\tLoss: 0.485738\n",
            "Train Epoch: 14 [6107/6845 (89%)]\tLoss: 0.097467\n",
            "Train Epoch: 14 [6108/6845 (89%)]\tLoss: 0.056462\n",
            "Train Epoch: 14 [6109/6845 (89%)]\tLoss: 0.054493\n",
            "Train Epoch: 14 [6110/6845 (89%)]\tLoss: 0.217353\n",
            "Train Epoch: 14 [6111/6845 (89%)]\tLoss: 0.114706\n",
            "Train Epoch: 14 [6112/6845 (89%)]\tLoss: 0.145591\n",
            "Train Epoch: 14 [6113/6845 (89%)]\tLoss: 0.063742\n",
            "Train Epoch: 14 [6114/6845 (89%)]\tLoss: 0.116607\n",
            "Train Epoch: 14 [6115/6845 (89%)]\tLoss: 0.084347\n",
            "Train Epoch: 14 [6116/6845 (89%)]\tLoss: 0.044117\n",
            "Train Epoch: 14 [6117/6845 (89%)]\tLoss: 0.616595\n",
            "Train Epoch: 14 [6118/6845 (89%)]\tLoss: 0.057209\n",
            "Train Epoch: 14 [6119/6845 (89%)]\tLoss: 0.158413\n",
            "Train Epoch: 14 [6120/6845 (89%)]\tLoss: 0.389452\n",
            "Train Epoch: 14 [6121/6845 (89%)]\tLoss: 0.049813\n",
            "Train Epoch: 14 [6122/6845 (89%)]\tLoss: 0.105114\n",
            "Train Epoch: 14 [6123/6845 (89%)]\tLoss: 0.188319\n",
            "Train Epoch: 14 [6124/6845 (89%)]\tLoss: 0.114979\n",
            "Train Epoch: 14 [6125/6845 (89%)]\tLoss: 0.887460\n",
            "Train Epoch: 14 [6126/6845 (89%)]\tLoss: 0.204467\n",
            "Train Epoch: 14 [6127/6845 (90%)]\tLoss: 0.543512\n",
            "Train Epoch: 14 [6128/6845 (90%)]\tLoss: 0.064088\n",
            "Train Epoch: 14 [6129/6845 (90%)]\tLoss: 0.099513\n",
            "Train Epoch: 14 [6130/6845 (90%)]\tLoss: 0.545363\n",
            "Train Epoch: 14 [6131/6845 (90%)]\tLoss: 0.127504\n",
            "Train Epoch: 14 [6132/6845 (90%)]\tLoss: 0.094190\n",
            "Train Epoch: 14 [6133/6845 (90%)]\tLoss: 0.524519\n",
            "Train Epoch: 14 [6134/6845 (90%)]\tLoss: 0.130720\n",
            "Train Epoch: 14 [6135/6845 (90%)]\tLoss: 0.850986\n",
            "Train Epoch: 14 [6136/6845 (90%)]\tLoss: 0.117840\n",
            "Train Epoch: 14 [6137/6845 (90%)]\tLoss: 0.857245\n",
            "Train Epoch: 14 [6138/6845 (90%)]\tLoss: 0.098933\n",
            "Train Epoch: 14 [6139/6845 (90%)]\tLoss: 1.110923\n",
            "Train Epoch: 14 [6140/6845 (90%)]\tLoss: 0.062655\n",
            "Train Epoch: 14 [6141/6845 (90%)]\tLoss: 0.097612\n",
            "Train Epoch: 14 [6142/6845 (90%)]\tLoss: 0.092504\n",
            "Train Epoch: 14 [6143/6845 (90%)]\tLoss: 0.619158\n",
            "Train Epoch: 14 [6144/6845 (90%)]\tLoss: 0.105521\n",
            "Train Epoch: 14 [6145/6845 (90%)]\tLoss: 0.919582\n",
            "Train Epoch: 14 [6146/6845 (90%)]\tLoss: 0.045995\n",
            "Train Epoch: 14 [6147/6845 (90%)]\tLoss: 0.164516\n",
            "Train Epoch: 14 [6148/6845 (90%)]\tLoss: 0.053429\n",
            "Train Epoch: 14 [6149/6845 (90%)]\tLoss: 0.048390\n",
            "Train Epoch: 14 [6150/6845 (90%)]\tLoss: 0.138884\n",
            "Train Epoch: 14 [6151/6845 (90%)]\tLoss: 0.052803\n",
            "Train Epoch: 14 [6152/6845 (90%)]\tLoss: 0.084274\n",
            "Train Epoch: 14 [6153/6845 (90%)]\tLoss: 0.096594\n",
            "Train Epoch: 14 [6154/6845 (90%)]\tLoss: 0.049206\n",
            "Train Epoch: 14 [6155/6845 (90%)]\tLoss: 0.074130\n",
            "Train Epoch: 14 [6156/6845 (90%)]\tLoss: 1.205117\n",
            "Train Epoch: 14 [6157/6845 (90%)]\tLoss: 0.278224\n",
            "Train Epoch: 14 [6158/6845 (90%)]\tLoss: 0.173630\n",
            "Train Epoch: 14 [6159/6845 (90%)]\tLoss: 0.136179\n",
            "Train Epoch: 14 [6160/6845 (90%)]\tLoss: 0.800959\n",
            "Train Epoch: 14 [6161/6845 (90%)]\tLoss: 0.151275\n",
            "Train Epoch: 14 [6162/6845 (90%)]\tLoss: 0.119985\n",
            "Train Epoch: 14 [6163/6845 (90%)]\tLoss: 0.038297\n",
            "Train Epoch: 14 [6164/6845 (90%)]\tLoss: 0.113447\n",
            "Train Epoch: 14 [6165/6845 (90%)]\tLoss: 0.526412\n",
            "Train Epoch: 14 [6166/6845 (90%)]\tLoss: 0.044185\n",
            "Train Epoch: 14 [6167/6845 (90%)]\tLoss: 0.039654\n",
            "Train Epoch: 14 [6168/6845 (90%)]\tLoss: 0.587190\n",
            "Train Epoch: 14 [6169/6845 (90%)]\tLoss: 0.048520\n",
            "Train Epoch: 14 [6170/6845 (90%)]\tLoss: 0.055848\n",
            "Train Epoch: 14 [6171/6845 (90%)]\tLoss: 0.063476\n",
            "Train Epoch: 14 [6172/6845 (90%)]\tLoss: 0.047696\n",
            "Train Epoch: 14 [6173/6845 (90%)]\tLoss: 0.050464\n",
            "Train Epoch: 14 [6174/6845 (90%)]\tLoss: 0.155444\n",
            "Train Epoch: 14 [6175/6845 (90%)]\tLoss: 0.096312\n",
            "Train Epoch: 14 [6176/6845 (90%)]\tLoss: 0.122675\n",
            "Train Epoch: 14 [6177/6845 (90%)]\tLoss: 0.478073\n",
            "Train Epoch: 14 [6178/6845 (90%)]\tLoss: 0.154168\n",
            "Train Epoch: 14 [6179/6845 (90%)]\tLoss: 0.044106\n",
            "Train Epoch: 14 [6180/6845 (90%)]\tLoss: 0.113762\n",
            "Train Epoch: 14 [6181/6845 (90%)]\tLoss: 0.103127\n",
            "Train Epoch: 14 [6182/6845 (90%)]\tLoss: 0.153307\n",
            "Train Epoch: 14 [6183/6845 (90%)]\tLoss: 0.488834\n",
            "Train Epoch: 14 [6184/6845 (90%)]\tLoss: 0.110576\n",
            "Train Epoch: 14 [6185/6845 (90%)]\tLoss: 0.181430\n",
            "Train Epoch: 14 [6186/6845 (90%)]\tLoss: 0.069219\n",
            "Train Epoch: 14 [6187/6845 (90%)]\tLoss: 0.086186\n",
            "Train Epoch: 14 [6188/6845 (90%)]\tLoss: 0.602994\n",
            "Train Epoch: 14 [6189/6845 (90%)]\tLoss: 0.156462\n",
            "Train Epoch: 14 [6190/6845 (90%)]\tLoss: 0.061411\n",
            "Train Epoch: 14 [6191/6845 (90%)]\tLoss: 0.118535\n",
            "Train Epoch: 14 [6192/6845 (90%)]\tLoss: 0.066847\n",
            "Train Epoch: 14 [6193/6845 (90%)]\tLoss: 0.059731\n",
            "Train Epoch: 14 [6194/6845 (90%)]\tLoss: 1.049835\n",
            "Train Epoch: 14 [6195/6845 (91%)]\tLoss: 0.037668\n",
            "Train Epoch: 14 [6196/6845 (91%)]\tLoss: 0.097576\n",
            "Train Epoch: 14 [6197/6845 (91%)]\tLoss: 0.101081\n",
            "Train Epoch: 14 [6198/6845 (91%)]\tLoss: 0.067359\n",
            "Train Epoch: 14 [6199/6845 (91%)]\tLoss: 0.050516\n",
            "Train Epoch: 14 [6200/6845 (91%)]\tLoss: 0.510180\n",
            "Train Epoch: 14 [6201/6845 (91%)]\tLoss: 0.067429\n",
            "Train Epoch: 14 [6202/6845 (91%)]\tLoss: 0.996218\n",
            "Train Epoch: 14 [6203/6845 (91%)]\tLoss: 0.100043\n",
            "Train Epoch: 14 [6204/6845 (91%)]\tLoss: 1.234529\n",
            "Train Epoch: 14 [6205/6845 (91%)]\tLoss: 0.537595\n",
            "Train Epoch: 14 [6206/6845 (91%)]\tLoss: 0.608046\n",
            "Train Epoch: 14 [6207/6845 (91%)]\tLoss: 0.544000\n",
            "Train Epoch: 14 [6208/6845 (91%)]\tLoss: 0.071215\n",
            "Train Epoch: 14 [6209/6845 (91%)]\tLoss: 0.687284\n",
            "Train Epoch: 14 [6210/6845 (91%)]\tLoss: 0.048335\n",
            "Train Epoch: 14 [6211/6845 (91%)]\tLoss: 1.426719\n",
            "Train Epoch: 14 [6212/6845 (91%)]\tLoss: 0.126257\n",
            "Train Epoch: 14 [6213/6845 (91%)]\tLoss: 0.412253\n",
            "Train Epoch: 14 [6214/6845 (91%)]\tLoss: 0.107644\n",
            "Train Epoch: 14 [6215/6845 (91%)]\tLoss: 0.101533\n",
            "Train Epoch: 14 [6216/6845 (91%)]\tLoss: 0.047752\n",
            "Train Epoch: 14 [6217/6845 (91%)]\tLoss: 0.277977\n",
            "Train Epoch: 14 [6218/6845 (91%)]\tLoss: 0.179015\n",
            "Train Epoch: 14 [6219/6845 (91%)]\tLoss: 0.084092\n",
            "Train Epoch: 14 [6220/6845 (91%)]\tLoss: 0.274966\n",
            "Train Epoch: 14 [6221/6845 (91%)]\tLoss: 1.009689\n",
            "Train Epoch: 14 [6222/6845 (91%)]\tLoss: 0.100919\n",
            "Train Epoch: 14 [6223/6845 (91%)]\tLoss: 0.084103\n",
            "Train Epoch: 14 [6224/6845 (91%)]\tLoss: 0.099135\n",
            "Train Epoch: 14 [6225/6845 (91%)]\tLoss: 0.198031\n",
            "Train Epoch: 14 [6226/6845 (91%)]\tLoss: 0.094931\n",
            "Train Epoch: 14 [6227/6845 (91%)]\tLoss: 0.823451\n",
            "Train Epoch: 14 [6228/6845 (91%)]\tLoss: 0.155569\n",
            "Train Epoch: 14 [6229/6845 (91%)]\tLoss: 0.431074\n",
            "Train Epoch: 14 [6230/6845 (91%)]\tLoss: 1.089694\n",
            "Train Epoch: 14 [6231/6845 (91%)]\tLoss: 0.744908\n",
            "Train Epoch: 14 [6232/6845 (91%)]\tLoss: 0.175608\n",
            "Train Epoch: 14 [6233/6845 (91%)]\tLoss: 0.122858\n",
            "Train Epoch: 14 [6234/6845 (91%)]\tLoss: 0.279333\n",
            "Train Epoch: 14 [6235/6845 (91%)]\tLoss: 0.080245\n",
            "Train Epoch: 14 [6236/6845 (91%)]\tLoss: 0.109127\n",
            "Train Epoch: 14 [6237/6845 (91%)]\tLoss: 0.216363\n",
            "Train Epoch: 14 [6238/6845 (91%)]\tLoss: 0.502097\n",
            "Train Epoch: 14 [6239/6845 (91%)]\tLoss: 0.420496\n",
            "Train Epoch: 14 [6240/6845 (91%)]\tLoss: 0.088844\n",
            "Train Epoch: 14 [6241/6845 (91%)]\tLoss: 0.085452\n",
            "Train Epoch: 14 [6242/6845 (91%)]\tLoss: 0.125177\n",
            "Train Epoch: 14 [6243/6845 (91%)]\tLoss: 0.451317\n",
            "Train Epoch: 14 [6244/6845 (91%)]\tLoss: 0.075730\n",
            "Train Epoch: 14 [6245/6845 (91%)]\tLoss: 0.114967\n",
            "Train Epoch: 14 [6246/6845 (91%)]\tLoss: 0.811023\n",
            "Train Epoch: 14 [6247/6845 (91%)]\tLoss: 0.082272\n",
            "Train Epoch: 14 [6248/6845 (91%)]\tLoss: 0.075756\n",
            "Train Epoch: 14 [6249/6845 (91%)]\tLoss: 0.379922\n",
            "Train Epoch: 14 [6250/6845 (91%)]\tLoss: 0.108004\n",
            "Train Epoch: 14 [6251/6845 (91%)]\tLoss: 0.790302\n",
            "Train Epoch: 14 [6252/6845 (91%)]\tLoss: 0.368631\n",
            "Train Epoch: 14 [6253/6845 (91%)]\tLoss: 0.101615\n",
            "Train Epoch: 14 [6254/6845 (91%)]\tLoss: 0.090516\n",
            "Train Epoch: 14 [6255/6845 (91%)]\tLoss: 0.122134\n",
            "Train Epoch: 14 [6256/6845 (91%)]\tLoss: 0.627769\n",
            "Train Epoch: 14 [6257/6845 (91%)]\tLoss: 0.672226\n",
            "Train Epoch: 14 [6258/6845 (91%)]\tLoss: 0.084945\n",
            "Train Epoch: 14 [6259/6845 (91%)]\tLoss: 0.304038\n",
            "Train Epoch: 14 [6260/6845 (91%)]\tLoss: 0.076259\n",
            "Train Epoch: 14 [6261/6845 (91%)]\tLoss: 0.106805\n",
            "Train Epoch: 14 [6262/6845 (91%)]\tLoss: 0.091555\n",
            "Train Epoch: 14 [6263/6845 (91%)]\tLoss: 1.104519\n",
            "Train Epoch: 14 [6264/6845 (92%)]\tLoss: 0.079022\n",
            "Train Epoch: 14 [6265/6845 (92%)]\tLoss: 0.071721\n",
            "Train Epoch: 14 [6266/6845 (92%)]\tLoss: 0.093402\n",
            "Train Epoch: 14 [6267/6845 (92%)]\tLoss: 0.149045\n",
            "Train Epoch: 14 [6268/6845 (92%)]\tLoss: 0.213000\n",
            "Train Epoch: 14 [6269/6845 (92%)]\tLoss: 0.085033\n",
            "Train Epoch: 14 [6270/6845 (92%)]\tLoss: 0.081715\n",
            "Train Epoch: 14 [6271/6845 (92%)]\tLoss: 0.275007\n",
            "Train Epoch: 14 [6272/6845 (92%)]\tLoss: 0.725054\n",
            "Train Epoch: 14 [6273/6845 (92%)]\tLoss: 0.136261\n",
            "Train Epoch: 14 [6274/6845 (92%)]\tLoss: 0.065174\n",
            "Train Epoch: 14 [6275/6845 (92%)]\tLoss: 0.084458\n",
            "Train Epoch: 14 [6276/6845 (92%)]\tLoss: 0.069112\n",
            "Train Epoch: 14 [6277/6845 (92%)]\tLoss: 0.106921\n",
            "Train Epoch: 14 [6278/6845 (92%)]\tLoss: 0.499667\n",
            "Train Epoch: 14 [6279/6845 (92%)]\tLoss: 0.150559\n",
            "Train Epoch: 14 [6280/6845 (92%)]\tLoss: 0.098518\n",
            "Train Epoch: 14 [6281/6845 (92%)]\tLoss: 0.150074\n",
            "Train Epoch: 14 [6282/6845 (92%)]\tLoss: 0.699826\n",
            "Train Epoch: 14 [6283/6845 (92%)]\tLoss: 0.142196\n",
            "Train Epoch: 14 [6284/6845 (92%)]\tLoss: 0.073158\n",
            "Train Epoch: 14 [6285/6845 (92%)]\tLoss: 0.127031\n",
            "Train Epoch: 14 [6286/6845 (92%)]\tLoss: 0.630646\n",
            "Train Epoch: 14 [6287/6845 (92%)]\tLoss: 0.080422\n",
            "Train Epoch: 14 [6288/6845 (92%)]\tLoss: 0.630968\n",
            "Train Epoch: 14 [6289/6845 (92%)]\tLoss: 0.096689\n",
            "Train Epoch: 14 [6290/6845 (92%)]\tLoss: 0.718219\n",
            "Train Epoch: 14 [6291/6845 (92%)]\tLoss: 1.065209\n",
            "Train Epoch: 14 [6292/6845 (92%)]\tLoss: 0.669524\n",
            "Train Epoch: 14 [6293/6845 (92%)]\tLoss: 0.107832\n",
            "Train Epoch: 14 [6294/6845 (92%)]\tLoss: 0.116426\n",
            "Train Epoch: 14 [6295/6845 (92%)]\tLoss: 0.170038\n",
            "Train Epoch: 14 [6296/6845 (92%)]\tLoss: 0.239642\n",
            "Train Epoch: 14 [6297/6845 (92%)]\tLoss: 0.056590\n",
            "Train Epoch: 14 [6298/6845 (92%)]\tLoss: 0.067530\n",
            "Train Epoch: 14 [6299/6845 (92%)]\tLoss: 0.087840\n",
            "Train Epoch: 14 [6300/6845 (92%)]\tLoss: 0.145918\n",
            "Train Epoch: 14 [6301/6845 (92%)]\tLoss: 0.162052\n",
            "Train Epoch: 14 [6302/6845 (92%)]\tLoss: 0.181363\n",
            "Train Epoch: 14 [6303/6845 (92%)]\tLoss: 0.759685\n",
            "Train Epoch: 14 [6304/6845 (92%)]\tLoss: 0.684246\n",
            "Train Epoch: 14 [6305/6845 (92%)]\tLoss: 0.921866\n",
            "Train Epoch: 14 [6306/6845 (92%)]\tLoss: 0.508899\n",
            "Train Epoch: 14 [6307/6845 (92%)]\tLoss: 1.344071\n",
            "Train Epoch: 14 [6308/6845 (92%)]\tLoss: 0.121236\n",
            "Train Epoch: 14 [6309/6845 (92%)]\tLoss: 0.820091\n",
            "Train Epoch: 14 [6310/6845 (92%)]\tLoss: 0.269440\n",
            "Train Epoch: 14 [6311/6845 (92%)]\tLoss: 0.197410\n",
            "Train Epoch: 14 [6312/6845 (92%)]\tLoss: 0.060542\n",
            "Train Epoch: 14 [6313/6845 (92%)]\tLoss: 0.171498\n",
            "Train Epoch: 14 [6314/6845 (92%)]\tLoss: 0.085740\n",
            "Train Epoch: 14 [6315/6845 (92%)]\tLoss: 0.144654\n",
            "Train Epoch: 14 [6316/6845 (92%)]\tLoss: 0.099413\n",
            "Train Epoch: 14 [6317/6845 (92%)]\tLoss: 0.072782\n",
            "Train Epoch: 14 [6318/6845 (92%)]\tLoss: 1.090846\n",
            "Train Epoch: 14 [6319/6845 (92%)]\tLoss: 0.240623\n",
            "Train Epoch: 14 [6320/6845 (92%)]\tLoss: 0.212502\n",
            "Train Epoch: 14 [6321/6845 (92%)]\tLoss: 0.569896\n",
            "Train Epoch: 14 [6322/6845 (92%)]\tLoss: 0.802197\n",
            "Train Epoch: 14 [6323/6845 (92%)]\tLoss: 0.985913\n",
            "Train Epoch: 14 [6324/6845 (92%)]\tLoss: 0.064676\n",
            "Train Epoch: 14 [6325/6845 (92%)]\tLoss: 1.282230\n",
            "Train Epoch: 14 [6326/6845 (92%)]\tLoss: 0.187805\n",
            "Train Epoch: 14 [6327/6845 (92%)]\tLoss: 0.657356\n",
            "Train Epoch: 14 [6328/6845 (92%)]\tLoss: 0.063289\n",
            "Train Epoch: 14 [6329/6845 (92%)]\tLoss: 0.066231\n",
            "Train Epoch: 14 [6330/6845 (92%)]\tLoss: 0.128600\n",
            "Train Epoch: 14 [6331/6845 (92%)]\tLoss: 0.196423\n",
            "Train Epoch: 14 [6332/6845 (93%)]\tLoss: 0.277754\n",
            "Train Epoch: 14 [6333/6845 (93%)]\tLoss: 0.111448\n",
            "Train Epoch: 14 [6334/6845 (93%)]\tLoss: 0.063677\n",
            "Train Epoch: 14 [6335/6845 (93%)]\tLoss: 0.093041\n",
            "Train Epoch: 14 [6336/6845 (93%)]\tLoss: 0.161541\n",
            "Train Epoch: 14 [6337/6845 (93%)]\tLoss: 0.540620\n",
            "Train Epoch: 14 [6338/6845 (93%)]\tLoss: 0.141853\n",
            "Train Epoch: 14 [6339/6845 (93%)]\tLoss: 0.700425\n",
            "Train Epoch: 14 [6340/6845 (93%)]\tLoss: 0.084756\n",
            "Train Epoch: 14 [6341/6845 (93%)]\tLoss: 0.144005\n",
            "Train Epoch: 14 [6342/6845 (93%)]\tLoss: 0.084533\n",
            "Train Epoch: 14 [6343/6845 (93%)]\tLoss: 0.210336\n",
            "Train Epoch: 14 [6344/6845 (93%)]\tLoss: 0.259583\n",
            "Train Epoch: 14 [6345/6845 (93%)]\tLoss: 0.062661\n",
            "Train Epoch: 14 [6346/6845 (93%)]\tLoss: 0.062011\n",
            "Train Epoch: 14 [6347/6845 (93%)]\tLoss: 0.097224\n",
            "Train Epoch: 14 [6348/6845 (93%)]\tLoss: 0.174170\n",
            "Train Epoch: 14 [6349/6845 (93%)]\tLoss: 0.080990\n",
            "Train Epoch: 14 [6350/6845 (93%)]\tLoss: 0.062363\n",
            "Train Epoch: 14 [6351/6845 (93%)]\tLoss: 0.126993\n",
            "Train Epoch: 14 [6352/6845 (93%)]\tLoss: 0.094277\n",
            "Train Epoch: 14 [6353/6845 (93%)]\tLoss: 0.108298\n",
            "Train Epoch: 14 [6354/6845 (93%)]\tLoss: 0.103332\n",
            "Train Epoch: 14 [6355/6845 (93%)]\tLoss: 0.047418\n",
            "Train Epoch: 14 [6356/6845 (93%)]\tLoss: 0.199282\n",
            "Train Epoch: 14 [6357/6845 (93%)]\tLoss: 0.058243\n",
            "Train Epoch: 14 [6358/6845 (93%)]\tLoss: 0.042928\n",
            "Train Epoch: 14 [6359/6845 (93%)]\tLoss: 0.072043\n",
            "Train Epoch: 14 [6360/6845 (93%)]\tLoss: 0.192337\n",
            "Train Epoch: 14 [6361/6845 (93%)]\tLoss: 0.487555\n",
            "Train Epoch: 14 [6362/6845 (93%)]\tLoss: 0.179578\n",
            "Train Epoch: 14 [6363/6845 (93%)]\tLoss: 0.081664\n",
            "Train Epoch: 14 [6364/6845 (93%)]\tLoss: 0.104390\n",
            "Train Epoch: 14 [6365/6845 (93%)]\tLoss: 0.072912\n",
            "Train Epoch: 14 [6366/6845 (93%)]\tLoss: 0.083994\n",
            "Train Epoch: 14 [6367/6845 (93%)]\tLoss: 0.056649\n",
            "Train Epoch: 14 [6368/6845 (93%)]\tLoss: 0.102459\n",
            "Train Epoch: 14 [6369/6845 (93%)]\tLoss: 0.088184\n",
            "Train Epoch: 14 [6370/6845 (93%)]\tLoss: 0.513587\n",
            "Train Epoch: 14 [6371/6845 (93%)]\tLoss: 0.037275\n",
            "Train Epoch: 14 [6372/6845 (93%)]\tLoss: 0.039996\n",
            "Train Epoch: 14 [6373/6845 (93%)]\tLoss: 0.042033\n",
            "Train Epoch: 14 [6374/6845 (93%)]\tLoss: 0.045746\n",
            "Train Epoch: 14 [6375/6845 (93%)]\tLoss: 0.178439\n",
            "Train Epoch: 14 [6376/6845 (93%)]\tLoss: 0.584445\n",
            "Train Epoch: 14 [6377/6845 (93%)]\tLoss: 0.131839\n",
            "Train Epoch: 14 [6378/6845 (93%)]\tLoss: 0.691367\n",
            "Train Epoch: 14 [6379/6845 (93%)]\tLoss: 0.110420\n",
            "Train Epoch: 14 [6380/6845 (93%)]\tLoss: 0.107790\n",
            "Train Epoch: 14 [6381/6845 (93%)]\tLoss: 0.153207\n",
            "Train Epoch: 14 [6382/6845 (93%)]\tLoss: 0.102212\n",
            "Train Epoch: 14 [6383/6845 (93%)]\tLoss: 0.119731\n",
            "Train Epoch: 14 [6384/6845 (93%)]\tLoss: 0.553141\n",
            "Train Epoch: 14 [6385/6845 (93%)]\tLoss: 1.195842\n",
            "Train Epoch: 14 [6386/6845 (93%)]\tLoss: 0.133178\n",
            "Train Epoch: 14 [6387/6845 (93%)]\tLoss: 0.152907\n",
            "Train Epoch: 14 [6388/6845 (93%)]\tLoss: 0.046751\n",
            "Train Epoch: 14 [6389/6845 (93%)]\tLoss: 0.069938\n",
            "Train Epoch: 14 [6390/6845 (93%)]\tLoss: 0.088598\n",
            "Train Epoch: 14 [6391/6845 (93%)]\tLoss: 0.074612\n",
            "Train Epoch: 14 [6392/6845 (93%)]\tLoss: 0.191631\n",
            "Train Epoch: 14 [6393/6845 (93%)]\tLoss: 0.083955\n",
            "Train Epoch: 14 [6394/6845 (93%)]\tLoss: 0.177033\n",
            "Train Epoch: 14 [6395/6845 (93%)]\tLoss: 0.549720\n",
            "Train Epoch: 14 [6396/6845 (93%)]\tLoss: 0.106489\n",
            "Train Epoch: 14 [6397/6845 (93%)]\tLoss: 0.166852\n",
            "Train Epoch: 14 [6398/6845 (93%)]\tLoss: 0.180552\n",
            "Train Epoch: 14 [6399/6845 (93%)]\tLoss: 0.550562\n",
            "Train Epoch: 14 [6400/6845 (93%)]\tLoss: 0.061007\n",
            "Train Epoch: 14 [6401/6845 (94%)]\tLoss: 0.096129\n",
            "Train Epoch: 14 [6402/6845 (94%)]\tLoss: 0.060307\n",
            "Train Epoch: 14 [6403/6845 (94%)]\tLoss: 0.063960\n",
            "Train Epoch: 14 [6404/6845 (94%)]\tLoss: 0.095714\n",
            "Train Epoch: 14 [6405/6845 (94%)]\tLoss: 0.059714\n",
            "Train Epoch: 14 [6406/6845 (94%)]\tLoss: 0.535640\n",
            "Train Epoch: 14 [6407/6845 (94%)]\tLoss: 0.071705\n",
            "Train Epoch: 14 [6408/6845 (94%)]\tLoss: 0.062026\n",
            "Train Epoch: 14 [6409/6845 (94%)]\tLoss: 0.052624\n",
            "Train Epoch: 14 [6410/6845 (94%)]\tLoss: 0.064119\n",
            "Train Epoch: 14 [6411/6845 (94%)]\tLoss: 0.051070\n",
            "Train Epoch: 14 [6412/6845 (94%)]\tLoss: 0.130902\n",
            "Train Epoch: 14 [6413/6845 (94%)]\tLoss: 0.863831\n",
            "Train Epoch: 14 [6414/6845 (94%)]\tLoss: 0.065103\n",
            "Train Epoch: 14 [6415/6845 (94%)]\tLoss: 0.092576\n",
            "Train Epoch: 14 [6416/6845 (94%)]\tLoss: 0.063104\n",
            "Train Epoch: 14 [6417/6845 (94%)]\tLoss: 0.130693\n",
            "Train Epoch: 14 [6418/6845 (94%)]\tLoss: 0.075927\n",
            "Train Epoch: 14 [6419/6845 (94%)]\tLoss: 0.173797\n",
            "Train Epoch: 14 [6420/6845 (94%)]\tLoss: 0.084788\n",
            "Train Epoch: 14 [6421/6845 (94%)]\tLoss: 0.158134\n",
            "Train Epoch: 14 [6422/6845 (94%)]\tLoss: 0.181024\n",
            "Train Epoch: 14 [6423/6845 (94%)]\tLoss: 0.754528\n",
            "Train Epoch: 14 [6424/6845 (94%)]\tLoss: 0.084695\n",
            "Train Epoch: 14 [6425/6845 (94%)]\tLoss: 0.164303\n",
            "Train Epoch: 14 [6426/6845 (94%)]\tLoss: 0.055709\n",
            "Train Epoch: 14 [6427/6845 (94%)]\tLoss: 0.107883\n",
            "Train Epoch: 14 [6428/6845 (94%)]\tLoss: 0.059943\n",
            "Train Epoch: 14 [6429/6845 (94%)]\tLoss: 0.805267\n",
            "Train Epoch: 14 [6430/6845 (94%)]\tLoss: 0.054223\n",
            "Train Epoch: 14 [6431/6845 (94%)]\tLoss: 0.085880\n",
            "Train Epoch: 14 [6432/6845 (94%)]\tLoss: 0.108165\n",
            "Train Epoch: 14 [6433/6845 (94%)]\tLoss: 0.051609\n",
            "Train Epoch: 14 [6434/6845 (94%)]\tLoss: 0.667192\n",
            "Train Epoch: 14 [6435/6845 (94%)]\tLoss: 0.085046\n",
            "Train Epoch: 14 [6436/6845 (94%)]\tLoss: 0.098327\n",
            "Train Epoch: 14 [6437/6845 (94%)]\tLoss: 0.157462\n",
            "Train Epoch: 14 [6438/6845 (94%)]\tLoss: 0.775761\n",
            "Train Epoch: 14 [6439/6845 (94%)]\tLoss: 0.059942\n",
            "Train Epoch: 14 [6440/6845 (94%)]\tLoss: 0.695118\n",
            "Train Epoch: 14 [6441/6845 (94%)]\tLoss: 0.055367\n",
            "Train Epoch: 14 [6442/6845 (94%)]\tLoss: 0.108890\n",
            "Train Epoch: 14 [6443/6845 (94%)]\tLoss: 1.066117\n",
            "Train Epoch: 14 [6444/6845 (94%)]\tLoss: 0.181500\n",
            "Train Epoch: 14 [6445/6845 (94%)]\tLoss: 0.066481\n",
            "Train Epoch: 14 [6446/6845 (94%)]\tLoss: 0.122699\n",
            "Train Epoch: 14 [6447/6845 (94%)]\tLoss: 0.084311\n",
            "Train Epoch: 14 [6448/6845 (94%)]\tLoss: 0.558456\n",
            "Train Epoch: 14 [6449/6845 (94%)]\tLoss: 0.116960\n",
            "Train Epoch: 14 [6450/6845 (94%)]\tLoss: 0.069436\n",
            "Train Epoch: 14 [6451/6845 (94%)]\tLoss: 0.875113\n",
            "Train Epoch: 14 [6452/6845 (94%)]\tLoss: 0.078252\n",
            "Train Epoch: 14 [6453/6845 (94%)]\tLoss: 0.060460\n",
            "Train Epoch: 14 [6454/6845 (94%)]\tLoss: 0.157688\n",
            "Train Epoch: 14 [6455/6845 (94%)]\tLoss: 0.051653\n",
            "Train Epoch: 14 [6456/6845 (94%)]\tLoss: 0.118875\n",
            "Train Epoch: 14 [6457/6845 (94%)]\tLoss: 0.772057\n",
            "Train Epoch: 14 [6458/6845 (94%)]\tLoss: 0.060007\n",
            "Train Epoch: 14 [6459/6845 (94%)]\tLoss: 0.072750\n",
            "Train Epoch: 14 [6460/6845 (94%)]\tLoss: 0.113258\n",
            "Train Epoch: 14 [6461/6845 (94%)]\tLoss: 0.551185\n",
            "Train Epoch: 14 [6462/6845 (94%)]\tLoss: 0.050289\n",
            "Train Epoch: 14 [6463/6845 (94%)]\tLoss: 1.150243\n",
            "Train Epoch: 14 [6464/6845 (94%)]\tLoss: 0.089310\n",
            "Train Epoch: 14 [6465/6845 (94%)]\tLoss: 0.523604\n",
            "Train Epoch: 14 [6466/6845 (94%)]\tLoss: 0.089527\n",
            "Train Epoch: 14 [6467/6845 (94%)]\tLoss: 0.093771\n",
            "Train Epoch: 14 [6468/6845 (94%)]\tLoss: 0.192969\n",
            "Train Epoch: 14 [6469/6845 (95%)]\tLoss: 0.068204\n",
            "Train Epoch: 14 [6470/6845 (95%)]\tLoss: 0.696741\n",
            "Train Epoch: 14 [6471/6845 (95%)]\tLoss: 0.073693\n",
            "Train Epoch: 14 [6472/6845 (95%)]\tLoss: 0.099195\n",
            "Train Epoch: 14 [6473/6845 (95%)]\tLoss: 0.094951\n",
            "Train Epoch: 14 [6474/6845 (95%)]\tLoss: 0.071564\n",
            "Train Epoch: 14 [6475/6845 (95%)]\tLoss: 0.065058\n",
            "Train Epoch: 14 [6476/6845 (95%)]\tLoss: 0.921443\n",
            "Train Epoch: 14 [6477/6845 (95%)]\tLoss: 0.056371\n",
            "Train Epoch: 14 [6478/6845 (95%)]\tLoss: 0.688003\n",
            "Train Epoch: 14 [6479/6845 (95%)]\tLoss: 0.082754\n",
            "Train Epoch: 14 [6480/6845 (95%)]\tLoss: 0.072846\n",
            "Train Epoch: 14 [6481/6845 (95%)]\tLoss: 0.571742\n",
            "Train Epoch: 14 [6482/6845 (95%)]\tLoss: 0.107901\n",
            "Train Epoch: 14 [6483/6845 (95%)]\tLoss: 0.141681\n",
            "Train Epoch: 14 [6484/6845 (95%)]\tLoss: 0.119078\n",
            "Train Epoch: 14 [6485/6845 (95%)]\tLoss: 0.067239\n",
            "Train Epoch: 14 [6486/6845 (95%)]\tLoss: 0.081097\n",
            "Train Epoch: 14 [6487/6845 (95%)]\tLoss: 0.096935\n",
            "Train Epoch: 14 [6488/6845 (95%)]\tLoss: 0.207432\n",
            "Train Epoch: 14 [6489/6845 (95%)]\tLoss: 0.075983\n",
            "Train Epoch: 14 [6490/6845 (95%)]\tLoss: 0.096478\n",
            "Train Epoch: 14 [6491/6845 (95%)]\tLoss: 0.058508\n",
            "Train Epoch: 14 [6492/6845 (95%)]\tLoss: 0.111865\n",
            "Train Epoch: 14 [6493/6845 (95%)]\tLoss: 0.058822\n",
            "Train Epoch: 14 [6494/6845 (95%)]\tLoss: 0.129412\n",
            "Train Epoch: 14 [6495/6845 (95%)]\tLoss: 0.087049\n",
            "Train Epoch: 14 [6496/6845 (95%)]\tLoss: 0.070081\n",
            "Train Epoch: 14 [6497/6845 (95%)]\tLoss: 0.056764\n",
            "Train Epoch: 14 [6498/6845 (95%)]\tLoss: 0.090624\n",
            "Train Epoch: 14 [6499/6845 (95%)]\tLoss: 0.112536\n",
            "Train Epoch: 14 [6500/6845 (95%)]\tLoss: 0.194151\n",
            "Train Epoch: 14 [6501/6845 (95%)]\tLoss: 0.097235\n",
            "Train Epoch: 14 [6502/6845 (95%)]\tLoss: 0.180882\n",
            "Train Epoch: 14 [6503/6845 (95%)]\tLoss: 0.117142\n",
            "Train Epoch: 14 [6504/6845 (95%)]\tLoss: 0.169106\n",
            "Train Epoch: 14 [6505/6845 (95%)]\tLoss: 0.618807\n",
            "Train Epoch: 14 [6506/6845 (95%)]\tLoss: 0.055914\n",
            "Train Epoch: 14 [6507/6845 (95%)]\tLoss: 0.637959\n",
            "Train Epoch: 14 [6508/6845 (95%)]\tLoss: 0.733140\n",
            "Train Epoch: 14 [6509/6845 (95%)]\tLoss: 0.061977\n",
            "Train Epoch: 14 [6510/6845 (95%)]\tLoss: 0.188729\n",
            "Train Epoch: 14 [6511/6845 (95%)]\tLoss: 0.058199\n",
            "Train Epoch: 14 [6512/6845 (95%)]\tLoss: 0.413277\n",
            "Train Epoch: 14 [6513/6845 (95%)]\tLoss: 0.073556\n",
            "Train Epoch: 14 [6514/6845 (95%)]\tLoss: 0.892367\n",
            "Train Epoch: 14 [6515/6845 (95%)]\tLoss: 0.073942\n",
            "Train Epoch: 14 [6516/6845 (95%)]\tLoss: 0.140928\n",
            "Train Epoch: 14 [6517/6845 (95%)]\tLoss: 0.658280\n",
            "Train Epoch: 14 [6518/6845 (95%)]\tLoss: 0.104981\n",
            "Train Epoch: 14 [6519/6845 (95%)]\tLoss: 0.053065\n",
            "Train Epoch: 14 [6520/6845 (95%)]\tLoss: 0.077569\n",
            "Train Epoch: 14 [6521/6845 (95%)]\tLoss: 1.533934\n",
            "Train Epoch: 14 [6522/6845 (95%)]\tLoss: 0.100028\n",
            "Train Epoch: 14 [6523/6845 (95%)]\tLoss: 0.489920\n",
            "Train Epoch: 14 [6524/6845 (95%)]\tLoss: 0.060633\n",
            "Train Epoch: 14 [6525/6845 (95%)]\tLoss: 0.838517\n",
            "Train Epoch: 14 [6526/6845 (95%)]\tLoss: 0.098559\n",
            "Train Epoch: 14 [6527/6845 (95%)]\tLoss: 0.167931\n",
            "Train Epoch: 14 [6528/6845 (95%)]\tLoss: 0.164369\n",
            "Train Epoch: 14 [6529/6845 (95%)]\tLoss: 0.599494\n",
            "Train Epoch: 14 [6530/6845 (95%)]\tLoss: 0.728328\n",
            "Train Epoch: 14 [6531/6845 (95%)]\tLoss: 0.636903\n",
            "Train Epoch: 14 [6532/6845 (95%)]\tLoss: 0.834052\n",
            "Train Epoch: 14 [6533/6845 (95%)]\tLoss: 0.126364\n",
            "Train Epoch: 14 [6534/6845 (95%)]\tLoss: 0.620179\n",
            "Train Epoch: 14 [6535/6845 (95%)]\tLoss: 0.150896\n",
            "Train Epoch: 14 [6536/6845 (95%)]\tLoss: 0.825940\n",
            "Train Epoch: 14 [6537/6845 (96%)]\tLoss: 0.115871\n",
            "Train Epoch: 14 [6538/6845 (96%)]\tLoss: 0.185498\n",
            "Train Epoch: 14 [6539/6845 (96%)]\tLoss: 0.070130\n",
            "Train Epoch: 14 [6540/6845 (96%)]\tLoss: 0.056301\n",
            "Train Epoch: 14 [6541/6845 (96%)]\tLoss: 0.482935\n",
            "Train Epoch: 14 [6542/6845 (96%)]\tLoss: 0.095280\n",
            "Train Epoch: 14 [6543/6845 (96%)]\tLoss: 0.703253\n",
            "Train Epoch: 14 [6544/6845 (96%)]\tLoss: 0.054467\n",
            "Train Epoch: 14 [6545/6845 (96%)]\tLoss: 0.152913\n",
            "Train Epoch: 14 [6546/6845 (96%)]\tLoss: 0.268600\n",
            "Train Epoch: 14 [6547/6845 (96%)]\tLoss: 0.107489\n",
            "Train Epoch: 14 [6548/6845 (96%)]\tLoss: 0.099925\n",
            "Train Epoch: 14 [6549/6845 (96%)]\tLoss: 0.433221\n",
            "Train Epoch: 14 [6550/6845 (96%)]\tLoss: 0.127906\n",
            "Train Epoch: 14 [6551/6845 (96%)]\tLoss: 0.706132\n",
            "Train Epoch: 14 [6552/6845 (96%)]\tLoss: 0.888970\n",
            "Train Epoch: 14 [6553/6845 (96%)]\tLoss: 0.150390\n",
            "Train Epoch: 14 [6554/6845 (96%)]\tLoss: 1.155635\n",
            "Train Epoch: 14 [6555/6845 (96%)]\tLoss: 0.102783\n",
            "Train Epoch: 14 [6556/6845 (96%)]\tLoss: 0.170916\n",
            "Train Epoch: 14 [6557/6845 (96%)]\tLoss: 0.245598\n",
            "Train Epoch: 14 [6558/6845 (96%)]\tLoss: 0.068554\n",
            "Train Epoch: 14 [6559/6845 (96%)]\tLoss: 0.172572\n",
            "Train Epoch: 14 [6560/6845 (96%)]\tLoss: 0.829452\n",
            "Train Epoch: 14 [6561/6845 (96%)]\tLoss: 0.058703\n",
            "Train Epoch: 14 [6562/6845 (96%)]\tLoss: 0.229621\n",
            "Train Epoch: 14 [6563/6845 (96%)]\tLoss: 0.136138\n",
            "Train Epoch: 14 [6564/6845 (96%)]\tLoss: 0.634884\n",
            "Train Epoch: 14 [6565/6845 (96%)]\tLoss: 0.155204\n",
            "Train Epoch: 14 [6566/6845 (96%)]\tLoss: 0.221354\n",
            "Train Epoch: 14 [6567/6845 (96%)]\tLoss: 0.561759\n",
            "Train Epoch: 14 [6568/6845 (96%)]\tLoss: 0.590896\n",
            "Train Epoch: 14 [6569/6845 (96%)]\tLoss: 0.087300\n",
            "Train Epoch: 14 [6570/6845 (96%)]\tLoss: 0.115063\n",
            "Train Epoch: 14 [6571/6845 (96%)]\tLoss: 0.556793\n",
            "Train Epoch: 14 [6572/6845 (96%)]\tLoss: 0.103732\n",
            "Train Epoch: 14 [6573/6845 (96%)]\tLoss: 0.226805\n",
            "Train Epoch: 14 [6574/6845 (96%)]\tLoss: 0.108105\n",
            "Train Epoch: 14 [6575/6845 (96%)]\tLoss: 0.098338\n",
            "Train Epoch: 14 [6576/6845 (96%)]\tLoss: 0.118971\n",
            "Train Epoch: 14 [6577/6845 (96%)]\tLoss: 0.061910\n",
            "Train Epoch: 14 [6578/6845 (96%)]\tLoss: 0.087049\n",
            "Train Epoch: 14 [6579/6845 (96%)]\tLoss: 0.490510\n",
            "Train Epoch: 14 [6580/6845 (96%)]\tLoss: 0.230593\n",
            "Train Epoch: 14 [6581/6845 (96%)]\tLoss: 0.695911\n",
            "Train Epoch: 14 [6582/6845 (96%)]\tLoss: 0.122106\n",
            "Train Epoch: 14 [6583/6845 (96%)]\tLoss: 0.424414\n",
            "Train Epoch: 14 [6584/6845 (96%)]\tLoss: 0.090250\n",
            "Train Epoch: 14 [6585/6845 (96%)]\tLoss: 0.615719\n",
            "Train Epoch: 14 [6586/6845 (96%)]\tLoss: 1.974982\n",
            "Train Epoch: 14 [6587/6845 (96%)]\tLoss: 0.562667\n",
            "Train Epoch: 14 [6588/6845 (96%)]\tLoss: 0.184284\n",
            "Train Epoch: 14 [6589/6845 (96%)]\tLoss: 0.193949\n",
            "Train Epoch: 14 [6590/6845 (96%)]\tLoss: 0.046089\n",
            "Train Epoch: 14 [6591/6845 (96%)]\tLoss: 0.102160\n",
            "Train Epoch: 14 [6592/6845 (96%)]\tLoss: 0.060752\n",
            "Train Epoch: 14 [6593/6845 (96%)]\tLoss: 0.073860\n",
            "Train Epoch: 14 [6594/6845 (96%)]\tLoss: 0.159627\n",
            "Train Epoch: 14 [6595/6845 (96%)]\tLoss: 0.184644\n",
            "Train Epoch: 14 [6596/6845 (96%)]\tLoss: 0.621678\n",
            "Train Epoch: 14 [6597/6845 (96%)]\tLoss: 0.126411\n",
            "Train Epoch: 14 [6598/6845 (96%)]\tLoss: 0.120936\n",
            "Train Epoch: 14 [6599/6845 (96%)]\tLoss: 0.062940\n",
            "Train Epoch: 14 [6600/6845 (96%)]\tLoss: 0.175303\n",
            "Train Epoch: 14 [6601/6845 (96%)]\tLoss: 0.518459\n",
            "Train Epoch: 14 [6602/6845 (96%)]\tLoss: 0.110444\n",
            "Train Epoch: 14 [6603/6845 (96%)]\tLoss: 0.153098\n",
            "Train Epoch: 14 [6604/6845 (96%)]\tLoss: 0.252356\n",
            "Train Epoch: 14 [6605/6845 (96%)]\tLoss: 0.448942\n",
            "Train Epoch: 14 [6606/6845 (97%)]\tLoss: 0.118318\n",
            "Train Epoch: 14 [6607/6845 (97%)]\tLoss: 0.107092\n",
            "Train Epoch: 14 [6608/6845 (97%)]\tLoss: 0.173711\n",
            "Train Epoch: 14 [6609/6845 (97%)]\tLoss: 0.063880\n",
            "Train Epoch: 14 [6610/6845 (97%)]\tLoss: 0.464717\n",
            "Train Epoch: 14 [6611/6845 (97%)]\tLoss: 0.108374\n",
            "Train Epoch: 14 [6612/6845 (97%)]\tLoss: 0.364063\n",
            "Train Epoch: 14 [6613/6845 (97%)]\tLoss: 0.201868\n",
            "Train Epoch: 14 [6614/6845 (97%)]\tLoss: 0.049254\n",
            "Train Epoch: 14 [6615/6845 (97%)]\tLoss: 0.079595\n",
            "Train Epoch: 14 [6616/6845 (97%)]\tLoss: 0.172839\n",
            "Train Epoch: 14 [6617/6845 (97%)]\tLoss: 0.597570\n",
            "Train Epoch: 14 [6618/6845 (97%)]\tLoss: 0.054028\n",
            "Train Epoch: 14 [6619/6845 (97%)]\tLoss: 0.100058\n",
            "Train Epoch: 14 [6620/6845 (97%)]\tLoss: 0.093419\n",
            "Train Epoch: 14 [6621/6845 (97%)]\tLoss: 0.178603\n",
            "Train Epoch: 14 [6622/6845 (97%)]\tLoss: 0.608038\n",
            "Train Epoch: 14 [6623/6845 (97%)]\tLoss: 0.162812\n",
            "Train Epoch: 14 [6624/6845 (97%)]\tLoss: 0.100366\n",
            "Train Epoch: 14 [6625/6845 (97%)]\tLoss: 0.082931\n",
            "Train Epoch: 14 [6626/6845 (97%)]\tLoss: 0.068370\n",
            "Train Epoch: 14 [6627/6845 (97%)]\tLoss: 0.109988\n",
            "Train Epoch: 14 [6628/6845 (97%)]\tLoss: 0.191854\n",
            "Train Epoch: 14 [6629/6845 (97%)]\tLoss: 0.112466\n",
            "Train Epoch: 14 [6630/6845 (97%)]\tLoss: 0.406709\n",
            "Train Epoch: 14 [6631/6845 (97%)]\tLoss: 0.147847\n",
            "Train Epoch: 14 [6632/6845 (97%)]\tLoss: 0.111502\n",
            "Train Epoch: 14 [6633/6845 (97%)]\tLoss: 0.331313\n",
            "Train Epoch: 14 [6634/6845 (97%)]\tLoss: 0.113600\n",
            "Train Epoch: 14 [6635/6845 (97%)]\tLoss: 0.751830\n",
            "Train Epoch: 14 [6636/6845 (97%)]\tLoss: 0.104398\n",
            "Train Epoch: 14 [6637/6845 (97%)]\tLoss: 0.166258\n",
            "Train Epoch: 14 [6638/6845 (97%)]\tLoss: 0.543858\n",
            "Train Epoch: 14 [6639/6845 (97%)]\tLoss: 0.080837\n",
            "Train Epoch: 14 [6640/6845 (97%)]\tLoss: 0.443233\n",
            "Train Epoch: 14 [6641/6845 (97%)]\tLoss: 0.432257\n",
            "Train Epoch: 14 [6642/6845 (97%)]\tLoss: 0.666803\n",
            "Train Epoch: 14 [6643/6845 (97%)]\tLoss: 0.676577\n",
            "Train Epoch: 14 [6644/6845 (97%)]\tLoss: 0.111602\n",
            "Train Epoch: 14 [6645/6845 (97%)]\tLoss: 0.161313\n",
            "Train Epoch: 14 [6646/6845 (97%)]\tLoss: 0.064680\n",
            "Train Epoch: 14 [6647/6845 (97%)]\tLoss: 0.596571\n",
            "Train Epoch: 14 [6648/6845 (97%)]\tLoss: 0.113799\n",
            "Train Epoch: 14 [6649/6845 (97%)]\tLoss: 0.633703\n",
            "Train Epoch: 14 [6650/6845 (97%)]\tLoss: 0.151647\n",
            "Train Epoch: 14 [6651/6845 (97%)]\tLoss: 0.107861\n",
            "Train Epoch: 14 [6652/6845 (97%)]\tLoss: 0.085110\n",
            "Train Epoch: 14 [6653/6845 (97%)]\tLoss: 0.113797\n",
            "Train Epoch: 14 [6654/6845 (97%)]\tLoss: 0.407293\n",
            "Train Epoch: 14 [6655/6845 (97%)]\tLoss: 0.107324\n",
            "Train Epoch: 14 [6656/6845 (97%)]\tLoss: 0.117734\n",
            "Train Epoch: 14 [6657/6845 (97%)]\tLoss: 0.343533\n",
            "Train Epoch: 14 [6658/6845 (97%)]\tLoss: 0.064771\n",
            "Train Epoch: 14 [6659/6845 (97%)]\tLoss: 0.581839\n",
            "Train Epoch: 14 [6660/6845 (97%)]\tLoss: 0.066489\n",
            "Train Epoch: 14 [6661/6845 (97%)]\tLoss: 0.248404\n",
            "Train Epoch: 14 [6662/6845 (97%)]\tLoss: 0.080924\n",
            "Train Epoch: 14 [6663/6845 (97%)]\tLoss: 0.258644\n",
            "Train Epoch: 14 [6664/6845 (97%)]\tLoss: 0.322572\n",
            "Train Epoch: 14 [6665/6845 (97%)]\tLoss: 0.624489\n",
            "Train Epoch: 14 [6666/6845 (97%)]\tLoss: 0.097906\n",
            "Train Epoch: 14 [6667/6845 (97%)]\tLoss: 0.068533\n",
            "Train Epoch: 14 [6668/6845 (97%)]\tLoss: 0.075975\n",
            "Train Epoch: 14 [6669/6845 (97%)]\tLoss: 0.097158\n",
            "Train Epoch: 14 [6670/6845 (97%)]\tLoss: 0.121319\n",
            "Train Epoch: 14 [6671/6845 (97%)]\tLoss: 0.096164\n",
            "Train Epoch: 14 [6672/6845 (97%)]\tLoss: 0.273964\n",
            "Train Epoch: 14 [6673/6845 (97%)]\tLoss: 0.449209\n",
            "Train Epoch: 14 [6674/6845 (98%)]\tLoss: 0.187684\n",
            "Train Epoch: 14 [6675/6845 (98%)]\tLoss: 0.119228\n",
            "Train Epoch: 14 [6676/6845 (98%)]\tLoss: 0.215080\n",
            "Train Epoch: 14 [6677/6845 (98%)]\tLoss: 0.085814\n",
            "Train Epoch: 14 [6678/6845 (98%)]\tLoss: 0.158293\n",
            "Train Epoch: 14 [6679/6845 (98%)]\tLoss: 0.220437\n",
            "Train Epoch: 14 [6680/6845 (98%)]\tLoss: 1.194837\n",
            "Train Epoch: 14 [6681/6845 (98%)]\tLoss: 0.128516\n",
            "Train Epoch: 14 [6682/6845 (98%)]\tLoss: 0.586720\n",
            "Train Epoch: 14 [6683/6845 (98%)]\tLoss: 0.072686\n",
            "Train Epoch: 14 [6684/6845 (98%)]\tLoss: 0.089169\n",
            "Train Epoch: 14 [6685/6845 (98%)]\tLoss: 0.088233\n",
            "Train Epoch: 14 [6686/6845 (98%)]\tLoss: 0.085970\n",
            "Train Epoch: 14 [6687/6845 (98%)]\tLoss: 0.202169\n",
            "Train Epoch: 14 [6688/6845 (98%)]\tLoss: 0.299413\n",
            "Train Epoch: 14 [6689/6845 (98%)]\tLoss: 0.151172\n",
            "Train Epoch: 14 [6690/6845 (98%)]\tLoss: 0.628447\n",
            "Train Epoch: 14 [6691/6845 (98%)]\tLoss: 0.070488\n",
            "Train Epoch: 14 [6692/6845 (98%)]\tLoss: 0.809743\n",
            "Train Epoch: 14 [6693/6845 (98%)]\tLoss: 0.265444\n",
            "Train Epoch: 14 [6694/6845 (98%)]\tLoss: 0.119064\n",
            "Train Epoch: 14 [6695/6845 (98%)]\tLoss: 0.100016\n",
            "Train Epoch: 14 [6696/6845 (98%)]\tLoss: 0.103673\n",
            "Train Epoch: 14 [6697/6845 (98%)]\tLoss: 0.098943\n",
            "Train Epoch: 14 [6698/6845 (98%)]\tLoss: 0.127706\n",
            "Train Epoch: 14 [6699/6845 (98%)]\tLoss: 0.226062\n",
            "Train Epoch: 14 [6700/6845 (98%)]\tLoss: 0.102861\n",
            "Train Epoch: 14 [6701/6845 (98%)]\tLoss: 0.167387\n",
            "Train Epoch: 14 [6702/6845 (98%)]\tLoss: 0.068756\n",
            "Train Epoch: 14 [6703/6845 (98%)]\tLoss: 0.117291\n",
            "Train Epoch: 14 [6704/6845 (98%)]\tLoss: 0.170752\n",
            "Train Epoch: 14 [6705/6845 (98%)]\tLoss: 0.269185\n",
            "Train Epoch: 14 [6706/6845 (98%)]\tLoss: 0.072925\n",
            "Train Epoch: 14 [6707/6845 (98%)]\tLoss: 0.685431\n",
            "Train Epoch: 14 [6708/6845 (98%)]\tLoss: 0.509287\n",
            "Train Epoch: 14 [6709/6845 (98%)]\tLoss: 0.651549\n",
            "Train Epoch: 14 [6710/6845 (98%)]\tLoss: 0.099928\n",
            "Train Epoch: 14 [6711/6845 (98%)]\tLoss: 0.608885\n",
            "Train Epoch: 14 [6712/6845 (98%)]\tLoss: 0.092523\n",
            "Train Epoch: 14 [6713/6845 (98%)]\tLoss: 0.454726\n",
            "Train Epoch: 14 [6714/6845 (98%)]\tLoss: 0.108412\n",
            "Train Epoch: 14 [6715/6845 (98%)]\tLoss: 0.130087\n",
            "Train Epoch: 14 [6716/6845 (98%)]\tLoss: 0.200826\n",
            "Train Epoch: 14 [6717/6845 (98%)]\tLoss: 0.072102\n",
            "Train Epoch: 14 [6718/6845 (98%)]\tLoss: 0.167516\n",
            "Train Epoch: 14 [6719/6845 (98%)]\tLoss: 0.874063\n",
            "Train Epoch: 14 [6720/6845 (98%)]\tLoss: 0.100410\n",
            "Train Epoch: 14 [6721/6845 (98%)]\tLoss: 0.093743\n",
            "Train Epoch: 14 [6722/6845 (98%)]\tLoss: 0.783857\n",
            "Train Epoch: 14 [6723/6845 (98%)]\tLoss: 0.080787\n",
            "Train Epoch: 14 [6724/6845 (98%)]\tLoss: 0.857408\n",
            "Train Epoch: 14 [6725/6845 (98%)]\tLoss: 0.061003\n",
            "Train Epoch: 14 [6726/6845 (98%)]\tLoss: 0.207968\n",
            "Train Epoch: 14 [6727/6845 (98%)]\tLoss: 0.428079\n",
            "Train Epoch: 14 [6728/6845 (98%)]\tLoss: 0.157042\n",
            "Train Epoch: 14 [6729/6845 (98%)]\tLoss: 0.094131\n",
            "Train Epoch: 14 [6730/6845 (98%)]\tLoss: 0.661809\n",
            "Train Epoch: 14 [6731/6845 (98%)]\tLoss: 0.247138\n",
            "Train Epoch: 14 [6732/6845 (98%)]\tLoss: 0.267954\n",
            "Train Epoch: 14 [6733/6845 (98%)]\tLoss: 0.052799\n",
            "Train Epoch: 14 [6734/6845 (98%)]\tLoss: 0.159186\n",
            "Train Epoch: 14 [6735/6845 (98%)]\tLoss: 0.118989\n",
            "Train Epoch: 14 [6736/6845 (98%)]\tLoss: 0.177364\n",
            "Train Epoch: 14 [6737/6845 (98%)]\tLoss: 0.107547\n",
            "Train Epoch: 14 [6738/6845 (98%)]\tLoss: 0.143201\n",
            "Train Epoch: 14 [6739/6845 (98%)]\tLoss: 0.124109\n",
            "Train Epoch: 14 [6740/6845 (98%)]\tLoss: 0.096751\n",
            "Train Epoch: 14 [6741/6845 (98%)]\tLoss: 0.913932\n",
            "Train Epoch: 14 [6742/6845 (98%)]\tLoss: 0.101687\n",
            "Train Epoch: 14 [6743/6845 (99%)]\tLoss: 0.131055\n",
            "Train Epoch: 14 [6744/6845 (99%)]\tLoss: 0.200068\n",
            "Train Epoch: 14 [6745/6845 (99%)]\tLoss: 0.079295\n",
            "Train Epoch: 14 [6746/6845 (99%)]\tLoss: 0.129701\n",
            "Train Epoch: 14 [6747/6845 (99%)]\tLoss: 0.091450\n",
            "Train Epoch: 14 [6748/6845 (99%)]\tLoss: 0.064135\n",
            "Train Epoch: 14 [6749/6845 (99%)]\tLoss: 0.096294\n",
            "Train Epoch: 14 [6750/6845 (99%)]\tLoss: 0.062539\n",
            "Train Epoch: 14 [6751/6845 (99%)]\tLoss: 0.061582\n",
            "Train Epoch: 14 [6752/6845 (99%)]\tLoss: 0.090556\n",
            "Train Epoch: 14 [6753/6845 (99%)]\tLoss: 0.772002\n",
            "Train Epoch: 14 [6754/6845 (99%)]\tLoss: 0.768439\n",
            "Train Epoch: 14 [6755/6845 (99%)]\tLoss: 0.162918\n",
            "Train Epoch: 14 [6756/6845 (99%)]\tLoss: 0.138862\n",
            "Train Epoch: 14 [6757/6845 (99%)]\tLoss: 0.202317\n",
            "Train Epoch: 14 [6758/6845 (99%)]\tLoss: 0.683724\n",
            "Train Epoch: 14 [6759/6845 (99%)]\tLoss: 0.100709\n",
            "Train Epoch: 14 [6760/6845 (99%)]\tLoss: 0.358987\n",
            "Train Epoch: 14 [6761/6845 (99%)]\tLoss: 0.106253\n",
            "Train Epoch: 14 [6762/6845 (99%)]\tLoss: 0.434975\n",
            "Train Epoch: 14 [6763/6845 (99%)]\tLoss: 0.071459\n",
            "Train Epoch: 14 [6764/6845 (99%)]\tLoss: 0.327720\n",
            "Train Epoch: 14 [6765/6845 (99%)]\tLoss: 0.071220\n",
            "Train Epoch: 14 [6766/6845 (99%)]\tLoss: 0.087486\n",
            "Train Epoch: 14 [6767/6845 (99%)]\tLoss: 1.333215\n",
            "Train Epoch: 14 [6768/6845 (99%)]\tLoss: 0.129386\n",
            "Train Epoch: 14 [6769/6845 (99%)]\tLoss: 0.069191\n",
            "Train Epoch: 14 [6770/6845 (99%)]\tLoss: 0.208894\n",
            "Train Epoch: 14 [6771/6845 (99%)]\tLoss: 1.140946\n",
            "Train Epoch: 14 [6772/6845 (99%)]\tLoss: 0.073906\n",
            "Train Epoch: 14 [6773/6845 (99%)]\tLoss: 0.415405\n",
            "Train Epoch: 14 [6774/6845 (99%)]\tLoss: 0.090115\n",
            "Train Epoch: 14 [6775/6845 (99%)]\tLoss: 0.071471\n",
            "Train Epoch: 14 [6776/6845 (99%)]\tLoss: 0.136830\n",
            "Train Epoch: 14 [6777/6845 (99%)]\tLoss: 0.486831\n",
            "Train Epoch: 14 [6778/6845 (99%)]\tLoss: 0.095126\n",
            "Train Epoch: 14 [6779/6845 (99%)]\tLoss: 0.699359\n",
            "Train Epoch: 14 [6780/6845 (99%)]\tLoss: 0.096411\n",
            "Train Epoch: 14 [6781/6845 (99%)]\tLoss: 0.907495\n",
            "Train Epoch: 14 [6782/6845 (99%)]\tLoss: 0.173467\n",
            "Train Epoch: 14 [6783/6845 (99%)]\tLoss: 0.475640\n",
            "Train Epoch: 14 [6784/6845 (99%)]\tLoss: 0.149191\n",
            "Train Epoch: 14 [6785/6845 (99%)]\tLoss: 0.219435\n",
            "Train Epoch: 14 [6786/6845 (99%)]\tLoss: 0.210672\n",
            "Train Epoch: 14 [6787/6845 (99%)]\tLoss: 0.488734\n",
            "Train Epoch: 14 [6788/6845 (99%)]\tLoss: 0.107155\n",
            "Train Epoch: 14 [6789/6845 (99%)]\tLoss: 0.111939\n",
            "Train Epoch: 14 [6790/6845 (99%)]\tLoss: 0.090204\n",
            "Train Epoch: 14 [6791/6845 (99%)]\tLoss: 0.357784\n",
            "Train Epoch: 14 [6792/6845 (99%)]\tLoss: 0.100364\n",
            "Train Epoch: 14 [6793/6845 (99%)]\tLoss: 0.140532\n",
            "Train Epoch: 14 [6794/6845 (99%)]\tLoss: 0.107282\n",
            "Train Epoch: 14 [6795/6845 (99%)]\tLoss: 0.134999\n",
            "Train Epoch: 14 [6796/6845 (99%)]\tLoss: 0.074732\n",
            "Train Epoch: 14 [6797/6845 (99%)]\tLoss: 0.270621\n",
            "Train Epoch: 14 [6798/6845 (99%)]\tLoss: 0.547367\n",
            "Train Epoch: 14 [6799/6845 (99%)]\tLoss: 0.572356\n",
            "Train Epoch: 14 [6800/6845 (99%)]\tLoss: 0.158228\n",
            "Train Epoch: 14 [6801/6845 (99%)]\tLoss: 0.091978\n",
            "Train Epoch: 14 [6802/6845 (99%)]\tLoss: 0.184594\n",
            "Train Epoch: 14 [6803/6845 (99%)]\tLoss: 0.367783\n",
            "Train Epoch: 14 [6804/6845 (99%)]\tLoss: 0.107995\n",
            "Train Epoch: 14 [6805/6845 (99%)]\tLoss: 0.112668\n",
            "Train Epoch: 14 [6806/6845 (99%)]\tLoss: 0.183281\n",
            "Train Epoch: 14 [6807/6845 (99%)]\tLoss: 0.707698\n",
            "Train Epoch: 14 [6808/6845 (99%)]\tLoss: 0.105841\n",
            "Train Epoch: 14 [6809/6845 (99%)]\tLoss: 0.116893\n",
            "Train Epoch: 14 [6810/6845 (99%)]\tLoss: 0.220376\n",
            "Train Epoch: 14 [6811/6845 (100%)]\tLoss: 0.752553\n",
            "Train Epoch: 14 [6812/6845 (100%)]\tLoss: 0.075754\n",
            "Train Epoch: 14 [6813/6845 (100%)]\tLoss: 0.090068\n",
            "Train Epoch: 14 [6814/6845 (100%)]\tLoss: 0.176394\n",
            "Train Epoch: 14 [6815/6845 (100%)]\tLoss: 0.071699\n",
            "Train Epoch: 14 [6816/6845 (100%)]\tLoss: 0.084246\n",
            "Train Epoch: 14 [6817/6845 (100%)]\tLoss: 0.199473\n",
            "Train Epoch: 14 [6818/6845 (100%)]\tLoss: 0.183862\n",
            "Train Epoch: 14 [6819/6845 (100%)]\tLoss: 0.138134\n",
            "Train Epoch: 14 [6820/6845 (100%)]\tLoss: 0.072615\n",
            "Train Epoch: 14 [6821/6845 (100%)]\tLoss: 0.420945\n",
            "Train Epoch: 14 [6822/6845 (100%)]\tLoss: 0.112092\n",
            "Train Epoch: 14 [6823/6845 (100%)]\tLoss: 0.085645\n",
            "Train Epoch: 14 [6824/6845 (100%)]\tLoss: 0.071824\n",
            "Train Epoch: 14 [6825/6845 (100%)]\tLoss: 0.083345\n",
            "Train Epoch: 14 [6826/6845 (100%)]\tLoss: 0.077991\n",
            "Train Epoch: 14 [6827/6845 (100%)]\tLoss: 0.118522\n",
            "Train Epoch: 14 [6828/6845 (100%)]\tLoss: 0.115422\n",
            "Train Epoch: 14 [6829/6845 (100%)]\tLoss: 0.090989\n",
            "Train Epoch: 14 [6830/6845 (100%)]\tLoss: 0.090689\n",
            "Train Epoch: 14 [6831/6845 (100%)]\tLoss: 1.259058\n",
            "Train Epoch: 14 [6832/6845 (100%)]\tLoss: 0.346619\n",
            "Train Epoch: 14 [6833/6845 (100%)]\tLoss: 0.083178\n",
            "Train Epoch: 14 [6834/6845 (100%)]\tLoss: 0.131415\n",
            "Train Epoch: 14 [6835/6845 (100%)]\tLoss: 0.695886\n",
            "Train Epoch: 14 [6836/6845 (100%)]\tLoss: 0.067252\n",
            "Train Epoch: 14 [6837/6845 (100%)]\tLoss: 0.513726\n",
            "Train Epoch: 14 [6838/6845 (100%)]\tLoss: 0.076474\n",
            "Train Epoch: 14 [6839/6845 (100%)]\tLoss: 0.069515\n",
            "Train Epoch: 14 [6840/6845 (100%)]\tLoss: 0.114531\n",
            "Train Epoch: 14 [6841/6845 (100%)]\tLoss: 0.083559\n",
            "Train Epoch: 14 [6842/6845 (100%)]\tLoss: 0.150367\n",
            "Train Epoch: 14 [6843/6845 (100%)]\tLoss: 0.147445\n",
            "Train Epoch: 14 [6844/6845 (100%)]\tLoss: 0.394928\n",
            "Epoch\n",
            "train/train_loss: 0.3949283957481384\n",
            "\n",
            "Train Loss: 0.395, Valid Loss: 0.298282, Accuracy: 0.36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.033 MB of 135.323 MB uploaded\\r'), FloatProgress(value=0.007636620110979857, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8c7cf1c30384b299a1a13ea52fa541e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>▁▃▂▂▁▄▁▂▁▁█▆▄▂▂▁▄▅▁▂▂▁▂▄▁▂▁▃▄▁▅▁▁▁▁▂▃▁▁▁</td></tr><tr><td>validation/accuracy</td><td>▂▂▄▇▅▆▅▄▇▇▁▂▅█▄</td></tr><tr><td>validation/loss</td><td>▂█▃▁▃▄▃▃▂▃▅▆▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train/loss</td><td>0.39493</td></tr><tr><td>validation/accuracy</td><td>0.35558</td></tr><tr><td>validation/loss</td><td>0.29828</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">copper-pyramid-30</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/3t02llmn' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/3t02llmn</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240830_092307-3t02llmn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "freeze_module = model.encoder_2d\n",
        "train_bestModel(model,train_dataloader,val_loader,freeze_module,epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyTDr47v2h2G"
      },
      "source": [
        "## Run test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I do the inference on the test data"
      ],
      "metadata": {
        "id": "ner6F0AgfQ22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 20 epochs model"
      ],
      "metadata": {
        "id": "06CZtKdaMG4X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "TOFQow1d2l3G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "8a067118887741b2b54840d19bf3c963",
            "267461683428407599555e4f27299fbe",
            "671295525e184bd1b021e3d790003112",
            "4b4483cb0f6747fd8c55f63562cbe8ce",
            "b309707382eb464ba41505eeda65e6f3",
            "2eba66f458234b71ac8cfb21df99587d",
            "9820c9da36024cc09e16c35705f424d0",
            "b5b2bfa2d3974b9caff995f7cbdf4dce"
          ]
        },
        "outputId": "93c08b3f-dfba-4184-95e7-ece0416ad7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md-cecca\u001b[0m (\u001b[33mcecca\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240830_112841-781o56q1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/781o56q1' target=\"_blank\">rare-plasma-31</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/781o56q1' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/781o56q1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a067118887741b2b54840d19bf3c963"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>validation/accuracy</td><td>▁</td></tr><tr><td>validation/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>validation/accuracy</td><td>0.43942</td></tr><tr><td>validation/loss</td><td>0.25578</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rare-plasma-31</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/781o56q1' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/781o56q1</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240830_112841-781o56q1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "test_loss, accuracy,predicted_list=test(model, test_loader, loss_funct, batch_idx=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "6GRqSSNJ2nhR"
      },
      "outputs": [],
      "source": [
        "y_test=test_loader.dataset.labels.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dZfUbytg2qbB"
      },
      "outputs": [],
      "source": [
        "predicted_list=[i.cpu().item() for i in predicted_list]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I evalute the best model on test data, by computing some metrics:\n",
        "\n",
        "- **Accuracy:** The ratio of correctly predicted instances to the total instances.\n",
        "\n",
        "- **Precision:** The ratio of correctly predicted positive observations to the total predicted positives.\n",
        "\n",
        "- **Recall:** The ratio of correctly predicted positive observations to all observations in the actual class.\n",
        "\n",
        "- **F1 Score:** The weighted average of Precision and Recall."
      ],
      "metadata": {
        "id": "4g05of5TfY2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "xTmNom2-2smE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "91f72b77-08e6-4eff-cb62-73fb20ec59ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy micro: 0.4394167923579688\n",
            "precision micro: 0.4394167923579688\n",
            "recall micro: 0.4394167923579688\n",
            "f1 micro: 0.4394167923579688\n",
            "\n",
            "\n",
            "accuracy macro: 0.4394167923579688\n",
            "precision macro: 0.07300637789373948\n",
            "recall macro: 0.08657609980920339\n",
            "f1 macro: 0.06737756145261167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGwCAYAAADFZj2cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+TklEQVR4nO3deVxU1f/H8dcMyCKyCAoIAuIGirgvoeaSppmZpmkambuVWC5lyjf3VFLLXHIvd82s1MzKJc0tTRHFzF3TxAVQEAZQFpn5/eGPyUkER2aYYebz/D7u49Hce+a+zxz5Dodzzr1XodFoNAghhBBCFEBp6goIIYQQwvxJh0EIIYQQhZIOgxBCCCEKJR0GIYQQQhRKOgxCCCGEKJR0GIQQQghRKOkwCCGEEKJQtqaugLGp1Wpu3LiBs7MzCoXC1NURQgihJ41GQ1paGj4+PiiVxvk7NzMzk+zsbIOcy87ODgcHB4Ocy5xYfIfhxo0b+Pn5mboaQgghiiguLo6KFSsa/LyZmZk4OnvA/bsGOZ+3tzeXL1+2uE6DxXcYnJ2dAbh4OQ5nFxcT10YIYUiZ2bkmyXWwszFJrrVKU6moGuin/T43tOzsbLh/F/uafcDGrmgny80m/vRKsrOzpcNQ0uRNQzi7uOAiHQYhLIqddBisitGnlW0dUBSxw6BRWO7SQIvvMAghhBBPRAEUtVNiwUvlpMMghBBCACiUD7ainsNCWe4nE0IIIYTByAiDEEIIAQ+mI4o8JWG5cxLSYRBCCCFApiQKYbmfTAghhBAGIyMMQgghBMiURCFkhKEASzfspfbL4/FuNpy2fWcSc+qKRWd/9d1+mvWahn+rD/Bv9QHt+n/Kzt9PGT03j7W1t2QbP/vmrRQiJq2iZodIAlt/QOvenxB75mq+ZT+c8Q0Vmg1jyTd7DF6PPJbe3uaYrR/lv9MST7tZ8K9Vy/1kRbRxRwxjZ29i9MAO7Fk9mlrVfOn27nxuJadZbLaPpxsThnbmt1UfsnvlKJ5tWJ3wD5Zw5tJNo+aCdba3ZBs3O0V1l5ffnkMpWxvWfvY2e9dGMmFoF9ycSz9S9ue9Jzh26h+8y7kaLP+/LL29zTFbGFaJ6DDMnz+fSpUq4eDgQJMmTThy5IjRMxes282bXZoS/nIYwZUrMCuyJ6Ud7Fiz5ZDFZndoEUq7ZiFU8fekaoAX44a8jFNpe47+ddmouWCd7S3Zxs2ev/ZXfDzdmP1ROPVqBuDv40GrJsFUqlhOp9zNWymM/fx75k/oja2t8e7gaOntbY7ZesubkijqZqHMvsPwzTffMHLkSCZMmMCxY8eoU6cO7du3JzEx0WiZ2Tn3iT0bR6vGQdp9SqWSlo2DiD5p3F+epsx+WG6umu93HOXuvWwahQYaNcta21uyjZu9/cBf1An2Y9DY5dTq+BHP953Bmi0Hdcqo1WrenbyGd15/jqDKFQyW/V/W0N7mlv1UijodYYirLMyY2X+yWbNmMWjQIPr160fNmjVZtGgRpUuXZtmyZUbLTEpJJzdXTXl33QedlHd3ITFJZbRcU2cDnLp4nYotRuLVbDgjo75h9cxBBBvxixSst70l27jZV28ksWrz7wRWLMfXn7/Dm680Z9znG9nw878jlF+s2YWNjZKB3VsaLDc/1tDe5pYtDM+sr5LIzs4mJiaGyMhI7T6lUknbtm05dCj/4aysrCyysrK0r1Uq+aHUR7UAL/atjUSVfo8fdh1nyMTVbF08zOidBiEMTa3WUCfYj/+93QmA0OoVOff3TVZt/p0eLzbmxNk4vvx2LzuWjTL+Q41EySBXSRTIrEcYbt++TW5uLl5eXjr7vby8iI+Pz/c9UVFRuLq6ajc/Pz+9cz3cymBjo3xkUc6tZBWeHsZ94qUpswHsStlS2a88dWv4M2FoZ2pV82XR+j1GzbTW9pZs42Z7erhQvZK3zr5qlby4nnAHgMMnLnH7TjoNu02kYosRVGwxgmvxyUz6YjONuk0yWD3AOtrb3LKfikxJFMjiPllkZCSpqanaLS4uTu9z2JWypW6wH3ujz2n3qdVq9kWfN/p8vimz86PWaMjOvm/UDGttb8k2bnbj2oFcvKq71unS1UQqepcF4NUXGrF71Yf8umKUdvMu58qQ15/j61lvG6weYB3tbW7ZT0UWPRbIrKckypUrh42NDQkJCTr7ExIS8Pb2zvc99vb22NvbFzl7yOvPMWTSaurV8Kd+SCUWfv0bGfeyCO/0TJHPba7Zk774gbZNQ/DzLkva3Uy+23aUAzEX+H7eEKPmgnW2t2QbN3vwa63o9NZs5qzcwctt6nH89D+s2XKImR++BoC7qxPurk4677G1taG8uwtVA7zyO2WRWHp7m2O2MCyz7jDY2dnRoEEDdu3aRZcuXYAHvdNdu3YxdOhQo2Z3bdeA2ynpTFv8E4lJaYRW9+W7uRHFMoxmquzbd9J5Z+IqEm6rcCnjQEhVX76fN4TWTWoYNRess70l27jZdWsEsCxqANMWbeXzFdvxq+DB5GGv0K19Q4Nl6MPS29scs/Umz5IokEKj0WhMXYmCfPPNN/Tp04fFixfTuHFjZs+ezYYNGzh79uwjaxvyo1KpcHV1JSEpFRcXM/wBFUI8tczsXJPkOtgZ734N4lEqlQovD1dSU43zPZ73e8K+aSQKW4cinUtzP5Osg1FGq6spmfUIA8Brr73GrVu3GD9+PPHx8dStW5dt27Y9UWdBCCGEEIZh9h0GgKFDhxp9CkIIIYSVUyoebEU9h4UqER0GIYQQwuhkDUOBLPeTCSGEEMJgZIRBCCGEALnTYyGkwyCEEEKATEkUwnI/mRBCCCEMRkYYhBBCCJApiULICIMQQggBJnn41L59++jUqRM+Pj4oFAo2b9782LJvv/02CoWC2bNn6+xPTk4mPDwcFxcX3NzcGDBgAOnp6Tpl/vzzT5599lkcHBzw8/NjxowZetUTpMMghBBCPGCCh09lZGRQp04d5s+fX2C5TZs28ccff+Dj4/PIsfDwcE6dOsXOnTvZunUr+/btY/DgwdrjKpWKdu3aERAQQExMDDNnzmTixIksWbJEr7rKlIQQouSy3NFfYSU6dOhAhw4dCixz/fp13n33XbZv307Hjh11jp05c4Zt27YRHR1Nw4YPnpMyb948XnzxRT799FN8fHxYu3Yt2dnZLFu2DDs7O0JCQoiNjWXWrFk6HYvCyAiDEEIIAQadklCpVDpbVlbWU1VJrVbTu3dvRo0aRUhIyCPHDx06hJubm7azANC2bVuUSiWHDx/WlmnRogV2dnbaMu3bt+fcuXPcuXPniesiHQYhhBACDDol4efnh6urq3aLiop6qipNnz4dW1tb3nvvvXyPx8fH4+npqbPP1tYWd3d34uPjtWX++/ylvNd5ZZ6ETEkIIYQQBhYXF6fztEp7e3u9zxETE8OcOXM4duwYCjO4+kJGGIQQQggADDEd8eDXqouLi872NB2G/fv3k5iYiL+/P7a2ttja2vLPP//w/vvvU6lSJQC8vb1JTEzUed/9+/dJTk7G29tbWyYhIUGnTN7rvDJP2DpCCCGEMMVVEgXp3bs3f/75J7GxsdrNx8eHUaNGsX37dgDCwsJISUkhJiZG+77du3ejVqtp0qSJtsy+ffvIycnRltm5cydBQUGULVv2iesjUxJCCCGEiaSnp3Px4kXt68uXLxMbG4u7uzv+/v54eHjolC9VqhTe3t4EBQUBUKNGDV544QUGDRrEokWLyMnJYejQofTs2VN7Cebrr7/OpEmTGDBgAKNHj+avv/5izpw5fP7553rVVToMQgghBPz/CEFRnyWh3wjD0aNHad26tfb1yJEjAejTpw8rVqx4onOsXbuWoUOH0qZNG5RKJd26dWPu3Lna466uruzYsYOIiAgaNGhAuXLlGD9+vF6XVIJ0GIQQQogHTPDwqVatWqHRaJ64/JUrVx7Z5+7uzrp16wp8X+3atdm/f79edfsvWcMghBBCiELJCEMBlm7Yy7w1u0hMUlGrmi/TR3WnQUgli83+ZMlPTF/6i86+agFeHPlunFFz81hbe0u2cbM//fIXPlu2TWdfFX9PDqz/CICuEfM4dPyizvHeXZoy48PXDFaH/7Lk9jbXbL3Iw6cKJCMMj7FxRwxjZ29i9MAO7Fk9mlrVfOn27nxuJadZdHZw5Qqc/WWadvvlyxFGzwTrbW/JNm52UKA3J378WLv9sGiYzvHwl8N0jo+L6GzQ/IdZQ3ubW7beTPDwqZLE7D+ZPk/yMqQF63bzZpemhL8cRnDlCsyK7ElpBzvWbDlk0dm2Nkq8yrloNw+3MkbPBOttb8k2bratrQ2eHi7a7b8/z44OdjrHnZ0cDJr/MGtob3PL1puZXVZpbsy+w/CkT/IypOyc+8SejaNV4yDtPqVSScvGQUSfvGyx2QB/x92iRof/UbfzBAaNXUFcfLLRM621vSXb+Nl/x92i7svjaPLqZIZMXMW1//w8b9xxlJod/ker8CimLvyRu5nZBs3PYy3tbU7ZwvDMfg3DkzzJ62FZWVk6D/lQqVR6ZyalpJObq6a8u7PO/vLuLly4kvCYdxmGKbMbhFRi/oQ3qBrgRcLtVKYv/YUXB33OwfUfGfUvL2ttb8k2bna9kADmjH2dKv6eJNxWMWvZNrq8M5c9a8ZQxsmBV55vQEXvsniXd+X0xRtMXbCFS1cTWRY1wGB1yGMN7W1u2U/FBFdJlCRm32HQV1RUFJMmTTJ1NUqk55v9+yS0WtV8aVirEqGdxrP512P07tzUhDUTQn9twmpq/7tmVV/qhwTQqOsktuw+zuudwujd5d+f6RpVfPDycKH7e/O5cu02lSqWM0WVhanJoscCWVxXKDIyktTUVO0WFxen9zk83MpgY6N8ZFHOrWQVnh4uj3mXYZgy+79cnUtT1d+Tv+NuGTXHWttbsos329W5NJX9ynP52u18j9cPCQDg8jXD/7xbY3ubOlsYnsV1GOzt7R956Ie+7ErZUjfYj73R57T71Go1+6LP0yg00JDVNavs/0q/m8Xl67fxLudq1BxrbW/JLt7sjLtZ/HM9Ca/H/KL668J1ALzKGf4XmTW2t6mzn4ZCoTDIZqksbkrCUIa8/hxDJq2mXg1/6odUYuHXv5FxL4vwTs9YbPa42Rt54dlQ/Cq4c/NWKp8s+QkbpZJu7RsYNRess70l27jZk+Zt5vnmtfDzLkv8bRWffvkzShsFXZ5vwJVrt9m4M4Y2YTVxdy3N6Ys3mDBnE8/UrULNqr4Gq8PDLL29zTFbXwb5hS8dBuvTtV0DbqekM23xTyQmpRFa3Zfv5kYUyzCaqbKvJ6YwcOxyklPvUq5sGZrUqczO5e9Trqxz4W8uImtsb8k2bvbNxBSGTFjJndQMPNzK0Lh2ZX5aMpJyZcuQlZ3D/uhzfPnNHu5mZuPj6UbH1nUY3re9wfL/y9Lb2xyzhWEpNPrcxNoEHn6SV7169Zg1axatW7fWPsmrMCqVCldXVxKSUp9qekIIYb4yc3JNkutQysYkudZKpVLh5eFKaqpxvsfzfk84dp6PopRjkc6lybnHvR8ijFZXUzL7EQZDPMlLCCGEKIxMSRTM7DsM+j7JSwghhBCGZ/YdBiGEEKI4yAhDwaTDIIQQQiAdhsJIh0EIIYRAOgyFsbgbNwkhhBDC8GSEQQghhABQ/P9W1HNYKOkwCCGEEMiURGFkSkIIIYQQhZIRBiGEEIK8p1sXdYTBMHUxR9JhsGDXku+ZJLeie9FurSrEk6o+9HuT5F5d3MMkucK4FBjiaZOW22OQKQkhhBBCFEpGGIQQQghk0WNhpMMghBBCgFxWWQiZkhBCCCFEoWSEQQghhAAwwJSERqYkhBBCCMtmiDUMRb/KwnxJh0EIIYRAOgyFkTUMQgghhCiUjDAIIYQQIFdJFEI6DAVYumEv89bsIjFJRa1qvkwf1Z0GIZVKZPaX63fz6+8nuRx3Cwc7W+rUrMSIAS8S6OepLfPtz3/w82/HOXPxOhl3s/j9+8m4lPn3ro3X45NZvO5XjsRe5PadNMp7uPDSc/UZ3KsNpUoV/UfJktpbsosne1lEc0L9y+Ll5sjABQfYceIGALZKBaO6hNK6ljf+5cqQdi+HA2cS+GTTnySkZmrf/9WQZtT0c8PD2QHV3WwOnEkgaqNuGYDBzwfx+rOV8XUvzZ30LJN+Zsk2HpmSKJhMSTzGxh0xjJ29idEDO7Bn9WhqVfOl27vzuZWcViKzj/55iZ6dmrJ29lCWRA3mfm4ub/1vKXczs7VlMjNzaNYwiIE9n8v3HJfjElGrNYwf1o1NSz7gw7deZsNPfzBn+S9PXa88ltbekl082aevpTD262OP7He0s6WWnxtzfzrNi1N3MnjR71T2duariOY65Q6eu8WQJYdoPf4X3lp0EP/yZVj4VlOdMpNeq0fP5oFM/e4Ez03YxoAFv+v/gbGM9i5p2cKwzL7DEBUVRaNGjXB2dsbT05MuXbpw7tw5o+cuWLebN7s0JfzlMIIrV2BWZE9KO9ixZsuhEpm9aNogurRrRNVK3gRV8WHK+69xMzGF0xeuacv07vosA197jjrBAfmeo3mjYKZ88BpNGwThV8GD1mEh9H21Jb/+/tdT1yuPpbW3ZBdP9qc//MX22OuP7E/LzCF8zj62xlzj74Q0jl9OZtzXx6gd4I5P2dLacl/tOs/xy8lcT75LzN9JLNx2lvqBHtgqH/yVWNXbmTdaVmHggt/Z+ecN4pIyOHn1jkk/s2QbT94IQ1E3S2X2HYa9e/cSERHBH3/8wc6dO8nJyaFdu3ZkZGQYLTM75z6xZ+No1ThIu0+pVNKycRDRJy8bLbc4s9MzHgy5ujqXLqRkwdIyMot8Dmtob8k2fbaLYynUag2qe9n5HnctbUeXJv7E/H2b+2oNAG1r+3D1VjptQitwYOqL/D61I9N7N9Q72xrb29TZT0M6DAUz+zUM27Zt03m9YsUKPD09iYmJoUWLFo+Uz8rKIivr3zlGlUqld2ZSSjq5uWrKuzvr7C/v7sKFKwl6n8/cstVqNdMXbaFeSCWqVfJ+6vNcvX6br3/4nfcHvVSk+lh6e0u26bPtbZVEdq3ND9FXSc+8r3Mssmtt+rSqSml7W2L+vk2/Lw5oj/mXK4OvhxMdG/gxcvkRlEoF47vX1Tvf2trbHLKF4Zn9CMN/paamAuDu7p7v8aioKFxdXbWbn59fcVavRJj6xSYu/hPPjMjwpz5Hwu1U3v7oS9q1qM2rLzYxYO2EMCxbpYIFg8NAoeCjdTGPHF+0/SwdpuwgfPZe1GoNn/drrD2mVIJDKRtGLD/MkYu3+eP8LT5cFV2c1RfFyBQjDPv27aNTp074+PigUCjYvHmz9lhOTg6jR48mNDQUJycnfHx8ePPNN7lx44bOOZKTkwkPD8fFxQU3NzcGDBhAenq6Tpk///yTZ599FgcHB/z8/JgxY4be7VOiOgxqtZrhw4fTrFkzatWqlW+ZyMhIUlNTtVtcXJzeOR5uZbCxUT6yKOdWsgpPD5enqru5ZE/9YhN7D5/hqxlv413e7anOkZiUyoAPF1G3ZgAThnUrcp0sub0l27TZeZ0FX3cnwmfvfWR0AeBORjaXE9PZfyaBiKV/0CbUh/qVPQBITM0kJ1fN5cR/v3wvxOu/WM9a2tucsp+KwkCbHjIyMqhTpw7z589/5Njdu3c5duwY48aN49ixY2zcuJFz587x8ssv65QLDw/n1KlT7Ny5k61bt7Jv3z4GDx6sPa5SqWjXrh0BAQHExMQwc+ZMJk6cyJIlS/Sqa4nqMERERPDXX3+xfv36x5axt7fHxcVFZ9OXXSlb6gb7sTf638WVarWafdHnaRQa+FR1N3W2RqNh6heb2H3wL76a8RYVvfMfoSlMwu1U+o9aRM1qFfn4/ddQKov+I2SJ7S3Zps/O6ywEejrz+uy9pGTkv3bhYcr//+vQzvbBz3X0xduUslESUM5JW6ayVxm962IN7W1u2SVFhw4dmDJlCq+88sojx1xdXdm5cyc9evQgKCiIZ555hi+++IKYmBiuXr0KwJkzZ9i2bRtffvklTZo0oXnz5sybN4/169drRyLWrl1LdnY2y5YtIyQkhJ49e/Lee+8xa9Ysvepq9msY8gwdOlTbc6pYsaLR84a8/hxDJq2mXg1/6odUYuHXv5FxL4vwTs+UyOypX2zi59+OM2diX5wc7bmd/GBtRxknRxzsSwFwO1nF7TtpXL1xG4ALl2/iVNqeCuXL4upSWttZqODpxvuDXuJO6r9/dZVzL9pfC5bW3pJdPNk1K7pp/9uvXBlqVnQjJSObxNR7LHqrKbX8y9Jv/n5slArKuzgAkJKRTU6umrqV3KlTyZ3oi7dJvZtNQPkyfPByLa4kpnHs7yQADpxN4OQ/yczs04hJG2JRKhR83Ku+ST+zZBuPIe/D8N/1c/b29tjb2xfp3PBgWl6hUODm5gbAoUOHcHNzo2HDfxfjtm3bFqVSyeHDh3nllVc4dOgQLVq0wM7OTlumffv2TJ8+nTt37lC2bNknyjb7DoNGo+Hdd99l06ZN7Nmzh8DA4umVdm3XgNsp6Uxb/BOJSWmEVvflu7kRxTKMZozsb7Y+uISp/6hFOvs/fr8HXdo1AmDDT3+wcM1O7bG+HyzUKXPo2Hmu3rjN1Ru3aRs+Rec8J7fPfOq6geW1t2QXT/a2ce20/z2hR10Avj14mc+3nqJdXV8Ato9rr/OeHp/9xh/nb3EvO5cX6vkyslMIjva2JKbeY++peOYuPUP2fTUAGg30n3+AST3r8+0HrbmbdZ89p+K1Uxam+MxPw1qz9WXIDsN/189NmDCBiRMnFuncmZmZjB49ml69emlHz+Pj4/H09NQpZ2tri7u7O/Hx8doy//3d6eXlpT32pB0GhUaj0RTpExjZkCFDWLduHT/88ANBQf9emuPq6oqjo2MB73xApVLh6upKQlLqU01PlGTXku+ZJLeie+H/LkIYgv9bG0ySe3VxD5PkWiuVSoWXhyupqcb5Hs/7PeEzcB1Ku6JdJq7OvsuNL18nLi5Op65PMsKgUCjYtGkTXbp0eeRYTk4O3bp149q1a+zZs0d77mnTprFy5cpH7k/k6enJpEmTeOedd2jXrh2BgYEsXrxYe/z06dOEhIRw+vRpatSo8USfzexHGBYufPBXbqtWrXT2L1++nL59+xZ/hYQQQohCPO0auvzk5OTQo0cP/vnnH3bv3q1zXm9vbxITE3XK379/n+TkZLy9vbVlEhJ0L2PNe51X5kmY/aJHjUaT7yadBSGEEAZlgqskCpPXWbhw4QK//vorHh6602FhYWGkpKQQE/PvJcO7d+9GrVbTpEkTbZl9+/aRk5OjLbNz506CgoKeeDoCSkCHQQghhCgOprgPQ3p6OrGxscTGxgJw+fJlYmNjuXr1Kjk5Obz66qscPXqUtWvXkpubS3x8PPHx8WRnP7jqp0aNGrzwwgsMGjSII0eO8PvvvzN06FB69uyJj48PAK+//jp2dnYMGDCAU6dO8c033zBnzhxGjhypV13NfkpCCCGEsFRHjx6ldevW2td5v8T79OnDxIkT2bJlCwB169bVed9vv/2mnapfu3YtQ4cOpU2bNiiVSrp168bcuXO1ZV1dXdmxYwcRERE0aNCAcuXKMX78eJ17NTwJ6TAIIYQQmObx1q1ataKgaw+e5LoEd3d31q1bV2CZ2rVrs3//fr3q9l/SYRBCCCEABQboMBh6EYMZkTUMQgghhCiUjDAIIYQQmGZKoiSRDoMQQggBhrks0nL7C9JhsGRyx0Vh6eSOi0IUH+kwCCGEEMiURGGkwyCEEEIgHYbCSIdBCCGEABSKB1tRz2Gp5LJKIYQQQhRKRhiEEEII8kYYijolYaDKmCHpMAghhBAABpiSsOTLKmVKQgghhBCFkhEGIYQQArlKojDSYRBCCCGQqyQKI1MSQgghhCiUjDAUYOmGvcxbs4vEJBW1qvkyfVR3GoRUkmwLy5Vs68ietXw7W387wYV/EnCwL0Xj2pWZOLQz1Sp5GS3zv6ypvc0lWx9KpQKlsmhDBJoivt+cmf0Iw8KFC6lduzYuLi64uLgQFhbGL7/8YvTcjTtiGDt7E6MHdmDP6tHUquZLt3fncys5TbItKFeyrSf74LGLDOzegh3LPmDjF0PJuZ9L13e/IONeltEyH2Zt7W0O2frKm5Io6mapzL7DULFiRT755BNiYmI4evQozz33HJ07d+bUqVNGzV2wbjdvdmlK+MthBFeuwKzInpR2sGPNlkNGzbXWbGv8zJJdvNnfzYvg9U7PUKNKBUKrV2TBhDe4Fn+H2DNxRst8mLW1tzlkC8My+w5Dp06dePHFF6lWrRrVq1dn6tSplClThj/++MNomdk594k9G0erxkHafUqlkpaNg4g+edloudaabY2fWbJNk/0wVXomAGVdShs9y1rb21z+rZ9U3lUSRd0sldl3GB6Wm5vL+vXrycjIICwsLN8yWVlZqFQqnU1fSSnp5OaqKe/urLO/vLsLiUn6n0+yzTNXsq0vO49arSZy1nc0qVOZmlV9jJ5nre1tDv/W+pApiYKViEWPJ0+eJCwsjMzMTMqUKcOmTZuoWbNmvmWjoqKYNGlSMddQCFGSfDBjA2cu3eSXpSNMXRVhRuQ+DAUrESMMQUFBxMbGcvjwYd555x369OnD6dOn8y0bGRlJamqqdouL039+0sOtDDY2ykcW5dxKVuHp4fJUn0GyzS9Xsq0vG2DUjA1s3/8XPy58D1+vskbPA+ttb1P/WwvDKhEdBjs7O6pWrUqDBg2IioqiTp06zJkzJ9+y9vb22isq8ja980rZUjfYj73R57T71Go1+6LP0yg08Kk/h2SbV65kW1e2RqNh1IwN/LTnBFsWvkeAbzmjZf2XNba3qbOfhqxhKFiJmJL4L7VaTVaWcS+FGvL6cwyZtJp6NfypH1KJhV//Rsa9LMI7PWPUXGvNtsbPLNnFm/3B9A18t/0o6z4dTJnSDiTcfjCH7lLGAUcHO6Pl5rG29jaHbH3JnR4LZvYdhsjISDp06IC/vz9paWmsW7eOPXv2sH37dqPmdm3XgNsp6Uxb/BOJSWmEVvflu7kRxTKMZo3Z1viZJbt4s5d9vx+Al97WHZ2cP/4NXi+GX17W1t7mkC0MS6HRaDSmrkRBBgwYwK5du7h58yaurq7Url2b0aNH8/zzzz/R+1UqFa6uriQkpT7V9IQQQgjTUqlUeHm4kppqnO/xvN8ToWO2YOPgVKRz5WZmcPKTl41WV1My+xGGr776ytRVEEIIYQVkSqJgJWLRoxBCCCFMy+xHGIQQQojiIPdhKJh0GIQQQghkSqIwMiUhhBBCiELJCIMQQgiBTEkURjoMQgghBDIlURjpMAghhBDICENhZA2DEEIIIQolIwxCCCEEgAGmJLDcAQbpMAghhBAgUxKFkSkJIYQQwkT27dtHp06d8PHxQaFQsHnzZp3jGo2G8ePHU6FCBRwdHWnbti0XLlzQKZOcnEx4eDguLi64ubkxYMAA0tPTdcr8+eefPPvsszg4OODn58eMGTP0rqt0GIQQQgj+vUqiqJs+MjIyqFOnDvPnz8/3+IwZM5g7dy6LFi3i8OHDODk50b59ezIzM7VlwsPDOXXqFDt37mTr1q3s27ePwYMHa4+rVCratWtHQEAAMTExzJw5k4kTJ7JkyRK96ipTEkIIIQSmmZLo0KEDHTp0yPeYRqNh9uzZjB07ls6dOwOwatUqvLy82Lx5Mz179uTMmTNs27aN6OhoGjZsCMC8efN48cUX+fTTT/Hx8WHt2rVkZ2ezbNky7OzsCAkJITY2llmzZul0LAojIwxCCCGEgalUKp0tKytL73NcvnyZ+Ph42rZtq93n6upKkyZNOHToEACHDh3Czc1N21kAaNu2LUqlksOHD2vLtGjRAjs7O22Z9u3bc+7cOe7cufPE9ZEOgxBCCIFhpyT8/PxwdXXVblFRUXrXJz4+HgAvLy+d/V5eXtpj8fHxeHp66hy3tbXF3d1dp0x+53g440nIlIQQQgiBYack4uLicHFx0e63t7cv0nnNgYwwCCGEEAbm4uKisz1Nh8Hb2xuAhIQEnf0JCQnaY97e3iQmJuocv3//PsnJyTpl8jvHwxlPQjoMQgghBP+OMBR1M5TAwEC8vb3ZtWuXdp9KpeLw4cOEhYUBEBYWRkpKCjExMdoyu3fvRq1W06RJE22Zffv2kZOToy2zc+dOgoKCKFu27BPXRzoMQgghBKa5rDI9PZ3Y2FhiY2OBBwsdY2NjuXr1KgqFguHDhzNlyhS2bNnCyZMnefPNN/Hx8aFLly4A1KhRgxdeeIFBgwZx5MgRfv/9d4YOHUrPnj3x8fEB4PXXX8fOzo4BAwZw6tQpvvnmG+bMmcPIkSP1qqusYSjA0g17mbdmF4lJKmpV82X6qO40CKkk2RaWK9nWk30jMYWJ837g10OnuJeZQ2DFcswf/wb1agYYNTePtbW3OWTrwxSXVR49epTWrVtrX+f9Eu/Tpw8rVqzgww8/JCMjg8GDB5OSkkLz5s3Ztm0bDg4O2vesXbuWoUOH0qZNG5RKJd26dWPu3Lna466uruzYsYOIiAgaNGhAuXLlGD9+vF6XVEIJG2H45JNPtD0uY9u4I4axszcxemAH9qweTa1qvnR7dz63ktMk24JyJdt6slNUd3lh4CxK2Sr5ds4Q/vjmI6YM74qbS2mjZT7M2trbHLJLglatWqHRaB7ZVqxYATzogEyePJn4+HgyMzP59ddfqV69us453N3dWbduHWlpaaSmprJs2TLKlCmjU6Z27drs37+fzMxMrl27xujRo/Wua4npMERHR7N48WJq165dLHkL1u3mzS5NCX85jODKFZgV2ZPSDnas2XJIsi0oV7KtJ3v2yp34epVl/oTeNAipRIBvOZ57pgaBFcsbLfNh1tbe5pCtL1NMSZQkJaLDkJ6eTnh4OEuXLtVrgcbTys65T+zZOFo1DtLuUyqVtGwcRPTJy5JtIbmSbV3Z2/afpF4Nf/qO+Ypq7cbQIvwTVm763Wh5D7PG9jZ19tMwt0WP5qZEdBgiIiLo2LGjzt2uHicrK+uRO2zpKyklndxcNeXdnXX2l3d3ITFJ//NJtnnmSrZ1ZV+5fptl3++nsl95vp8XQf9uzRnz2Xd8vfUPo2Xmscb2NnW2MDyzX/S4fv16jh07RnR09BOVj4qKYtKkSUaulRCipFGrNdSt4c/4iJcBqB3kx5m/b7J84wF6vfSMiWsnzIGCok8pWO74gpmPMMTFxTFs2DDWrl2rsyK0IJGRkaSmpmq3uLg4vXM93MpgY6N8ZFHOrWQVnh4uj3mXYVhjtjV+Zsku/myvci4EV9a9SU31St5ci3/ye+k/LWtsb1NnPw2lQmGQzVKZdYchJiaGxMRE6tevj62tLba2tuzdu5e5c+dia2tLbm7uI++xt7d/5A5b+rIrZUvdYD/2Rp/T7lOr1eyLPk+j0MAifSbJNp9cybau7CZ1KnPhH9074l26mkhFb3ejZeaxxvY2dbYwPLOekmjTpg0nT57U2devXz+Cg4MZPXo0NjY2Rsse8vpzDJm0mno1/KkfUomFX/9Gxr0swjsZf+jSGrOt8TNLdvFmD+n1HO0HfMZny7fzStv6xJy6wspNv/P5/3oZLVMn38ra2xyy9WWIqxwseIDBvDsMzs7O1KpVS2efk5MTHh4ej+w3tK7tGnA7JZ1pi38iMSmN0Oq+fDc3oliG0awx2xo/s2QXb3b9kABWzxzE5PlbmPnlLwT4eDBtZDd6dGhktMyHWVt7m0O2vkxx46aSRKHRaDSmroQ+WrVqRd26dZk9e/YTlVepVLi6upKQlPpU0xNCCCFMS6VS4eXhSmqqcb7H835PtP1sF7aOTkU61/17Gfz6fhuj1dWUzHqEIT979uwxdRWEEEIIq1PiOgxCCCGEUSgMMKVguTMS0mEQQgghQBY9FsasL6sUQgghhHmQEQYhhBACUPz//4p6DkslHQYhhBACUCoebEU9h6WSKQkhhBBCFEpGGIQQQgjkxk2FkQ6DEEIIgVwlUZgn6jBs2bLliU/48ssvP3VlhGHdz1WbJNfWRma6RPG4nZZlktxyzvYmyRXClJ6ow9ClS5cnOplCocj3CZJCCCGEuTPE46kt+fHWT9RhUKtN85eqEEIIUVxkSqJgRVrDkJmZiYODg6HqIoQQQpiMLHosmN6Tzbm5uXz88cf4+vpSpkwZ/v77bwDGjRvHV199ZfAKCiGEEML09O4wTJ06lRUrVjBjxgzs7Oy0+2vVqsWXX35p0MoJIYQQxSVvSqKom6XSu8OwatUqlixZQnh4ODY2Ntr9derU4ezZswatnBBCCFFc8hY9FnWzVHp3GK5fv07VqlUf2a9Wq8nJyTFIpYQQQghhXvTuMNSsWZP9+/c/sv+7776jXr16BqmUEEIIUdwUBtosld5XSYwfP54+ffpw/fp11Go1Gzdu5Ny5c6xatYqtW7cao45CCCGE0clVEgXTu8PQuXNnfvzxRyZPnoyTkxPjx4+nfv36/Pjjjzz//PPGqKPJLN2wl3lrdpGYpKJWNV+mj+pOg5BKFpE9e+UOftrzJxf+ScDRvhSNQgMZH/EyVQO8ALh6I4kGXSfl+94vp/ajcxvDjyZZcntLtvGzj5y4xJff7OHUhWskJqlYMLkvzzcP1R7/cPrXbNp+VOc9zzYKYtn0wdrXrXpN4XrCHZ0yHwx8kbdeb/PU9XqYJbV3SckWhvNU9/B99tln2blzJ4mJidy9e5cDBw7Qrl07Q9fNpDbuiGHs7E2MHtiBPatHU6uaL93enc+t5DSLyD54/CL9uz3Lti9H8u3cCHLu59J92AIy7j241a6vV1n++mmKzjZ6UAecStvTJqymweqRx9LbW7KNn30vM5vgKj5MeK/rY8u0aBzMwe8maLfPx77xSJlh/V7QKdP7leZPXaeHWVp7l4RsfeU93rqom6V66pv+Hz16lNWrV7N69WpiYmIMWScdEydO1A4T5W3BwcFGy8uzYN1u3uzSlPCXwwiuXIFZkT0p7WDHmi2HLCJ7w+wh9HqpCcGVK1Crmi/zxoVzLf4OJ87GAWBjo8TLw0Vn+2nvn3RuU48ypQ1/H31Lb2/JNn52yyY1GDmgA+2eDX1sGbtSNpR3d9Furs6lHynj5GivU6a0o2F+3i2tvUtCtr7++7vmaTdLpXeH4dq1azz77LM0btyYYcOGMWzYMBo1akTz5s25du2aMepISEgIN2/e1G4HDhwwSk6e7Jz7xJ6No1XjIO0+pVJJy8ZBRJ+8bJHZqvRMAMq6PPoFCnDi7FX+On+d8E7PGDzbGttbsk2TfTj2Ek26TqDdm58w/vPvuJOa8UiZJV/vplGXcbw8+DOWrv+N+wZ4Po61trcps4Xh6b2GYeDAgeTk5HDmzBmCgh78EJw7d45+/foxcOBAtm3bZvhK2tri7e1t8PM+TlJKOrm5asq7O+vsL+/uwoUrCRaXrVarGTt7I41rV6ZGFZ98y6zd8gfVK3nRuHZlg+dbW3tLtmmyWzQKpn3zUCpW8ODqjdt89tUvDByzlA1fvIfN/z9h9c2uzxJSzRdX59IcO3WFz778mVvJKv43pHORsq2xvU2d/bQseICgyPTuMOzdu5eDBw9qOwsAQUFBzJs3j2effdaglctz4cIFfHx8cHBwICwsjKioKPz9/fMtm5WVRVbWv4+8ValURqmTJRk981vOXrrJ1iXD8j1+LzOb73fE8H6/9sVcMyEM56Xn/l2oG1S5AkGVfWjzxjQOn7hI0/rVAejfvaW2THAVH0qVsmH8rO94f2BH7O2K9OgdUQLIVRIF03tKws/PL98bNOXm5uLjk/9fp0XRpEkTVqxYwbZt21i4cCGXL1/m2WefJS0t/wUzUVFRuLq6ajc/Pz+9Mz3cymBjo3xkUc6tZBWeHi5P9TnMNXv0p9+y4/dTbFrwLj6eZfMt8+NvsdzLzKbHi40Mng/W1d6Sbdrsh/n7eFDW1Yl/ric9tkzd4ADu56q5Hp9cpCxrbW9z+bd+UrLosWB6dxhmzpzJu+++y9Gj/16edPToUYYNG8ann35q0MoBdOjQge7du1O7dm3at2/Pzz//TEpKChs2bMi3fGRkJKmpqdotLi5O70y7UrbUDfZjb/Q57T61Ws2+6PM0Cg186s9iTtkajYbRn37Lz3v/ZOMXQwnw8Xhs2bVb/qD9s7UoV9b5sWWKwhraW7LNI/thN2+lkKK6i6f743+uT1+6jlKpwKNsmSJlWWt7m8u/tTCMJxpjK1u2rM4wS0ZGBk2aNMHW9sHb79+/j62tLf3796dLly5GqWgeNzc3qlevzsWLF/M9bm9vj7190Vc1D3n9OYZMWk29Gv7UD6nEwq9/I+NellEW/Zkie/TMb/l+RwyrZgykjJMDCUkPpm5cnBxwdPj3oWJ/x93iUOwlvp71lsGy82Pp7S3Zxs/OuJfFP9dva19fu5nM6YvXcXMujatLaeat3EH7FrUp7+7M1Ru3mbH4JwJ8PWje6MFVV8dPXSH2zFWeqVcVJ0d7jp++wrQFW+jctkG+V1OYw2eWbMOSKYmCPVGHYfbs2UauxpNLT0/n0qVL9O7d26g5Xds14HZKOtMW/0RiUhqh1X35bm5EsQyjFUf28o0PrjTpMmSezv65Y8Pp9VIT7et1W//Ax9ON1k2Meymrpbe3ZBs/+69zcbwxcqH29bSFWwB4pX1DJg9/lXN/32DTjqOkpd/D08OF5g2DGN7vBe3aBLtStvz023HmrdxOds59KlbwoN+rLej3ast88/Rlae1dErL1ZYhbO1tudwEUGo1GY+pKFOSDDz6gU6dOBAQEcOPGDSZMmEBsbCynT5+mfPnyhb5fpVLh6upKQlIqLi7m9wNqTPdz1SbJtbV56tt7CKGX22lZhRcygnLOhr8XiXg8lUqFl4crqanG+R7P+z0R/tVB7EoXbfop+246awc0feK65ubmMnHiRNasWUN8fDw+Pj707duXsWPHakcrNBoNEyZMYOnSpaSkpNCsWTMWLlxItWrVtOdJTk7m3Xff5ccff0SpVNKtWzfmzJlDmTJF+zwPK9Ky38zMTLKzs3X2Gfof89q1a/Tq1YukpCTKly9P8+bN+eOPP56osyCEEEI8KUM8nlrf90+fPp2FCxeycuVKQkJCOHr0KP369cPV1ZX33nsPgBkzZjB37lxWrlxJYGAg48aNo3379pw+fRoHBwcAwsPDuXnzJjt37iQnJ4d+/foxePBg1q1bV6TP8zC9OwwZGRmMHj2aDRs2kJT06OriXAPc5ORh69evN+j5hBBCiPwoFEW/D0Pe+/97Sf/j1tcdPHiQzp0707FjRwAqVarE119/zZEjR4AHowuzZ89m7NixdO784H4gq1atwsvLi82bN9OzZ0/OnDnDtm3biI6OpmHDhgDMmzePF198kU8//dRgVzDqPXb84Ycfsnv3bhYuXIi9vT1ffvklkyZNwsfHh1WrVhmkUkIIIURJ5ufnp3OJf1RUVL7lmjZtyq5duzh//jwAJ06c4MCBA3To0AGAy5cvEx8fT9u2bbXvcXV1pUmTJhw69OD22ocOHcLNzU3bWQBo27YtSqWSw4cPG+wz6T3C8OOPP7Jq1SpatWpFv379ePbZZ6latSoBAQGsXbuW8PBwg1VOCCGEKC6GvEoiLi5OZ4r+cVfvjRkzBpVKRXBwMDY2NuTm5jJ16lTt79L4+HgAvLy8dN7n5eWlPRYfH4+np6fOcVtbW9zd3bVlDEHvDkNycjKVKz+4PbCLiwvJyQ9uaNK8eXPeeecdg1VMCCGEKE6GnJJwcXF5ojV9GzZsYO3ataxbt46QkBBiY2MZPnw4Pj4+9OnTp2iVMTC9pyQqV67M5csPHhoSHBysvYHSjz/+iJubm0ErJ4QQQliyUaNGMWbMGHr27EloaCi9e/dmxIgR2imMvOcoJSToPnsjISFBe8zb25vExESd4/fv3yc5Odmgz2HSu8PQr18/Tpw4ATwYSpk/fz4ODg6MGDGCUaNGGaxiQgghRHHKu0qiqJs+7t69i1Kp+6vYxsYGtfrBZfGBgYF4e3uza9cu7XGVSsXhw4cJCwsDICwsjJSUFGJiYrRldu/ejVqtpkmTJhiK3lMSI0aM0P5327ZtOXv2LDExMVStWpXatWsbrGJCCCFEcTLklMST6tSpE1OnTsXf35+QkBCOHz/OrFmz6N+///+fT8Hw4cOZMmUK1apV015W6ePjo72zco0aNXjhhRcYNGgQixYtIicnh6FDh9KzZ0+DPuOpyI9fCwgIICAgwBB1EUIIIUzGFLeGnjdvHuPGjWPIkCEkJibi4+PDW2+9xfjx47VlPvzwQzIyMhg8eDApKSk0b96cbdu2ae/BALB27VqGDh1KmzZttDdumjt3bpE+y3890Z0e9QnNu9GEuZA7PRY/udOjKC5yp0frUFx3ehy45ohB7vT45RuNjVZXU3qiEYbPP//8iU6mUCjMrsNgzYp6xzIhzJ1abdZ3thcljJKnWNiXzzks1RN1GPKuihBCCCEslTytsmCW3BkSQgghhIEUedGjEEIIYQkUClAW81USJYl0GIQQQggedBaK2mEo6vvNmUxJCCGEEKJQMsIghBBCIIseC/NUIwz79+/njTfeICwsjOvXrwOwevVqDhw4YNDKCSGEEMUlb0qiqJul0rvD8P3339O+fXscHR05fvw4WVkPbpySmprKtGnTDF5BIYQQQpie3h2GKVOmsGjRIpYuXUqpUqW0+5s1a8axY8cMWjkhhBCiuOQ9S6Kom6XSew3DuXPnaNGixSP7XV1dSUlJMUSdzMbSDXuZt2YXiUkqalXzZfqo7jQIqWQx2QePX+SLNbuIPXuVhNsqVs0YSMeWdQDIuZ/L1EVb+fXgKf65noRzGQdaNgpifERnKpR3NWg98lh6e0u2cbOj/7zEVxv28NeF69xKUjF/Ul/aNqulU+bSPwnM/PInok/8Ta46lyr+Xsyb0Acfr7IA3EpWMWPJVg7GXCDjXiaBFT15+/U2tG9hmAfrWVJ7l5RsfTzN0ybzO4el0nuEwdvbm4sXLz6y/8CBA1SuXNkglTIHG3fEMHb2JkYP7MCe1aOpVc2Xbu/O51ZymsVk372XRUg1X2aM6vHIsXuZ2fx5Lo4P+r/A7lUfsvKTgVy8mkj4B4sNWoc81tDekm3c7LuZ2QRV9mHCu6/ke/zqjdu8Pnw+lf08Wf3ZO2xZ8j5D3ngee7t//24aPX09l+NusfDjfvy45AOebx7K8CmrOX3h+lPXK4+ltXdJyNaX0kCbpdL7sw0aNIhhw4Zx+PBhFAoFN27cYO3atXzwwQe88847Bq/g9evXeeONN/Dw8MDR0ZHQ0FCOHj1q8Jz/WrBuN292aUr4y2EEV67ArMielHawY82WQxaT3bZpCB+9/RIvtarzyDGXMo5snDeULm3rUy3Ai0ahgUz/oDsnzsZxLT7ZoPUA62hvyTZudsvGNRjRvwPPNw/N9/jny7bRokkwHw5+iZrVfPH3KUebpiF4lHXWljl+6gpvdGlO7WB//Hw8GPJGW1ycHDl14dpT1yuPpbV3ScgWhqV3h2HMmDG8/vrrtGnThvT0dFq0aMHAgQN56623ePfddw1auTt37tCsWTNKlSrFL7/8wunTp/nss88oW7asQXP+KzvnPrFn42jVOEi7T6lU0rJxENEnjftcDVNmF0aVfg+FQoFLGUeDntda21uyiy9brVaz5/AZKlUsz4DRSwh7dQLdh87h19//0ilXL6QSv+yJJUV1F7VazU+/HScrJ4fGdaoUKd/a2tscsp+GrGEomN5rGBQKBR999BGjRo3i4sWLpKenU7NmTcqUKdojQfMzffp0/Pz8WL58uXZfYGBgge/JysrSXrkBDx5bqq+klHRyc9WUd3fW2V/e3YULVxL0Pl9JyS5IZlYOk7/YQrd2DQzeYbDW9pbs4stOSknn7r0slq7fzfC+HfhgUEf2R59j6MSVrPr0bW2HYPa43oz4eDVNuo7H1kaJg70dX0zsS4BvuSLnW1N7m0P201BigDUMWG6P4amnW+zs7KhZsyaNGzc2SmcBYMuWLTRs2JDu3bvj6elJvXr1WLp0aYHviYqKwtXVVbv5+fkZpW7WJOd+LgM+WoYGDTM/fHS9gxDmLu8x2G3CatH31RbUqOrL4F7P0eqZGqzf+u/Q+Jzl21Bl3GPFjLf4fsFw+r3aguEfr+bc3zdNVXUhzIbeIwytW7cu8E5Wu3fvLlKFHvb333+zcOFCRo4cyf/+9z+io6N57733sLOzo0+fPvm+JzIykpEjR2pfq1QqvTsNHm5lsLFRPrIo51ayCk8PF/0/SAnJzk/O/Vz6/28ZcTeT2bzgPYOPLoD1trdkF192WVcnbG2UVAnw0tlfxd+TmL+uAA8WRa754Xe2fvkB1Sp5AxBcxYejJy+zdsvvTB7+6lPnW1t7m0P20zDElIIlT0noPcJQt25d6tSpo91q1qxJdnY2x44dIzQ0/8VGT0utVlO/fn2mTZtGvXr1GDx4MIMGDWLRokWPfY+9vT0uLi46m77sStlSN9iPvdHndOqyL/o8jUILnhIpKlNm/1deZ+HvuFts/GIo7q5ORsmx1vaW7OLLtitlS2iQH5evJersv3LtNr6eD9ZE3cvMAR69LM5GqUDz/yMURcm3pvY2h+ynIXd6LJjeIwyff/55vvsnTpxIenp6kSv0sAoVKlCzZk2dfTVq1OD77783aE5+hrz+HEMmraZeDX/qh1Ri4de/kXEvi/BOz1hMdvrdLC5fu6V9ffVGEifPX6OsS2m8yrnSd8xX/Hkujq8/e4tctYaEpAfrQcq6lMaulGEfQ2IN7S3Zxs3OuJfF1eu3ta+v3UzmzMXruDqXxserLAN6tGLElDU0Cq1Mk7pV2R99lt8OnWbVZw+u7qrs70mAbznGz/6O0W91ws2lNL/+/he/H7vA4in9zfIzS7YoTgb71n/jjTdo3Lgxn376qaFOSbNmzTh37pzOvvPnzxMQEGCwjMfp2q4Bt1PSmbb4JxKT0git7st3cyOKZRituLJjz1yl85C52tdjZ28CoGfHxowe+CLb9p8EoGXv6Trv+2HBezRvUM2gdbGG9pZs42b/dS6ONz/4d/QxatEWAF5p15BPPuzJ881DmTisG0vW72bK/M0E+nkyd8KbNPz/v3RL2dqwZOoAPvvyZ94eu4y7mVn4+5Tjkw970rJJjaJ9YCyvvUtCtr4UiqLfeMmSpyQUGo2maGNt/2/16tWMHj2aGzduGOJ0AERHR9O0aVMmTZpEjx49OHLkCIMGDWLJkiWEh4c/0TlUKhWurq4kJKU+1fRESaYu4jDq01Ja8picMCuJqZkmyfV0dTBJrrVSqVR4ebiSmmqc7/G83xP/23wMByfnwt9QgMyMNKZ1qW+0upqS3iMMXbt21Xmt0Wi4efMmR48eZdy4cQarGECjRo3YtGkTkZGRTJ48mcDAQGbPnv3EnQUhhBBCGIbeHQZXV93nCCiVSoKCgpg8eTLt2rUzWMXyvPTSS7z00ksGP68QQgjxMEMsWrTkAVa9Ogy5ubn069eP0NBQo99tUQghhChOiv//X1HPYan0uqzSxsaGdu3aWdxTKYUQQgi5rLJget+HoVatWvz999/GqIsQQgghzJTeHYYpU6bwwQcfsHXrVm7evIlKpdLZhBBCiJJIRhgK9sRrGCZPnsz777/Piy++CMDLL7+sc4tojUaDQqEgNzfX8LUUQgghjEyhUBT46IMnPYeleuIOw6RJk3j77bf57bffjFkfIYQQQpihJ+4w5N3fqWXLlkarjBBCCGEqclllwfS6rNKSh1qEEEJYN3laZcH06jBUr1690E5DcnJykSokDEdtmLt+601pwdchC/NiX8rG1FUQwmro1WGYNGnSI3d6FEIIISyBUqEo8sOnivp+c6ZXh6Fnz554enoaqy5CCCGEycgahoI98X0YZP2CEEIIYb30vkpCCCGEsEgGWPRoyUu4nrjDoFarjVkPIYQQwqSUKIq8aNuSF33rfWtoIYQQwhLlXVZZ1E1f169f54033sDDwwNHR0dCQ0M5evSo9rhGo2H8+PFUqFABR0dH2rZty4ULF3TOkZycTHh4OC4uLri5uTFgwADS09OL2iQ6pMMghBBCmMidO3do1qwZpUqV4pdffuH06dN89tlnlC1bVltmxowZzJ07l0WLFnH48GGcnJxo3749mZmZ2jLh4eGcOnWKnTt3snXrVvbt28fgwYMNWle9rpIQQgghLJUhr5L478MY7e3tsbe3f6T89OnT8fPzY/ny5dp9gYGB2v/WaDTMnj2bsWPH0rlzZwBWrVqFl5cXmzdvpmfPnpw5c4Zt27YRHR1Nw4YNAZg3bx4vvvgin376KT4+PkX7UHmfzSBnEUIIIUq4vPswFHUD8PPzw9XVVbtFRUXlm7llyxYaNmxI9+7d8fT0pF69eixdulR7/PLly8THx9O2bVvtPldXV5o0acKhQ4cAOHToEG5ubtrOAkDbtm1RKpUcPnzYYO0jIwwFWLphL/PW7CIxSUWtar5MH9WdBiGVLCJ79sod/LTnTy78k4CjfSkahQYyPuJlqgZ4act0fmcuB49f1Hlfn1ea8eno1wxWj4dZcntLtvGzD5+4xJKvd3Py/DUSk1QsntKf9s+GApBzP5dPv/yZPX+c4erNJJydHGjeoDqj33oJr3L/3owuRZXBhDkb2XXwFAqlgg4t6jDh3VdwKv3oX4ZPw5Lau6Rkm0pcXBwuLi7a1/mNLgD8/fffLFy4kJEjR/K///2P6Oho3nvvPezs7OjTpw/x8fEAeHl56bzPy8tLeyw+Pv6ReyTZ2tri7u6uLWMIMsLwGBt3xDB29iZGD+zAntWjqVXNl27vzudWcppFZB88fpH+3Z5l25cj+XZuBDn3c+k+bAEZ97J0yvXu3JS/fpqi3SYMfdlgdXiYpbe3ZBs/++69bGpU9WXy8G6PHLuXmc2p89d4983n2br0fRZ93I9LcYkM/N+XOuWGfbyG81fiWf3ZOyyLGsSRE5eI/HTDU9fpYZbW3iUhW1+GXPTo4uKisz2uw6BWq6lfvz7Tpk2jXr16DB48mEGDBrFo0aJi/ORPxuw7DJUqVdI+o/zhLSIiwqi5C9bt5s0uTQl/OYzgyhWYFdmT0g52rNlyyKi5xZW9YfYQer3UhODKFahVzZd548K5Fn+HE2fjdMo5OpTCy8NFuzk7ORqsDg+z9PaWbONnt36mBh8MfJEXWtR+5JhLGUfWzHqHl56rRxV/T+qHVGLysG6cPHeN6wl3ALh4JYG9R84yfdRr1KsZQKPalZk4rCs/7j5Owu3Up65XHktr75KQrS8lBpiS0POyygoVKlCzZk2dfTVq1ODq1asAeHt7A5CQkKBTJiEhQXvM29ubxMREneP3798nOTlZW8YQzL7DEB0dzc2bN7Xbzp07AejevbvRMrNz7hN7No5WjYO0+5RKJS0bBxF98rLRck2ZrUp/sNq2rEtpnf3fbz9KUPtInn09io8XbOFuZrbBs62xvSXbNNkPS8u4h0KhwKXMg07wsVNXcCnjSO1gf22Z5g2qo1QqOH76nyJlWWt7m8u/tTlr1qwZ586d09l3/vx5AgICgAcLIL29vdm1a5f2uEql4vDhw4SFhQEQFhZGSkoKMTEx2jK7d+9GrVbTpEkTg9XV7NcwlC9fXuf1J598QpUqVWjZsmW+5bOyssjK+ndY/b8rVZ9EUko6ublqyrs769bF3YULVxIe8y7DMEW2Wq1m7OyNNK5dmRpV/l1N2619Ayp6u+NdzpXTF68zef4WLv2TyIrpAw2ab23tLdmmy86TmZXDJ4u38nKbejg7OQBwK1lFubJldMrZ2trg5ly6yMPn1tre5vBvrQ9TPN56xIgRNG3alGnTptGjRw+OHDnCkiVLWLJkyf+fT8Hw4cOZMmUK1apVIzAwkHHjxuHj40OXLl2AByMSL7zwgnYqIycnh6FDh9KzZ0+DXSEBJaDD8LDs7GzWrFnDyJEjH/tsi6ioKCZNmlTMNSvZRs/8lrOXbrJ1yTCd/W92aab975pVffAq50rXoV9w+dotAiuW/+9phCgRcu7nMnTiSjQaDVNGGm+kUpQ8Soo+7K7v+xs1asSmTZuIjIxk8uTJBAYGMnv2bMLDw7VlPvzwQzIyMhg8eDApKSk0b96cbdu24eDgoC2zdu1ahg4dSps2bVAqlXTr1o25c+cW8dPoKlEdhs2bN5OSkkLfvn0fWyYyMpKRI0dqX6tUKvz8/PTK8XArg42N8pG/Km4lq/D0cHnMuwyjuLNHf/otO34/xZZFw/DxLFtg2fohD4bILl+7bdAOgzW1t2SbNjvnfi4RE1ZyLeEOX38+RDu6AA/+6r19R/fOePfv55KSdveRv5D1Za3tbcrskuSll17ipZdeeuxxhULB5MmTmTx58mPLuLu7s27dOmNUT8vs1zA87KuvvqJDhw4FDrHY29s/sjpVX3albKkb7Mfe6H/nldRqNfuiz9MoNLCAdxZdcWVrNBpGf/otP+/9k41fDCXAx6PQ9/x1/joAXgb+P7o1tLdkmz47r7Nw5fot1s56h7KuTjrH64dUQpV+j5Pn/l34e/D4BdRqDfVqBhQp2xrb29TZTyO/BfZPs1mqEjPC8M8///Drr7+ycePGYskb8vpzDJm0mno1/KkfUomFX/9Gxr0swjs9YxHZo2d+y/c7Ylg1YyBlnBxISHqw1sPFyQFHBzsuX7vFxh0xtG1ak7IuTpy+eINxczYSVq8KIdV8DVaPPJbe3pJt/OyMu1lcuX5b+zruZhKnLlzHzaU0nh4uvDN+BafOX+OrTwaSm6sm8f9/5t1cSmNXypaqlbxo2TiYMTO/Yer73bl/P5cJszfS6bl6OvdqMKfPLNmGpaDoD5u03O5CCeowLF++HE9PTzp27FgseV3bNeB2SjrTFv9EYlIaodV9+W5uRLEMoxVH9vKNBwDoMmSezv65Y8Pp9VIT7ErZsjf6HIvX7+FuZjY+nmV5qVVdRvZvZ7A6PMzS21uyjZ/957k4eg2fr309Zf4PAHR7oRHD+77Ar7//BcCLAz7Ved/XsyMIq1cVgDnj3mD87I2Ej1iIUqnghRa1mfhe16eu08Msrb1LQra+Hr5TY1HOYakUGo1GY+pKFEatVhMYGEivXr345JNP9HqvSqXC1dWVhKTUp5qeKMnu55rmkeS2NiVqpkuUYKl3c0yS61q6lElyrZVKpcLLw5XUVON8j+f9nliy5zSOZYq2XuVeehqDW9U0Wl1NqUSMMPz6669cvXqV/v37m7oqQgghLJjljg8UXYnoMLRr144SMBAihBCiBDPFfRhKEhk7FkIIIUShSsQIgxBCCGFshrgsUi6rFEIIISycKe70WJJY8mcTQgghhIHICIMQQgiBTEkURjoMQgghBHKnx8LIlIQQQgghCiUjDEIIIQQyJVEY6TBYsNtp2SbJ9XZzKLyQEAZQqeUIk+Teif7CJLnCuOQqiYJJh0EIIYRARhgKY8mdISGEEEIYiIwwCCGEEMhVEoWRDoMQQgiBPHyqMDIlIYQQQohCyQiDEEIIAShRoCzipEJR32/OpMMghBBCIFMShZEpCSGEEEIUSkYYhBBCCEDx//8r6jkslXQYCrB0w17mrdlFYpKKWtV8mT6qOw1CKpXI7Og/L7Hs2z2cOn+dW8kq5k3sS9tmtbTHM+5lMevLn9h18BQpqgwqervzRpfm9OzUVFvmzfcXEP3n3zrnfa3jM0wc/upT1+thltTekl082V/Peos6wf5UKO9K+AdL+Hnvn9pj8ye8wesvPaNT/tdDp+n+3gLt63WfvUVodV/KlXUmJe0ue4+cY+K8H4i/narzvqFvtKFPl2b4VShLUkqG/h/2/5X09i6J2fqQKYmCmfWURG5uLuPGjSMwMBBHR0eqVKnCxx9/jEajMXr2xh0xjJ29idEDO7Bn9WhqVfOl27vzuZWcViKz72VmE1TZh3HvvpLv8emLtnDg6DlmjOnFT199yJtdWzDli83sPnhKp1z3F5uw75vx2u2DQS89dZ0eZmntLdnFk/3X+euMmvHNY4//evAUQS9EareBHy3XOb7/6Hn6RS6j8auT6TP6SwIrlmPl9AE6ZT55/1V6dw5j/NxNNO4+hdffX6xXHfNYQnuXtGxhWGbdYZg+fToLFy7kiy++4MyZM0yfPp0ZM2Ywb948o2cvWLebN7s0JfzlMIIrV2BWZE9KO9ixZsuhEpndonENhvfrwPPNQ/M9fvz0FTo/35DGdari6+1Oj47PEFSlAn+eu6pTzsHejvLuLtqtjJNhnhthae0t2cWTPXXRVn7a8+djj2dl3ycxKU27pabd0zm+8OvfOPrXFeLi73Dkz8vMXrmThrUqYWvz4KuxeiUv+r/6LOEfLOGXfSe5eiOJE2fj9P/AWEZ7l7RsfSn+/yqJomyWPCVh1h2GgwcP0rlzZzp27EilSpV49dVXadeuHUeOHDFqbnbOfWLPxtGqcZB2n1KppGXjIKJPXrbI7Ho1K/HboVMk3E5Fo9FwOPYiV67dplmD6jrltu4+Rli38XQaNJNZX/3MvcyiP+DKGttbsosnu3mDapzfHsWR78bx2ejXKOvq9Niybi6lefWFhhz58zL3c9UAvPBsKFeu36Z981rEbp7IiR8mMeej1/Wuh7W0tzllP428KYmibpbKrNcwNG3alCVLlnD+/HmqV6/OiRMnOHDgALNmzXrse7KyssjKytK+VqlUeucmpaSTm6umvLuzzv7y7i5cuJKg9/lKQvbYiFcYP/tbWvX6GFsbJQqlgskjutOodhVtmZeeq4+PZ1k8y7lw7u+bfPblT1yOS2TexL5FyrbG9pZs42fvOniGrb+d4J/rSVSqWI5xQzrx7Zx3aNf/M9Tqf6c1Jw7tzMAeLXBytOfIn5fpOXKR9lgl33L4ebvTuU093pm4GqVSybSRXfWuizW0t7llPw1Zw1Aws+4wjBkzBpVKRXBwMDY2NuTm5jJ16lTCw8Mf+56oqCgmTZpUjLW0DGt+OMCJM1dZMLkfPl5lOfrn33w8bxOeHi40rf9glKFHx38XkFUPrEB5d2f6fbiYqzdu4+9TzlRVFyJfG3fGaP/79KUbnLp4ndjNk2jeoBr7os9rj81d/SurtxzCz9ud0YM6sGhib14b8aDToFAqcLAvxTsTV3PpaiIA7368lr1rxhTvhxHCDJj1lMSGDRtYu3Yt69at49ixY6xcuZJPP/2UlStXPvY9kZGRpKamare4OP3nGz3cymBjo3xkUc6tZBWeHi56n8/cszOzcpi97BdGv92J1mEhBFX2IbxLczq0rMPyb/c+9n21g/0BuHo9qUj51tbekm2a7H+uJ3H7ThqVK5bX2Z+cmsGlq4nsOXKWAR8tp13zWjQKDQQg4XYqOfdztZ0FgPNP8ZexNba3qbOfhsJA/7NUZt1hGDVqFGPGjKFnz56EhobSu3dvRowYQVRU1GPfY29vj4uLi86mL7tSttQN9mNv9DntPrVazb7o89ovEmMxRfb9+7nk3M9F+Z+xNBsbpc7Q7X+dvXQDgPIezo8t8ySsrb0l2zTZPp5uuLs6kZD0+GnKvP8P2JV6MPh6+MTflLK1oZLvvyNoVf099c62xvY2dfbTUCoMs1kqs56SuHv3Lkqlbp/GxsYGtVpt9Owhrz/HkEmrqVfDn/ohlVj49W9k3MsivNMzhb/ZDLMz7mVx9fpt7etr8cmcuXgdV5fS+HiWpVHtysxcuhUH+1L4eJYl+s+/+WHnUUa//TIAV2/cZuvu47RsXAM3l9Kc+/smnyzaQsPQygRV9jHLzyzZlp9dq7qv9r8DfDyoVd2XlNS73FFlMHrQi2zZHUtCkorAiuWY9G4X/o67za5DZwBoEBJA/ZoBHDpxiVTVXSpVLM9Hb3fk77hb2gV5e46cI/bMVb4YH07kZ9+jVCqY+WEPk35myRamYtYdhk6dOjF16lT8/f0JCQnh+PHjzJo1i/79+xs9u2u7BtxOSWfa4p9ITEojtLov382NKJZhNGNknzofR58P/l3MNX3RFgC6PN+QqA978tlHb/D5Vz8zKmodqWl38fEqy/B+Hej5UhgApWxtOXTsAqs27udeZjbe5d14/tlQ3nm9bdE+7P+ztPaW7OLJ3r82Uvvf00Z2A2Dd1j94/5NvqFnVl54dm+Dq7Ej8rVR2Hz7LtEVbyc65D8C9zBxeal2HMYM7UtrRjoTbqew6dIZPly3TltFoNPQauZjpo7rz05Lh3M3M5teDp5/qr2NLaO+Slq0vudNjwRSa4rgL0lNKS0tj3LhxbNq0icTERHx8fOjVqxfjx4/Hzs7uic6hUqlwdXUlISn1qaYnSrL4lEyT5Hq7GebeDEIUpmyjoSbJvRP9hUlyrZVKpcLLw5XUVON8j+f9nvjx6GWcyhRtijUjPY1ODQONVldTMusRBmdnZ2bPns3s2bNNXRUhhBDCqpl1h0EIIYQoLgqKPqVguRMSZn6VhBBCCFFcTH2VxCeffIJCoWD48OHafZmZmURERODh4UGZMmXo1q0bCQm6l/ZevXqVjh07Urp0aTw9PRk1ahT3799/+oo8hnQYhBBCCBOLjo5m8eLF1K5dW2f/iBEj+PHHH/n222/Zu3cvN27coGvXf+82mpubS8eOHcnOzubgwYOsXLmSFStWMH78eIPXUToMQgghBIa9cZNKpdLZHn5kwX+lp6cTHh7O0qVLKVu2rHZ/amoqX331FbNmzeK5556jQYMGLF++nIMHD/LHH38AsGPHDk6fPs2aNWuoW7cuHTp04OOPP2b+/PlkZxf9WT8Pkw6DEEIIgWEfPuXn54erq6t2K+iGgxEREXTs2JG2bXUvU4+JiSEnJ0dnf3BwMP7+/hw69OBpn4cOHSI0NBQvLy9tmfbt26NSqTh16pQBW0cWPQohhBBA3qLHop8DIC4uTueySnt7+3zLr1+/nmPHjhEdHf3Isfj4eOzs7HBzc9PZ7+XlRXx8vLbMw52FvON5xwxJOgxCCCGEgT3Jowni4uIYNmwYO3fuxMHB/O9fI1MSQgghBKBEgVJRxE2PMYqYmBgSExOpX78+tra22NrasnfvXubOnYutrS1eXl5kZ2eTkpKi876EhAS8vb0B8Pb2fuSqibzXeWUMRUYYLJjccVFYutuH55m6CsKCGHJK4km0adOGkydP6uzr168fwcHBjB49Gj8/P0qVKsWuXbvo1u3Brc/PnTvH1atXCQt7cNv+sLAwpk6dSmJiIp6eDx6MtnPnTlxcXKhZs2YRP40u6TAIIYQQJuDs7EytWrV09jk5OeHh4aHdP2DAAEaOHIm7uzsuLi68++67hIWF8cwzDx7e1a5dO2rWrEnv3r2ZMWMG8fHxjB07loiIiMeum3ha0mEQQgghoPiHGJ7A559/jlKppFu3bmRlZdG+fXsWLFigPW5jY8PWrVt55513CAsLw8nJiT59+jB58mTDVgQzf/iUIVjzw6eEsHS5atN8fdkU5XZ+Qm/F9fCpXcev4uRctPNnpKloU8/fIh8+JYsehRBCCFEomZIQQgghAB668VJRzmGppMMghBBCYJZLGMyKTEkIIYQQolAywiCEEEKADDEUQjoMQgghBOg8bbIo57BU0mEQQggh0H3aZFHOYamkw1CApRv2Mm/NLhKTVNSq5sv0Ud1pEFLJorNvJKYwcd4P/HroFPcycwisWI7549+gXs0Ao2dbY3tLtvGyZ6/YwdY9J7jwTwKO9qVoFBrI+KGdqRbw4El+d1IzmL70Z347fJbrCXfwcCvDiy1rE/lWR1zKOBqsHg+z5PY212xhOGa/6DEtLY3hw4cTEBCAo6MjTZs2zfcxoIa2cUcMY2dvYvTADuxZPZpa1Xzp9u58biWnWWx2iuouLwycRSlbJd/OGcIf33zElOFdcXMpbdRcsM72lmzjZh88fpEBrz7L9q/e57u5EeTcz6X7e/PJuJcFQPztVOJvpTLpvS7sXxfJvPHh7Dp0mmFT1hmsDg+z9PY2x2x9KQy0WSqz7zAMHDiQnTt3snr1ak6ePEm7du1o27Yt169fN2rugnW7ebNLU8JfDiO4cgVmRfaktIMda7YcMmquKbNnr9yJr1dZ5k/oTYOQSgT4luO5Z2oQWLG8UXPBOttbso2bvWHOEHq99AzBlStQq3pFvhj/Btfi73DibBwANar4sGL6QF54NpTAiuVp0TCIj97pxPYDf3H/fq7B6pHH0tvbHLP1Jj2GApl1h+HevXt8//33zJgxgxYtWlC1alUmTpxI1apVWbhwodFys3PuE3s2jlaNg7T7lEolLRsHEX3ystFyTZ29bf9J6tXwp++Yr6jWbgwtwj9h5abfjZoJ1tvekl282ar0TADKFjBipkq/h7OTA7a2NgbNtsb2NnW2MDyz7jDcv3+f3NxcHBx0H9Ps6OjIgQMH8n1PVlYWKpVKZ9NXUko6ublqyrs76+wv7+5CYpL+5ysp2Veu32bZ9/up7Fee7+dF0L9bc8Z89h1fb/3DqLnW2t6SXXzZarWajz7/nia1K1Ojis9j6/XZsm282aWpwfOtrb3NIftpKAz0P0tl1h0GZ2dnwsLC+Pjjj7lx4wa5ubmsWbOGQ4cOcfPmzXzfExUVhaurq3bz8/Mr5lqXXGq1htpBfoyPeJnaQX707dqcN7s0ZfnG/DtnQpQUH878lrN/32TplL75Hk9Lv0evkYsICvTmw0EvFm/lhNnIu0qiqJulMusOA8Dq1avRaDT4+vpib2/P3Llz6dWrF0pl/lWPjIwkNTVVu8XFxemd6eFWBhsb5SOLcm4lq/D0MO7Tx0yZ7VXOheDK3jr7qlfy5lr8HaPmWmt7S3bxZI+euYEdB/5i84J38fEq+8jxtIxMegxfSJnS9qycPohSBp6OAOtqb3PJFoZn9h2GKlWqsHfvXtLT04mLi+PIkSPk5ORQuXLlfMvb29vj4uKis+nLrpQtdYP92Bt9TrtPrVazL/o8jUIDn/qzmHt2kzqVufBPos6+S1cTqejtbtRca21vyTZutkajYfTMDfy09082zX+XAJ9yj5RJS79H9/fmU6qUDWs+fQsH+1IGy3+YNbS3uWU/DVnzWLAScx8GJycnnJycuHPnDtu3b2fGjBlGzRvy+nMMmbSaejX8qR9SiYVf/0bGvSzCOz1j1FxTZg/p9RztB3zGZ8u380rb+sScusLKTb/z+f96GTUXrLO9Jdu42R/O3MD322NYPXMQZZwcSPj/OXMXJwccHexIS7/Hq+8t4F5WNgsnvUlaRiZpGQ8WRpb7/7+MDcnS29scs/Umt4YukNl3GLZv345GoyEoKIiLFy8yatQogoOD6devn1Fzu7ZrwO2UdKYt/onEpDRCq/vy3dyIYhlGM1V2/ZAAVs8cxOT5W5j55S8E+HgwbWQ3enRoZNRcsM72lmzjZi///sHam87vzNXZP29cOL1eeoYT564Rc+oKAI26TdYpc2zTRPx9PAxWF7D89jbHbGFYCo1GozF1JQqyYcMGIiMjuXbtGu7u7nTr1o2pU6fi6ur6RO9XqVS4urqSkJT6VNMTQgjzlas2zdeXjdKC/4w0QyqVCi8PV1JTjfM9nvd74vdT1ynjXLTzp6epaBbia7S6mpLZjzD06NGDHj16mLoaQgghLJw8S6JgZt9hEEIIIYqDLGEomNlfJSGEEEII05MRBiGEEAJkiKEQ0mEQQgghwCC3dpZbQwshhBDCqskIgxBCCIFcJVEY6TAIIYQQyBKGwsiUhBBCCCEKJSMMQogSS+70KAxKhhgKJB0GIYQQArlKojAyJSGEEEKIQskIgxBCCIFcJVEY6TAIIYQQyBKGwkiHQQghhADpMRRC1jAIIYQQolAywiCEEEIgV0kURjoMQgghBIABFj1acH9BpiSEEEIIUTjpMBRg6Ya91H55PN7NhtO270xiTl2x6Ozfj12k54hF1OjwP8o2GspPe04YPfNh1tbekl282XNX7cQr7D3Gfv69dt8Hn6yn8auTCGj5PjU7RPLmh0u4cCXBaHWwpvY2l2x9KAy06SMqKopGjRrh7OyMp6cnXbp04dy5czplMjMziYiIwMPDgzJlytCtWzcSEnR/Tq9evUrHjh0pXbo0np6ejBo1ivv37+tZm4JJh+ExNu6IYezsTYwe2IE9q0dTq5ov3d6dz63kNIvNvnsvi1rVfZn54WtGzcmPNba3ZBdf9vHT/7Bq8+/UrOqjs792sB9zPgpn//r/sX72EDQaeG34AnJz1QavgzW1t7lk680EPYa9e/cSERHBH3/8wc6dO8nJyaFdu3ZkZGRoy4wYMYIff/yRb7/9lr1793Ljxg26du2qPZ6bm0vHjh3Jzs7m4MGDrFy5khUrVjB+/PinbIj8mbTDsG/fPjp16oSPjw8KhYLNmzfrHNdoNIwfP54KFSrg6OhI27ZtuXDhQrHUbcG63bzZpSnhL4cRXLkCsyJ7UtrBjjVbDlls9vPNQhj7Tideal3HqDn5scb2luziyc64m8WQiav4bEwv3JxL6xx7s0szwupVxb+CB7WD/BjzVkeuJ9wh7maSwethLe1tTtklwbZt2+jbty8hISHUqVOHFStWcPXqVWJiYgBITU3lq6++YtasWTz33HM0aNCA5cuXc/DgQf744w8AduzYwenTp1mzZg1169alQ4cOfPzxx8yfP5/s7GyD1dWkHYaMjAzq1KnD/Pnz8z0+Y8YM5s6dy6JFizh8+DBOTk60b9+ezMxMo9YrO+c+sWfjaNU4SLtPqVTSsnEQ0ScvW2y2qVhre0t28WSP+fRb2jYNoeVDefnJuJfF+q2H8ffxwMerrEHrYE3tbS7ZT0NhoP8BqFQqnS0rK+uJ6pCamgqAu7s7ADExMeTk5NC2bVttmeDgYPz9/Tl06EGn69ChQ4SGhuLl5aUt0759e1QqFadOnTJI24CJOwwdOnRgypQpvPLKK48c02g0zJ49m7Fjx9K5c2dq167NqlWruHHjxiMjEYaWlJJObq6a8u7OOvvLu7uQmKSy2GxTsdb2lmzjZ2/aGcOf5+L46J1Ojy2z/Pv9BD73AZWfG8XuQ6f5ds4Q7EoZ9gIya2lvc8p+Gnm3hi7qBuDn54erq6t2i4qKKjRfrVYzfPhwmjVrRq1atQCIj4/Hzs4ONzc3nbJeXl7Ex8dryzzcWcg7nnfMUMz2ssrLly8THx+v06tydXWlSZMmHDp0iJ49e+b7vqysLJ2enEplfj+UQgjju55wh7Gfb2TD3CE42Jd6bLlu7RvSsnEQCbdVLFi3m0Fjl/Pj4hEFvkeIwsTFxeHi4qJ9bW9vX+h7IiIi+Ouvvzhw4IAxq/bUzLbDkNcryq/XVFCPKSoqikmTJhUp28OtDDY2ykcW5dxKVuHp4fKYdxmGKbNNxVrbW7KNm33ibBy376TxfN+Z2n25uWoOxV5i2ff7ids7CxsbJS5lHHEp40hlP08a1KpE9XZj+Hnvn3Rt18BgdbGG9ja37KdhyDtDu7i46HQYCjN06FC2bt3Kvn37qFixona/t7c32dnZpKSk6IwyJCQk4O3trS1z5MgRnfPlXUWRV8YQLO4qicjISFJTU7VbXFyc3uewK2VL3WA/9kb/e2mLWq1mX/R5GoUGGrK6ZpVtKtba3pJt3OwWDauzZ80Ydq38ULvVreFPt/YN2LXyQ2xsHv3602g0oNGQnWPYy9Gsob3NLfupmOAqCY1Gw9ChQ9m0aRO7d+8mMFC3XRo0aECpUqXYtWuXdt+5c+e4evUqYWFhAISFhXHy5EkSExO1ZXbu3ImLiws1a9bUr0IFMNsRhrxeUUJCAhUqVNDuT0hIoG7duo99n729/RMN/RRmyOvPMWTSaurV8Kd+SCUWfv0bGfeyCO/0TJHPba7Z6XezuBx3S/v6nxtJnDx3DTfX0vh5uxs12xrbW7KNm13GyYEaVXQvoyztYEdZFydqVPHhyvXb/PDrMVo1CcbDrQw3E1OYu/pXHOxL0SbMcF+yeSy9vc0xW1+muDV0REQE69at44cffsDZ2Vk7gu7q6oqjoyOurq4MGDCAkSNH4u7ujouLC++++y5hYWE888yDNmzXrh01a9akd+/ezJgxg/j4eMaOHUtERIRBfh/mMdsOQ2BgIN7e3uzatUvbQVCpVBw+fJh33nnH6Pld2zXgdko60xb/RGJSGqHVfflubkSxDKOZKjv2zD90enuu9vVHn28EoFfHJiyY2Nuo2dbY3pJtmuw8DnalOHzib5Z8s5fUtLuUd3fmmbpV2LpkxCOL9AzBWtvbHP6tzdnChQsBaNWqlc7+5cuX07dvXwA+//xzlEol3bp1Iysri/bt27NgwQJtWRsbG7Zu3co777xDWFgYTk5O9OnTh8mTJxu0rgqNRqMx6Bn1kJ6ezsWLFwGoV68es2bNonXr1ri7u+Pv78/06dP55JNPWLlyJYGBgYwbN44///yT06dP4+Dg8EQZKpUKV1dXEpJS9ZpPEkKYv+z7hr/B0pOws7W42VyzplKp8PJwJTXVON/jeb8n/rqciHMRz5+mUlEr0NNodTUlk44wHD16lNatW2tfjxw5EoA+ffqwYsUKPvzwQzIyMhg8eDApKSk0b96cbdu2PXFnQQghhHhShlz0aIlMOsJQHGSEQQjLJSMM1qG4RhhOGWiEIURGGIQQQgjL9fCNl4pyDkslHQYhhBACkEmJgsm4mhBCCCEKJSMMQgghBDIlURjpMAghhBDIhERhZEpCCCGEEIWSEQYhhBACmZIojHQYhBBCCEzzLImSRDoMFsxU9+RSWHIXW5iVHLlxkzAkWcRQIPmpF0IIIUShZIRBCCGEQAYYCiMdBiGEEAJZ9FgYmZIQQgghRKFkhEEIIYRArpIojHQYhBBCCJBFDIWQKQkhhBBCFEpGGIQQQghkgKEw0mEQQgghkKskCiMdhgIs3bCXeWt2kZikolY1X6aP6k6DkEoWk33w2EXmrdnFibNXib+tYvWMgXRsVUd7XKPRELXkZ1ZvPkhq+j2a1A7k09GvUcXf06D1yGPp7S3ZxZudm6tm1vJtbNxxlMSkNLzLudC9Q2OG9WmnvRvpiKlr+XZbtM77WjYOZu1nbxusHg+z5PY212xhOLKG4TE27ohh7OxNjB7YgT2rR1Ormi/d3p3PreQ0i8nOyMyiVjVfZozqke/xuat+Zck3e/lszGvsXPY+pR3tefW9BWRm5Ri0HmAd7S3ZxZu9YO0uVm3+nSnDu7FnzRgi3+7EwnW7Wfb9Pp1yrZoEc2zzZO02f+KbBqvDwyy9vc0xW3+KIv/PkiclTNph2LdvH506dcLHxweFQsHmzZt1jm/cuJF27drh4eGBQqEgNja22Oq2YN1u3uzSlPCXwwiuXIFZkT0p7WDHmi2HLCb7+aYhfPTOS7zUus4jxzQaDYvW7+H9/u15sWVtQqr5snBib+Jvp/LT3j8NWg+wjvaW7OLNPvrXZdo1r0WbpiH4VfDgpdZ1adE4iNjTV3XK2ZeyxdPDRbu5OZc2WB0eZuntbY7Z+sqbkijqZqlM2mHIyMigTp06zJ8//7HHmzdvzvTp04u1Xtk594k9G0erxkHafUqlkpaNg4g+edlisx/2z40kEpJUOvVwKeNIg5BKBq+Htba3ZBs3u2GtQH6POc/fVxMBOH3xOtF//k3rZ2rolDsUe5E6ncbS4vWpRH66gTupGQarQx5raG9zyxaGZ9I1DB06dKBDhw6PPd67d28Arly58sTnzMrKIisrS/tapVLpXa+klHRyc9WUd3fW2V/e3YULVxL0Pl9JyX5YQpLq/3P/Ww9nEpP0b9OCWGt7S7ZxsyPeaEPa3UxavhGFjVJBrlrD6EEv0rVdQ22ZVk1q0KFlHfwquPPP9dtMX/ITb4xazJaFw7GxMdzfU9bQ3uaWLQzP4hY9RkVFMWnSJFNXQwhhYj/ujmXTzhi+GN+b6oHenLpwnYnzNuFVzpXuHRoD0LltfW35GlV8qFHVh2avTeHQ8Ys0b1jdVFUXJiJXSRTM4hY9RkZGkpqaqt3i4uL0PoeHWxlsbJSPLMq5lazC08PFUFU1u+yHef1/1qP1SDN4Pay1vSXbuNlTFm4hIrwNndvWp0YVH159oRGDerTiizW/PvY9AT7lcHd14sr1WwarB1hHe5tb9tMo+pLHot9a2pxZXIfB3t4eFxcXnU1fdqVsqRvsx97oc9p9arWafdHnaRQaaMjqmlX2wwJ8PPDycNGphyr9HjGnrhi8Htba3pJt3Ox7mdko//Pnno1SgVqteex7biSmcEd1F08PV4PVA6yjvc0tWxiexU1JGMqQ159jyKTV1KvhT/2QSiz8+jcy7mUR3ukZi8lOv5vF5Wv//iX1z40kTp6/RlmX0lT0duftnq34bNl2qvh5EuDjwbRFW/Eu50rHlrUNWg+wjvaW7OLNfr5pCHNX78TXqyzVA73568J1lnyzh9c6NgEg424Ws5Zv48VWdfB0d+af60lMXbiFSr7laNk42GD1yGPp7W2O2fqSKYmCSYfhMbq2a8DtlHSmLf6JxKQ0Qqv78t3ciGIZRiuu7NgzV3n5nbna12NnbwKgV8fGzJ/Qm/febEtGZjYjpn1Navo9nqlTmW/nDMHBvpRB6wHW0d6SXbzZH4/oxswvf+Z/s77j9p10vMu58Ebnpgzv2x4ApY2Cs5du8N22aFTp9/Aq50KLRsGMGvgi9naG/2q09PY2x2x9ya2hC6bQaDSPH58zsvT0dC5evAhAvXr1mDVrFq1bt8bd3R1/f3+Sk5O5evUqN27coGPHjqxfv56goCC8vb3x9vZ+ogyVSoWrqysJSalPNT1Rkpnqn1ZhyV1sYVYyMu+bJNfJQf7WKk4qlQovD1dSU43zPZ73e+Jawp0in1+lUlHRq6zR6mpKJl3DcPToUerVq0e9evUAGDlyJPXq1WP8+PEAbNmyhXr16tGxY0cAevbsSb169Vi0aJHJ6iyEEMJCKQy0WSiTdpNbtWpV4F/Bffv2pW/fvsVXISGEEFbLEFc5yFUSQgghhLBqMhEnhBBCIFdJFEY6DEIIIQRylURhpMMghBBCgPQYCiFrGIQQQggTmz9/PpUqVcLBwYEmTZpw5MgRU1fpEdJhEEIIITDdsyS++eYbRo4cyYQJEzh27Bh16tShffv2JCYmGuFTPj3pMAghhBD8u+ixqJu+Zs2axaBBg+jXrx81a9Zk0aJFlC5dmmXLlhn+QxaBxa9hyLvPQ5pKZeKaFD+506OwdHdNdKfH3GyL/+o0K3nf38b+TlMZ4PdE3jn+ey57e3vs7e0fKZ+dnU1MTAyRkZHafUqlkrZt23Lo0KEi18eQLP6nPi3twWNVqwb6mbgmQgghiiItLQ1XV8M+SRTAzs4Ob29vqhno90SZMmXw89M914QJE5g4ceIjZW/fvk1ubi5eXl46+728vDh79qxB6mMoFt9h8PHxIS4uDmdnZ73/8lWpVPj5+REXF1fs9wSXbOvJtsbPLNnyc6YPjUZDWloaPj4+RqgdODg4cPnyZbKzsw1yPo1G88jvm/xGF0oai+8wKJVKKlasWKRzuLi4mOwhIpJtPdnW+JklW37OnpQxRhYe5uDggIODg1Ez8lOuXDlsbGxISEjQ2Z+QkPDED1ksLrLoUQghhDAROzs7GjRowK5du7T71Go1u3btIiwszIQ1e5TFjzAIIYQQ5mzkyJH06dOHhg0b0rhxY2bPnk1GRgb9+vUzddV0SIehAPb29kyYMMEkc0+SbT3Z1viZJVt+zsS/XnvtNW7dusX48eOJj4+nbt26bNu27ZGFkKam0Jjq2jshhBBClBiyhkEIIYQQhZIOgxBCCCEKJR0GIYQQQhRKOgxCCCGEKJR0GApgiseN7tu3j06dOuHj44NCoWDz5s1Gz8wTFRVFo0aNcHZ2xtPTky5dunDu3LliyV64cCG1a9fW3tglLCyMX375pViyH/bJJ5+gUCgYPny40bMmTpyIQqHQ2YKDg42em+f69eu88cYbeHh44OjoSGhoKEePHjV6bqVKlR753AqFgoiICKPm5ubmMm7cOAIDA3F0dKRKlSp8/PHHxfbMlbS0NIYPH05AQACOjo40bdqU6Ohog+cU9h2i0WgYP348FSpUwNHRkbZt23LhwoViyd64cSPt2rXDw8MDhUJBbGysQXJF8ZAOw2OY6nGjGRkZ1KlTh/nz5xs1Jz979+4lIiKCP/74g507d5KTk0O7du3IyMgwenbFihX55JNPiImJ4ejRozz33HN07tyZU6dOGT07T3R0NIsXL6Z27drFlhkSEsLNmze124EDB4ol986dOzRr1oxSpUrxyy+/cPr0aT777DPKli1r9Ozo6Gidz7xz504AunfvbtTc6dOns3DhQr744gvOnDnD9OnTmTFjBvPmzTNqbp6BAweyc+dOVq9ezcmTJ2nXrh1t27bl+vXrBs0p7DtkxowZzJ07l0WLFnH48GGcnJxo3749mZmZRs/OyMigefPmTJ8+vchZwgQ0Il+NGzfWREREaF/n5uZqfHx8NFFRUcVWB0CzadOmYsv7r8TERA2g2bt3r0nyy5Ytq/nyyy+LJSstLU1TrVo1zc6dOzUtW7bUDBs2zOiZEyZM0NSpU8foOfkZPXq0pnnz5ibJ/q9hw4ZpqlSpolGr1UbN6dixo6Z///46+7p27aoJDw83aq5Go9HcvXtXY2Njo9m6davO/vr162s++ugjo+X+9ztErVZrvL29NTNnztTuS0lJ0djb22u+/vpro2Y/7PLlyxpAc/z4cYNmCuOSEYZ85D1utG3bttp95vq4UWNKTU0FwN3dvVhzc3NzWb9+PRkZGcV2a9SIiAg6duyo829eHC5cuICPjw+VK1cmPDycq1evFkvuli1baNiwId27d8fT05N69eqxdOnSYsl+WHZ2NmvWrKF///5Gfyx606ZN2bVrF+fPnwfgxIkTHDhwgA4dOhg1F+D+/fvk5uY+8qwCR0fHYhtVArh8+TLx8fE6P+eurq40adLEqr7bxNOROz3moyQ9btRY1Go1w4cPp1mzZtSqVatYMk+ePElYWBiZmZmUKVOGTZs2UbNmTaPnrl+/nmPHjhllPrkgTZo0YcWKFQQFBXHz5k0mTZrEs88+y19//YWzs7NRs//++28WLlzIyJEj+d///kd0dDTvvfcednZ29OnTx6jZD9u8eTMpKSn07dvX6FljxoxBpVIRHByMjY0Nubm5TJ06lfDwcKNnOzs7ExYWxscff0yNGjXw8vLi66+/5tChQ1StWtXo+Xni4+MB8v1uyzsmxONIh0HkKyIigr/++qtY//oJCgoiNjaW1NRUvvvuO/r06cPevXuN2mmIi4tj2LBh7Ny5s9ifVPfwX7a1a9emSZMmBAQEsGHDBgYMGGDUbLVaTcOGDZk2bRoA9erV46+//mLRokXF2mH46quv6NChg9EeW/ywDRs2sHbtWtatW0dISAixsbEMHz4cHx+fYvnMq1evpn///vj6+mJjY0P9+vXp1asXMTExRs8WwhBkSiIfJelxo8YwdOhQtm7dym+//VbkR4Prw87OjqpVq9KgQQOioqKoU6cOc+bMMWpmTEwMiYmJ1K9fH1tbW2xtbdm7dy9z587F1taW3Nxco+Y/zM3NjerVq3Px4kWjZ1WoUOGRjliNGjWKbUoE4J9//uHXX39l4MCBxZI3atQoxowZQ8+ePQkNDaV3796MGDGCqKioYsmvUqUKe/fuJT09nbi4OI4cOUJOTg6VK1culnxA+/1lrd9tomikw5CPkvS4UUPSaDQMHTqUTZs2sXv3bgIDA01aH7VaTVZWllEz2rRpw8mTJ4mNjdVuDRs2JDw8nNjYWGxsbIya/7D09HQuXbpEhQoVjJ7VrFmzRy6ZPX/+PAEBAUbPzrN8+XI8PT3p2LFjseTdvXsXpVL3K8/Gxga1Wl0s+XmcnJyoUKECd+7cYfv27XTu3LnYsgMDA/H29tb5blOpVBw+fNiiv9uEYciUxGOY6nGj6enpOn9hXr58mdjYWNzd3fH39zdqdkREBOvWreOHH37A2dlZO6fp6uqKo6OjUbMjIyPp0KED/v7+pKWlsW7dOvbs2cP27duNmuvs7PzIGg0nJyc8PDyMvnbjgw8+oFOnTgQEBHDjxg0mTJiAjY0NvXr1MmouwIgRI2jatCnTpk2jR48eHDlyhCVLlrBkyRKjZ8ODzuDy5cvp06cPtrbF8zXUqVMnpk6dir+/PyEhIRw/fpxZs2bRv3//Ysnfvn07Go2GoKAgLl68yKhRowgODjb4d0ph3yHDhw9nypQpVKtWjcDAQMaNG4ePjw9dunQxenZycjJXr17lxo0bANpOq7e3t4xwlASmvkzDnM2bN0/j7++vsbOz0zRu3Fjzxx9/GD3zt99+0wCPbH369DF6dn65gGb58uVGz+7fv78mICBAY2dnpylfvrymTZs2mh07dhg9Nz/FdVnla6+9pqlQoYLGzs5O4+vrq3nttdc0Fy9eNHpunh9//FFTq1Ytjb29vSY4OFizZMmSYsvevn27BtCcO3eu2DJVKpVm2LBhGn9/f42Dg4OmcuXKmo8++kiTlZVVLPnffPONpnLlyho7OzuNt7e3JiIiQpOSkmLwnMK+Q9RqtWbcuHEaLy8vjb29vaZNmzYG+3coLHv58uX5Hp8wYYJB8oVxyeOthRBCCFEoWcMghBBCiEJJh0EIIYQQhZIOgxBCCCEKJR0GIYQQQhRKOgxCCCGEKJR0GIQQQghRKOkwCCGEEKJQ0mEQQgghRKGkwyBEMejbt6/OrXdbtWrF8OHDi70ee/bsQaFQkJKS8tgyCoWCzZs3P/E5J06cSN26dYtUrytXrqBQKIiNjS3SeYQQxiMdBmG1+vbti0KhQKFQaJ+UOXnyZO7fv2/07I0bN/Lxxx8/Udkn+SUvhBDGJg+fElbthRdeYPny5WRlZfHzzz8TERFBqVKliIyMfKRsdnY2dnZ2Bsl1d3c3yHmEEKK4yAiDsGr29vZ4e3sTEBDAO++8Q9u2bdmyZQvw7zTC1KlT8fHxISgoCIC4uDh69OiBm5sb7u7udO7cmStXrmjPmZuby8iRI3Fzc8PDw4MPP/yQ/z6y5b9TEllZWYwePRo/Pz/s7e2pWrUqX331FVeuXKF169YAlC1bFoVCQd++fYEHT3yMiooiMDAQR0dH6tSpw3fffaeT8/PPP1O9enUcHR1p3bq1Tj2f1OjRo6levTqlS5emcuXKjBs3jpycnEfKLV68GD8/P0qXLk2PHj1ITU3VOf7ll19So0YNHBwcCA4OZsGCBXrXRQhhOtJhEOIhjo6OZGdna1/v2rWLc+fOsXPnTrZu3UpOTg7t27fH2dmZ/fv38/vvv1OmTBleeOEF7fs+++wzVqxYwbJlyzhw4ADJycls2rSpwNw333yTr7/+mrlz53LmzBkWL15MmTJl8PPz4/vvvwcePAr45s2bzJkzB4CoqChWrVrFokWLOHXqFCNGjOCNN95g7969wIOOTdeuXenUqROxsbEMHDiQMWPG6N0mzs7OrFixgtOnTzNnzhyWLl3K559/rlPm4sWLbNiwgR9//JFt27Zx/PhxhgwZoj2+du1axo8fz9SpUzlz5gzTpk1j3LhxrFy5Uu/6CCFMxMRPyxTCZPr06aPp3LmzRqN58MjfnTt3auzt7TUffPCB9riXl5fO449Xr16tCQoK0qjVau2+rKwsjaOjo2b79u0ajUajqVChgmbGjBna4zk5OZqKFStqszQa3Udonzt3TgNodu7cmW898x4ZfOfOHe2+zMxMTenSpTUHDx7UKTtgwABNr169NBqNRhMZGampWbOmzvHRo0c/cq7/AjSbNm167PGZM2dqGjRooH09YcIEjY2NjebatWvafb/88otGqVRqbt68qdFoNJoqVapo1q1bp3Oejz/+WBMWFqbRaDSay5cvawDN8ePHH5srhDAtWcMgrNrWrVspU6YMOTk5qNVqXn/9dSZOnKg9HhoaqrNu4cSJE1y8eBFnZ2ed82RmZnLp0iVSU1O5efMmTZo00R6ztbWlYcOGj0xL5ImNjcXGxoaWLVs+cb0vXrzI3bt3ef7553X2Z2dnU69ePQDOnDmjUw+AsLCwJ87I88033zB37lwuXbpEeno69+/fx8XFRaeMv78/vr6+OjlqtZpz587h7OzMpUuXGDBgAIMGDdKWuX//Pq6urnrXRwhhGtJhEFatdevWLFy4EDs7O3x8fLC11f2/hJOTk87r9PR0GjRowNq1ax85V/ny5Z+qDo6Ojnq/Jz09HYCffvpJ5xc1PFiXYSiHDh0iPDycSZMm0b59e1xdXVm/fj2fffaZ3nVdunTpIx0YGxsbg9VVCGFc0mEQVs3JyYmqVas+cfn69evzzTff4Onp+chf2XkqVKjA4cOHadGiBfDgL+mYmBjq16+fb/nQ0FDUajV79+6lbdu2jxzPG+HIzc3V7qtZsyb29vZcvXr1sSMTNWrU0C7gzPPHH38U/iEfcvDgQQICAvjoo4+0+/75559Hyl29epUbN27g4+OjzVEqlQQFBeHl5YWPjw9///034eHheuULIcyHLHoUQg/h4eGUK1eOzp07s3//fi5fvsyePXt47733uHbtGgDDhg3jk08+YfPmzZw9e5YhQ4YUeA+FSpUq0adPH/r378/mzZu159ywYQMAAQEBKBQKtm7dyq1bt0hPT8fZ2ZkPPviAESNGsHLlSi5dusSxY8eYN2+ediHh22+/zYULFxg1ahTnzp1j3bp1rFixQq/PW61aNa5evcr69eu5dOkSc+fOzXcBp4ODA3369OHEiRPs37+f9957jx49euDt7Q3ApEmTiIqKYu7cuZw/f56TJ0+yfPlyZs2apVd9hBCmIx0GIfRQunRp9u3bh7+/P127dqVGjRoMGDCAzMxM7YjD+++/T+/evenTpw9hYWE4OzvzyiuvFHjehQsX8uqrrzJkyBCCg4MZNGgQGRkZAPj6+jJp0iTGjBmDl5cXQ4cOBeDjjz9m3LhxREVFUaNGDV544QV++uknAgMDgQfrCr7//ns2b95MnTp1WLRoEdOmTdPr87788suMGDGCoUOHUrduXQ4ePMi4ceMeKVe1alW6du3Kiy++SLt27ahdu7bOZZMDBw7kyy+/ZPny5YSGhtKyZUtWrFihrasQwvwpNI9biSWEEEII8f9khEEIIYQQhZIOgxBCCCEKJR0GIYQQQhRKOgxCCCGEKJR0GIQQQghRKOkwCCGEEKJQ0mEQQgghRKGkwyCEEEKIQkmHQQghhBCFkg6DEEIIIQolHQYhhBBCFOr/AG4+8A/+spQMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, predicted_list)\n",
        "precision = precision_score(y_test, predicted_list, average='micro')\n",
        "recall = recall_score(y_test, predicted_list, average='micro')\n",
        "f1 = f1_score(y_test, predicted_list, average='micro')\n",
        "\n",
        "accuracy_m = accuracy_score(y_test, predicted_list)\n",
        "precision_m = precision_score(y_test, predicted_list, average='macro')\n",
        "recall_m = recall_score(y_test, predicted_list, average='macro')\n",
        "f1_m = f1_score(y_test, predicted_list, average='macro')\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test,\n",
        "                                        predicted_list,\n",
        "                                        cmap=plt.cm.Blues)\n",
        "\n",
        "print(f'accuracy micro: {accuracy}')\n",
        "print(f'precision micro: {precision}')\n",
        "print(f'recall micro: {recall}')\n",
        "print(f'f1 micro: {f1}\\n\\n')\n",
        "\n",
        "\n",
        "print(f'accuracy macro: {accuracy_m}')\n",
        "print(f'precision macro: {precision_m}')\n",
        "print(f'recall macro: {recall_m}')\n",
        "print(f'f1 macro: {f1_m}')\n",
        "\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 5 epochs model"
      ],
      "metadata": {
        "id": "rgZdX7eyMSP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I can load the model using PyTorch\n",
        "model = SlowFusionNetVLAD(dropout=0.4)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # check for GPU availability\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yDmz1XFXMUV3",
        "outputId": "6b241b6a-b717-49e7-9e59-61ab6d037e9c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SlowFusionNetVLAD(\n",
              "  (encoder_2d): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "        )\n",
              "        (1): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
              "        )\n",
              "        (1): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
              "        )\n",
              "        (2): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
              "        )\n",
              "        (3): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
              "        )\n",
              "        (1): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
              "        )\n",
              "        (2): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
              "        )\n",
              "        (3): FusedMBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
              "        )\n",
              "        (5): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "        )\n",
              "        (5): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
              "        )\n",
              "        (6): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
              "        )\n",
              "        (7): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
              "        )\n",
              "        (8): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
              "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
              "        )\n",
              "        (5): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
              "        )\n",
              "        (6): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
              "        )\n",
              "        (7): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
              "        )\n",
              "        (8): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
              "        )\n",
              "        (9): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
              "        )\n",
              "        (10): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
              "        )\n",
              "        (11): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
              "        )\n",
              "        (12): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
              "        )\n",
              "        (13): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
              "        )\n",
              "        (14): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
              "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (7): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (encoder_3d): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv3d(192, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (pool_layer): NetVLAD(\n",
              "    (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=327680, out_features=12, bias=True)\n",
              "  (drop): Dropout(p=0.4, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, accuracy,predicted_list=test(model, test_loader, loss_funct, batch_idx=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352,
          "referenced_widgets": [
            "e800c228644445758f6b84bdb307728a",
            "8db47d05707f457f9d247badb22d6843",
            "7feb63d0325b4789a22f6d639b56517f",
            "598fed1a1de044cc9a23e0687d1e00b7",
            "e26e27a45e5b4d719be6189a4c5a63c6",
            "8f206eebbf47492f99edd4f5f2b23c4d",
            "da797cdf8d834867a44bc2e4a93c8a02",
            "23e23a6396694d1c8de2384c14c91b95"
          ]
        },
        "id": "vyp34rDcMq9o",
        "outputId": "c4b3676f-d1b9-4d5b-cd5b-2f4a3c4bb72e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240830_121837-qy264lrt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cecca/AdvancedTechniques/runs/qy264lrt' target=\"_blank\">gallant-disco-34</a></strong> to <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/qy264lrt' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/qy264lrt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.18722594523041283, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e800c228644445758f6b84bdb307728a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>validation/accuracy</td><td>▁</td></tr><tr><td>validation/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>validation/accuracy</td><td>0.364</td></tr><tr><td>validation/loss</td><td>0.23625</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gallant-disco-34</strong> at: <a href='https://wandb.ai/cecca/AdvancedTechniques/runs/qy264lrt' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques/runs/qy264lrt</a><br/> View project at: <a href='https://wandb.ai/cecca/AdvancedTechniques' target=\"_blank\">https://wandb.ai/cecca/AdvancedTechniques</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240830_121837-qy264lrt/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_list=[i.cpu().item() for i in predicted_list]"
      ],
      "metadata": {
        "id": "pmQ_HlPqPCo6"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, predicted_list)\n",
        "precision = precision_score(y_test, predicted_list, average='micro')\n",
        "recall = recall_score(y_test, predicted_list, average='micro')\n",
        "f1 = f1_score(y_test, predicted_list, average='micro')\n",
        "\n",
        "accuracy_m = accuracy_score(y_test, predicted_list)\n",
        "precision_m = precision_score(y_test, predicted_list, average='macro')\n",
        "recall_m = recall_score(y_test, predicted_list, average='macro')\n",
        "f1_m = f1_score(y_test, predicted_list, average='macro')\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test,\n",
        "                                        predicted_list,\n",
        "                                        cmap=plt.cm.Blues)\n",
        "\n",
        "print(f'accuracy micro: {accuracy}')\n",
        "print(f'precision micro: {precision}')\n",
        "print(f'recall micro: {recall}')\n",
        "print(f'f1 micro: {f1}\\n\\n')\n",
        "\n",
        "\n",
        "print(f'accuracy macro: {accuracy_m}')\n",
        "print(f'precision macro: {precision_m}')\n",
        "print(f'recall macro: {recall_m}')\n",
        "print(f'f1 macro: {f1_m}')\n",
        "\n",
        "plt.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "tsxaaQg2MrvM",
        "outputId": "84c04c7f-f1ec-420b-8d4f-90abd08ea6d3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy micro: 0.3640020110608346\n",
            "precision micro: 0.3640020110608346\n",
            "recall micro: 0.3640020110608346\n",
            "f1 micro: 0.36400201106083463\n",
            "\n",
            "\n",
            "accuracy macro: 0.3640020110608346\n",
            "precision macro: 0.030333500921736214\n",
            "recall macro: 0.08333333333333333\n",
            "f1 macro: 0.044477208502273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DyTDr47v2h2G",
        "06CZtKdaMG4X",
        "rgZdX7eyMSP0"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54f2ee6195c74b9fafdb67e845983b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eda307355254b798a68be363df35827",
              "IPY_MODEL_a3f7a0cc432b46228c65b9a0c793cc20"
            ],
            "layout": "IPY_MODEL_7f15538309364ed89e932679dfd17d4f"
          }
        },
        "5eda307355254b798a68be363df35827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5d93f6f42548338d1acf1d579a8633",
            "placeholder": "​",
            "style": "IPY_MODEL_a4bc278b57ee4bfdb43dca4e6536126e",
            "value": "542.198 MB of 542.198 MB uploaded\r"
          }
        },
        "a3f7a0cc432b46228c65b9a0c793cc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05395abfd33e44a4877d2572237f3f86",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_995b17a93aa042a9848ef375d1118147",
            "value": 1
          }
        },
        "7f15538309364ed89e932679dfd17d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5d93f6f42548338d1acf1d579a8633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4bc278b57ee4bfdb43dca4e6536126e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05395abfd33e44a4877d2572237f3f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995b17a93aa042a9848ef375d1118147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c75fc2d1f064f2b86a071b6d4228231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c325a789424f4662987614a8cac594e0",
              "IPY_MODEL_30b4df2b9cc848c0b9745aeedcadcf01"
            ],
            "layout": "IPY_MODEL_b2af51ee4a9a4f13a861912f7e17a8cb"
          }
        },
        "c325a789424f4662987614a8cac594e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669061f8a5434978bf361c37ba582170",
            "placeholder": "​",
            "style": "IPY_MODEL_94ac1cd48bc34af2ae20d53e52b5e166",
            "value": "542.198 MB of 542.198 MB uploaded\r"
          }
        },
        "30b4df2b9cc848c0b9745aeedcadcf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dd90a2f793442dc9062b0466f87150e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12a2c163cc8d449aaa7375cee81c06a4",
            "value": 1
          }
        },
        "b2af51ee4a9a4f13a861912f7e17a8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "669061f8a5434978bf361c37ba582170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ac1cd48bc34af2ae20d53e52b5e166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dd90a2f793442dc9062b0466f87150e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a2c163cc8d449aaa7375cee81c06a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "594cbd9216664d31a708dfeefb371fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7d3b81665c54ab597c14119138cc9c1",
              "IPY_MODEL_934be64636d145d99f318d7aa5a58b3a"
            ],
            "layout": "IPY_MODEL_29d602b43f494457bc0158603782c5ec"
          }
        },
        "d7d3b81665c54ab597c14119138cc9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852aa0110c87474ab6be1b4c79b7817a",
            "placeholder": "​",
            "style": "IPY_MODEL_e74956629dc4431d92e2ff792bb09cf1",
            "value": "406.878 MB of 406.878 MB uploaded\r"
          }
        },
        "934be64636d145d99f318d7aa5a58b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e630f1f95941e78e7a22ecd112e270",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aeba7209f42047fdb06d8c9807ea8144",
            "value": 1
          }
        },
        "29d602b43f494457bc0158603782c5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852aa0110c87474ab6be1b4c79b7817a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e74956629dc4431d92e2ff792bb09cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e630f1f95941e78e7a22ecd112e270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeba7209f42047fdb06d8c9807ea8144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc3766f0d55e4cecb2e8100ba40c7014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9978de6d376845c4b22e517fafc301e0",
              "IPY_MODEL_aebcd3adf72e4ace918e81de09654436"
            ],
            "layout": "IPY_MODEL_ebdb507c60da4c348157e2cdc9c8988f"
          }
        },
        "9978de6d376845c4b22e517fafc301e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90b55f3fee524482852cff5652c7248b",
            "placeholder": "​",
            "style": "IPY_MODEL_8a45c9f067574d5ea09c439d68ce20c7",
            "value": "270.835 MB of 270.835 MB uploaded\r"
          }
        },
        "aebcd3adf72e4ace918e81de09654436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078c41090e1b4804a9227560b2ffabbf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c8207f1c91b4b0ab975a6b4d9dcc9d4",
            "value": 1
          }
        },
        "ebdb507c60da4c348157e2cdc9c8988f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b55f3fee524482852cff5652c7248b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a45c9f067574d5ea09c439d68ce20c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "078c41090e1b4804a9227560b2ffabbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8207f1c91b4b0ab975a6b4d9dcc9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50efaff24d9d47479b30bf029c23a951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5270a6a786b4f90b62da73b035b46eb",
              "IPY_MODEL_af5db11571364e348392a91167fbbb1f"
            ],
            "layout": "IPY_MODEL_477545b20ce948f5bc5c9699122ece16"
          }
        },
        "d5270a6a786b4f90b62da73b035b46eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0653731a0a934005afb4de6ab95a9a04",
            "placeholder": "​",
            "style": "IPY_MODEL_7a4b82e138364f998a2b3544d2491c44",
            "value": "812.116 MB of 812.116 MB uploaded\r"
          }
        },
        "af5db11571364e348392a91167fbbb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f33ee5593143bfbeaff582ad7486a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c09211f1b84f41f1a27bed300c3d1398",
            "value": 1
          }
        },
        "477545b20ce948f5bc5c9699122ece16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0653731a0a934005afb4de6ab95a9a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4b82e138364f998a2b3544d2491c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9f33ee5593143bfbeaff582ad7486a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09211f1b84f41f1a27bed300c3d1398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34b369c4055d4ab0b092d350dbfb4a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48c8a970639945388dcbcb3ccc529f7e",
              "IPY_MODEL_dcdb164b0b834d998b2797df0e3ef2a1"
            ],
            "layout": "IPY_MODEL_3b85d3618b3c44b79e947bb889825a91"
          }
        },
        "48c8a970639945388dcbcb3ccc529f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_effa492022514065a7fa1b23afd1f74c",
            "placeholder": "​",
            "style": "IPY_MODEL_27f1e5cb58c14f7eb24a08aff76a768a",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "dcdb164b0b834d998b2797df0e3ef2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a3afc78501447c95fc2f94a3b622b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bc4d1efaed74f93aea9f57eddb685db",
            "value": 1
          }
        },
        "3b85d3618b3c44b79e947bb889825a91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effa492022514065a7fa1b23afd1f74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f1e5cb58c14f7eb24a08aff76a768a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05a3afc78501447c95fc2f94a3b622b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc4d1efaed74f93aea9f57eddb685db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8c7cf1c30384b299a1a13ea52fa541e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c5e7ee087a43f0a3df5b150d78d290",
              "IPY_MODEL_f91857373c7d4cfaaafb4bdab3599f17"
            ],
            "layout": "IPY_MODEL_2109ccea576c4e2a96856946d18e3445"
          }
        },
        "19c5e7ee087a43f0a3df5b150d78d290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf35cfb11a2a4de0a3254e9296e112f8",
            "placeholder": "​",
            "style": "IPY_MODEL_78eef56438994dd5856af18b1197747b",
            "value": "140.084 MB of 140.084 MB uploaded\r"
          }
        },
        "f91857373c7d4cfaaafb4bdab3599f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67367e6ba96348f885b7cdf4afb5fb79",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85e5b6d09abd45daab46dcf18bff6866",
            "value": 1
          }
        },
        "2109ccea576c4e2a96856946d18e3445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf35cfb11a2a4de0a3254e9296e112f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78eef56438994dd5856af18b1197747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67367e6ba96348f885b7cdf4afb5fb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e5b6d09abd45daab46dcf18bff6866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a067118887741b2b54840d19bf3c963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_267461683428407599555e4f27299fbe",
              "IPY_MODEL_671295525e184bd1b021e3d790003112"
            ],
            "layout": "IPY_MODEL_4b4483cb0f6747fd8c55f63562cbe8ce"
          }
        },
        "267461683428407599555e4f27299fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b309707382eb464ba41505eeda65e6f3",
            "placeholder": "​",
            "style": "IPY_MODEL_2eba66f458234b71ac8cfb21df99587d",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "671295525e184bd1b021e3d790003112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9820c9da36024cc09e16c35705f424d0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5b2bfa2d3974b9caff995f7cbdf4dce",
            "value": 1
          }
        },
        "4b4483cb0f6747fd8c55f63562cbe8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b309707382eb464ba41505eeda65e6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eba66f458234b71ac8cfb21df99587d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9820c9da36024cc09e16c35705f424d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b2bfa2d3974b9caff995f7cbdf4dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e800c228644445758f6b84bdb307728a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8db47d05707f457f9d247badb22d6843",
              "IPY_MODEL_7feb63d0325b4789a22f6d639b56517f"
            ],
            "layout": "IPY_MODEL_598fed1a1de044cc9a23e0687d1e00b7"
          }
        },
        "8db47d05707f457f9d247badb22d6843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26e27a45e5b4d719be6189a4c5a63c6",
            "placeholder": "​",
            "style": "IPY_MODEL_8f206eebbf47492f99edd4f5f2b23c4d",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "7feb63d0325b4789a22f6d639b56517f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da797cdf8d834867a44bc2e4a93c8a02",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23e23a6396694d1c8de2384c14c91b95",
            "value": 1
          }
        },
        "598fed1a1de044cc9a23e0687d1e00b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26e27a45e5b4d719be6189a4c5a63c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f206eebbf47492f99edd4f5f2b23c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da797cdf8d834867a44bc2e4a93c8a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23e23a6396694d1c8de2384c14c91b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}